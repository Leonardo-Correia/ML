{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN aplicado à Buckley–Leverett\n",
    "\n",
    "Leonardo Correia\n",
    "\n",
    "Nicholas Smaal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardocorreia/opt/anaconda3/envs/manim_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/leonardocorreia/Documents/ML/Disciplinas/PCS5042_IA leis fisica_MOR/Pinn-2.ipynb Célula: 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leonardocorreia/Documents/ML/Disciplinas/PCS5042_IA%20leis%20fisica_MOR/Pinn-2.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net \u001b[39m=\u001b[39m Net()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardocorreia/Documents/ML/Disciplinas/PCS5042_IA%20leis%20fisica_MOR/Pinn-2.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardocorreia/Documents/ML/Disciplinas/PCS5042_IA%20leis%20fisica_MOR/Pinn-2.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mse_cost_function \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss() \u001b[39m# Mean squared error\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Net' is not defined"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento da PDE\n",
    "\n",
    "$$ velocidade = u(x,t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,t, net):\n",
    "    u = net(x,t) #Criando uma variável dependente da posição e do tempo\n",
    "\n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    u_xx= torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]\n",
    "    e= 2.5*10**(-3)\n",
    "    \n",
    "    M = 1.0\n",
    "    fw = (u**2)/((u**2)+((1-u)**2)/M)\n",
    "    fw_u = torch.autograd.grad(fw.sum(), u, create_graph=True)[0]\n",
    "    pde = u_t + fw_u*u_x-e*u_xx\n",
    "    return pde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolvimento das condições de contorno\n",
    "\n",
    "x_bc1 = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "t_bc1 = np.zeros((500,1))\n",
    "u_bc1 = np.zeros((500,1))\n",
    "\n",
    "x_bc2 = np.zeros((500,1))\n",
    "t_bc2 = np.random.uniform(low=0.001, high=1.0, size=(500,1))\n",
    "u_bc2 = np.ones((500,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Traning Loss: tensor(0.5064)\n",
      "1 Traning Loss: tensor(0.5054)\n",
      "2 Traning Loss: tensor(0.5045)\n",
      "3 Traning Loss: tensor(0.5037)\n",
      "4 Traning Loss: tensor(0.5030)\n",
      "5 Traning Loss: tensor(0.5023)\n",
      "6 Traning Loss: tensor(0.5017)\n",
      "7 Traning Loss: tensor(0.5013)\n",
      "8 Traning Loss: tensor(0.5009)\n",
      "9 Traning Loss: tensor(0.5006)\n",
      "10 Traning Loss: tensor(0.5003)\n",
      "11 Traning Loss: tensor(0.5002)\n",
      "12 Traning Loss: tensor(0.5001)\n",
      "13 Traning Loss: tensor(0.5000)\n",
      "14 Traning Loss: tensor(0.5000)\n",
      "15 Traning Loss: tensor(0.5000)\n",
      "16 Traning Loss: tensor(0.5000)\n",
      "17 Traning Loss: tensor(0.5001)\n",
      "18 Traning Loss: tensor(0.5001)\n",
      "19 Traning Loss: tensor(0.5002)\n",
      "20 Traning Loss: tensor(0.5002)\n",
      "21 Traning Loss: tensor(0.5003)\n",
      "22 Traning Loss: tensor(0.5003)\n",
      "23 Traning Loss: tensor(0.5003)\n",
      "24 Traning Loss: tensor(0.5003)\n",
      "25 Traning Loss: tensor(0.5003)\n",
      "26 Traning Loss: tensor(0.5003)\n",
      "27 Traning Loss: tensor(0.5002)\n",
      "28 Traning Loss: tensor(0.5002)\n",
      "29 Traning Loss: tensor(0.5001)\n",
      "30 Traning Loss: tensor(0.5001)\n",
      "31 Traning Loss: tensor(0.5001)\n",
      "32 Traning Loss: tensor(0.5000)\n",
      "33 Traning Loss: tensor(0.5000)\n",
      "34 Traning Loss: tensor(0.5000)\n",
      "35 Traning Loss: tensor(0.5000)\n",
      "36 Traning Loss: tensor(0.5000)\n",
      "37 Traning Loss: tensor(0.5000)\n",
      "38 Traning Loss: tensor(0.5000)\n",
      "39 Traning Loss: tensor(0.5000)\n",
      "40 Traning Loss: tensor(0.5000)\n",
      "41 Traning Loss: tensor(0.5000)\n",
      "42 Traning Loss: tensor(0.5000)\n",
      "43 Traning Loss: tensor(0.5000)\n",
      "44 Traning Loss: tensor(0.5000)\n",
      "45 Traning Loss: tensor(0.5000)\n",
      "46 Traning Loss: tensor(0.5000)\n",
      "47 Traning Loss: tensor(0.5000)\n",
      "48 Traning Loss: tensor(0.5000)\n",
      "49 Traning Loss: tensor(0.5000)\n",
      "50 Traning Loss: tensor(0.5000)\n",
      "51 Traning Loss: tensor(0.5000)\n",
      "52 Traning Loss: tensor(0.5000)\n",
      "53 Traning Loss: tensor(0.5000)\n",
      "54 Traning Loss: tensor(0.5000)\n",
      "55 Traning Loss: tensor(0.5000)\n",
      "56 Traning Loss: tensor(0.4999)\n",
      "57 Traning Loss: tensor(0.4999)\n",
      "58 Traning Loss: tensor(0.4999)\n",
      "59 Traning Loss: tensor(0.4999)\n",
      "60 Traning Loss: tensor(0.4999)\n",
      "61 Traning Loss: tensor(0.4999)\n",
      "62 Traning Loss: tensor(0.4999)\n",
      "63 Traning Loss: tensor(0.4999)\n",
      "64 Traning Loss: tensor(0.4999)\n",
      "65 Traning Loss: tensor(0.4999)\n",
      "66 Traning Loss: tensor(0.4999)\n",
      "67 Traning Loss: tensor(0.4999)\n",
      "68 Traning Loss: tensor(0.4999)\n",
      "69 Traning Loss: tensor(0.4999)\n",
      "70 Traning Loss: tensor(0.4999)\n",
      "71 Traning Loss: tensor(0.4999)\n",
      "72 Traning Loss: tensor(0.4999)\n",
      "73 Traning Loss: tensor(0.4999)\n",
      "74 Traning Loss: tensor(0.4999)\n",
      "75 Traning Loss: tensor(0.4999)\n",
      "76 Traning Loss: tensor(0.4999)\n",
      "77 Traning Loss: tensor(0.4999)\n",
      "78 Traning Loss: tensor(0.4999)\n",
      "79 Traning Loss: tensor(0.4999)\n",
      "80 Traning Loss: tensor(0.4999)\n",
      "81 Traning Loss: tensor(0.4999)\n",
      "82 Traning Loss: tensor(0.4999)\n",
      "83 Traning Loss: tensor(0.4999)\n",
      "84 Traning Loss: tensor(0.4999)\n",
      "85 Traning Loss: tensor(0.4999)\n",
      "86 Traning Loss: tensor(0.4999)\n",
      "87 Traning Loss: tensor(0.4999)\n",
      "88 Traning Loss: tensor(0.4999)\n",
      "89 Traning Loss: tensor(0.4999)\n",
      "90 Traning Loss: tensor(0.4999)\n",
      "91 Traning Loss: tensor(0.4999)\n",
      "92 Traning Loss: tensor(0.4999)\n",
      "93 Traning Loss: tensor(0.4999)\n",
      "94 Traning Loss: tensor(0.4999)\n",
      "95 Traning Loss: tensor(0.4999)\n",
      "96 Traning Loss: tensor(0.4999)\n",
      "97 Traning Loss: tensor(0.4999)\n",
      "98 Traning Loss: tensor(0.4999)\n",
      "99 Traning Loss: tensor(0.4999)\n",
      "100 Traning Loss: tensor(0.4999)\n",
      "101 Traning Loss: tensor(0.4999)\n",
      "102 Traning Loss: tensor(0.4999)\n",
      "103 Traning Loss: tensor(0.4999)\n",
      "104 Traning Loss: tensor(0.4999)\n",
      "105 Traning Loss: tensor(0.4999)\n",
      "106 Traning Loss: tensor(0.4999)\n",
      "107 Traning Loss: tensor(0.4999)\n",
      "108 Traning Loss: tensor(0.4999)\n",
      "109 Traning Loss: tensor(0.4999)\n",
      "110 Traning Loss: tensor(0.4999)\n",
      "111 Traning Loss: tensor(0.4999)\n",
      "112 Traning Loss: tensor(0.4999)\n",
      "113 Traning Loss: tensor(0.4999)\n",
      "114 Traning Loss: tensor(0.4999)\n",
      "115 Traning Loss: tensor(0.4999)\n",
      "116 Traning Loss: tensor(0.4999)\n",
      "117 Traning Loss: tensor(0.4999)\n",
      "118 Traning Loss: tensor(0.4999)\n",
      "119 Traning Loss: tensor(0.4999)\n",
      "120 Traning Loss: tensor(0.4999)\n",
      "121 Traning Loss: tensor(0.4999)\n",
      "122 Traning Loss: tensor(0.4999)\n",
      "123 Traning Loss: tensor(0.4999)\n",
      "124 Traning Loss: tensor(0.4999)\n",
      "125 Traning Loss: tensor(0.4999)\n",
      "126 Traning Loss: tensor(0.4999)\n",
      "127 Traning Loss: tensor(0.4999)\n",
      "128 Traning Loss: tensor(0.4999)\n",
      "129 Traning Loss: tensor(0.4998)\n",
      "130 Traning Loss: tensor(0.4998)\n",
      "131 Traning Loss: tensor(0.4998)\n",
      "132 Traning Loss: tensor(0.4998)\n",
      "133 Traning Loss: tensor(0.4998)\n",
      "134 Traning Loss: tensor(0.4998)\n",
      "135 Traning Loss: tensor(0.4998)\n",
      "136 Traning Loss: tensor(0.4998)\n",
      "137 Traning Loss: tensor(0.4998)\n",
      "138 Traning Loss: tensor(0.4998)\n",
      "139 Traning Loss: tensor(0.4998)\n",
      "140 Traning Loss: tensor(0.4998)\n",
      "141 Traning Loss: tensor(0.4998)\n",
      "142 Traning Loss: tensor(0.4998)\n",
      "143 Traning Loss: tensor(0.4998)\n",
      "144 Traning Loss: tensor(0.4998)\n",
      "145 Traning Loss: tensor(0.4998)\n",
      "146 Traning Loss: tensor(0.4998)\n",
      "147 Traning Loss: tensor(0.4998)\n",
      "148 Traning Loss: tensor(0.4998)\n",
      "149 Traning Loss: tensor(0.4998)\n",
      "150 Traning Loss: tensor(0.4998)\n",
      "151 Traning Loss: tensor(0.4998)\n",
      "152 Traning Loss: tensor(0.4998)\n",
      "153 Traning Loss: tensor(0.4998)\n",
      "154 Traning Loss: tensor(0.4998)\n",
      "155 Traning Loss: tensor(0.4998)\n",
      "156 Traning Loss: tensor(0.4998)\n",
      "157 Traning Loss: tensor(0.4998)\n",
      "158 Traning Loss: tensor(0.4998)\n",
      "159 Traning Loss: tensor(0.4998)\n",
      "160 Traning Loss: tensor(0.4998)\n",
      "161 Traning Loss: tensor(0.4998)\n",
      "162 Traning Loss: tensor(0.4998)\n",
      "163 Traning Loss: tensor(0.4997)\n",
      "164 Traning Loss: tensor(0.4997)\n",
      "165 Traning Loss: tensor(0.4997)\n",
      "166 Traning Loss: tensor(0.4997)\n",
      "167 Traning Loss: tensor(0.4997)\n",
      "168 Traning Loss: tensor(0.4997)\n",
      "169 Traning Loss: tensor(0.4997)\n",
      "170 Traning Loss: tensor(0.4997)\n",
      "171 Traning Loss: tensor(0.4997)\n",
      "172 Traning Loss: tensor(0.4997)\n",
      "173 Traning Loss: tensor(0.4997)\n",
      "174 Traning Loss: tensor(0.4997)\n",
      "175 Traning Loss: tensor(0.4997)\n",
      "176 Traning Loss: tensor(0.4997)\n",
      "177 Traning Loss: tensor(0.4997)\n",
      "178 Traning Loss: tensor(0.4997)\n",
      "179 Traning Loss: tensor(0.4997)\n",
      "180 Traning Loss: tensor(0.4997)\n",
      "181 Traning Loss: tensor(0.4997)\n",
      "182 Traning Loss: tensor(0.4997)\n",
      "183 Traning Loss: tensor(0.4997)\n",
      "184 Traning Loss: tensor(0.4996)\n",
      "185 Traning Loss: tensor(0.4996)\n",
      "186 Traning Loss: tensor(0.4996)\n",
      "187 Traning Loss: tensor(0.4996)\n",
      "188 Traning Loss: tensor(0.4996)\n",
      "189 Traning Loss: tensor(0.4996)\n",
      "190 Traning Loss: tensor(0.4996)\n",
      "191 Traning Loss: tensor(0.4996)\n",
      "192 Traning Loss: tensor(0.4996)\n",
      "193 Traning Loss: tensor(0.4996)\n",
      "194 Traning Loss: tensor(0.4996)\n",
      "195 Traning Loss: tensor(0.4996)\n",
      "196 Traning Loss: tensor(0.4996)\n",
      "197 Traning Loss: tensor(0.4996)\n",
      "198 Traning Loss: tensor(0.4995)\n",
      "199 Traning Loss: tensor(0.4995)\n",
      "200 Traning Loss: tensor(0.4995)\n",
      "201 Traning Loss: tensor(0.4995)\n",
      "202 Traning Loss: tensor(0.4995)\n",
      "203 Traning Loss: tensor(0.4995)\n",
      "204 Traning Loss: tensor(0.4995)\n",
      "205 Traning Loss: tensor(0.4995)\n",
      "206 Traning Loss: tensor(0.4995)\n",
      "207 Traning Loss: tensor(0.4995)\n",
      "208 Traning Loss: tensor(0.4994)\n",
      "209 Traning Loss: tensor(0.4994)\n",
      "210 Traning Loss: tensor(0.4994)\n",
      "211 Traning Loss: tensor(0.4994)\n",
      "212 Traning Loss: tensor(0.4994)\n",
      "213 Traning Loss: tensor(0.4994)\n",
      "214 Traning Loss: tensor(0.4994)\n",
      "215 Traning Loss: tensor(0.4994)\n",
      "216 Traning Loss: tensor(0.4993)\n",
      "217 Traning Loss: tensor(0.4993)\n",
      "218 Traning Loss: tensor(0.4993)\n",
      "219 Traning Loss: tensor(0.4993)\n",
      "220 Traning Loss: tensor(0.4993)\n",
      "221 Traning Loss: tensor(0.4993)\n",
      "222 Traning Loss: tensor(0.4993)\n",
      "223 Traning Loss: tensor(0.4992)\n",
      "224 Traning Loss: tensor(0.4992)\n",
      "225 Traning Loss: tensor(0.4992)\n",
      "226 Traning Loss: tensor(0.4992)\n",
      "227 Traning Loss: tensor(0.4992)\n",
      "228 Traning Loss: tensor(0.4992)\n",
      "229 Traning Loss: tensor(0.4991)\n",
      "230 Traning Loss: tensor(0.4991)\n",
      "231 Traning Loss: tensor(0.4991)\n",
      "232 Traning Loss: tensor(0.4991)\n",
      "233 Traning Loss: tensor(0.4991)\n",
      "234 Traning Loss: tensor(0.4990)\n",
      "235 Traning Loss: tensor(0.4990)\n",
      "236 Traning Loss: tensor(0.4990)\n",
      "237 Traning Loss: tensor(0.4990)\n",
      "238 Traning Loss: tensor(0.4989)\n",
      "239 Traning Loss: tensor(0.4989)\n",
      "240 Traning Loss: tensor(0.4989)\n",
      "241 Traning Loss: tensor(0.4989)\n",
      "242 Traning Loss: tensor(0.4988)\n",
      "243 Traning Loss: tensor(0.4988)\n",
      "244 Traning Loss: tensor(0.4988)\n",
      "245 Traning Loss: tensor(0.4987)\n",
      "246 Traning Loss: tensor(0.4987)\n",
      "247 Traning Loss: tensor(0.4987)\n",
      "248 Traning Loss: tensor(0.4987)\n",
      "249 Traning Loss: tensor(0.4986)\n",
      "250 Traning Loss: tensor(0.4986)\n",
      "251 Traning Loss: tensor(0.4986)\n",
      "252 Traning Loss: tensor(0.4985)\n",
      "253 Traning Loss: tensor(0.4985)\n",
      "254 Traning Loss: tensor(0.4984)\n",
      "255 Traning Loss: tensor(0.4984)\n",
      "256 Traning Loss: tensor(0.4984)\n",
      "257 Traning Loss: tensor(0.4983)\n",
      "258 Traning Loss: tensor(0.4983)\n",
      "259 Traning Loss: tensor(0.4982)\n",
      "260 Traning Loss: tensor(0.4982)\n",
      "261 Traning Loss: tensor(0.4981)\n",
      "262 Traning Loss: tensor(0.4981)\n",
      "263 Traning Loss: tensor(0.4980)\n",
      "264 Traning Loss: tensor(0.4980)\n",
      "265 Traning Loss: tensor(0.4979)\n",
      "266 Traning Loss: tensor(0.4979)\n",
      "267 Traning Loss: tensor(0.4978)\n",
      "268 Traning Loss: tensor(0.4978)\n",
      "269 Traning Loss: tensor(0.4977)\n",
      "270 Traning Loss: tensor(0.4977)\n",
      "271 Traning Loss: tensor(0.4976)\n",
      "272 Traning Loss: tensor(0.4975)\n",
      "273 Traning Loss: tensor(0.4975)\n",
      "274 Traning Loss: tensor(0.4974)\n",
      "275 Traning Loss: tensor(0.4973)\n",
      "276 Traning Loss: tensor(0.4973)\n",
      "277 Traning Loss: tensor(0.4972)\n",
      "278 Traning Loss: tensor(0.4971)\n",
      "279 Traning Loss: tensor(0.4970)\n",
      "280 Traning Loss: tensor(0.4969)\n",
      "281 Traning Loss: tensor(0.4969)\n",
      "282 Traning Loss: tensor(0.4968)\n",
      "283 Traning Loss: tensor(0.4967)\n",
      "284 Traning Loss: tensor(0.4966)\n",
      "285 Traning Loss: tensor(0.4965)\n",
      "286 Traning Loss: tensor(0.4964)\n",
      "287 Traning Loss: tensor(0.4963)\n",
      "288 Traning Loss: tensor(0.4962)\n",
      "289 Traning Loss: tensor(0.4961)\n",
      "290 Traning Loss: tensor(0.4960)\n",
      "291 Traning Loss: tensor(0.4958)\n",
      "292 Traning Loss: tensor(0.4957)\n",
      "293 Traning Loss: tensor(0.4956)\n",
      "294 Traning Loss: tensor(0.4955)\n",
      "295 Traning Loss: tensor(0.4953)\n",
      "296 Traning Loss: tensor(0.4952)\n",
      "297 Traning Loss: tensor(0.4951)\n",
      "298 Traning Loss: tensor(0.4949)\n",
      "299 Traning Loss: tensor(0.4948)\n",
      "300 Traning Loss: tensor(0.4946)\n",
      "301 Traning Loss: tensor(0.4945)\n",
      "302 Traning Loss: tensor(0.4943)\n",
      "303 Traning Loss: tensor(0.4941)\n",
      "304 Traning Loss: tensor(0.4940)\n",
      "305 Traning Loss: tensor(0.4938)\n",
      "306 Traning Loss: tensor(0.4936)\n",
      "307 Traning Loss: tensor(0.4934)\n",
      "308 Traning Loss: tensor(0.4932)\n",
      "309 Traning Loss: tensor(0.4930)\n",
      "310 Traning Loss: tensor(0.4928)\n",
      "311 Traning Loss: tensor(0.4926)\n",
      "312 Traning Loss: tensor(0.4924)\n",
      "313 Traning Loss: tensor(0.4922)\n",
      "314 Traning Loss: tensor(0.4919)\n",
      "315 Traning Loss: tensor(0.4917)\n",
      "316 Traning Loss: tensor(0.4914)\n",
      "317 Traning Loss: tensor(0.4912)\n",
      "318 Traning Loss: tensor(0.4909)\n",
      "319 Traning Loss: tensor(0.4907)\n",
      "320 Traning Loss: tensor(0.4904)\n",
      "321 Traning Loss: tensor(0.4901)\n",
      "322 Traning Loss: tensor(0.4898)\n",
      "323 Traning Loss: tensor(0.4895)\n",
      "324 Traning Loss: tensor(0.4892)\n",
      "325 Traning Loss: tensor(0.4888)\n",
      "326 Traning Loss: tensor(0.4885)\n",
      "327 Traning Loss: tensor(0.4882)\n",
      "328 Traning Loss: tensor(0.4878)\n",
      "329 Traning Loss: tensor(0.4874)\n",
      "330 Traning Loss: tensor(0.4871)\n",
      "331 Traning Loss: tensor(0.4867)\n",
      "332 Traning Loss: tensor(0.4863)\n",
      "333 Traning Loss: tensor(0.4859)\n",
      "334 Traning Loss: tensor(0.4854)\n",
      "335 Traning Loss: tensor(0.4850)\n",
      "336 Traning Loss: tensor(0.4845)\n",
      "337 Traning Loss: tensor(0.4841)\n",
      "338 Traning Loss: tensor(0.4836)\n",
      "339 Traning Loss: tensor(0.4831)\n",
      "340 Traning Loss: tensor(0.4826)\n",
      "341 Traning Loss: tensor(0.4821)\n",
      "342 Traning Loss: tensor(0.4815)\n",
      "343 Traning Loss: tensor(0.4810)\n",
      "344 Traning Loss: tensor(0.4804)\n",
      "345 Traning Loss: tensor(0.4798)\n",
      "346 Traning Loss: tensor(0.4792)\n",
      "347 Traning Loss: tensor(0.4786)\n",
      "348 Traning Loss: tensor(0.4780)\n",
      "349 Traning Loss: tensor(0.4773)\n",
      "350 Traning Loss: tensor(0.4767)\n",
      "351 Traning Loss: tensor(0.4760)\n",
      "352 Traning Loss: tensor(0.4753)\n",
      "353 Traning Loss: tensor(0.4745)\n",
      "354 Traning Loss: tensor(0.4738)\n",
      "355 Traning Loss: tensor(0.4730)\n",
      "356 Traning Loss: tensor(0.4722)\n",
      "357 Traning Loss: tensor(0.4714)\n",
      "358 Traning Loss: tensor(0.4706)\n",
      "359 Traning Loss: tensor(0.4697)\n",
      "360 Traning Loss: tensor(0.4688)\n",
      "361 Traning Loss: tensor(0.4679)\n",
      "362 Traning Loss: tensor(0.4670)\n",
      "363 Traning Loss: tensor(0.4661)\n",
      "364 Traning Loss: tensor(0.4651)\n",
      "365 Traning Loss: tensor(0.4641)\n",
      "366 Traning Loss: tensor(0.4631)\n",
      "367 Traning Loss: tensor(0.4620)\n",
      "368 Traning Loss: tensor(0.4609)\n",
      "369 Traning Loss: tensor(0.4598)\n",
      "370 Traning Loss: tensor(0.4587)\n",
      "371 Traning Loss: tensor(0.4575)\n",
      "372 Traning Loss: tensor(0.4563)\n",
      "373 Traning Loss: tensor(0.4551)\n",
      "374 Traning Loss: tensor(0.4538)\n",
      "375 Traning Loss: tensor(0.4526)\n",
      "376 Traning Loss: tensor(0.4513)\n",
      "377 Traning Loss: tensor(0.4499)\n",
      "378 Traning Loss: tensor(0.4485)\n",
      "379 Traning Loss: tensor(0.4471)\n",
      "380 Traning Loss: tensor(0.4457)\n",
      "381 Traning Loss: tensor(0.4442)\n",
      "382 Traning Loss: tensor(0.4427)\n",
      "383 Traning Loss: tensor(0.4412)\n",
      "384 Traning Loss: tensor(0.4396)\n",
      "385 Traning Loss: tensor(0.4380)\n",
      "386 Traning Loss: tensor(0.4364)\n",
      "387 Traning Loss: tensor(0.4347)\n",
      "388 Traning Loss: tensor(0.4330)\n",
      "389 Traning Loss: tensor(0.4312)\n",
      "390 Traning Loss: tensor(0.4295)\n",
      "391 Traning Loss: tensor(0.4277)\n",
      "392 Traning Loss: tensor(0.4258)\n",
      "393 Traning Loss: tensor(0.4239)\n",
      "394 Traning Loss: tensor(0.4220)\n",
      "395 Traning Loss: tensor(0.4200)\n",
      "396 Traning Loss: tensor(0.4180)\n",
      "397 Traning Loss: tensor(0.4160)\n",
      "398 Traning Loss: tensor(0.4140)\n",
      "399 Traning Loss: tensor(0.4118)\n",
      "400 Traning Loss: tensor(0.4097)\n",
      "401 Traning Loss: tensor(0.4075)\n",
      "402 Traning Loss: tensor(0.4054)\n",
      "403 Traning Loss: tensor(0.4031)\n",
      "404 Traning Loss: tensor(0.4009)\n",
      "405 Traning Loss: tensor(0.3985)\n",
      "406 Traning Loss: tensor(0.3961)\n",
      "407 Traning Loss: tensor(0.3938)\n",
      "408 Traning Loss: tensor(0.3913)\n",
      "409 Traning Loss: tensor(0.3889)\n",
      "410 Traning Loss: tensor(0.3864)\n",
      "411 Traning Loss: tensor(0.3839)\n",
      "412 Traning Loss: tensor(0.3813)\n",
      "413 Traning Loss: tensor(0.3787)\n",
      "414 Traning Loss: tensor(0.3761)\n",
      "415 Traning Loss: tensor(0.3734)\n",
      "416 Traning Loss: tensor(0.3707)\n",
      "417 Traning Loss: tensor(0.3680)\n",
      "418 Traning Loss: tensor(0.3652)\n",
      "419 Traning Loss: tensor(0.3623)\n",
      "420 Traning Loss: tensor(0.3595)\n",
      "421 Traning Loss: tensor(0.3566)\n",
      "422 Traning Loss: tensor(0.3536)\n",
      "423 Traning Loss: tensor(0.3508)\n",
      "424 Traning Loss: tensor(0.3477)\n",
      "425 Traning Loss: tensor(0.3447)\n",
      "426 Traning Loss: tensor(0.3416)\n",
      "427 Traning Loss: tensor(0.3386)\n",
      "428 Traning Loss: tensor(0.3354)\n",
      "429 Traning Loss: tensor(0.3323)\n",
      "430 Traning Loss: tensor(0.3291)\n",
      "431 Traning Loss: tensor(0.3258)\n",
      "432 Traning Loss: tensor(0.3225)\n",
      "433 Traning Loss: tensor(0.3193)\n",
      "434 Traning Loss: tensor(0.3159)\n",
      "435 Traning Loss: tensor(0.3125)\n",
      "436 Traning Loss: tensor(0.3093)\n",
      "437 Traning Loss: tensor(0.3058)\n",
      "438 Traning Loss: tensor(0.3023)\n",
      "439 Traning Loss: tensor(0.2989)\n",
      "440 Traning Loss: tensor(0.2955)\n",
      "441 Traning Loss: tensor(0.2920)\n",
      "442 Traning Loss: tensor(0.2884)\n",
      "443 Traning Loss: tensor(0.2850)\n",
      "444 Traning Loss: tensor(0.2813)\n",
      "445 Traning Loss: tensor(0.2779)\n",
      "446 Traning Loss: tensor(0.2744)\n",
      "447 Traning Loss: tensor(0.2708)\n",
      "448 Traning Loss: tensor(0.2673)\n",
      "449 Traning Loss: tensor(0.2638)\n",
      "450 Traning Loss: tensor(0.2603)\n",
      "451 Traning Loss: tensor(0.2568)\n",
      "452 Traning Loss: tensor(0.2535)\n",
      "453 Traning Loss: tensor(0.2501)\n",
      "454 Traning Loss: tensor(0.2466)\n",
      "455 Traning Loss: tensor(0.2435)\n",
      "456 Traning Loss: tensor(0.2402)\n",
      "457 Traning Loss: tensor(0.2370)\n",
      "458 Traning Loss: tensor(0.2337)\n",
      "459 Traning Loss: tensor(0.2307)\n",
      "460 Traning Loss: tensor(0.2276)\n",
      "461 Traning Loss: tensor(0.2247)\n",
      "462 Traning Loss: tensor(0.2220)\n",
      "463 Traning Loss: tensor(0.2192)\n",
      "464 Traning Loss: tensor(0.2164)\n",
      "465 Traning Loss: tensor(0.2140)\n",
      "466 Traning Loss: tensor(0.2113)\n",
      "467 Traning Loss: tensor(0.2090)\n",
      "468 Traning Loss: tensor(0.2068)\n",
      "469 Traning Loss: tensor(0.2046)\n",
      "470 Traning Loss: tensor(0.2027)\n",
      "471 Traning Loss: tensor(0.2007)\n",
      "472 Traning Loss: tensor(0.1984)\n",
      "473 Traning Loss: tensor(0.1967)\n",
      "474 Traning Loss: tensor(0.1951)\n",
      "475 Traning Loss: tensor(0.1933)\n",
      "476 Traning Loss: tensor(0.1921)\n",
      "477 Traning Loss: tensor(0.1908)\n",
      "478 Traning Loss: tensor(0.1894)\n",
      "479 Traning Loss: tensor(0.1878)\n",
      "480 Traning Loss: tensor(0.1873)\n",
      "481 Traning Loss: tensor(0.1861)\n",
      "482 Traning Loss: tensor(0.1855)\n",
      "483 Traning Loss: tensor(0.1843)\n",
      "484 Traning Loss: tensor(0.1835)\n",
      "485 Traning Loss: tensor(0.1829)\n",
      "486 Traning Loss: tensor(0.1823)\n",
      "487 Traning Loss: tensor(0.1816)\n",
      "488 Traning Loss: tensor(0.1812)\n",
      "489 Traning Loss: tensor(0.1806)\n",
      "490 Traning Loss: tensor(0.1807)\n",
      "491 Traning Loss: tensor(0.1801)\n",
      "492 Traning Loss: tensor(0.1797)\n",
      "493 Traning Loss: tensor(0.1794)\n",
      "494 Traning Loss: tensor(0.1798)\n",
      "495 Traning Loss: tensor(0.1796)\n",
      "496 Traning Loss: tensor(0.1793)\n",
      "497 Traning Loss: tensor(0.1792)\n",
      "498 Traning Loss: tensor(0.1789)\n",
      "499 Traning Loss: tensor(0.1787)\n",
      "500 Traning Loss: tensor(0.1795)\n",
      "501 Traning Loss: tensor(0.1787)\n",
      "502 Traning Loss: tensor(0.1787)\n",
      "503 Traning Loss: tensor(0.1787)\n",
      "504 Traning Loss: tensor(0.1774)\n",
      "505 Traning Loss: tensor(0.1794)\n",
      "506 Traning Loss: tensor(0.1786)\n",
      "507 Traning Loss: tensor(0.1784)\n",
      "508 Traning Loss: tensor(0.1786)\n",
      "509 Traning Loss: tensor(0.1781)\n",
      "510 Traning Loss: tensor(0.1785)\n",
      "511 Traning Loss: tensor(0.1793)\n",
      "512 Traning Loss: tensor(0.1785)\n",
      "513 Traning Loss: tensor(0.1777)\n",
      "514 Traning Loss: tensor(0.1780)\n",
      "515 Traning Loss: tensor(0.1780)\n",
      "516 Traning Loss: tensor(0.1781)\n",
      "517 Traning Loss: tensor(0.1788)\n",
      "518 Traning Loss: tensor(0.1778)\n",
      "519 Traning Loss: tensor(0.1783)\n",
      "520 Traning Loss: tensor(0.1787)\n",
      "521 Traning Loss: tensor(0.1776)\n",
      "522 Traning Loss: tensor(0.1784)\n",
      "523 Traning Loss: tensor(0.1778)\n",
      "524 Traning Loss: tensor(0.1773)\n",
      "525 Traning Loss: tensor(0.1781)\n",
      "526 Traning Loss: tensor(0.1773)\n",
      "527 Traning Loss: tensor(0.1777)\n",
      "528 Traning Loss: tensor(0.1774)\n",
      "529 Traning Loss: tensor(0.1781)\n",
      "530 Traning Loss: tensor(0.1782)\n",
      "531 Traning Loss: tensor(0.1771)\n",
      "532 Traning Loss: tensor(0.1782)\n",
      "533 Traning Loss: tensor(0.1782)\n",
      "534 Traning Loss: tensor(0.1781)\n",
      "535 Traning Loss: tensor(0.1781)\n",
      "536 Traning Loss: tensor(0.1770)\n",
      "537 Traning Loss: tensor(0.1775)\n",
      "538 Traning Loss: tensor(0.1772)\n",
      "539 Traning Loss: tensor(0.1777)\n",
      "540 Traning Loss: tensor(0.1777)\n",
      "541 Traning Loss: tensor(0.1772)\n",
      "542 Traning Loss: tensor(0.1780)\n",
      "543 Traning Loss: tensor(0.1778)\n",
      "544 Traning Loss: tensor(0.1771)\n",
      "545 Traning Loss: tensor(0.1769)\n",
      "546 Traning Loss: tensor(0.1772)\n",
      "547 Traning Loss: tensor(0.1777)\n",
      "548 Traning Loss: tensor(0.1769)\n",
      "549 Traning Loss: tensor(0.1772)\n",
      "550 Traning Loss: tensor(0.1769)\n",
      "551 Traning Loss: tensor(0.1770)\n",
      "552 Traning Loss: tensor(0.1770)\n",
      "553 Traning Loss: tensor(0.1776)\n",
      "554 Traning Loss: tensor(0.1768)\n",
      "555 Traning Loss: tensor(0.1773)\n",
      "556 Traning Loss: tensor(0.1771)\n",
      "557 Traning Loss: tensor(0.1770)\n",
      "558 Traning Loss: tensor(0.1770)\n",
      "559 Traning Loss: tensor(0.1766)\n",
      "560 Traning Loss: tensor(0.1765)\n",
      "561 Traning Loss: tensor(0.1762)\n",
      "562 Traning Loss: tensor(0.1773)\n",
      "563 Traning Loss: tensor(0.1762)\n",
      "564 Traning Loss: tensor(0.1773)\n",
      "565 Traning Loss: tensor(0.1765)\n",
      "566 Traning Loss: tensor(0.1764)\n",
      "567 Traning Loss: tensor(0.1765)\n",
      "568 Traning Loss: tensor(0.1766)\n",
      "569 Traning Loss: tensor(0.1773)\n",
      "570 Traning Loss: tensor(0.1764)\n",
      "571 Traning Loss: tensor(0.1767)\n",
      "572 Traning Loss: tensor(0.1762)\n",
      "573 Traning Loss: tensor(0.1765)\n",
      "574 Traning Loss: tensor(0.1768)\n",
      "575 Traning Loss: tensor(0.1763)\n",
      "576 Traning Loss: tensor(0.1760)\n",
      "577 Traning Loss: tensor(0.1762)\n",
      "578 Traning Loss: tensor(0.1761)\n",
      "579 Traning Loss: tensor(0.1755)\n",
      "580 Traning Loss: tensor(0.1763)\n",
      "581 Traning Loss: tensor(0.1763)\n",
      "582 Traning Loss: tensor(0.1753)\n",
      "583 Traning Loss: tensor(0.1757)\n",
      "584 Traning Loss: tensor(0.1758)\n",
      "585 Traning Loss: tensor(0.1756)\n",
      "586 Traning Loss: tensor(0.1756)\n",
      "587 Traning Loss: tensor(0.1752)\n",
      "588 Traning Loss: tensor(0.1762)\n",
      "589 Traning Loss: tensor(0.1750)\n",
      "590 Traning Loss: tensor(0.1758)\n",
      "591 Traning Loss: tensor(0.1764)\n",
      "592 Traning Loss: tensor(0.1755)\n",
      "593 Traning Loss: tensor(0.1761)\n",
      "594 Traning Loss: tensor(0.1762)\n",
      "595 Traning Loss: tensor(0.1754)\n",
      "596 Traning Loss: tensor(0.1761)\n",
      "597 Traning Loss: tensor(0.1754)\n",
      "598 Traning Loss: tensor(0.1752)\n",
      "599 Traning Loss: tensor(0.1754)\n",
      "600 Traning Loss: tensor(0.1751)\n",
      "601 Traning Loss: tensor(0.1755)\n",
      "602 Traning Loss: tensor(0.1746)\n",
      "603 Traning Loss: tensor(0.1756)\n",
      "604 Traning Loss: tensor(0.1754)\n",
      "605 Traning Loss: tensor(0.1754)\n",
      "606 Traning Loss: tensor(0.1749)\n",
      "607 Traning Loss: tensor(0.1753)\n",
      "608 Traning Loss: tensor(0.1753)\n",
      "609 Traning Loss: tensor(0.1758)\n",
      "610 Traning Loss: tensor(0.1748)\n",
      "611 Traning Loss: tensor(0.1744)\n",
      "612 Traning Loss: tensor(0.1753)\n",
      "613 Traning Loss: tensor(0.1753)\n",
      "614 Traning Loss: tensor(0.1751)\n",
      "615 Traning Loss: tensor(0.1745)\n",
      "616 Traning Loss: tensor(0.1741)\n",
      "617 Traning Loss: tensor(0.1744)\n",
      "618 Traning Loss: tensor(0.1745)\n",
      "619 Traning Loss: tensor(0.1748)\n",
      "620 Traning Loss: tensor(0.1749)\n",
      "621 Traning Loss: tensor(0.1745)\n",
      "622 Traning Loss: tensor(0.1751)\n",
      "623 Traning Loss: tensor(0.1748)\n",
      "624 Traning Loss: tensor(0.1745)\n",
      "625 Traning Loss: tensor(0.1741)\n",
      "626 Traning Loss: tensor(0.1750)\n",
      "627 Traning Loss: tensor(0.1743)\n",
      "628 Traning Loss: tensor(0.1749)\n",
      "629 Traning Loss: tensor(0.1747)\n",
      "630 Traning Loss: tensor(0.1741)\n",
      "631 Traning Loss: tensor(0.1747)\n",
      "632 Traning Loss: tensor(0.1746)\n",
      "633 Traning Loss: tensor(0.1739)\n",
      "634 Traning Loss: tensor(0.1748)\n",
      "635 Traning Loss: tensor(0.1741)\n",
      "636 Traning Loss: tensor(0.1742)\n",
      "637 Traning Loss: tensor(0.1746)\n",
      "638 Traning Loss: tensor(0.1741)\n",
      "639 Traning Loss: tensor(0.1741)\n",
      "640 Traning Loss: tensor(0.1741)\n",
      "641 Traning Loss: tensor(0.1740)\n",
      "642 Traning Loss: tensor(0.1738)\n",
      "643 Traning Loss: tensor(0.1738)\n",
      "644 Traning Loss: tensor(0.1735)\n",
      "645 Traning Loss: tensor(0.1742)\n",
      "646 Traning Loss: tensor(0.1742)\n",
      "647 Traning Loss: tensor(0.1734)\n",
      "648 Traning Loss: tensor(0.1737)\n",
      "649 Traning Loss: tensor(0.1740)\n",
      "650 Traning Loss: tensor(0.1731)\n",
      "651 Traning Loss: tensor(0.1735)\n",
      "652 Traning Loss: tensor(0.1731)\n",
      "653 Traning Loss: tensor(0.1735)\n",
      "654 Traning Loss: tensor(0.1735)\n",
      "655 Traning Loss: tensor(0.1736)\n",
      "656 Traning Loss: tensor(0.1738)\n",
      "657 Traning Loss: tensor(0.1730)\n",
      "658 Traning Loss: tensor(0.1727)\n",
      "659 Traning Loss: tensor(0.1729)\n",
      "660 Traning Loss: tensor(0.1735)\n",
      "661 Traning Loss: tensor(0.1729)\n",
      "662 Traning Loss: tensor(0.1730)\n",
      "663 Traning Loss: tensor(0.1732)\n",
      "664 Traning Loss: tensor(0.1730)\n",
      "665 Traning Loss: tensor(0.1724)\n",
      "666 Traning Loss: tensor(0.1727)\n",
      "667 Traning Loss: tensor(0.1734)\n",
      "668 Traning Loss: tensor(0.1726)\n",
      "669 Traning Loss: tensor(0.1733)\n",
      "670 Traning Loss: tensor(0.1732)\n",
      "671 Traning Loss: tensor(0.1723)\n",
      "672 Traning Loss: tensor(0.1725)\n",
      "673 Traning Loss: tensor(0.1729)\n",
      "674 Traning Loss: tensor(0.1723)\n",
      "675 Traning Loss: tensor(0.1730)\n",
      "676 Traning Loss: tensor(0.1729)\n",
      "677 Traning Loss: tensor(0.1724)\n",
      "678 Traning Loss: tensor(0.1728)\n",
      "679 Traning Loss: tensor(0.1726)\n",
      "680 Traning Loss: tensor(0.1723)\n",
      "681 Traning Loss: tensor(0.1727)\n",
      "682 Traning Loss: tensor(0.1725)\n",
      "683 Traning Loss: tensor(0.1725)\n",
      "684 Traning Loss: tensor(0.1724)\n",
      "685 Traning Loss: tensor(0.1727)\n",
      "686 Traning Loss: tensor(0.1726)\n",
      "687 Traning Loss: tensor(0.1720)\n",
      "688 Traning Loss: tensor(0.1726)\n",
      "689 Traning Loss: tensor(0.1727)\n",
      "690 Traning Loss: tensor(0.1724)\n",
      "691 Traning Loss: tensor(0.1722)\n",
      "692 Traning Loss: tensor(0.1714)\n",
      "693 Traning Loss: tensor(0.1721)\n",
      "694 Traning Loss: tensor(0.1720)\n",
      "695 Traning Loss: tensor(0.1716)\n",
      "696 Traning Loss: tensor(0.1718)\n",
      "697 Traning Loss: tensor(0.1718)\n",
      "698 Traning Loss: tensor(0.1718)\n",
      "699 Traning Loss: tensor(0.1721)\n",
      "700 Traning Loss: tensor(0.1718)\n",
      "701 Traning Loss: tensor(0.1716)\n",
      "702 Traning Loss: tensor(0.1720)\n",
      "703 Traning Loss: tensor(0.1716)\n",
      "704 Traning Loss: tensor(0.1713)\n",
      "705 Traning Loss: tensor(0.1719)\n",
      "706 Traning Loss: tensor(0.1718)\n",
      "707 Traning Loss: tensor(0.1719)\n",
      "708 Traning Loss: tensor(0.1717)\n",
      "709 Traning Loss: tensor(0.1712)\n",
      "710 Traning Loss: tensor(0.1710)\n",
      "711 Traning Loss: tensor(0.1713)\n",
      "712 Traning Loss: tensor(0.1714)\n",
      "713 Traning Loss: tensor(0.1711)\n",
      "714 Traning Loss: tensor(0.1717)\n",
      "715 Traning Loss: tensor(0.1713)\n",
      "716 Traning Loss: tensor(0.1707)\n",
      "717 Traning Loss: tensor(0.1710)\n",
      "718 Traning Loss: tensor(0.1709)\n",
      "719 Traning Loss: tensor(0.1710)\n",
      "720 Traning Loss: tensor(0.1707)\n",
      "721 Traning Loss: tensor(0.1705)\n",
      "722 Traning Loss: tensor(0.1707)\n",
      "723 Traning Loss: tensor(0.1711)\n",
      "724 Traning Loss: tensor(0.1710)\n",
      "725 Traning Loss: tensor(0.1716)\n",
      "726 Traning Loss: tensor(0.1705)\n",
      "727 Traning Loss: tensor(0.1706)\n",
      "728 Traning Loss: tensor(0.1711)\n",
      "729 Traning Loss: tensor(0.1714)\n",
      "730 Traning Loss: tensor(0.1708)\n",
      "731 Traning Loss: tensor(0.1708)\n",
      "732 Traning Loss: tensor(0.1708)\n",
      "733 Traning Loss: tensor(0.1707)\n",
      "734 Traning Loss: tensor(0.1709)\n",
      "735 Traning Loss: tensor(0.1706)\n",
      "736 Traning Loss: tensor(0.1705)\n",
      "737 Traning Loss: tensor(0.1705)\n",
      "738 Traning Loss: tensor(0.1705)\n",
      "739 Traning Loss: tensor(0.1710)\n",
      "740 Traning Loss: tensor(0.1700)\n",
      "741 Traning Loss: tensor(0.1700)\n",
      "742 Traning Loss: tensor(0.1699)\n",
      "743 Traning Loss: tensor(0.1703)\n",
      "744 Traning Loss: tensor(0.1701)\n",
      "745 Traning Loss: tensor(0.1695)\n",
      "746 Traning Loss: tensor(0.1700)\n",
      "747 Traning Loss: tensor(0.1696)\n",
      "748 Traning Loss: tensor(0.1698)\n",
      "749 Traning Loss: tensor(0.1699)\n",
      "750 Traning Loss: tensor(0.1702)\n",
      "751 Traning Loss: tensor(0.1699)\n",
      "752 Traning Loss: tensor(0.1700)\n",
      "753 Traning Loss: tensor(0.1705)\n",
      "754 Traning Loss: tensor(0.1699)\n",
      "755 Traning Loss: tensor(0.1695)\n",
      "756 Traning Loss: tensor(0.1695)\n",
      "757 Traning Loss: tensor(0.1695)\n",
      "758 Traning Loss: tensor(0.1698)\n",
      "759 Traning Loss: tensor(0.1689)\n",
      "760 Traning Loss: tensor(0.1703)\n",
      "761 Traning Loss: tensor(0.1696)\n",
      "762 Traning Loss: tensor(0.1694)\n",
      "763 Traning Loss: tensor(0.1701)\n",
      "764 Traning Loss: tensor(0.1695)\n",
      "765 Traning Loss: tensor(0.1696)\n",
      "766 Traning Loss: tensor(0.1692)\n",
      "767 Traning Loss: tensor(0.1689)\n",
      "768 Traning Loss: tensor(0.1692)\n",
      "769 Traning Loss: tensor(0.1692)\n",
      "770 Traning Loss: tensor(0.1687)\n",
      "771 Traning Loss: tensor(0.1693)\n",
      "772 Traning Loss: tensor(0.1693)\n",
      "773 Traning Loss: tensor(0.1690)\n",
      "774 Traning Loss: tensor(0.1690)\n",
      "775 Traning Loss: tensor(0.1692)\n",
      "776 Traning Loss: tensor(0.1691)\n",
      "777 Traning Loss: tensor(0.1689)\n",
      "778 Traning Loss: tensor(0.1684)\n",
      "779 Traning Loss: tensor(0.1689)\n",
      "780 Traning Loss: tensor(0.1691)\n",
      "781 Traning Loss: tensor(0.1686)\n",
      "782 Traning Loss: tensor(0.1688)\n",
      "783 Traning Loss: tensor(0.1689)\n",
      "784 Traning Loss: tensor(0.1685)\n",
      "785 Traning Loss: tensor(0.1684)\n",
      "786 Traning Loss: tensor(0.1682)\n",
      "787 Traning Loss: tensor(0.1687)\n",
      "788 Traning Loss: tensor(0.1679)\n",
      "789 Traning Loss: tensor(0.1681)\n",
      "790 Traning Loss: tensor(0.1684)\n",
      "791 Traning Loss: tensor(0.1684)\n",
      "792 Traning Loss: tensor(0.1688)\n",
      "793 Traning Loss: tensor(0.1681)\n",
      "794 Traning Loss: tensor(0.1681)\n",
      "795 Traning Loss: tensor(0.1686)\n",
      "796 Traning Loss: tensor(0.1690)\n",
      "797 Traning Loss: tensor(0.1680)\n",
      "798 Traning Loss: tensor(0.1678)\n",
      "799 Traning Loss: tensor(0.1679)\n",
      "800 Traning Loss: tensor(0.1680)\n",
      "801 Traning Loss: tensor(0.1679)\n",
      "802 Traning Loss: tensor(0.1682)\n",
      "803 Traning Loss: tensor(0.1676)\n",
      "804 Traning Loss: tensor(0.1679)\n",
      "805 Traning Loss: tensor(0.1678)\n",
      "806 Traning Loss: tensor(0.1679)\n",
      "807 Traning Loss: tensor(0.1681)\n",
      "808 Traning Loss: tensor(0.1678)\n",
      "809 Traning Loss: tensor(0.1680)\n",
      "810 Traning Loss: tensor(0.1675)\n",
      "811 Traning Loss: tensor(0.1677)\n",
      "812 Traning Loss: tensor(0.1680)\n",
      "813 Traning Loss: tensor(0.1673)\n",
      "814 Traning Loss: tensor(0.1671)\n",
      "815 Traning Loss: tensor(0.1674)\n",
      "816 Traning Loss: tensor(0.1674)\n",
      "817 Traning Loss: tensor(0.1680)\n",
      "818 Traning Loss: tensor(0.1678)\n",
      "819 Traning Loss: tensor(0.1680)\n",
      "820 Traning Loss: tensor(0.1672)\n",
      "821 Traning Loss: tensor(0.1675)\n",
      "822 Traning Loss: tensor(0.1673)\n",
      "823 Traning Loss: tensor(0.1676)\n",
      "824 Traning Loss: tensor(0.1668)\n",
      "825 Traning Loss: tensor(0.1670)\n",
      "826 Traning Loss: tensor(0.1672)\n",
      "827 Traning Loss: tensor(0.1669)\n",
      "828 Traning Loss: tensor(0.1673)\n",
      "829 Traning Loss: tensor(0.1668)\n",
      "830 Traning Loss: tensor(0.1669)\n",
      "831 Traning Loss: tensor(0.1668)\n",
      "832 Traning Loss: tensor(0.1670)\n",
      "833 Traning Loss: tensor(0.1665)\n",
      "834 Traning Loss: tensor(0.1665)\n",
      "835 Traning Loss: tensor(0.1672)\n",
      "836 Traning Loss: tensor(0.1673)\n",
      "837 Traning Loss: tensor(0.1666)\n",
      "838 Traning Loss: tensor(0.1662)\n",
      "839 Traning Loss: tensor(0.1662)\n",
      "840 Traning Loss: tensor(0.1663)\n",
      "841 Traning Loss: tensor(0.1662)\n",
      "842 Traning Loss: tensor(0.1659)\n",
      "843 Traning Loss: tensor(0.1664)\n",
      "844 Traning Loss: tensor(0.1669)\n",
      "845 Traning Loss: tensor(0.1663)\n",
      "846 Traning Loss: tensor(0.1665)\n",
      "847 Traning Loss: tensor(0.1660)\n",
      "848 Traning Loss: tensor(0.1659)\n",
      "849 Traning Loss: tensor(0.1660)\n",
      "850 Traning Loss: tensor(0.1662)\n",
      "851 Traning Loss: tensor(0.1659)\n",
      "852 Traning Loss: tensor(0.1655)\n",
      "853 Traning Loss: tensor(0.1656)\n",
      "854 Traning Loss: tensor(0.1663)\n",
      "855 Traning Loss: tensor(0.1656)\n",
      "856 Traning Loss: tensor(0.1662)\n",
      "857 Traning Loss: tensor(0.1649)\n",
      "858 Traning Loss: tensor(0.1658)\n",
      "859 Traning Loss: tensor(0.1663)\n",
      "860 Traning Loss: tensor(0.1655)\n",
      "861 Traning Loss: tensor(0.1661)\n",
      "862 Traning Loss: tensor(0.1657)\n",
      "863 Traning Loss: tensor(0.1658)\n",
      "864 Traning Loss: tensor(0.1655)\n",
      "865 Traning Loss: tensor(0.1654)\n",
      "866 Traning Loss: tensor(0.1655)\n",
      "867 Traning Loss: tensor(0.1655)\n",
      "868 Traning Loss: tensor(0.1655)\n",
      "869 Traning Loss: tensor(0.1657)\n",
      "870 Traning Loss: tensor(0.1650)\n",
      "871 Traning Loss: tensor(0.1661)\n",
      "872 Traning Loss: tensor(0.1651)\n",
      "873 Traning Loss: tensor(0.1648)\n",
      "874 Traning Loss: tensor(0.1658)\n",
      "875 Traning Loss: tensor(0.1654)\n",
      "876 Traning Loss: tensor(0.1653)\n",
      "877 Traning Loss: tensor(0.1652)\n",
      "878 Traning Loss: tensor(0.1653)\n",
      "879 Traning Loss: tensor(0.1648)\n",
      "880 Traning Loss: tensor(0.1649)\n",
      "881 Traning Loss: tensor(0.1651)\n",
      "882 Traning Loss: tensor(0.1650)\n",
      "883 Traning Loss: tensor(0.1649)\n",
      "884 Traning Loss: tensor(0.1647)\n",
      "885 Traning Loss: tensor(0.1640)\n",
      "886 Traning Loss: tensor(0.1648)\n",
      "887 Traning Loss: tensor(0.1648)\n",
      "888 Traning Loss: tensor(0.1647)\n",
      "889 Traning Loss: tensor(0.1648)\n",
      "890 Traning Loss: tensor(0.1644)\n",
      "891 Traning Loss: tensor(0.1649)\n",
      "892 Traning Loss: tensor(0.1644)\n",
      "893 Traning Loss: tensor(0.1647)\n",
      "894 Traning Loss: tensor(0.1642)\n",
      "895 Traning Loss: tensor(0.1644)\n",
      "896 Traning Loss: tensor(0.1653)\n",
      "897 Traning Loss: tensor(0.1644)\n",
      "898 Traning Loss: tensor(0.1641)\n",
      "899 Traning Loss: tensor(0.1644)\n",
      "900 Traning Loss: tensor(0.1640)\n",
      "901 Traning Loss: tensor(0.1647)\n",
      "902 Traning Loss: tensor(0.1643)\n",
      "903 Traning Loss: tensor(0.1641)\n",
      "904 Traning Loss: tensor(0.1637)\n",
      "905 Traning Loss: tensor(0.1640)\n",
      "906 Traning Loss: tensor(0.1641)\n",
      "907 Traning Loss: tensor(0.1635)\n",
      "908 Traning Loss: tensor(0.1640)\n",
      "909 Traning Loss: tensor(0.1638)\n",
      "910 Traning Loss: tensor(0.1636)\n",
      "911 Traning Loss: tensor(0.1636)\n",
      "912 Traning Loss: tensor(0.1635)\n",
      "913 Traning Loss: tensor(0.1635)\n",
      "914 Traning Loss: tensor(0.1640)\n",
      "915 Traning Loss: tensor(0.1635)\n",
      "916 Traning Loss: tensor(0.1633)\n",
      "917 Traning Loss: tensor(0.1639)\n",
      "918 Traning Loss: tensor(0.1631)\n",
      "919 Traning Loss: tensor(0.1635)\n",
      "920 Traning Loss: tensor(0.1634)\n",
      "921 Traning Loss: tensor(0.1630)\n",
      "922 Traning Loss: tensor(0.1640)\n",
      "923 Traning Loss: tensor(0.1634)\n",
      "924 Traning Loss: tensor(0.1631)\n",
      "925 Traning Loss: tensor(0.1635)\n",
      "926 Traning Loss: tensor(0.1634)\n",
      "927 Traning Loss: tensor(0.1631)\n",
      "928 Traning Loss: tensor(0.1631)\n",
      "929 Traning Loss: tensor(0.1627)\n",
      "930 Traning Loss: tensor(0.1631)\n",
      "931 Traning Loss: tensor(0.1631)\n",
      "932 Traning Loss: tensor(0.1624)\n",
      "933 Traning Loss: tensor(0.1626)\n",
      "934 Traning Loss: tensor(0.1624)\n",
      "935 Traning Loss: tensor(0.1629)\n",
      "936 Traning Loss: tensor(0.1628)\n",
      "937 Traning Loss: tensor(0.1629)\n",
      "938 Traning Loss: tensor(0.1624)\n",
      "939 Traning Loss: tensor(0.1629)\n",
      "940 Traning Loss: tensor(0.1632)\n",
      "941 Traning Loss: tensor(0.1626)\n",
      "942 Traning Loss: tensor(0.1619)\n",
      "943 Traning Loss: tensor(0.1630)\n",
      "944 Traning Loss: tensor(0.1627)\n",
      "945 Traning Loss: tensor(0.1624)\n",
      "946 Traning Loss: tensor(0.1618)\n",
      "947 Traning Loss: tensor(0.1624)\n",
      "948 Traning Loss: tensor(0.1620)\n",
      "949 Traning Loss: tensor(0.1627)\n",
      "950 Traning Loss: tensor(0.1624)\n",
      "951 Traning Loss: tensor(0.1619)\n",
      "952 Traning Loss: tensor(0.1622)\n",
      "953 Traning Loss: tensor(0.1628)\n",
      "954 Traning Loss: tensor(0.1615)\n",
      "955 Traning Loss: tensor(0.1623)\n",
      "956 Traning Loss: tensor(0.1620)\n",
      "957 Traning Loss: tensor(0.1614)\n",
      "958 Traning Loss: tensor(0.1616)\n",
      "959 Traning Loss: tensor(0.1618)\n",
      "960 Traning Loss: tensor(0.1619)\n",
      "961 Traning Loss: tensor(0.1618)\n",
      "962 Traning Loss: tensor(0.1614)\n",
      "963 Traning Loss: tensor(0.1622)\n",
      "964 Traning Loss: tensor(0.1615)\n",
      "965 Traning Loss: tensor(0.1617)\n",
      "966 Traning Loss: tensor(0.1617)\n",
      "967 Traning Loss: tensor(0.1615)\n",
      "968 Traning Loss: tensor(0.1616)\n",
      "969 Traning Loss: tensor(0.1613)\n",
      "970 Traning Loss: tensor(0.1615)\n",
      "971 Traning Loss: tensor(0.1616)\n",
      "972 Traning Loss: tensor(0.1615)\n",
      "973 Traning Loss: tensor(0.1613)\n",
      "974 Traning Loss: tensor(0.1619)\n",
      "975 Traning Loss: tensor(0.1611)\n",
      "976 Traning Loss: tensor(0.1614)\n",
      "977 Traning Loss: tensor(0.1620)\n",
      "978 Traning Loss: tensor(0.1611)\n",
      "979 Traning Loss: tensor(0.1616)\n",
      "980 Traning Loss: tensor(0.1615)\n",
      "981 Traning Loss: tensor(0.1605)\n",
      "982 Traning Loss: tensor(0.1612)\n",
      "983 Traning Loss: tensor(0.1612)\n",
      "984 Traning Loss: tensor(0.1611)\n",
      "985 Traning Loss: tensor(0.1606)\n",
      "986 Traning Loss: tensor(0.1609)\n",
      "987 Traning Loss: tensor(0.1610)\n",
      "988 Traning Loss: tensor(0.1611)\n",
      "989 Traning Loss: tensor(0.1612)\n",
      "990 Traning Loss: tensor(0.1605)\n",
      "991 Traning Loss: tensor(0.1611)\n",
      "992 Traning Loss: tensor(0.1605)\n",
      "993 Traning Loss: tensor(0.1606)\n",
      "994 Traning Loss: tensor(0.1608)\n",
      "995 Traning Loss: tensor(0.1609)\n",
      "996 Traning Loss: tensor(0.1600)\n",
      "997 Traning Loss: tensor(0.1610)\n",
      "998 Traning Loss: tensor(0.1603)\n",
      "999 Traning Loss: tensor(0.1606)\n",
      "1000 Traning Loss: tensor(0.1603)\n",
      "1001 Traning Loss: tensor(0.1604)\n",
      "1002 Traning Loss: tensor(0.1600)\n",
      "1003 Traning Loss: tensor(0.1600)\n",
      "1004 Traning Loss: tensor(0.1608)\n",
      "1005 Traning Loss: tensor(0.1606)\n",
      "1006 Traning Loss: tensor(0.1604)\n",
      "1007 Traning Loss: tensor(0.1605)\n",
      "1008 Traning Loss: tensor(0.1602)\n",
      "1009 Traning Loss: tensor(0.1597)\n",
      "1010 Traning Loss: tensor(0.1601)\n",
      "1011 Traning Loss: tensor(0.1605)\n",
      "1012 Traning Loss: tensor(0.1598)\n",
      "1013 Traning Loss: tensor(0.1604)\n",
      "1014 Traning Loss: tensor(0.1599)\n",
      "1015 Traning Loss: tensor(0.1599)\n",
      "1016 Traning Loss: tensor(0.1602)\n",
      "1017 Traning Loss: tensor(0.1599)\n",
      "1018 Traning Loss: tensor(0.1597)\n",
      "1019 Traning Loss: tensor(0.1603)\n",
      "1020 Traning Loss: tensor(0.1603)\n",
      "1021 Traning Loss: tensor(0.1594)\n",
      "1022 Traning Loss: tensor(0.1593)\n",
      "1023 Traning Loss: tensor(0.1595)\n",
      "1024 Traning Loss: tensor(0.1601)\n",
      "1025 Traning Loss: tensor(0.1596)\n",
      "1026 Traning Loss: tensor(0.1594)\n",
      "1027 Traning Loss: tensor(0.1599)\n",
      "1028 Traning Loss: tensor(0.1595)\n",
      "1029 Traning Loss: tensor(0.1597)\n",
      "1030 Traning Loss: tensor(0.1592)\n",
      "1031 Traning Loss: tensor(0.1600)\n",
      "1032 Traning Loss: tensor(0.1594)\n",
      "1033 Traning Loss: tensor(0.1596)\n",
      "1034 Traning Loss: tensor(0.1589)\n",
      "1035 Traning Loss: tensor(0.1593)\n",
      "1036 Traning Loss: tensor(0.1593)\n",
      "1037 Traning Loss: tensor(0.1589)\n",
      "1038 Traning Loss: tensor(0.1586)\n",
      "1039 Traning Loss: tensor(0.1593)\n",
      "1040 Traning Loss: tensor(0.1586)\n",
      "1041 Traning Loss: tensor(0.1592)\n",
      "1042 Traning Loss: tensor(0.1596)\n",
      "1043 Traning Loss: tensor(0.1598)\n",
      "1044 Traning Loss: tensor(0.1588)\n",
      "1045 Traning Loss: tensor(0.1586)\n",
      "1046 Traning Loss: tensor(0.1595)\n",
      "1047 Traning Loss: tensor(0.1590)\n",
      "1048 Traning Loss: tensor(0.1581)\n",
      "1049 Traning Loss: tensor(0.1588)\n",
      "1050 Traning Loss: tensor(0.1587)\n",
      "1051 Traning Loss: tensor(0.1582)\n",
      "1052 Traning Loss: tensor(0.1585)\n",
      "1053 Traning Loss: tensor(0.1585)\n",
      "1054 Traning Loss: tensor(0.1588)\n",
      "1055 Traning Loss: tensor(0.1585)\n",
      "1056 Traning Loss: tensor(0.1583)\n",
      "1057 Traning Loss: tensor(0.1585)\n",
      "1058 Traning Loss: tensor(0.1590)\n",
      "1059 Traning Loss: tensor(0.1580)\n",
      "1060 Traning Loss: tensor(0.1581)\n",
      "1061 Traning Loss: tensor(0.1583)\n",
      "1062 Traning Loss: tensor(0.1583)\n",
      "1063 Traning Loss: tensor(0.1580)\n",
      "1064 Traning Loss: tensor(0.1585)\n",
      "1065 Traning Loss: tensor(0.1582)\n",
      "1066 Traning Loss: tensor(0.1580)\n",
      "1067 Traning Loss: tensor(0.1583)\n",
      "1068 Traning Loss: tensor(0.1581)\n",
      "1069 Traning Loss: tensor(0.1582)\n",
      "1070 Traning Loss: tensor(0.1583)\n",
      "1071 Traning Loss: tensor(0.1578)\n",
      "1072 Traning Loss: tensor(0.1578)\n",
      "1073 Traning Loss: tensor(0.1576)\n",
      "1074 Traning Loss: tensor(0.1574)\n",
      "1075 Traning Loss: tensor(0.1579)\n",
      "1076 Traning Loss: tensor(0.1573)\n",
      "1077 Traning Loss: tensor(0.1581)\n",
      "1078 Traning Loss: tensor(0.1577)\n",
      "1079 Traning Loss: tensor(0.1572)\n",
      "1080 Traning Loss: tensor(0.1572)\n",
      "1081 Traning Loss: tensor(0.1575)\n",
      "1082 Traning Loss: tensor(0.1581)\n",
      "1083 Traning Loss: tensor(0.1570)\n",
      "1084 Traning Loss: tensor(0.1575)\n",
      "1085 Traning Loss: tensor(0.1576)\n",
      "1086 Traning Loss: tensor(0.1571)\n",
      "1087 Traning Loss: tensor(0.1575)\n",
      "1088 Traning Loss: tensor(0.1571)\n",
      "1089 Traning Loss: tensor(0.1569)\n",
      "1090 Traning Loss: tensor(0.1571)\n",
      "1091 Traning Loss: tensor(0.1576)\n",
      "1092 Traning Loss: tensor(0.1569)\n",
      "1093 Traning Loss: tensor(0.1575)\n",
      "1094 Traning Loss: tensor(0.1569)\n",
      "1095 Traning Loss: tensor(0.1578)\n",
      "1096 Traning Loss: tensor(0.1578)\n",
      "1097 Traning Loss: tensor(0.1572)\n",
      "1098 Traning Loss: tensor(0.1566)\n",
      "1099 Traning Loss: tensor(0.1565)\n",
      "1100 Traning Loss: tensor(0.1565)\n",
      "1101 Traning Loss: tensor(0.1571)\n",
      "1102 Traning Loss: tensor(0.1566)\n",
      "1103 Traning Loss: tensor(0.1575)\n",
      "1104 Traning Loss: tensor(0.1577)\n",
      "1105 Traning Loss: tensor(0.1570)\n",
      "1106 Traning Loss: tensor(0.1568)\n",
      "1107 Traning Loss: tensor(0.1572)\n",
      "1108 Traning Loss: tensor(0.1565)\n",
      "1109 Traning Loss: tensor(0.1567)\n",
      "1110 Traning Loss: tensor(0.1568)\n",
      "1111 Traning Loss: tensor(0.1559)\n",
      "1112 Traning Loss: tensor(0.1564)\n",
      "1113 Traning Loss: tensor(0.1565)\n",
      "1114 Traning Loss: tensor(0.1573)\n",
      "1115 Traning Loss: tensor(0.1561)\n",
      "1116 Traning Loss: tensor(0.1565)\n",
      "1117 Traning Loss: tensor(0.1567)\n",
      "1118 Traning Loss: tensor(0.1566)\n",
      "1119 Traning Loss: tensor(0.1566)\n",
      "1120 Traning Loss: tensor(0.1558)\n",
      "1121 Traning Loss: tensor(0.1557)\n",
      "1122 Traning Loss: tensor(0.1567)\n",
      "1123 Traning Loss: tensor(0.1568)\n",
      "1124 Traning Loss: tensor(0.1559)\n",
      "1125 Traning Loss: tensor(0.1561)\n",
      "1126 Traning Loss: tensor(0.1558)\n",
      "1127 Traning Loss: tensor(0.1562)\n",
      "1128 Traning Loss: tensor(0.1563)\n",
      "1129 Traning Loss: tensor(0.1561)\n",
      "1130 Traning Loss: tensor(0.1556)\n",
      "1131 Traning Loss: tensor(0.1553)\n",
      "1132 Traning Loss: tensor(0.1558)\n",
      "1133 Traning Loss: tensor(0.1564)\n",
      "1134 Traning Loss: tensor(0.1562)\n",
      "1135 Traning Loss: tensor(0.1550)\n",
      "1136 Traning Loss: tensor(0.1556)\n",
      "1137 Traning Loss: tensor(0.1553)\n",
      "1138 Traning Loss: tensor(0.1559)\n",
      "1139 Traning Loss: tensor(0.1563)\n",
      "1140 Traning Loss: tensor(0.1555)\n",
      "1141 Traning Loss: tensor(0.1562)\n",
      "1142 Traning Loss: tensor(0.1556)\n",
      "1143 Traning Loss: tensor(0.1552)\n",
      "1144 Traning Loss: tensor(0.1559)\n",
      "1145 Traning Loss: tensor(0.1555)\n",
      "1146 Traning Loss: tensor(0.1558)\n",
      "1147 Traning Loss: tensor(0.1551)\n",
      "1148 Traning Loss: tensor(0.1561)\n",
      "1149 Traning Loss: tensor(0.1553)\n",
      "1150 Traning Loss: tensor(0.1555)\n",
      "1151 Traning Loss: tensor(0.1548)\n",
      "1152 Traning Loss: tensor(0.1556)\n",
      "1153 Traning Loss: tensor(0.1553)\n",
      "1154 Traning Loss: tensor(0.1553)\n",
      "1155 Traning Loss: tensor(0.1548)\n",
      "1156 Traning Loss: tensor(0.1556)\n",
      "1157 Traning Loss: tensor(0.1544)\n",
      "1158 Traning Loss: tensor(0.1559)\n",
      "1159 Traning Loss: tensor(0.1552)\n",
      "1160 Traning Loss: tensor(0.1549)\n",
      "1161 Traning Loss: tensor(0.1547)\n",
      "1162 Traning Loss: tensor(0.1555)\n",
      "1163 Traning Loss: tensor(0.1549)\n",
      "1164 Traning Loss: tensor(0.1547)\n",
      "1165 Traning Loss: tensor(0.1554)\n",
      "1166 Traning Loss: tensor(0.1549)\n",
      "1167 Traning Loss: tensor(0.1546)\n",
      "1168 Traning Loss: tensor(0.1545)\n",
      "1169 Traning Loss: tensor(0.1546)\n",
      "1170 Traning Loss: tensor(0.1548)\n",
      "1171 Traning Loss: tensor(0.1546)\n",
      "1172 Traning Loss: tensor(0.1546)\n",
      "1173 Traning Loss: tensor(0.1544)\n",
      "1174 Traning Loss: tensor(0.1548)\n",
      "1175 Traning Loss: tensor(0.1535)\n",
      "1176 Traning Loss: tensor(0.1542)\n",
      "1177 Traning Loss: tensor(0.1540)\n",
      "1178 Traning Loss: tensor(0.1541)\n",
      "1179 Traning Loss: tensor(0.1541)\n",
      "1180 Traning Loss: tensor(0.1549)\n",
      "1181 Traning Loss: tensor(0.1545)\n",
      "1182 Traning Loss: tensor(0.1547)\n",
      "1183 Traning Loss: tensor(0.1542)\n",
      "1184 Traning Loss: tensor(0.1542)\n",
      "1185 Traning Loss: tensor(0.1542)\n",
      "1186 Traning Loss: tensor(0.1546)\n",
      "1187 Traning Loss: tensor(0.1543)\n",
      "1188 Traning Loss: tensor(0.1543)\n",
      "1189 Traning Loss: tensor(0.1541)\n",
      "1190 Traning Loss: tensor(0.1543)\n",
      "1191 Traning Loss: tensor(0.1541)\n",
      "1192 Traning Loss: tensor(0.1553)\n",
      "1193 Traning Loss: tensor(0.1542)\n",
      "1194 Traning Loss: tensor(0.1535)\n",
      "1195 Traning Loss: tensor(0.1536)\n",
      "1196 Traning Loss: tensor(0.1539)\n",
      "1197 Traning Loss: tensor(0.1536)\n",
      "1198 Traning Loss: tensor(0.1539)\n",
      "1199 Traning Loss: tensor(0.1540)\n",
      "1200 Traning Loss: tensor(0.1539)\n",
      "1201 Traning Loss: tensor(0.1535)\n",
      "1202 Traning Loss: tensor(0.1542)\n",
      "1203 Traning Loss: tensor(0.1541)\n",
      "1204 Traning Loss: tensor(0.1532)\n",
      "1205 Traning Loss: tensor(0.1541)\n",
      "1206 Traning Loss: tensor(0.1533)\n",
      "1207 Traning Loss: tensor(0.1532)\n",
      "1208 Traning Loss: tensor(0.1538)\n",
      "1209 Traning Loss: tensor(0.1542)\n",
      "1210 Traning Loss: tensor(0.1533)\n",
      "1211 Traning Loss: tensor(0.1534)\n",
      "1212 Traning Loss: tensor(0.1545)\n",
      "1213 Traning Loss: tensor(0.1537)\n",
      "1214 Traning Loss: tensor(0.1533)\n",
      "1215 Traning Loss: tensor(0.1531)\n",
      "1216 Traning Loss: tensor(0.1534)\n",
      "1217 Traning Loss: tensor(0.1535)\n",
      "1218 Traning Loss: tensor(0.1531)\n",
      "1219 Traning Loss: tensor(0.1518)\n",
      "1220 Traning Loss: tensor(0.1537)\n",
      "1221 Traning Loss: tensor(0.1531)\n",
      "1222 Traning Loss: tensor(0.1527)\n",
      "1223 Traning Loss: tensor(0.1529)\n",
      "1224 Traning Loss: tensor(0.1530)\n",
      "1225 Traning Loss: tensor(0.1527)\n",
      "1226 Traning Loss: tensor(0.1533)\n",
      "1227 Traning Loss: tensor(0.1524)\n",
      "1228 Traning Loss: tensor(0.1523)\n",
      "1229 Traning Loss: tensor(0.1533)\n",
      "1230 Traning Loss: tensor(0.1526)\n",
      "1231 Traning Loss: tensor(0.1525)\n",
      "1232 Traning Loss: tensor(0.1529)\n",
      "1233 Traning Loss: tensor(0.1527)\n",
      "1234 Traning Loss: tensor(0.1532)\n",
      "1235 Traning Loss: tensor(0.1531)\n",
      "1236 Traning Loss: tensor(0.1537)\n",
      "1237 Traning Loss: tensor(0.1523)\n",
      "1238 Traning Loss: tensor(0.1521)\n",
      "1239 Traning Loss: tensor(0.1522)\n",
      "1240 Traning Loss: tensor(0.1530)\n",
      "1241 Traning Loss: tensor(0.1526)\n",
      "1242 Traning Loss: tensor(0.1523)\n",
      "1243 Traning Loss: tensor(0.1529)\n",
      "1244 Traning Loss: tensor(0.1529)\n",
      "1245 Traning Loss: tensor(0.1525)\n",
      "1246 Traning Loss: tensor(0.1529)\n",
      "1247 Traning Loss: tensor(0.1525)\n",
      "1248 Traning Loss: tensor(0.1524)\n",
      "1249 Traning Loss: tensor(0.1525)\n",
      "1250 Traning Loss: tensor(0.1522)\n",
      "1251 Traning Loss: tensor(0.1520)\n",
      "1252 Traning Loss: tensor(0.1527)\n",
      "1253 Traning Loss: tensor(0.1516)\n",
      "1254 Traning Loss: tensor(0.1525)\n",
      "1255 Traning Loss: tensor(0.1519)\n",
      "1256 Traning Loss: tensor(0.1520)\n",
      "1257 Traning Loss: tensor(0.1513)\n",
      "1258 Traning Loss: tensor(0.1524)\n",
      "1259 Traning Loss: tensor(0.1523)\n",
      "1260 Traning Loss: tensor(0.1525)\n",
      "1261 Traning Loss: tensor(0.1520)\n",
      "1262 Traning Loss: tensor(0.1524)\n",
      "1263 Traning Loss: tensor(0.1518)\n",
      "1264 Traning Loss: tensor(0.1529)\n",
      "1265 Traning Loss: tensor(0.1517)\n",
      "1266 Traning Loss: tensor(0.1522)\n",
      "1267 Traning Loss: tensor(0.1526)\n",
      "1268 Traning Loss: tensor(0.1524)\n",
      "1269 Traning Loss: tensor(0.1513)\n",
      "1270 Traning Loss: tensor(0.1522)\n",
      "1271 Traning Loss: tensor(0.1517)\n",
      "1272 Traning Loss: tensor(0.1520)\n",
      "1273 Traning Loss: tensor(0.1512)\n",
      "1274 Traning Loss: tensor(0.1519)\n",
      "1275 Traning Loss: tensor(0.1512)\n",
      "1276 Traning Loss: tensor(0.1512)\n",
      "1277 Traning Loss: tensor(0.1512)\n",
      "1278 Traning Loss: tensor(0.1518)\n",
      "1279 Traning Loss: tensor(0.1524)\n",
      "1280 Traning Loss: tensor(0.1524)\n",
      "1281 Traning Loss: tensor(0.1516)\n",
      "1282 Traning Loss: tensor(0.1517)\n",
      "1283 Traning Loss: tensor(0.1517)\n",
      "1284 Traning Loss: tensor(0.1512)\n",
      "1285 Traning Loss: tensor(0.1516)\n",
      "1286 Traning Loss: tensor(0.1513)\n",
      "1287 Traning Loss: tensor(0.1516)\n",
      "1288 Traning Loss: tensor(0.1509)\n",
      "1289 Traning Loss: tensor(0.1510)\n",
      "1290 Traning Loss: tensor(0.1512)\n",
      "1291 Traning Loss: tensor(0.1508)\n",
      "1292 Traning Loss: tensor(0.1512)\n",
      "1293 Traning Loss: tensor(0.1513)\n",
      "1294 Traning Loss: tensor(0.1508)\n",
      "1295 Traning Loss: tensor(0.1506)\n",
      "1296 Traning Loss: tensor(0.1512)\n",
      "1297 Traning Loss: tensor(0.1511)\n",
      "1298 Traning Loss: tensor(0.1516)\n",
      "1299 Traning Loss: tensor(0.1514)\n",
      "1300 Traning Loss: tensor(0.1517)\n",
      "1301 Traning Loss: tensor(0.1501)\n",
      "1302 Traning Loss: tensor(0.1511)\n",
      "1303 Traning Loss: tensor(0.1506)\n",
      "1304 Traning Loss: tensor(0.1510)\n",
      "1305 Traning Loss: tensor(0.1509)\n",
      "1306 Traning Loss: tensor(0.1504)\n",
      "1307 Traning Loss: tensor(0.1515)\n",
      "1308 Traning Loss: tensor(0.1508)\n",
      "1309 Traning Loss: tensor(0.1509)\n",
      "1310 Traning Loss: tensor(0.1509)\n",
      "1311 Traning Loss: tensor(0.1503)\n",
      "1312 Traning Loss: tensor(0.1510)\n",
      "1313 Traning Loss: tensor(0.1506)\n",
      "1314 Traning Loss: tensor(0.1513)\n",
      "1315 Traning Loss: tensor(0.1509)\n",
      "1316 Traning Loss: tensor(0.1504)\n",
      "1317 Traning Loss: tensor(0.1508)\n",
      "1318 Traning Loss: tensor(0.1508)\n",
      "1319 Traning Loss: tensor(0.1508)\n",
      "1320 Traning Loss: tensor(0.1500)\n",
      "1321 Traning Loss: tensor(0.1504)\n",
      "1322 Traning Loss: tensor(0.1504)\n",
      "1323 Traning Loss: tensor(0.1500)\n",
      "1324 Traning Loss: tensor(0.1506)\n",
      "1325 Traning Loss: tensor(0.1503)\n",
      "1326 Traning Loss: tensor(0.1509)\n",
      "1327 Traning Loss: tensor(0.1511)\n",
      "1328 Traning Loss: tensor(0.1507)\n",
      "1329 Traning Loss: tensor(0.1503)\n",
      "1330 Traning Loss: tensor(0.1502)\n",
      "1331 Traning Loss: tensor(0.1499)\n",
      "1332 Traning Loss: tensor(0.1495)\n",
      "1333 Traning Loss: tensor(0.1498)\n",
      "1334 Traning Loss: tensor(0.1506)\n",
      "1335 Traning Loss: tensor(0.1506)\n",
      "1336 Traning Loss: tensor(0.1500)\n",
      "1337 Traning Loss: tensor(0.1497)\n",
      "1338 Traning Loss: tensor(0.1497)\n",
      "1339 Traning Loss: tensor(0.1501)\n",
      "1340 Traning Loss: tensor(0.1495)\n",
      "1341 Traning Loss: tensor(0.1501)\n",
      "1342 Traning Loss: tensor(0.1499)\n",
      "1343 Traning Loss: tensor(0.1492)\n",
      "1344 Traning Loss: tensor(0.1505)\n",
      "1345 Traning Loss: tensor(0.1505)\n",
      "1346 Traning Loss: tensor(0.1496)\n",
      "1347 Traning Loss: tensor(0.1495)\n",
      "1348 Traning Loss: tensor(0.1498)\n",
      "1349 Traning Loss: tensor(0.1496)\n",
      "1350 Traning Loss: tensor(0.1503)\n",
      "1351 Traning Loss: tensor(0.1494)\n",
      "1352 Traning Loss: tensor(0.1499)\n",
      "1353 Traning Loss: tensor(0.1492)\n",
      "1354 Traning Loss: tensor(0.1496)\n",
      "1355 Traning Loss: tensor(0.1494)\n",
      "1356 Traning Loss: tensor(0.1496)\n",
      "1357 Traning Loss: tensor(0.1500)\n",
      "1358 Traning Loss: tensor(0.1491)\n",
      "1359 Traning Loss: tensor(0.1491)\n",
      "1360 Traning Loss: tensor(0.1494)\n",
      "1361 Traning Loss: tensor(0.1496)\n",
      "1362 Traning Loss: tensor(0.1498)\n",
      "1363 Traning Loss: tensor(0.1491)\n",
      "1364 Traning Loss: tensor(0.1503)\n",
      "1365 Traning Loss: tensor(0.1498)\n",
      "1366 Traning Loss: tensor(0.1497)\n",
      "1367 Traning Loss: tensor(0.1492)\n",
      "1368 Traning Loss: tensor(0.1497)\n",
      "1369 Traning Loss: tensor(0.1490)\n",
      "1370 Traning Loss: tensor(0.1493)\n",
      "1371 Traning Loss: tensor(0.1490)\n",
      "1372 Traning Loss: tensor(0.1491)\n",
      "1373 Traning Loss: tensor(0.1493)\n",
      "1374 Traning Loss: tensor(0.1496)\n",
      "1375 Traning Loss: tensor(0.1493)\n",
      "1376 Traning Loss: tensor(0.1497)\n",
      "1377 Traning Loss: tensor(0.1491)\n",
      "1378 Traning Loss: tensor(0.1493)\n",
      "1379 Traning Loss: tensor(0.1488)\n",
      "1380 Traning Loss: tensor(0.1489)\n",
      "1381 Traning Loss: tensor(0.1488)\n",
      "1382 Traning Loss: tensor(0.1492)\n",
      "1383 Traning Loss: tensor(0.1489)\n",
      "1384 Traning Loss: tensor(0.1492)\n",
      "1385 Traning Loss: tensor(0.1491)\n",
      "1386 Traning Loss: tensor(0.1495)\n",
      "1387 Traning Loss: tensor(0.1492)\n",
      "1388 Traning Loss: tensor(0.1490)\n",
      "1389 Traning Loss: tensor(0.1487)\n",
      "1390 Traning Loss: tensor(0.1491)\n",
      "1391 Traning Loss: tensor(0.1490)\n",
      "1392 Traning Loss: tensor(0.1488)\n",
      "1393 Traning Loss: tensor(0.1491)\n",
      "1394 Traning Loss: tensor(0.1489)\n",
      "1395 Traning Loss: tensor(0.1495)\n",
      "1396 Traning Loss: tensor(0.1490)\n",
      "1397 Traning Loss: tensor(0.1478)\n",
      "1398 Traning Loss: tensor(0.1491)\n",
      "1399 Traning Loss: tensor(0.1487)\n",
      "1400 Traning Loss: tensor(0.1486)\n",
      "1401 Traning Loss: tensor(0.1482)\n",
      "1402 Traning Loss: tensor(0.1485)\n",
      "1403 Traning Loss: tensor(0.1483)\n",
      "1404 Traning Loss: tensor(0.1481)\n",
      "1405 Traning Loss: tensor(0.1486)\n",
      "1406 Traning Loss: tensor(0.1485)\n",
      "1407 Traning Loss: tensor(0.1484)\n",
      "1408 Traning Loss: tensor(0.1479)\n",
      "1409 Traning Loss: tensor(0.1482)\n",
      "1410 Traning Loss: tensor(0.1477)\n",
      "1411 Traning Loss: tensor(0.1483)\n",
      "1412 Traning Loss: tensor(0.1478)\n",
      "1413 Traning Loss: tensor(0.1478)\n",
      "1414 Traning Loss: tensor(0.1475)\n",
      "1415 Traning Loss: tensor(0.1489)\n",
      "1416 Traning Loss: tensor(0.1487)\n",
      "1417 Traning Loss: tensor(0.1475)\n",
      "1418 Traning Loss: tensor(0.1485)\n",
      "1419 Traning Loss: tensor(0.1481)\n",
      "1420 Traning Loss: tensor(0.1480)\n",
      "1421 Traning Loss: tensor(0.1490)\n",
      "1422 Traning Loss: tensor(0.1477)\n",
      "1423 Traning Loss: tensor(0.1485)\n",
      "1424 Traning Loss: tensor(0.1480)\n",
      "1425 Traning Loss: tensor(0.1479)\n",
      "1426 Traning Loss: tensor(0.1483)\n",
      "1427 Traning Loss: tensor(0.1476)\n",
      "1428 Traning Loss: tensor(0.1474)\n",
      "1429 Traning Loss: tensor(0.1483)\n",
      "1430 Traning Loss: tensor(0.1480)\n",
      "1431 Traning Loss: tensor(0.1477)\n",
      "1432 Traning Loss: tensor(0.1482)\n",
      "1433 Traning Loss: tensor(0.1485)\n",
      "1434 Traning Loss: tensor(0.1477)\n",
      "1435 Traning Loss: tensor(0.1469)\n",
      "1436 Traning Loss: tensor(0.1484)\n",
      "1437 Traning Loss: tensor(0.1470)\n",
      "1438 Traning Loss: tensor(0.1477)\n",
      "1439 Traning Loss: tensor(0.1484)\n",
      "1440 Traning Loss: tensor(0.1474)\n",
      "1441 Traning Loss: tensor(0.1482)\n",
      "1442 Traning Loss: tensor(0.1488)\n",
      "1443 Traning Loss: tensor(0.1479)\n",
      "1444 Traning Loss: tensor(0.1467)\n",
      "1445 Traning Loss: tensor(0.1479)\n",
      "1446 Traning Loss: tensor(0.1479)\n",
      "1447 Traning Loss: tensor(0.1470)\n",
      "1448 Traning Loss: tensor(0.1475)\n",
      "1449 Traning Loss: tensor(0.1483)\n",
      "1450 Traning Loss: tensor(0.1478)\n",
      "1451 Traning Loss: tensor(0.1477)\n",
      "1452 Traning Loss: tensor(0.1475)\n",
      "1453 Traning Loss: tensor(0.1477)\n",
      "1454 Traning Loss: tensor(0.1480)\n",
      "1455 Traning Loss: tensor(0.1469)\n",
      "1456 Traning Loss: tensor(0.1475)\n",
      "1457 Traning Loss: tensor(0.1474)\n",
      "1458 Traning Loss: tensor(0.1472)\n",
      "1459 Traning Loss: tensor(0.1474)\n",
      "1460 Traning Loss: tensor(0.1471)\n",
      "1461 Traning Loss: tensor(0.1467)\n",
      "1462 Traning Loss: tensor(0.1473)\n",
      "1463 Traning Loss: tensor(0.1470)\n",
      "1464 Traning Loss: tensor(0.1473)\n",
      "1465 Traning Loss: tensor(0.1470)\n",
      "1466 Traning Loss: tensor(0.1463)\n",
      "1467 Traning Loss: tensor(0.1472)\n",
      "1468 Traning Loss: tensor(0.1473)\n",
      "1469 Traning Loss: tensor(0.1467)\n",
      "1470 Traning Loss: tensor(0.1468)\n",
      "1471 Traning Loss: tensor(0.1458)\n",
      "1472 Traning Loss: tensor(0.1468)\n",
      "1473 Traning Loss: tensor(0.1473)\n",
      "1474 Traning Loss: tensor(0.1459)\n",
      "1475 Traning Loss: tensor(0.1470)\n",
      "1476 Traning Loss: tensor(0.1473)\n",
      "1477 Traning Loss: tensor(0.1469)\n",
      "1478 Traning Loss: tensor(0.1465)\n",
      "1479 Traning Loss: tensor(0.1474)\n",
      "1480 Traning Loss: tensor(0.1472)\n",
      "1481 Traning Loss: tensor(0.1474)\n",
      "1482 Traning Loss: tensor(0.1466)\n",
      "1483 Traning Loss: tensor(0.1465)\n",
      "1484 Traning Loss: tensor(0.1475)\n",
      "1485 Traning Loss: tensor(0.1470)\n",
      "1486 Traning Loss: tensor(0.1474)\n",
      "1487 Traning Loss: tensor(0.1466)\n",
      "1488 Traning Loss: tensor(0.1464)\n",
      "1489 Traning Loss: tensor(0.1468)\n",
      "1490 Traning Loss: tensor(0.1467)\n",
      "1491 Traning Loss: tensor(0.1474)\n",
      "1492 Traning Loss: tensor(0.1464)\n",
      "1493 Traning Loss: tensor(0.1466)\n",
      "1494 Traning Loss: tensor(0.1466)\n",
      "1495 Traning Loss: tensor(0.1464)\n",
      "1496 Traning Loss: tensor(0.1465)\n",
      "1497 Traning Loss: tensor(0.1463)\n",
      "1498 Traning Loss: tensor(0.1473)\n",
      "1499 Traning Loss: tensor(0.1471)\n",
      "1500 Traning Loss: tensor(0.1463)\n",
      "1501 Traning Loss: tensor(0.1467)\n",
      "1502 Traning Loss: tensor(0.1471)\n",
      "1503 Traning Loss: tensor(0.1467)\n",
      "1504 Traning Loss: tensor(0.1463)\n",
      "1505 Traning Loss: tensor(0.1467)\n",
      "1506 Traning Loss: tensor(0.1457)\n",
      "1507 Traning Loss: tensor(0.1462)\n",
      "1508 Traning Loss: tensor(0.1463)\n",
      "1509 Traning Loss: tensor(0.1460)\n",
      "1510 Traning Loss: tensor(0.1464)\n",
      "1511 Traning Loss: tensor(0.1467)\n",
      "1512 Traning Loss: tensor(0.1463)\n",
      "1513 Traning Loss: tensor(0.1466)\n",
      "1514 Traning Loss: tensor(0.1464)\n",
      "1515 Traning Loss: tensor(0.1468)\n",
      "1516 Traning Loss: tensor(0.1467)\n",
      "1517 Traning Loss: tensor(0.1463)\n",
      "1518 Traning Loss: tensor(0.1474)\n",
      "1519 Traning Loss: tensor(0.1455)\n",
      "1520 Traning Loss: tensor(0.1458)\n",
      "1521 Traning Loss: tensor(0.1458)\n",
      "1522 Traning Loss: tensor(0.1467)\n",
      "1523 Traning Loss: tensor(0.1460)\n",
      "1524 Traning Loss: tensor(0.1461)\n",
      "1525 Traning Loss: tensor(0.1457)\n",
      "1526 Traning Loss: tensor(0.1457)\n",
      "1527 Traning Loss: tensor(0.1461)\n",
      "1528 Traning Loss: tensor(0.1462)\n",
      "1529 Traning Loss: tensor(0.1458)\n",
      "1530 Traning Loss: tensor(0.1458)\n",
      "1531 Traning Loss: tensor(0.1457)\n",
      "1532 Traning Loss: tensor(0.1459)\n",
      "1533 Traning Loss: tensor(0.1450)\n",
      "1534 Traning Loss: tensor(0.1464)\n",
      "1535 Traning Loss: tensor(0.1454)\n",
      "1536 Traning Loss: tensor(0.1452)\n",
      "1537 Traning Loss: tensor(0.1464)\n",
      "1538 Traning Loss: tensor(0.1462)\n",
      "1539 Traning Loss: tensor(0.1455)\n",
      "1540 Traning Loss: tensor(0.1461)\n",
      "1541 Traning Loss: tensor(0.1457)\n",
      "1542 Traning Loss: tensor(0.1462)\n",
      "1543 Traning Loss: tensor(0.1453)\n",
      "1544 Traning Loss: tensor(0.1459)\n",
      "1545 Traning Loss: tensor(0.1454)\n",
      "1546 Traning Loss: tensor(0.1460)\n",
      "1547 Traning Loss: tensor(0.1469)\n",
      "1548 Traning Loss: tensor(0.1455)\n",
      "1549 Traning Loss: tensor(0.1455)\n",
      "1550 Traning Loss: tensor(0.1455)\n",
      "1551 Traning Loss: tensor(0.1456)\n",
      "1552 Traning Loss: tensor(0.1453)\n",
      "1553 Traning Loss: tensor(0.1449)\n",
      "1554 Traning Loss: tensor(0.1463)\n",
      "1555 Traning Loss: tensor(0.1456)\n",
      "1556 Traning Loss: tensor(0.1452)\n",
      "1557 Traning Loss: tensor(0.1456)\n",
      "1558 Traning Loss: tensor(0.1456)\n",
      "1559 Traning Loss: tensor(0.1460)\n",
      "1560 Traning Loss: tensor(0.1449)\n",
      "1561 Traning Loss: tensor(0.1452)\n",
      "1562 Traning Loss: tensor(0.1455)\n",
      "1563 Traning Loss: tensor(0.1451)\n",
      "1564 Traning Loss: tensor(0.1455)\n",
      "1565 Traning Loss: tensor(0.1455)\n",
      "1566 Traning Loss: tensor(0.1460)\n",
      "1567 Traning Loss: tensor(0.1459)\n",
      "1568 Traning Loss: tensor(0.1454)\n",
      "1569 Traning Loss: tensor(0.1456)\n",
      "1570 Traning Loss: tensor(0.1454)\n",
      "1571 Traning Loss: tensor(0.1456)\n",
      "1572 Traning Loss: tensor(0.1458)\n",
      "1573 Traning Loss: tensor(0.1449)\n",
      "1574 Traning Loss: tensor(0.1455)\n",
      "1575 Traning Loss: tensor(0.1458)\n",
      "1576 Traning Loss: tensor(0.1449)\n",
      "1577 Traning Loss: tensor(0.1444)\n",
      "1578 Traning Loss: tensor(0.1449)\n",
      "1579 Traning Loss: tensor(0.1462)\n",
      "1580 Traning Loss: tensor(0.1449)\n",
      "1581 Traning Loss: tensor(0.1451)\n",
      "1582 Traning Loss: tensor(0.1461)\n",
      "1583 Traning Loss: tensor(0.1445)\n",
      "1584 Traning Loss: tensor(0.1443)\n",
      "1585 Traning Loss: tensor(0.1453)\n",
      "1586 Traning Loss: tensor(0.1446)\n",
      "1587 Traning Loss: tensor(0.1447)\n",
      "1588 Traning Loss: tensor(0.1440)\n",
      "1589 Traning Loss: tensor(0.1450)\n",
      "1590 Traning Loss: tensor(0.1447)\n",
      "1591 Traning Loss: tensor(0.1448)\n",
      "1592 Traning Loss: tensor(0.1446)\n",
      "1593 Traning Loss: tensor(0.1443)\n",
      "1594 Traning Loss: tensor(0.1448)\n",
      "1595 Traning Loss: tensor(0.1446)\n",
      "1596 Traning Loss: tensor(0.1449)\n",
      "1597 Traning Loss: tensor(0.1438)\n",
      "1598 Traning Loss: tensor(0.1448)\n",
      "1599 Traning Loss: tensor(0.1444)\n",
      "1600 Traning Loss: tensor(0.1444)\n",
      "1601 Traning Loss: tensor(0.1450)\n",
      "1602 Traning Loss: tensor(0.1449)\n",
      "1603 Traning Loss: tensor(0.1443)\n",
      "1604 Traning Loss: tensor(0.1445)\n",
      "1605 Traning Loss: tensor(0.1450)\n",
      "1606 Traning Loss: tensor(0.1450)\n",
      "1607 Traning Loss: tensor(0.1446)\n",
      "1608 Traning Loss: tensor(0.1446)\n",
      "1609 Traning Loss: tensor(0.1445)\n",
      "1610 Traning Loss: tensor(0.1448)\n",
      "1611 Traning Loss: tensor(0.1453)\n",
      "1612 Traning Loss: tensor(0.1440)\n",
      "1613 Traning Loss: tensor(0.1443)\n",
      "1614 Traning Loss: tensor(0.1448)\n",
      "1615 Traning Loss: tensor(0.1443)\n",
      "1616 Traning Loss: tensor(0.1434)\n",
      "1617 Traning Loss: tensor(0.1447)\n",
      "1618 Traning Loss: tensor(0.1447)\n",
      "1619 Traning Loss: tensor(0.1448)\n",
      "1620 Traning Loss: tensor(0.1448)\n",
      "1621 Traning Loss: tensor(0.1452)\n",
      "1622 Traning Loss: tensor(0.1444)\n",
      "1623 Traning Loss: tensor(0.1432)\n",
      "1624 Traning Loss: tensor(0.1438)\n",
      "1625 Traning Loss: tensor(0.1441)\n",
      "1626 Traning Loss: tensor(0.1448)\n",
      "1627 Traning Loss: tensor(0.1444)\n",
      "1628 Traning Loss: tensor(0.1448)\n",
      "1629 Traning Loss: tensor(0.1441)\n",
      "1630 Traning Loss: tensor(0.1447)\n",
      "1631 Traning Loss: tensor(0.1446)\n",
      "1632 Traning Loss: tensor(0.1449)\n",
      "1633 Traning Loss: tensor(0.1443)\n",
      "1634 Traning Loss: tensor(0.1446)\n",
      "1635 Traning Loss: tensor(0.1442)\n",
      "1636 Traning Loss: tensor(0.1434)\n",
      "1637 Traning Loss: tensor(0.1446)\n",
      "1638 Traning Loss: tensor(0.1437)\n",
      "1639 Traning Loss: tensor(0.1438)\n",
      "1640 Traning Loss: tensor(0.1440)\n",
      "1641 Traning Loss: tensor(0.1442)\n",
      "1642 Traning Loss: tensor(0.1438)\n",
      "1643 Traning Loss: tensor(0.1441)\n",
      "1644 Traning Loss: tensor(0.1431)\n",
      "1645 Traning Loss: tensor(0.1440)\n",
      "1646 Traning Loss: tensor(0.1438)\n",
      "1647 Traning Loss: tensor(0.1446)\n",
      "1648 Traning Loss: tensor(0.1445)\n",
      "1649 Traning Loss: tensor(0.1442)\n",
      "1650 Traning Loss: tensor(0.1442)\n",
      "1651 Traning Loss: tensor(0.1442)\n",
      "1652 Traning Loss: tensor(0.1441)\n",
      "1653 Traning Loss: tensor(0.1437)\n",
      "1654 Traning Loss: tensor(0.1449)\n",
      "1655 Traning Loss: tensor(0.1433)\n",
      "1656 Traning Loss: tensor(0.1436)\n",
      "1657 Traning Loss: tensor(0.1435)\n",
      "1658 Traning Loss: tensor(0.1434)\n",
      "1659 Traning Loss: tensor(0.1445)\n",
      "1660 Traning Loss: tensor(0.1439)\n",
      "1661 Traning Loss: tensor(0.1443)\n",
      "1662 Traning Loss: tensor(0.1446)\n",
      "1663 Traning Loss: tensor(0.1434)\n",
      "1664 Traning Loss: tensor(0.1437)\n",
      "1665 Traning Loss: tensor(0.1440)\n",
      "1666 Traning Loss: tensor(0.1439)\n",
      "1667 Traning Loss: tensor(0.1434)\n",
      "1668 Traning Loss: tensor(0.1432)\n",
      "1669 Traning Loss: tensor(0.1433)\n",
      "1670 Traning Loss: tensor(0.1436)\n",
      "1671 Traning Loss: tensor(0.1444)\n",
      "1672 Traning Loss: tensor(0.1445)\n",
      "1673 Traning Loss: tensor(0.1438)\n",
      "1674 Traning Loss: tensor(0.1449)\n",
      "1675 Traning Loss: tensor(0.1441)\n",
      "1676 Traning Loss: tensor(0.1436)\n",
      "1677 Traning Loss: tensor(0.1442)\n",
      "1678 Traning Loss: tensor(0.1431)\n",
      "1679 Traning Loss: tensor(0.1437)\n",
      "1680 Traning Loss: tensor(0.1431)\n",
      "1681 Traning Loss: tensor(0.1438)\n",
      "1682 Traning Loss: tensor(0.1434)\n",
      "1683 Traning Loss: tensor(0.1432)\n",
      "1684 Traning Loss: tensor(0.1431)\n",
      "1685 Traning Loss: tensor(0.1432)\n",
      "1686 Traning Loss: tensor(0.1426)\n",
      "1687 Traning Loss: tensor(0.1443)\n",
      "1688 Traning Loss: tensor(0.1440)\n",
      "1689 Traning Loss: tensor(0.1430)\n",
      "1690 Traning Loss: tensor(0.1432)\n",
      "1691 Traning Loss: tensor(0.1429)\n",
      "1692 Traning Loss: tensor(0.1439)\n",
      "1693 Traning Loss: tensor(0.1432)\n",
      "1694 Traning Loss: tensor(0.1438)\n",
      "1695 Traning Loss: tensor(0.1442)\n",
      "1696 Traning Loss: tensor(0.1425)\n",
      "1697 Traning Loss: tensor(0.1437)\n",
      "1698 Traning Loss: tensor(0.1440)\n",
      "1699 Traning Loss: tensor(0.1439)\n",
      "1700 Traning Loss: tensor(0.1428)\n",
      "1701 Traning Loss: tensor(0.1433)\n",
      "1702 Traning Loss: tensor(0.1436)\n",
      "1703 Traning Loss: tensor(0.1431)\n",
      "1704 Traning Loss: tensor(0.1432)\n",
      "1705 Traning Loss: tensor(0.1436)\n",
      "1706 Traning Loss: tensor(0.1425)\n",
      "1707 Traning Loss: tensor(0.1438)\n",
      "1708 Traning Loss: tensor(0.1434)\n",
      "1709 Traning Loss: tensor(0.1429)\n",
      "1710 Traning Loss: tensor(0.1431)\n",
      "1711 Traning Loss: tensor(0.1429)\n",
      "1712 Traning Loss: tensor(0.1430)\n",
      "1713 Traning Loss: tensor(0.1429)\n",
      "1714 Traning Loss: tensor(0.1439)\n",
      "1715 Traning Loss: tensor(0.1430)\n",
      "1716 Traning Loss: tensor(0.1436)\n",
      "1717 Traning Loss: tensor(0.1428)\n",
      "1718 Traning Loss: tensor(0.1427)\n",
      "1719 Traning Loss: tensor(0.1435)\n",
      "1720 Traning Loss: tensor(0.1429)\n",
      "1721 Traning Loss: tensor(0.1429)\n",
      "1722 Traning Loss: tensor(0.1442)\n",
      "1723 Traning Loss: tensor(0.1420)\n",
      "1724 Traning Loss: tensor(0.1426)\n",
      "1725 Traning Loss: tensor(0.1425)\n",
      "1726 Traning Loss: tensor(0.1429)\n",
      "1727 Traning Loss: tensor(0.1431)\n",
      "1728 Traning Loss: tensor(0.1423)\n",
      "1729 Traning Loss: tensor(0.1428)\n",
      "1730 Traning Loss: tensor(0.1434)\n",
      "1731 Traning Loss: tensor(0.1427)\n",
      "1732 Traning Loss: tensor(0.1427)\n",
      "1733 Traning Loss: tensor(0.1432)\n",
      "1734 Traning Loss: tensor(0.1426)\n",
      "1735 Traning Loss: tensor(0.1427)\n",
      "1736 Traning Loss: tensor(0.1428)\n",
      "1737 Traning Loss: tensor(0.1423)\n",
      "1738 Traning Loss: tensor(0.1431)\n",
      "1739 Traning Loss: tensor(0.1431)\n",
      "1740 Traning Loss: tensor(0.1423)\n",
      "1741 Traning Loss: tensor(0.1430)\n",
      "1742 Traning Loss: tensor(0.1428)\n",
      "1743 Traning Loss: tensor(0.1432)\n",
      "1744 Traning Loss: tensor(0.1429)\n",
      "1745 Traning Loss: tensor(0.1427)\n",
      "1746 Traning Loss: tensor(0.1429)\n",
      "1747 Traning Loss: tensor(0.1435)\n",
      "1748 Traning Loss: tensor(0.1428)\n",
      "1749 Traning Loss: tensor(0.1427)\n",
      "1750 Traning Loss: tensor(0.1426)\n",
      "1751 Traning Loss: tensor(0.1432)\n",
      "1752 Traning Loss: tensor(0.1416)\n",
      "1753 Traning Loss: tensor(0.1433)\n",
      "1754 Traning Loss: tensor(0.1426)\n",
      "1755 Traning Loss: tensor(0.1426)\n",
      "1756 Traning Loss: tensor(0.1436)\n",
      "1757 Traning Loss: tensor(0.1429)\n",
      "1758 Traning Loss: tensor(0.1416)\n",
      "1759 Traning Loss: tensor(0.1422)\n",
      "1760 Traning Loss: tensor(0.1429)\n",
      "1761 Traning Loss: tensor(0.1425)\n",
      "1762 Traning Loss: tensor(0.1428)\n",
      "1763 Traning Loss: tensor(0.1426)\n",
      "1764 Traning Loss: tensor(0.1425)\n",
      "1765 Traning Loss: tensor(0.1420)\n",
      "1766 Traning Loss: tensor(0.1425)\n",
      "1767 Traning Loss: tensor(0.1417)\n",
      "1768 Traning Loss: tensor(0.1432)\n",
      "1769 Traning Loss: tensor(0.1422)\n",
      "1770 Traning Loss: tensor(0.1420)\n",
      "1771 Traning Loss: tensor(0.1430)\n",
      "1772 Traning Loss: tensor(0.1425)\n",
      "1773 Traning Loss: tensor(0.1428)\n",
      "1774 Traning Loss: tensor(0.1429)\n",
      "1775 Traning Loss: tensor(0.1422)\n",
      "1776 Traning Loss: tensor(0.1422)\n",
      "1777 Traning Loss: tensor(0.1423)\n",
      "1778 Traning Loss: tensor(0.1427)\n",
      "1779 Traning Loss: tensor(0.1425)\n",
      "1780 Traning Loss: tensor(0.1421)\n",
      "1781 Traning Loss: tensor(0.1428)\n",
      "1782 Traning Loss: tensor(0.1424)\n",
      "1783 Traning Loss: tensor(0.1421)\n",
      "1784 Traning Loss: tensor(0.1432)\n",
      "1785 Traning Loss: tensor(0.1419)\n",
      "1786 Traning Loss: tensor(0.1416)\n",
      "1787 Traning Loss: tensor(0.1421)\n",
      "1788 Traning Loss: tensor(0.1421)\n",
      "1789 Traning Loss: tensor(0.1428)\n",
      "1790 Traning Loss: tensor(0.1421)\n",
      "1791 Traning Loss: tensor(0.1420)\n",
      "1792 Traning Loss: tensor(0.1425)\n",
      "1793 Traning Loss: tensor(0.1425)\n",
      "1794 Traning Loss: tensor(0.1427)\n",
      "1795 Traning Loss: tensor(0.1418)\n",
      "1796 Traning Loss: tensor(0.1423)\n",
      "1797 Traning Loss: tensor(0.1411)\n",
      "1798 Traning Loss: tensor(0.1424)\n",
      "1799 Traning Loss: tensor(0.1418)\n",
      "1800 Traning Loss: tensor(0.1424)\n",
      "1801 Traning Loss: tensor(0.1415)\n",
      "1802 Traning Loss: tensor(0.1412)\n",
      "1803 Traning Loss: tensor(0.1427)\n",
      "1804 Traning Loss: tensor(0.1420)\n",
      "1805 Traning Loss: tensor(0.1424)\n",
      "1806 Traning Loss: tensor(0.1414)\n",
      "1807 Traning Loss: tensor(0.1423)\n",
      "1808 Traning Loss: tensor(0.1424)\n",
      "1809 Traning Loss: tensor(0.1430)\n",
      "1810 Traning Loss: tensor(0.1416)\n",
      "1811 Traning Loss: tensor(0.1423)\n",
      "1812 Traning Loss: tensor(0.1424)\n",
      "1813 Traning Loss: tensor(0.1421)\n",
      "1814 Traning Loss: tensor(0.1419)\n",
      "1815 Traning Loss: tensor(0.1419)\n",
      "1816 Traning Loss: tensor(0.1411)\n",
      "1817 Traning Loss: tensor(0.1424)\n",
      "1818 Traning Loss: tensor(0.1420)\n",
      "1819 Traning Loss: tensor(0.1418)\n",
      "1820 Traning Loss: tensor(0.1428)\n",
      "1821 Traning Loss: tensor(0.1415)\n",
      "1822 Traning Loss: tensor(0.1417)\n",
      "1823 Traning Loss: tensor(0.1418)\n",
      "1824 Traning Loss: tensor(0.1421)\n",
      "1825 Traning Loss: tensor(0.1418)\n",
      "1826 Traning Loss: tensor(0.1417)\n",
      "1827 Traning Loss: tensor(0.1419)\n",
      "1828 Traning Loss: tensor(0.1410)\n",
      "1829 Traning Loss: tensor(0.1408)\n",
      "1830 Traning Loss: tensor(0.1424)\n",
      "1831 Traning Loss: tensor(0.1414)\n",
      "1832 Traning Loss: tensor(0.1413)\n",
      "1833 Traning Loss: tensor(0.1417)\n",
      "1834 Traning Loss: tensor(0.1411)\n",
      "1835 Traning Loss: tensor(0.1425)\n",
      "1836 Traning Loss: tensor(0.1421)\n",
      "1837 Traning Loss: tensor(0.1419)\n",
      "1838 Traning Loss: tensor(0.1426)\n",
      "1839 Traning Loss: tensor(0.1420)\n",
      "1840 Traning Loss: tensor(0.1419)\n",
      "1841 Traning Loss: tensor(0.1422)\n",
      "1842 Traning Loss: tensor(0.1420)\n",
      "1843 Traning Loss: tensor(0.1420)\n",
      "1844 Traning Loss: tensor(0.1415)\n",
      "1845 Traning Loss: tensor(0.1420)\n",
      "1846 Traning Loss: tensor(0.1414)\n",
      "1847 Traning Loss: tensor(0.1407)\n",
      "1848 Traning Loss: tensor(0.1413)\n",
      "1849 Traning Loss: tensor(0.1415)\n",
      "1850 Traning Loss: tensor(0.1410)\n",
      "1851 Traning Loss: tensor(0.1410)\n",
      "1852 Traning Loss: tensor(0.1411)\n",
      "1853 Traning Loss: tensor(0.1414)\n",
      "1854 Traning Loss: tensor(0.1405)\n",
      "1855 Traning Loss: tensor(0.1411)\n",
      "1856 Traning Loss: tensor(0.1408)\n",
      "1857 Traning Loss: tensor(0.1410)\n",
      "1858 Traning Loss: tensor(0.1406)\n",
      "1859 Traning Loss: tensor(0.1423)\n",
      "1860 Traning Loss: tensor(0.1423)\n",
      "1861 Traning Loss: tensor(0.1418)\n",
      "1862 Traning Loss: tensor(0.1408)\n",
      "1863 Traning Loss: tensor(0.1421)\n",
      "1864 Traning Loss: tensor(0.1410)\n",
      "1865 Traning Loss: tensor(0.1414)\n",
      "1866 Traning Loss: tensor(0.1414)\n",
      "1867 Traning Loss: tensor(0.1409)\n",
      "1868 Traning Loss: tensor(0.1411)\n",
      "1869 Traning Loss: tensor(0.1420)\n",
      "1870 Traning Loss: tensor(0.1408)\n",
      "1871 Traning Loss: tensor(0.1405)\n",
      "1872 Traning Loss: tensor(0.1410)\n",
      "1873 Traning Loss: tensor(0.1414)\n",
      "1874 Traning Loss: tensor(0.1412)\n",
      "1875 Traning Loss: tensor(0.1401)\n",
      "1876 Traning Loss: tensor(0.1418)\n",
      "1877 Traning Loss: tensor(0.1401)\n",
      "1878 Traning Loss: tensor(0.1406)\n",
      "1879 Traning Loss: tensor(0.1399)\n",
      "1880 Traning Loss: tensor(0.1412)\n",
      "1881 Traning Loss: tensor(0.1418)\n",
      "1882 Traning Loss: tensor(0.1406)\n",
      "1883 Traning Loss: tensor(0.1410)\n",
      "1884 Traning Loss: tensor(0.1416)\n",
      "1885 Traning Loss: tensor(0.1412)\n",
      "1886 Traning Loss: tensor(0.1410)\n",
      "1887 Traning Loss: tensor(0.1417)\n",
      "1888 Traning Loss: tensor(0.1420)\n",
      "1889 Traning Loss: tensor(0.1415)\n",
      "1890 Traning Loss: tensor(0.1410)\n",
      "1891 Traning Loss: tensor(0.1411)\n",
      "1892 Traning Loss: tensor(0.1411)\n",
      "1893 Traning Loss: tensor(0.1408)\n",
      "1894 Traning Loss: tensor(0.1408)\n",
      "1895 Traning Loss: tensor(0.1406)\n",
      "1896 Traning Loss: tensor(0.1404)\n",
      "1897 Traning Loss: tensor(0.1409)\n",
      "1898 Traning Loss: tensor(0.1418)\n",
      "1899 Traning Loss: tensor(0.1415)\n",
      "1900 Traning Loss: tensor(0.1408)\n",
      "1901 Traning Loss: tensor(0.1416)\n",
      "1902 Traning Loss: tensor(0.1412)\n",
      "1903 Traning Loss: tensor(0.1413)\n",
      "1904 Traning Loss: tensor(0.1403)\n",
      "1905 Traning Loss: tensor(0.1407)\n",
      "1906 Traning Loss: tensor(0.1410)\n",
      "1907 Traning Loss: tensor(0.1404)\n",
      "1908 Traning Loss: tensor(0.1410)\n",
      "1909 Traning Loss: tensor(0.1407)\n",
      "1910 Traning Loss: tensor(0.1419)\n",
      "1911 Traning Loss: tensor(0.1419)\n",
      "1912 Traning Loss: tensor(0.1411)\n",
      "1913 Traning Loss: tensor(0.1406)\n",
      "1914 Traning Loss: tensor(0.1411)\n",
      "1915 Traning Loss: tensor(0.1407)\n",
      "1916 Traning Loss: tensor(0.1403)\n",
      "1917 Traning Loss: tensor(0.1409)\n",
      "1918 Traning Loss: tensor(0.1408)\n",
      "1919 Traning Loss: tensor(0.1418)\n",
      "1920 Traning Loss: tensor(0.1408)\n",
      "1921 Traning Loss: tensor(0.1404)\n",
      "1922 Traning Loss: tensor(0.1406)\n",
      "1923 Traning Loss: tensor(0.1405)\n",
      "1924 Traning Loss: tensor(0.1410)\n",
      "1925 Traning Loss: tensor(0.1411)\n",
      "1926 Traning Loss: tensor(0.1405)\n",
      "1927 Traning Loss: tensor(0.1405)\n",
      "1928 Traning Loss: tensor(0.1416)\n",
      "1929 Traning Loss: tensor(0.1401)\n",
      "1930 Traning Loss: tensor(0.1395)\n",
      "1931 Traning Loss: tensor(0.1403)\n",
      "1932 Traning Loss: tensor(0.1403)\n",
      "1933 Traning Loss: tensor(0.1405)\n",
      "1934 Traning Loss: tensor(0.1404)\n",
      "1935 Traning Loss: tensor(0.1403)\n",
      "1936 Traning Loss: tensor(0.1399)\n",
      "1937 Traning Loss: tensor(0.1411)\n",
      "1938 Traning Loss: tensor(0.1405)\n",
      "1939 Traning Loss: tensor(0.1407)\n",
      "1940 Traning Loss: tensor(0.1404)\n",
      "1941 Traning Loss: tensor(0.1404)\n",
      "1942 Traning Loss: tensor(0.1405)\n",
      "1943 Traning Loss: tensor(0.1406)\n",
      "1944 Traning Loss: tensor(0.1387)\n",
      "1945 Traning Loss: tensor(0.1403)\n",
      "1946 Traning Loss: tensor(0.1399)\n",
      "1947 Traning Loss: tensor(0.1403)\n",
      "1948 Traning Loss: tensor(0.1406)\n",
      "1949 Traning Loss: tensor(0.1410)\n",
      "1950 Traning Loss: tensor(0.1403)\n",
      "1951 Traning Loss: tensor(0.1404)\n",
      "1952 Traning Loss: tensor(0.1407)\n",
      "1953 Traning Loss: tensor(0.1413)\n",
      "1954 Traning Loss: tensor(0.1414)\n",
      "1955 Traning Loss: tensor(0.1397)\n",
      "1956 Traning Loss: tensor(0.1409)\n",
      "1957 Traning Loss: tensor(0.1401)\n",
      "1958 Traning Loss: tensor(0.1398)\n",
      "1959 Traning Loss: tensor(0.1392)\n",
      "1960 Traning Loss: tensor(0.1400)\n",
      "1961 Traning Loss: tensor(0.1398)\n",
      "1962 Traning Loss: tensor(0.1414)\n",
      "1963 Traning Loss: tensor(0.1399)\n",
      "1964 Traning Loss: tensor(0.1406)\n",
      "1965 Traning Loss: tensor(0.1393)\n",
      "1966 Traning Loss: tensor(0.1413)\n",
      "1967 Traning Loss: tensor(0.1406)\n",
      "1968 Traning Loss: tensor(0.1402)\n",
      "1969 Traning Loss: tensor(0.1401)\n",
      "1970 Traning Loss: tensor(0.1403)\n",
      "1971 Traning Loss: tensor(0.1399)\n",
      "1972 Traning Loss: tensor(0.1404)\n",
      "1973 Traning Loss: tensor(0.1398)\n",
      "1974 Traning Loss: tensor(0.1407)\n",
      "1975 Traning Loss: tensor(0.1397)\n",
      "1976 Traning Loss: tensor(0.1410)\n",
      "1977 Traning Loss: tensor(0.1393)\n",
      "1978 Traning Loss: tensor(0.1407)\n",
      "1979 Traning Loss: tensor(0.1398)\n",
      "1980 Traning Loss: tensor(0.1397)\n",
      "1981 Traning Loss: tensor(0.1405)\n",
      "1982 Traning Loss: tensor(0.1407)\n",
      "1983 Traning Loss: tensor(0.1406)\n",
      "1984 Traning Loss: tensor(0.1399)\n",
      "1985 Traning Loss: tensor(0.1404)\n",
      "1986 Traning Loss: tensor(0.1396)\n",
      "1987 Traning Loss: tensor(0.1395)\n",
      "1988 Traning Loss: tensor(0.1392)\n",
      "1989 Traning Loss: tensor(0.1403)\n",
      "1990 Traning Loss: tensor(0.1393)\n",
      "1991 Traning Loss: tensor(0.1404)\n",
      "1992 Traning Loss: tensor(0.1402)\n",
      "1993 Traning Loss: tensor(0.1402)\n",
      "1994 Traning Loss: tensor(0.1401)\n",
      "1995 Traning Loss: tensor(0.1402)\n",
      "1996 Traning Loss: tensor(0.1397)\n",
      "1997 Traning Loss: tensor(0.1403)\n",
      "1998 Traning Loss: tensor(0.1395)\n",
      "1999 Traning Loss: tensor(0.1400)\n",
      "2000 Traning Loss: tensor(0.1390)\n",
      "2001 Traning Loss: tensor(0.1402)\n",
      "2002 Traning Loss: tensor(0.1394)\n",
      "2003 Traning Loss: tensor(0.1402)\n",
      "2004 Traning Loss: tensor(0.1392)\n",
      "2005 Traning Loss: tensor(0.1410)\n",
      "2006 Traning Loss: tensor(0.1395)\n",
      "2007 Traning Loss: tensor(0.1396)\n",
      "2008 Traning Loss: tensor(0.1401)\n",
      "2009 Traning Loss: tensor(0.1403)\n",
      "2010 Traning Loss: tensor(0.1397)\n",
      "2011 Traning Loss: tensor(0.1395)\n",
      "2012 Traning Loss: tensor(0.1396)\n",
      "2013 Traning Loss: tensor(0.1402)\n",
      "2014 Traning Loss: tensor(0.1397)\n",
      "2015 Traning Loss: tensor(0.1392)\n",
      "2016 Traning Loss: tensor(0.1403)\n",
      "2017 Traning Loss: tensor(0.1399)\n",
      "2018 Traning Loss: tensor(0.1403)\n",
      "2019 Traning Loss: tensor(0.1403)\n",
      "2020 Traning Loss: tensor(0.1398)\n",
      "2021 Traning Loss: tensor(0.1391)\n",
      "2022 Traning Loss: tensor(0.1400)\n",
      "2023 Traning Loss: tensor(0.1398)\n",
      "2024 Traning Loss: tensor(0.1396)\n",
      "2025 Traning Loss: tensor(0.1392)\n",
      "2026 Traning Loss: tensor(0.1398)\n",
      "2027 Traning Loss: tensor(0.1395)\n",
      "2028 Traning Loss: tensor(0.1400)\n",
      "2029 Traning Loss: tensor(0.1392)\n",
      "2030 Traning Loss: tensor(0.1392)\n",
      "2031 Traning Loss: tensor(0.1403)\n",
      "2032 Traning Loss: tensor(0.1406)\n",
      "2033 Traning Loss: tensor(0.1403)\n",
      "2034 Traning Loss: tensor(0.1395)\n",
      "2035 Traning Loss: tensor(0.1400)\n",
      "2036 Traning Loss: tensor(0.1397)\n",
      "2037 Traning Loss: tensor(0.1397)\n",
      "2038 Traning Loss: tensor(0.1395)\n",
      "2039 Traning Loss: tensor(0.1407)\n",
      "2040 Traning Loss: tensor(0.1398)\n",
      "2041 Traning Loss: tensor(0.1408)\n",
      "2042 Traning Loss: tensor(0.1387)\n",
      "2043 Traning Loss: tensor(0.1394)\n",
      "2044 Traning Loss: tensor(0.1390)\n",
      "2045 Traning Loss: tensor(0.1399)\n",
      "2046 Traning Loss: tensor(0.1393)\n",
      "2047 Traning Loss: tensor(0.1392)\n",
      "2048 Traning Loss: tensor(0.1393)\n",
      "2049 Traning Loss: tensor(0.1393)\n",
      "2050 Traning Loss: tensor(0.1400)\n",
      "2051 Traning Loss: tensor(0.1400)\n",
      "2052 Traning Loss: tensor(0.1397)\n",
      "2053 Traning Loss: tensor(0.1383)\n",
      "2054 Traning Loss: tensor(0.1391)\n",
      "2055 Traning Loss: tensor(0.1390)\n",
      "2056 Traning Loss: tensor(0.1387)\n",
      "2057 Traning Loss: tensor(0.1391)\n",
      "2058 Traning Loss: tensor(0.1394)\n",
      "2059 Traning Loss: tensor(0.1391)\n",
      "2060 Traning Loss: tensor(0.1393)\n",
      "2061 Traning Loss: tensor(0.1392)\n",
      "2062 Traning Loss: tensor(0.1405)\n",
      "2063 Traning Loss: tensor(0.1388)\n",
      "2064 Traning Loss: tensor(0.1384)\n",
      "2065 Traning Loss: tensor(0.1392)\n",
      "2066 Traning Loss: tensor(0.1403)\n",
      "2067 Traning Loss: tensor(0.1391)\n",
      "2068 Traning Loss: tensor(0.1396)\n",
      "2069 Traning Loss: tensor(0.1390)\n",
      "2070 Traning Loss: tensor(0.1391)\n",
      "2071 Traning Loss: tensor(0.1391)\n",
      "2072 Traning Loss: tensor(0.1389)\n",
      "2073 Traning Loss: tensor(0.1392)\n",
      "2074 Traning Loss: tensor(0.1383)\n",
      "2075 Traning Loss: tensor(0.1394)\n",
      "2076 Traning Loss: tensor(0.1387)\n",
      "2077 Traning Loss: tensor(0.1377)\n",
      "2078 Traning Loss: tensor(0.1397)\n",
      "2079 Traning Loss: tensor(0.1386)\n",
      "2080 Traning Loss: tensor(0.1390)\n",
      "2081 Traning Loss: tensor(0.1393)\n",
      "2082 Traning Loss: tensor(0.1398)\n",
      "2083 Traning Loss: tensor(0.1380)\n",
      "2084 Traning Loss: tensor(0.1385)\n",
      "2085 Traning Loss: tensor(0.1390)\n",
      "2086 Traning Loss: tensor(0.1386)\n",
      "2087 Traning Loss: tensor(0.1380)\n",
      "2088 Traning Loss: tensor(0.1398)\n",
      "2089 Traning Loss: tensor(0.1401)\n",
      "2090 Traning Loss: tensor(0.1392)\n",
      "2091 Traning Loss: tensor(0.1390)\n",
      "2092 Traning Loss: tensor(0.1397)\n",
      "2093 Traning Loss: tensor(0.1382)\n",
      "2094 Traning Loss: tensor(0.1388)\n",
      "2095 Traning Loss: tensor(0.1393)\n",
      "2096 Traning Loss: tensor(0.1386)\n",
      "2097 Traning Loss: tensor(0.1393)\n",
      "2098 Traning Loss: tensor(0.1389)\n",
      "2099 Traning Loss: tensor(0.1388)\n",
      "2100 Traning Loss: tensor(0.1385)\n",
      "2101 Traning Loss: tensor(0.1390)\n",
      "2102 Traning Loss: tensor(0.1402)\n",
      "2103 Traning Loss: tensor(0.1389)\n",
      "2104 Traning Loss: tensor(0.1390)\n",
      "2105 Traning Loss: tensor(0.1397)\n",
      "2106 Traning Loss: tensor(0.1391)\n",
      "2107 Traning Loss: tensor(0.1384)\n",
      "2108 Traning Loss: tensor(0.1396)\n",
      "2109 Traning Loss: tensor(0.1380)\n",
      "2110 Traning Loss: tensor(0.1381)\n",
      "2111 Traning Loss: tensor(0.1389)\n",
      "2112 Traning Loss: tensor(0.1398)\n",
      "2113 Traning Loss: tensor(0.1384)\n",
      "2114 Traning Loss: tensor(0.1385)\n",
      "2115 Traning Loss: tensor(0.1390)\n",
      "2116 Traning Loss: tensor(0.1392)\n",
      "2117 Traning Loss: tensor(0.1392)\n",
      "2118 Traning Loss: tensor(0.1377)\n",
      "2119 Traning Loss: tensor(0.1396)\n",
      "2120 Traning Loss: tensor(0.1392)\n",
      "2121 Traning Loss: tensor(0.1374)\n",
      "2122 Traning Loss: tensor(0.1395)\n",
      "2123 Traning Loss: tensor(0.1392)\n",
      "2124 Traning Loss: tensor(0.1389)\n",
      "2125 Traning Loss: tensor(0.1388)\n",
      "2126 Traning Loss: tensor(0.1387)\n",
      "2127 Traning Loss: tensor(0.1389)\n",
      "2128 Traning Loss: tensor(0.1385)\n",
      "2129 Traning Loss: tensor(0.1389)\n",
      "2130 Traning Loss: tensor(0.1391)\n",
      "2131 Traning Loss: tensor(0.1388)\n",
      "2132 Traning Loss: tensor(0.1378)\n",
      "2133 Traning Loss: tensor(0.1383)\n",
      "2134 Traning Loss: tensor(0.1381)\n",
      "2135 Traning Loss: tensor(0.1387)\n",
      "2136 Traning Loss: tensor(0.1387)\n",
      "2137 Traning Loss: tensor(0.1399)\n",
      "2138 Traning Loss: tensor(0.1382)\n",
      "2139 Traning Loss: tensor(0.1376)\n",
      "2140 Traning Loss: tensor(0.1393)\n",
      "2141 Traning Loss: tensor(0.1385)\n",
      "2142 Traning Loss: tensor(0.1384)\n",
      "2143 Traning Loss: tensor(0.1384)\n",
      "2144 Traning Loss: tensor(0.1379)\n",
      "2145 Traning Loss: tensor(0.1387)\n",
      "2146 Traning Loss: tensor(0.1375)\n",
      "2147 Traning Loss: tensor(0.1387)\n",
      "2148 Traning Loss: tensor(0.1373)\n",
      "2149 Traning Loss: tensor(0.1388)\n",
      "2150 Traning Loss: tensor(0.1392)\n",
      "2151 Traning Loss: tensor(0.1388)\n",
      "2152 Traning Loss: tensor(0.1384)\n",
      "2153 Traning Loss: tensor(0.1384)\n",
      "2154 Traning Loss: tensor(0.1382)\n",
      "2155 Traning Loss: tensor(0.1387)\n",
      "2156 Traning Loss: tensor(0.1374)\n",
      "2157 Traning Loss: tensor(0.1381)\n",
      "2158 Traning Loss: tensor(0.1384)\n",
      "2159 Traning Loss: tensor(0.1386)\n",
      "2160 Traning Loss: tensor(0.1382)\n",
      "2161 Traning Loss: tensor(0.1385)\n",
      "2162 Traning Loss: tensor(0.1374)\n",
      "2163 Traning Loss: tensor(0.1386)\n",
      "2164 Traning Loss: tensor(0.1389)\n",
      "2165 Traning Loss: tensor(0.1388)\n",
      "2166 Traning Loss: tensor(0.1385)\n",
      "2167 Traning Loss: tensor(0.1383)\n",
      "2168 Traning Loss: tensor(0.1380)\n",
      "2169 Traning Loss: tensor(0.1386)\n",
      "2170 Traning Loss: tensor(0.1389)\n",
      "2171 Traning Loss: tensor(0.1388)\n",
      "2172 Traning Loss: tensor(0.1388)\n",
      "2173 Traning Loss: tensor(0.1382)\n",
      "2174 Traning Loss: tensor(0.1380)\n",
      "2175 Traning Loss: tensor(0.1385)\n",
      "2176 Traning Loss: tensor(0.1388)\n",
      "2177 Traning Loss: tensor(0.1379)\n",
      "2178 Traning Loss: tensor(0.1374)\n",
      "2179 Traning Loss: tensor(0.1386)\n",
      "2180 Traning Loss: tensor(0.1385)\n",
      "2181 Traning Loss: tensor(0.1384)\n",
      "2182 Traning Loss: tensor(0.1386)\n",
      "2183 Traning Loss: tensor(0.1376)\n",
      "2184 Traning Loss: tensor(0.1373)\n",
      "2185 Traning Loss: tensor(0.1374)\n",
      "2186 Traning Loss: tensor(0.1384)\n",
      "2187 Traning Loss: tensor(0.1384)\n",
      "2188 Traning Loss: tensor(0.1376)\n",
      "2189 Traning Loss: tensor(0.1385)\n",
      "2190 Traning Loss: tensor(0.1376)\n",
      "2191 Traning Loss: tensor(0.1381)\n",
      "2192 Traning Loss: tensor(0.1378)\n",
      "2193 Traning Loss: tensor(0.1383)\n",
      "2194 Traning Loss: tensor(0.1373)\n",
      "2195 Traning Loss: tensor(0.1385)\n",
      "2196 Traning Loss: tensor(0.1379)\n",
      "2197 Traning Loss: tensor(0.1369)\n",
      "2198 Traning Loss: tensor(0.1386)\n",
      "2199 Traning Loss: tensor(0.1376)\n",
      "2200 Traning Loss: tensor(0.1389)\n",
      "2201 Traning Loss: tensor(0.1375)\n",
      "2202 Traning Loss: tensor(0.1384)\n",
      "2203 Traning Loss: tensor(0.1388)\n",
      "2204 Traning Loss: tensor(0.1378)\n",
      "2205 Traning Loss: tensor(0.1385)\n",
      "2206 Traning Loss: tensor(0.1393)\n",
      "2207 Traning Loss: tensor(0.1388)\n",
      "2208 Traning Loss: tensor(0.1369)\n",
      "2209 Traning Loss: tensor(0.1378)\n",
      "2210 Traning Loss: tensor(0.1384)\n",
      "2211 Traning Loss: tensor(0.1377)\n",
      "2212 Traning Loss: tensor(0.1389)\n",
      "2213 Traning Loss: tensor(0.1372)\n",
      "2214 Traning Loss: tensor(0.1387)\n",
      "2215 Traning Loss: tensor(0.1379)\n",
      "2216 Traning Loss: tensor(0.1375)\n",
      "2217 Traning Loss: tensor(0.1380)\n",
      "2218 Traning Loss: tensor(0.1383)\n",
      "2219 Traning Loss: tensor(0.1381)\n",
      "2220 Traning Loss: tensor(0.1373)\n",
      "2221 Traning Loss: tensor(0.1379)\n",
      "2222 Traning Loss: tensor(0.1374)\n",
      "2223 Traning Loss: tensor(0.1379)\n",
      "2224 Traning Loss: tensor(0.1378)\n",
      "2225 Traning Loss: tensor(0.1386)\n",
      "2226 Traning Loss: tensor(0.1381)\n",
      "2227 Traning Loss: tensor(0.1376)\n",
      "2228 Traning Loss: tensor(0.1383)\n",
      "2229 Traning Loss: tensor(0.1378)\n",
      "2230 Traning Loss: tensor(0.1382)\n",
      "2231 Traning Loss: tensor(0.1368)\n",
      "2232 Traning Loss: tensor(0.1375)\n",
      "2233 Traning Loss: tensor(0.1381)\n",
      "2234 Traning Loss: tensor(0.1379)\n",
      "2235 Traning Loss: tensor(0.1386)\n",
      "2236 Traning Loss: tensor(0.1378)\n",
      "2237 Traning Loss: tensor(0.1382)\n",
      "2238 Traning Loss: tensor(0.1373)\n",
      "2239 Traning Loss: tensor(0.1375)\n",
      "2240 Traning Loss: tensor(0.1373)\n",
      "2241 Traning Loss: tensor(0.1370)\n",
      "2242 Traning Loss: tensor(0.1373)\n",
      "2243 Traning Loss: tensor(0.1376)\n",
      "2244 Traning Loss: tensor(0.1374)\n",
      "2245 Traning Loss: tensor(0.1376)\n",
      "2246 Traning Loss: tensor(0.1372)\n",
      "2247 Traning Loss: tensor(0.1373)\n",
      "2248 Traning Loss: tensor(0.1381)\n",
      "2249 Traning Loss: tensor(0.1378)\n",
      "2250 Traning Loss: tensor(0.1375)\n",
      "2251 Traning Loss: tensor(0.1361)\n",
      "2252 Traning Loss: tensor(0.1376)\n",
      "2253 Traning Loss: tensor(0.1371)\n",
      "2254 Traning Loss: tensor(0.1365)\n",
      "2255 Traning Loss: tensor(0.1386)\n",
      "2256 Traning Loss: tensor(0.1383)\n",
      "2257 Traning Loss: tensor(0.1381)\n",
      "2258 Traning Loss: tensor(0.1381)\n",
      "2259 Traning Loss: tensor(0.1367)\n",
      "2260 Traning Loss: tensor(0.1376)\n",
      "2261 Traning Loss: tensor(0.1368)\n",
      "2262 Traning Loss: tensor(0.1370)\n",
      "2263 Traning Loss: tensor(0.1387)\n",
      "2264 Traning Loss: tensor(0.1378)\n",
      "2265 Traning Loss: tensor(0.1380)\n",
      "2266 Traning Loss: tensor(0.1365)\n",
      "2267 Traning Loss: tensor(0.1379)\n",
      "2268 Traning Loss: tensor(0.1384)\n",
      "2269 Traning Loss: tensor(0.1374)\n",
      "2270 Traning Loss: tensor(0.1369)\n",
      "2271 Traning Loss: tensor(0.1367)\n",
      "2272 Traning Loss: tensor(0.1375)\n",
      "2273 Traning Loss: tensor(0.1375)\n",
      "2274 Traning Loss: tensor(0.1376)\n",
      "2275 Traning Loss: tensor(0.1374)\n",
      "2276 Traning Loss: tensor(0.1366)\n",
      "2277 Traning Loss: tensor(0.1373)\n",
      "2278 Traning Loss: tensor(0.1368)\n",
      "2279 Traning Loss: tensor(0.1364)\n",
      "2280 Traning Loss: tensor(0.1381)\n",
      "2281 Traning Loss: tensor(0.1377)\n",
      "2282 Traning Loss: tensor(0.1378)\n",
      "2283 Traning Loss: tensor(0.1369)\n",
      "2284 Traning Loss: tensor(0.1380)\n",
      "2285 Traning Loss: tensor(0.1366)\n",
      "2286 Traning Loss: tensor(0.1370)\n",
      "2287 Traning Loss: tensor(0.1369)\n",
      "2288 Traning Loss: tensor(0.1368)\n",
      "2289 Traning Loss: tensor(0.1374)\n",
      "2290 Traning Loss: tensor(0.1386)\n",
      "2291 Traning Loss: tensor(0.1372)\n",
      "2292 Traning Loss: tensor(0.1374)\n",
      "2293 Traning Loss: tensor(0.1367)\n",
      "2294 Traning Loss: tensor(0.1386)\n",
      "2295 Traning Loss: tensor(0.1368)\n",
      "2296 Traning Loss: tensor(0.1366)\n",
      "2297 Traning Loss: tensor(0.1375)\n",
      "2298 Traning Loss: tensor(0.1371)\n",
      "2299 Traning Loss: tensor(0.1378)\n",
      "2300 Traning Loss: tensor(0.1374)\n",
      "2301 Traning Loss: tensor(0.1374)\n",
      "2302 Traning Loss: tensor(0.1380)\n",
      "2303 Traning Loss: tensor(0.1378)\n",
      "2304 Traning Loss: tensor(0.1361)\n",
      "2305 Traning Loss: tensor(0.1368)\n",
      "2306 Traning Loss: tensor(0.1368)\n",
      "2307 Traning Loss: tensor(0.1365)\n",
      "2308 Traning Loss: tensor(0.1370)\n",
      "2309 Traning Loss: tensor(0.1365)\n",
      "2310 Traning Loss: tensor(0.1368)\n",
      "2311 Traning Loss: tensor(0.1372)\n",
      "2312 Traning Loss: tensor(0.1369)\n",
      "2313 Traning Loss: tensor(0.1365)\n",
      "2314 Traning Loss: tensor(0.1356)\n",
      "2315 Traning Loss: tensor(0.1372)\n",
      "2316 Traning Loss: tensor(0.1368)\n",
      "2317 Traning Loss: tensor(0.1373)\n",
      "2318 Traning Loss: tensor(0.1367)\n",
      "2319 Traning Loss: tensor(0.1368)\n",
      "2320 Traning Loss: tensor(0.1369)\n",
      "2321 Traning Loss: tensor(0.1385)\n",
      "2322 Traning Loss: tensor(0.1376)\n",
      "2323 Traning Loss: tensor(0.1372)\n",
      "2324 Traning Loss: tensor(0.1372)\n",
      "2325 Traning Loss: tensor(0.1374)\n",
      "2326 Traning Loss: tensor(0.1368)\n",
      "2327 Traning Loss: tensor(0.1372)\n",
      "2328 Traning Loss: tensor(0.1369)\n",
      "2329 Traning Loss: tensor(0.1377)\n",
      "2330 Traning Loss: tensor(0.1362)\n",
      "2331 Traning Loss: tensor(0.1370)\n",
      "2332 Traning Loss: tensor(0.1376)\n",
      "2333 Traning Loss: tensor(0.1365)\n",
      "2334 Traning Loss: tensor(0.1372)\n",
      "2335 Traning Loss: tensor(0.1373)\n",
      "2336 Traning Loss: tensor(0.1373)\n",
      "2337 Traning Loss: tensor(0.1371)\n",
      "2338 Traning Loss: tensor(0.1369)\n",
      "2339 Traning Loss: tensor(0.1366)\n",
      "2340 Traning Loss: tensor(0.1372)\n",
      "2341 Traning Loss: tensor(0.1369)\n",
      "2342 Traning Loss: tensor(0.1368)\n",
      "2343 Traning Loss: tensor(0.1361)\n",
      "2344 Traning Loss: tensor(0.1369)\n",
      "2345 Traning Loss: tensor(0.1362)\n",
      "2346 Traning Loss: tensor(0.1376)\n",
      "2347 Traning Loss: tensor(0.1371)\n",
      "2348 Traning Loss: tensor(0.1368)\n",
      "2349 Traning Loss: tensor(0.1370)\n",
      "2350 Traning Loss: tensor(0.1372)\n",
      "2351 Traning Loss: tensor(0.1369)\n",
      "2352 Traning Loss: tensor(0.1365)\n",
      "2353 Traning Loss: tensor(0.1370)\n",
      "2354 Traning Loss: tensor(0.1368)\n",
      "2355 Traning Loss: tensor(0.1369)\n",
      "2356 Traning Loss: tensor(0.1380)\n",
      "2357 Traning Loss: tensor(0.1372)\n",
      "2358 Traning Loss: tensor(0.1368)\n",
      "2359 Traning Loss: tensor(0.1366)\n",
      "2360 Traning Loss: tensor(0.1365)\n",
      "2361 Traning Loss: tensor(0.1361)\n",
      "2362 Traning Loss: tensor(0.1359)\n",
      "2363 Traning Loss: tensor(0.1371)\n",
      "2364 Traning Loss: tensor(0.1371)\n",
      "2365 Traning Loss: tensor(0.1356)\n",
      "2366 Traning Loss: tensor(0.1371)\n",
      "2367 Traning Loss: tensor(0.1366)\n",
      "2368 Traning Loss: tensor(0.1371)\n",
      "2369 Traning Loss: tensor(0.1370)\n",
      "2370 Traning Loss: tensor(0.1361)\n",
      "2371 Traning Loss: tensor(0.1364)\n",
      "2372 Traning Loss: tensor(0.1371)\n",
      "2373 Traning Loss: tensor(0.1355)\n",
      "2374 Traning Loss: tensor(0.1363)\n",
      "2375 Traning Loss: tensor(0.1365)\n",
      "2376 Traning Loss: tensor(0.1364)\n",
      "2377 Traning Loss: tensor(0.1369)\n",
      "2378 Traning Loss: tensor(0.1365)\n",
      "2379 Traning Loss: tensor(0.1372)\n",
      "2380 Traning Loss: tensor(0.1362)\n",
      "2381 Traning Loss: tensor(0.1368)\n",
      "2382 Traning Loss: tensor(0.1366)\n",
      "2383 Traning Loss: tensor(0.1358)\n",
      "2384 Traning Loss: tensor(0.1366)\n",
      "2385 Traning Loss: tensor(0.1364)\n",
      "2386 Traning Loss: tensor(0.1359)\n",
      "2387 Traning Loss: tensor(0.1359)\n",
      "2388 Traning Loss: tensor(0.1370)\n",
      "2389 Traning Loss: tensor(0.1363)\n",
      "2390 Traning Loss: tensor(0.1366)\n",
      "2391 Traning Loss: tensor(0.1365)\n",
      "2392 Traning Loss: tensor(0.1364)\n",
      "2393 Traning Loss: tensor(0.1366)\n",
      "2394 Traning Loss: tensor(0.1354)\n",
      "2395 Traning Loss: tensor(0.1364)\n",
      "2396 Traning Loss: tensor(0.1354)\n",
      "2397 Traning Loss: tensor(0.1358)\n",
      "2398 Traning Loss: tensor(0.1366)\n",
      "2399 Traning Loss: tensor(0.1367)\n",
      "2400 Traning Loss: tensor(0.1361)\n",
      "2401 Traning Loss: tensor(0.1364)\n",
      "2402 Traning Loss: tensor(0.1361)\n",
      "2403 Traning Loss: tensor(0.1365)\n",
      "2404 Traning Loss: tensor(0.1363)\n",
      "2405 Traning Loss: tensor(0.1367)\n",
      "2406 Traning Loss: tensor(0.1351)\n",
      "2407 Traning Loss: tensor(0.1365)\n",
      "2408 Traning Loss: tensor(0.1364)\n",
      "2409 Traning Loss: tensor(0.1370)\n",
      "2410 Traning Loss: tensor(0.1364)\n",
      "2411 Traning Loss: tensor(0.1360)\n",
      "2412 Traning Loss: tensor(0.1364)\n",
      "2413 Traning Loss: tensor(0.1370)\n",
      "2414 Traning Loss: tensor(0.1364)\n",
      "2415 Traning Loss: tensor(0.1364)\n",
      "2416 Traning Loss: tensor(0.1381)\n",
      "2417 Traning Loss: tensor(0.1371)\n",
      "2418 Traning Loss: tensor(0.1375)\n",
      "2419 Traning Loss: tensor(0.1367)\n",
      "2420 Traning Loss: tensor(0.1361)\n",
      "2421 Traning Loss: tensor(0.1366)\n",
      "2422 Traning Loss: tensor(0.1354)\n",
      "2423 Traning Loss: tensor(0.1366)\n",
      "2424 Traning Loss: tensor(0.1358)\n",
      "2425 Traning Loss: tensor(0.1362)\n",
      "2426 Traning Loss: tensor(0.1374)\n",
      "2427 Traning Loss: tensor(0.1363)\n",
      "2428 Traning Loss: tensor(0.1365)\n",
      "2429 Traning Loss: tensor(0.1361)\n",
      "2430 Traning Loss: tensor(0.1362)\n",
      "2431 Traning Loss: tensor(0.1360)\n",
      "2432 Traning Loss: tensor(0.1356)\n",
      "2433 Traning Loss: tensor(0.1358)\n",
      "2434 Traning Loss: tensor(0.1370)\n",
      "2435 Traning Loss: tensor(0.1349)\n",
      "2436 Traning Loss: tensor(0.1370)\n",
      "2437 Traning Loss: tensor(0.1357)\n",
      "2438 Traning Loss: tensor(0.1365)\n",
      "2439 Traning Loss: tensor(0.1359)\n",
      "2440 Traning Loss: tensor(0.1366)\n",
      "2441 Traning Loss: tensor(0.1357)\n",
      "2442 Traning Loss: tensor(0.1357)\n",
      "2443 Traning Loss: tensor(0.1360)\n",
      "2444 Traning Loss: tensor(0.1369)\n",
      "2445 Traning Loss: tensor(0.1359)\n",
      "2446 Traning Loss: tensor(0.1365)\n",
      "2447 Traning Loss: tensor(0.1357)\n",
      "2448 Traning Loss: tensor(0.1362)\n",
      "2449 Traning Loss: tensor(0.1343)\n",
      "2450 Traning Loss: tensor(0.1364)\n",
      "2451 Traning Loss: tensor(0.1362)\n",
      "2452 Traning Loss: tensor(0.1367)\n",
      "2453 Traning Loss: tensor(0.1357)\n",
      "2454 Traning Loss: tensor(0.1361)\n",
      "2455 Traning Loss: tensor(0.1362)\n",
      "2456 Traning Loss: tensor(0.1360)\n",
      "2457 Traning Loss: tensor(0.1352)\n",
      "2458 Traning Loss: tensor(0.1350)\n",
      "2459 Traning Loss: tensor(0.1348)\n",
      "2460 Traning Loss: tensor(0.1368)\n",
      "2461 Traning Loss: tensor(0.1363)\n",
      "2462 Traning Loss: tensor(0.1359)\n",
      "2463 Traning Loss: tensor(0.1358)\n",
      "2464 Traning Loss: tensor(0.1355)\n",
      "2465 Traning Loss: tensor(0.1362)\n",
      "2466 Traning Loss: tensor(0.1354)\n",
      "2467 Traning Loss: tensor(0.1374)\n",
      "2468 Traning Loss: tensor(0.1353)\n",
      "2469 Traning Loss: tensor(0.1359)\n",
      "2470 Traning Loss: tensor(0.1357)\n",
      "2471 Traning Loss: tensor(0.1370)\n",
      "2472 Traning Loss: tensor(0.1351)\n",
      "2473 Traning Loss: tensor(0.1362)\n",
      "2474 Traning Loss: tensor(0.1355)\n",
      "2475 Traning Loss: tensor(0.1347)\n",
      "2476 Traning Loss: tensor(0.1373)\n",
      "2477 Traning Loss: tensor(0.1360)\n",
      "2478 Traning Loss: tensor(0.1354)\n",
      "2479 Traning Loss: tensor(0.1355)\n",
      "2480 Traning Loss: tensor(0.1354)\n",
      "2481 Traning Loss: tensor(0.1351)\n",
      "2482 Traning Loss: tensor(0.1360)\n",
      "2483 Traning Loss: tensor(0.1358)\n",
      "2484 Traning Loss: tensor(0.1343)\n",
      "2485 Traning Loss: tensor(0.1358)\n",
      "2486 Traning Loss: tensor(0.1364)\n",
      "2487 Traning Loss: tensor(0.1359)\n",
      "2488 Traning Loss: tensor(0.1362)\n",
      "2489 Traning Loss: tensor(0.1348)\n",
      "2490 Traning Loss: tensor(0.1354)\n",
      "2491 Traning Loss: tensor(0.1350)\n",
      "2492 Traning Loss: tensor(0.1352)\n",
      "2493 Traning Loss: tensor(0.1348)\n",
      "2494 Traning Loss: tensor(0.1351)\n",
      "2495 Traning Loss: tensor(0.1362)\n",
      "2496 Traning Loss: tensor(0.1348)\n",
      "2497 Traning Loss: tensor(0.1358)\n",
      "2498 Traning Loss: tensor(0.1353)\n",
      "2499 Traning Loss: tensor(0.1346)\n",
      "2500 Traning Loss: tensor(0.1359)\n",
      "2501 Traning Loss: tensor(0.1355)\n",
      "2502 Traning Loss: tensor(0.1359)\n",
      "2503 Traning Loss: tensor(0.1355)\n",
      "2504 Traning Loss: tensor(0.1356)\n",
      "2505 Traning Loss: tensor(0.1363)\n",
      "2506 Traning Loss: tensor(0.1350)\n",
      "2507 Traning Loss: tensor(0.1356)\n",
      "2508 Traning Loss: tensor(0.1369)\n",
      "2509 Traning Loss: tensor(0.1351)\n",
      "2510 Traning Loss: tensor(0.1367)\n",
      "2511 Traning Loss: tensor(0.1359)\n",
      "2512 Traning Loss: tensor(0.1353)\n",
      "2513 Traning Loss: tensor(0.1354)\n",
      "2514 Traning Loss: tensor(0.1353)\n",
      "2515 Traning Loss: tensor(0.1355)\n",
      "2516 Traning Loss: tensor(0.1360)\n",
      "2517 Traning Loss: tensor(0.1356)\n",
      "2518 Traning Loss: tensor(0.1357)\n",
      "2519 Traning Loss: tensor(0.1355)\n",
      "2520 Traning Loss: tensor(0.1348)\n",
      "2521 Traning Loss: tensor(0.1363)\n",
      "2522 Traning Loss: tensor(0.1355)\n",
      "2523 Traning Loss: tensor(0.1347)\n",
      "2524 Traning Loss: tensor(0.1347)\n",
      "2525 Traning Loss: tensor(0.1354)\n",
      "2526 Traning Loss: tensor(0.1357)\n",
      "2527 Traning Loss: tensor(0.1352)\n",
      "2528 Traning Loss: tensor(0.1358)\n",
      "2529 Traning Loss: tensor(0.1351)\n",
      "2530 Traning Loss: tensor(0.1348)\n",
      "2531 Traning Loss: tensor(0.1344)\n",
      "2532 Traning Loss: tensor(0.1350)\n",
      "2533 Traning Loss: tensor(0.1357)\n",
      "2534 Traning Loss: tensor(0.1354)\n",
      "2535 Traning Loss: tensor(0.1356)\n",
      "2536 Traning Loss: tensor(0.1348)\n",
      "2537 Traning Loss: tensor(0.1351)\n",
      "2538 Traning Loss: tensor(0.1352)\n",
      "2539 Traning Loss: tensor(0.1351)\n",
      "2540 Traning Loss: tensor(0.1345)\n",
      "2541 Traning Loss: tensor(0.1344)\n",
      "2542 Traning Loss: tensor(0.1351)\n",
      "2543 Traning Loss: tensor(0.1345)\n",
      "2544 Traning Loss: tensor(0.1350)\n",
      "2545 Traning Loss: tensor(0.1359)\n",
      "2546 Traning Loss: tensor(0.1344)\n",
      "2547 Traning Loss: tensor(0.1350)\n",
      "2548 Traning Loss: tensor(0.1354)\n",
      "2549 Traning Loss: tensor(0.1346)\n",
      "2550 Traning Loss: tensor(0.1358)\n",
      "2551 Traning Loss: tensor(0.1346)\n",
      "2552 Traning Loss: tensor(0.1346)\n",
      "2553 Traning Loss: tensor(0.1350)\n",
      "2554 Traning Loss: tensor(0.1355)\n",
      "2555 Traning Loss: tensor(0.1352)\n",
      "2556 Traning Loss: tensor(0.1355)\n",
      "2557 Traning Loss: tensor(0.1348)\n",
      "2558 Traning Loss: tensor(0.1358)\n",
      "2559 Traning Loss: tensor(0.1348)\n",
      "2560 Traning Loss: tensor(0.1341)\n",
      "2561 Traning Loss: tensor(0.1344)\n",
      "2562 Traning Loss: tensor(0.1349)\n",
      "2563 Traning Loss: tensor(0.1349)\n",
      "2564 Traning Loss: tensor(0.1340)\n",
      "2565 Traning Loss: tensor(0.1361)\n",
      "2566 Traning Loss: tensor(0.1345)\n",
      "2567 Traning Loss: tensor(0.1347)\n",
      "2568 Traning Loss: tensor(0.1356)\n",
      "2569 Traning Loss: tensor(0.1355)\n",
      "2570 Traning Loss: tensor(0.1346)\n",
      "2571 Traning Loss: tensor(0.1357)\n",
      "2572 Traning Loss: tensor(0.1351)\n",
      "2573 Traning Loss: tensor(0.1349)\n",
      "2574 Traning Loss: tensor(0.1348)\n",
      "2575 Traning Loss: tensor(0.1347)\n",
      "2576 Traning Loss: tensor(0.1360)\n",
      "2577 Traning Loss: tensor(0.1350)\n",
      "2578 Traning Loss: tensor(0.1342)\n",
      "2579 Traning Loss: tensor(0.1343)\n",
      "2580 Traning Loss: tensor(0.1347)\n",
      "2581 Traning Loss: tensor(0.1358)\n",
      "2582 Traning Loss: tensor(0.1345)\n",
      "2583 Traning Loss: tensor(0.1349)\n",
      "2584 Traning Loss: tensor(0.1340)\n",
      "2585 Traning Loss: tensor(0.1354)\n",
      "2586 Traning Loss: tensor(0.1350)\n",
      "2587 Traning Loss: tensor(0.1348)\n",
      "2588 Traning Loss: tensor(0.1358)\n",
      "2589 Traning Loss: tensor(0.1343)\n",
      "2590 Traning Loss: tensor(0.1350)\n",
      "2591 Traning Loss: tensor(0.1353)\n",
      "2592 Traning Loss: tensor(0.1348)\n",
      "2593 Traning Loss: tensor(0.1348)\n",
      "2594 Traning Loss: tensor(0.1345)\n",
      "2595 Traning Loss: tensor(0.1353)\n",
      "2596 Traning Loss: tensor(0.1349)\n",
      "2597 Traning Loss: tensor(0.1354)\n",
      "2598 Traning Loss: tensor(0.1356)\n",
      "2599 Traning Loss: tensor(0.1352)\n",
      "2600 Traning Loss: tensor(0.1346)\n",
      "2601 Traning Loss: tensor(0.1349)\n",
      "2602 Traning Loss: tensor(0.1345)\n",
      "2603 Traning Loss: tensor(0.1347)\n",
      "2604 Traning Loss: tensor(0.1348)\n",
      "2605 Traning Loss: tensor(0.1348)\n",
      "2606 Traning Loss: tensor(0.1349)\n",
      "2607 Traning Loss: tensor(0.1347)\n",
      "2608 Traning Loss: tensor(0.1340)\n",
      "2609 Traning Loss: tensor(0.1351)\n",
      "2610 Traning Loss: tensor(0.1340)\n",
      "2611 Traning Loss: tensor(0.1342)\n",
      "2612 Traning Loss: tensor(0.1353)\n",
      "2613 Traning Loss: tensor(0.1342)\n",
      "2614 Traning Loss: tensor(0.1343)\n",
      "2615 Traning Loss: tensor(0.1342)\n",
      "2616 Traning Loss: tensor(0.1339)\n",
      "2617 Traning Loss: tensor(0.1348)\n",
      "2618 Traning Loss: tensor(0.1348)\n",
      "2619 Traning Loss: tensor(0.1351)\n",
      "2620 Traning Loss: tensor(0.1344)\n",
      "2621 Traning Loss: tensor(0.1339)\n",
      "2622 Traning Loss: tensor(0.1336)\n",
      "2623 Traning Loss: tensor(0.1343)\n",
      "2624 Traning Loss: tensor(0.1354)\n",
      "2625 Traning Loss: tensor(0.1357)\n",
      "2626 Traning Loss: tensor(0.1339)\n",
      "2627 Traning Loss: tensor(0.1349)\n",
      "2628 Traning Loss: tensor(0.1348)\n",
      "2629 Traning Loss: tensor(0.1351)\n",
      "2630 Traning Loss: tensor(0.1345)\n",
      "2631 Traning Loss: tensor(0.1345)\n",
      "2632 Traning Loss: tensor(0.1348)\n",
      "2633 Traning Loss: tensor(0.1350)\n",
      "2634 Traning Loss: tensor(0.1356)\n",
      "2635 Traning Loss: tensor(0.1342)\n",
      "2636 Traning Loss: tensor(0.1344)\n",
      "2637 Traning Loss: tensor(0.1341)\n",
      "2638 Traning Loss: tensor(0.1344)\n",
      "2639 Traning Loss: tensor(0.1343)\n",
      "2640 Traning Loss: tensor(0.1339)\n",
      "2641 Traning Loss: tensor(0.1342)\n",
      "2642 Traning Loss: tensor(0.1344)\n",
      "2643 Traning Loss: tensor(0.1347)\n",
      "2644 Traning Loss: tensor(0.1341)\n",
      "2645 Traning Loss: tensor(0.1346)\n",
      "2646 Traning Loss: tensor(0.1354)\n",
      "2647 Traning Loss: tensor(0.1340)\n",
      "2648 Traning Loss: tensor(0.1344)\n",
      "2649 Traning Loss: tensor(0.1334)\n",
      "2650 Traning Loss: tensor(0.1346)\n",
      "2651 Traning Loss: tensor(0.1337)\n",
      "2652 Traning Loss: tensor(0.1342)\n",
      "2653 Traning Loss: tensor(0.1348)\n",
      "2654 Traning Loss: tensor(0.1330)\n",
      "2655 Traning Loss: tensor(0.1338)\n",
      "2656 Traning Loss: tensor(0.1344)\n",
      "2657 Traning Loss: tensor(0.1344)\n",
      "2658 Traning Loss: tensor(0.1343)\n",
      "2659 Traning Loss: tensor(0.1344)\n",
      "2660 Traning Loss: tensor(0.1330)\n",
      "2661 Traning Loss: tensor(0.1343)\n",
      "2662 Traning Loss: tensor(0.1337)\n",
      "2663 Traning Loss: tensor(0.1342)\n",
      "2664 Traning Loss: tensor(0.1340)\n",
      "2665 Traning Loss: tensor(0.1335)\n",
      "2666 Traning Loss: tensor(0.1340)\n",
      "2667 Traning Loss: tensor(0.1339)\n",
      "2668 Traning Loss: tensor(0.1342)\n",
      "2669 Traning Loss: tensor(0.1348)\n",
      "2670 Traning Loss: tensor(0.1342)\n",
      "2671 Traning Loss: tensor(0.1332)\n",
      "2672 Traning Loss: tensor(0.1339)\n",
      "2673 Traning Loss: tensor(0.1334)\n",
      "2674 Traning Loss: tensor(0.1336)\n",
      "2675 Traning Loss: tensor(0.1345)\n",
      "2676 Traning Loss: tensor(0.1343)\n",
      "2677 Traning Loss: tensor(0.1338)\n",
      "2678 Traning Loss: tensor(0.1338)\n",
      "2679 Traning Loss: tensor(0.1336)\n",
      "2680 Traning Loss: tensor(0.1340)\n",
      "2681 Traning Loss: tensor(0.1350)\n",
      "2682 Traning Loss: tensor(0.1338)\n",
      "2683 Traning Loss: tensor(0.1338)\n",
      "2684 Traning Loss: tensor(0.1335)\n",
      "2685 Traning Loss: tensor(0.1343)\n",
      "2686 Traning Loss: tensor(0.1342)\n",
      "2687 Traning Loss: tensor(0.1337)\n",
      "2688 Traning Loss: tensor(0.1341)\n",
      "2689 Traning Loss: tensor(0.1347)\n",
      "2690 Traning Loss: tensor(0.1353)\n",
      "2691 Traning Loss: tensor(0.1338)\n",
      "2692 Traning Loss: tensor(0.1335)\n",
      "2693 Traning Loss: tensor(0.1342)\n",
      "2694 Traning Loss: tensor(0.1338)\n",
      "2695 Traning Loss: tensor(0.1353)\n",
      "2696 Traning Loss: tensor(0.1342)\n",
      "2697 Traning Loss: tensor(0.1345)\n",
      "2698 Traning Loss: tensor(0.1335)\n",
      "2699 Traning Loss: tensor(0.1335)\n",
      "2700 Traning Loss: tensor(0.1338)\n",
      "2701 Traning Loss: tensor(0.1342)\n",
      "2702 Traning Loss: tensor(0.1340)\n",
      "2703 Traning Loss: tensor(0.1331)\n",
      "2704 Traning Loss: tensor(0.1339)\n",
      "2705 Traning Loss: tensor(0.1334)\n",
      "2706 Traning Loss: tensor(0.1340)\n",
      "2707 Traning Loss: tensor(0.1345)\n",
      "2708 Traning Loss: tensor(0.1330)\n",
      "2709 Traning Loss: tensor(0.1333)\n",
      "2710 Traning Loss: tensor(0.1338)\n",
      "2711 Traning Loss: tensor(0.1336)\n",
      "2712 Traning Loss: tensor(0.1344)\n",
      "2713 Traning Loss: tensor(0.1340)\n",
      "2714 Traning Loss: tensor(0.1340)\n",
      "2715 Traning Loss: tensor(0.1340)\n",
      "2716 Traning Loss: tensor(0.1335)\n",
      "2717 Traning Loss: tensor(0.1334)\n",
      "2718 Traning Loss: tensor(0.1338)\n",
      "2719 Traning Loss: tensor(0.1354)\n",
      "2720 Traning Loss: tensor(0.1334)\n",
      "2721 Traning Loss: tensor(0.1337)\n",
      "2722 Traning Loss: tensor(0.1338)\n",
      "2723 Traning Loss: tensor(0.1332)\n",
      "2724 Traning Loss: tensor(0.1342)\n",
      "2725 Traning Loss: tensor(0.1333)\n",
      "2726 Traning Loss: tensor(0.1333)\n",
      "2727 Traning Loss: tensor(0.1342)\n",
      "2728 Traning Loss: tensor(0.1334)\n",
      "2729 Traning Loss: tensor(0.1341)\n",
      "2730 Traning Loss: tensor(0.1334)\n",
      "2731 Traning Loss: tensor(0.1339)\n",
      "2732 Traning Loss: tensor(0.1333)\n",
      "2733 Traning Loss: tensor(0.1328)\n",
      "2734 Traning Loss: tensor(0.1332)\n",
      "2735 Traning Loss: tensor(0.1339)\n",
      "2736 Traning Loss: tensor(0.1336)\n",
      "2737 Traning Loss: tensor(0.1339)\n",
      "2738 Traning Loss: tensor(0.1336)\n",
      "2739 Traning Loss: tensor(0.1321)\n",
      "2740 Traning Loss: tensor(0.1326)\n",
      "2741 Traning Loss: tensor(0.1332)\n",
      "2742 Traning Loss: tensor(0.1337)\n",
      "2743 Traning Loss: tensor(0.1334)\n",
      "2744 Traning Loss: tensor(0.1341)\n",
      "2745 Traning Loss: tensor(0.1335)\n",
      "2746 Traning Loss: tensor(0.1336)\n",
      "2747 Traning Loss: tensor(0.1331)\n",
      "2748 Traning Loss: tensor(0.1331)\n",
      "2749 Traning Loss: tensor(0.1326)\n",
      "2750 Traning Loss: tensor(0.1345)\n",
      "2751 Traning Loss: tensor(0.1334)\n",
      "2752 Traning Loss: tensor(0.1333)\n",
      "2753 Traning Loss: tensor(0.1337)\n",
      "2754 Traning Loss: tensor(0.1329)\n",
      "2755 Traning Loss: tensor(0.1335)\n",
      "2756 Traning Loss: tensor(0.1328)\n",
      "2757 Traning Loss: tensor(0.1341)\n",
      "2758 Traning Loss: tensor(0.1334)\n",
      "2759 Traning Loss: tensor(0.1335)\n",
      "2760 Traning Loss: tensor(0.1320)\n",
      "2761 Traning Loss: tensor(0.1332)\n",
      "2762 Traning Loss: tensor(0.1333)\n",
      "2763 Traning Loss: tensor(0.1329)\n",
      "2764 Traning Loss: tensor(0.1331)\n",
      "2765 Traning Loss: tensor(0.1338)\n",
      "2766 Traning Loss: tensor(0.1338)\n",
      "2767 Traning Loss: tensor(0.1322)\n",
      "2768 Traning Loss: tensor(0.1332)\n",
      "2769 Traning Loss: tensor(0.1329)\n",
      "2770 Traning Loss: tensor(0.1327)\n",
      "2771 Traning Loss: tensor(0.1338)\n",
      "2772 Traning Loss: tensor(0.1336)\n",
      "2773 Traning Loss: tensor(0.1326)\n",
      "2774 Traning Loss: tensor(0.1336)\n",
      "2775 Traning Loss: tensor(0.1324)\n",
      "2776 Traning Loss: tensor(0.1325)\n",
      "2777 Traning Loss: tensor(0.1336)\n",
      "2778 Traning Loss: tensor(0.1329)\n",
      "2779 Traning Loss: tensor(0.1342)\n",
      "2780 Traning Loss: tensor(0.1330)\n",
      "2781 Traning Loss: tensor(0.1331)\n",
      "2782 Traning Loss: tensor(0.1330)\n",
      "2783 Traning Loss: tensor(0.1325)\n",
      "2784 Traning Loss: tensor(0.1325)\n",
      "2785 Traning Loss: tensor(0.1324)\n",
      "2786 Traning Loss: tensor(0.1326)\n",
      "2787 Traning Loss: tensor(0.1335)\n",
      "2788 Traning Loss: tensor(0.1333)\n",
      "2789 Traning Loss: tensor(0.1326)\n",
      "2790 Traning Loss: tensor(0.1333)\n",
      "2791 Traning Loss: tensor(0.1331)\n",
      "2792 Traning Loss: tensor(0.1336)\n",
      "2793 Traning Loss: tensor(0.1331)\n",
      "2794 Traning Loss: tensor(0.1324)\n",
      "2795 Traning Loss: tensor(0.1316)\n",
      "2796 Traning Loss: tensor(0.1329)\n",
      "2797 Traning Loss: tensor(0.1338)\n",
      "2798 Traning Loss: tensor(0.1331)\n",
      "2799 Traning Loss: tensor(0.1327)\n",
      "2800 Traning Loss: tensor(0.1332)\n",
      "2801 Traning Loss: tensor(0.1334)\n",
      "2802 Traning Loss: tensor(0.1324)\n",
      "2803 Traning Loss: tensor(0.1330)\n",
      "2804 Traning Loss: tensor(0.1322)\n",
      "2805 Traning Loss: tensor(0.1327)\n",
      "2806 Traning Loss: tensor(0.1324)\n",
      "2807 Traning Loss: tensor(0.1324)\n",
      "2808 Traning Loss: tensor(0.1329)\n",
      "2809 Traning Loss: tensor(0.1330)\n",
      "2810 Traning Loss: tensor(0.1335)\n",
      "2811 Traning Loss: tensor(0.1325)\n",
      "2812 Traning Loss: tensor(0.1336)\n",
      "2813 Traning Loss: tensor(0.1329)\n",
      "2814 Traning Loss: tensor(0.1327)\n",
      "2815 Traning Loss: tensor(0.1325)\n",
      "2816 Traning Loss: tensor(0.1335)\n",
      "2817 Traning Loss: tensor(0.1327)\n",
      "2818 Traning Loss: tensor(0.1324)\n",
      "2819 Traning Loss: tensor(0.1336)\n",
      "2820 Traning Loss: tensor(0.1323)\n",
      "2821 Traning Loss: tensor(0.1325)\n",
      "2822 Traning Loss: tensor(0.1328)\n",
      "2823 Traning Loss: tensor(0.1325)\n",
      "2824 Traning Loss: tensor(0.1326)\n",
      "2825 Traning Loss: tensor(0.1312)\n",
      "2826 Traning Loss: tensor(0.1342)\n",
      "2827 Traning Loss: tensor(0.1324)\n",
      "2828 Traning Loss: tensor(0.1320)\n",
      "2829 Traning Loss: tensor(0.1326)\n",
      "2830 Traning Loss: tensor(0.1332)\n",
      "2831 Traning Loss: tensor(0.1313)\n",
      "2832 Traning Loss: tensor(0.1324)\n",
      "2833 Traning Loss: tensor(0.1334)\n",
      "2834 Traning Loss: tensor(0.1331)\n",
      "2835 Traning Loss: tensor(0.1317)\n",
      "2836 Traning Loss: tensor(0.1329)\n",
      "2837 Traning Loss: tensor(0.1323)\n",
      "2838 Traning Loss: tensor(0.1314)\n",
      "2839 Traning Loss: tensor(0.1327)\n",
      "2840 Traning Loss: tensor(0.1324)\n",
      "2841 Traning Loss: tensor(0.1311)\n",
      "2842 Traning Loss: tensor(0.1338)\n",
      "2843 Traning Loss: tensor(0.1320)\n",
      "2844 Traning Loss: tensor(0.1317)\n",
      "2845 Traning Loss: tensor(0.1329)\n",
      "2846 Traning Loss: tensor(0.1323)\n",
      "2847 Traning Loss: tensor(0.1320)\n",
      "2848 Traning Loss: tensor(0.1323)\n",
      "2849 Traning Loss: tensor(0.1322)\n",
      "2850 Traning Loss: tensor(0.1320)\n",
      "2851 Traning Loss: tensor(0.1318)\n",
      "2852 Traning Loss: tensor(0.1326)\n",
      "2853 Traning Loss: tensor(0.1323)\n",
      "2854 Traning Loss: tensor(0.1329)\n",
      "2855 Traning Loss: tensor(0.1320)\n",
      "2856 Traning Loss: tensor(0.1323)\n",
      "2857 Traning Loss: tensor(0.1334)\n",
      "2858 Traning Loss: tensor(0.1327)\n",
      "2859 Traning Loss: tensor(0.1325)\n",
      "2860 Traning Loss: tensor(0.1323)\n",
      "2861 Traning Loss: tensor(0.1315)\n",
      "2862 Traning Loss: tensor(0.1316)\n",
      "2863 Traning Loss: tensor(0.1324)\n",
      "2864 Traning Loss: tensor(0.1335)\n",
      "2865 Traning Loss: tensor(0.1333)\n",
      "2866 Traning Loss: tensor(0.1330)\n",
      "2867 Traning Loss: tensor(0.1315)\n",
      "2868 Traning Loss: tensor(0.1325)\n",
      "2869 Traning Loss: tensor(0.1337)\n",
      "2870 Traning Loss: tensor(0.1329)\n",
      "2871 Traning Loss: tensor(0.1330)\n",
      "2872 Traning Loss: tensor(0.1321)\n",
      "2873 Traning Loss: tensor(0.1318)\n",
      "2874 Traning Loss: tensor(0.1327)\n",
      "2875 Traning Loss: tensor(0.1327)\n",
      "2876 Traning Loss: tensor(0.1329)\n",
      "2877 Traning Loss: tensor(0.1323)\n",
      "2878 Traning Loss: tensor(0.1330)\n",
      "2879 Traning Loss: tensor(0.1318)\n",
      "2880 Traning Loss: tensor(0.1319)\n",
      "2881 Traning Loss: tensor(0.1322)\n",
      "2882 Traning Loss: tensor(0.1316)\n",
      "2883 Traning Loss: tensor(0.1321)\n",
      "2884 Traning Loss: tensor(0.1318)\n",
      "2885 Traning Loss: tensor(0.1315)\n",
      "2886 Traning Loss: tensor(0.1319)\n",
      "2887 Traning Loss: tensor(0.1324)\n",
      "2888 Traning Loss: tensor(0.1320)\n",
      "2889 Traning Loss: tensor(0.1334)\n",
      "2890 Traning Loss: tensor(0.1319)\n",
      "2891 Traning Loss: tensor(0.1310)\n",
      "2892 Traning Loss: tensor(0.1320)\n",
      "2893 Traning Loss: tensor(0.1312)\n",
      "2894 Traning Loss: tensor(0.1319)\n",
      "2895 Traning Loss: tensor(0.1327)\n",
      "2896 Traning Loss: tensor(0.1315)\n",
      "2897 Traning Loss: tensor(0.1317)\n",
      "2898 Traning Loss: tensor(0.1315)\n",
      "2899 Traning Loss: tensor(0.1315)\n",
      "2900 Traning Loss: tensor(0.1307)\n",
      "2901 Traning Loss: tensor(0.1322)\n",
      "2902 Traning Loss: tensor(0.1320)\n",
      "2903 Traning Loss: tensor(0.1325)\n",
      "2904 Traning Loss: tensor(0.1315)\n",
      "2905 Traning Loss: tensor(0.1307)\n",
      "2906 Traning Loss: tensor(0.1330)\n",
      "2907 Traning Loss: tensor(0.1334)\n",
      "2908 Traning Loss: tensor(0.1326)\n",
      "2909 Traning Loss: tensor(0.1319)\n",
      "2910 Traning Loss: tensor(0.1313)\n",
      "2911 Traning Loss: tensor(0.1317)\n",
      "2912 Traning Loss: tensor(0.1318)\n",
      "2913 Traning Loss: tensor(0.1314)\n",
      "2914 Traning Loss: tensor(0.1311)\n",
      "2915 Traning Loss: tensor(0.1316)\n",
      "2916 Traning Loss: tensor(0.1317)\n",
      "2917 Traning Loss: tensor(0.1335)\n",
      "2918 Traning Loss: tensor(0.1306)\n",
      "2919 Traning Loss: tensor(0.1316)\n",
      "2920 Traning Loss: tensor(0.1319)\n",
      "2921 Traning Loss: tensor(0.1312)\n",
      "2922 Traning Loss: tensor(0.1321)\n",
      "2923 Traning Loss: tensor(0.1303)\n",
      "2924 Traning Loss: tensor(0.1309)\n",
      "2925 Traning Loss: tensor(0.1309)\n",
      "2926 Traning Loss: tensor(0.1306)\n",
      "2927 Traning Loss: tensor(0.1315)\n",
      "2928 Traning Loss: tensor(0.1315)\n",
      "2929 Traning Loss: tensor(0.1320)\n",
      "2930 Traning Loss: tensor(0.1332)\n",
      "2931 Traning Loss: tensor(0.1319)\n",
      "2932 Traning Loss: tensor(0.1316)\n",
      "2933 Traning Loss: tensor(0.1315)\n",
      "2934 Traning Loss: tensor(0.1307)\n",
      "2935 Traning Loss: tensor(0.1327)\n",
      "2936 Traning Loss: tensor(0.1321)\n",
      "2937 Traning Loss: tensor(0.1299)\n",
      "2938 Traning Loss: tensor(0.1327)\n",
      "2939 Traning Loss: tensor(0.1310)\n",
      "2940 Traning Loss: tensor(0.1317)\n",
      "2941 Traning Loss: tensor(0.1317)\n",
      "2942 Traning Loss: tensor(0.1314)\n",
      "2943 Traning Loss: tensor(0.1303)\n",
      "2944 Traning Loss: tensor(0.1313)\n",
      "2945 Traning Loss: tensor(0.1298)\n",
      "2946 Traning Loss: tensor(0.1321)\n",
      "2947 Traning Loss: tensor(0.1311)\n",
      "2948 Traning Loss: tensor(0.1322)\n",
      "2949 Traning Loss: tensor(0.1314)\n",
      "2950 Traning Loss: tensor(0.1307)\n",
      "2951 Traning Loss: tensor(0.1313)\n",
      "2952 Traning Loss: tensor(0.1319)\n",
      "2953 Traning Loss: tensor(0.1316)\n",
      "2954 Traning Loss: tensor(0.1306)\n",
      "2955 Traning Loss: tensor(0.1305)\n",
      "2956 Traning Loss: tensor(0.1308)\n",
      "2957 Traning Loss: tensor(0.1314)\n",
      "2958 Traning Loss: tensor(0.1314)\n",
      "2959 Traning Loss: tensor(0.1305)\n",
      "2960 Traning Loss: tensor(0.1318)\n",
      "2961 Traning Loss: tensor(0.1300)\n",
      "2962 Traning Loss: tensor(0.1307)\n",
      "2963 Traning Loss: tensor(0.1306)\n",
      "2964 Traning Loss: tensor(0.1310)\n",
      "2965 Traning Loss: tensor(0.1311)\n",
      "2966 Traning Loss: tensor(0.1314)\n",
      "2967 Traning Loss: tensor(0.1304)\n",
      "2968 Traning Loss: tensor(0.1305)\n",
      "2969 Traning Loss: tensor(0.1311)\n",
      "2970 Traning Loss: tensor(0.1315)\n",
      "2971 Traning Loss: tensor(0.1309)\n",
      "2972 Traning Loss: tensor(0.1312)\n",
      "2973 Traning Loss: tensor(0.1299)\n",
      "2974 Traning Loss: tensor(0.1306)\n",
      "2975 Traning Loss: tensor(0.1311)\n",
      "2976 Traning Loss: tensor(0.1306)\n",
      "2977 Traning Loss: tensor(0.1309)\n",
      "2978 Traning Loss: tensor(0.1312)\n",
      "2979 Traning Loss: tensor(0.1311)\n",
      "2980 Traning Loss: tensor(0.1319)\n",
      "2981 Traning Loss: tensor(0.1307)\n",
      "2982 Traning Loss: tensor(0.1300)\n",
      "2983 Traning Loss: tensor(0.1308)\n",
      "2984 Traning Loss: tensor(0.1301)\n",
      "2985 Traning Loss: tensor(0.1312)\n",
      "2986 Traning Loss: tensor(0.1299)\n",
      "2987 Traning Loss: tensor(0.1314)\n",
      "2988 Traning Loss: tensor(0.1310)\n",
      "2989 Traning Loss: tensor(0.1321)\n",
      "2990 Traning Loss: tensor(0.1310)\n",
      "2991 Traning Loss: tensor(0.1302)\n",
      "2992 Traning Loss: tensor(0.1307)\n",
      "2993 Traning Loss: tensor(0.1293)\n",
      "2994 Traning Loss: tensor(0.1315)\n",
      "2995 Traning Loss: tensor(0.1311)\n",
      "2996 Traning Loss: tensor(0.1310)\n",
      "2997 Traning Loss: tensor(0.1308)\n",
      "2998 Traning Loss: tensor(0.1312)\n",
      "2999 Traning Loss: tensor(0.1298)\n",
      "3000 Traning Loss: tensor(0.1295)\n",
      "3001 Traning Loss: tensor(0.1311)\n",
      "3002 Traning Loss: tensor(0.1294)\n",
      "3003 Traning Loss: tensor(0.1308)\n",
      "3004 Traning Loss: tensor(0.1306)\n",
      "3005 Traning Loss: tensor(0.1312)\n",
      "3006 Traning Loss: tensor(0.1311)\n",
      "3007 Traning Loss: tensor(0.1304)\n",
      "3008 Traning Loss: tensor(0.1305)\n",
      "3009 Traning Loss: tensor(0.1306)\n",
      "3010 Traning Loss: tensor(0.1302)\n",
      "3011 Traning Loss: tensor(0.1312)\n",
      "3012 Traning Loss: tensor(0.1308)\n",
      "3013 Traning Loss: tensor(0.1303)\n",
      "3014 Traning Loss: tensor(0.1303)\n",
      "3015 Traning Loss: tensor(0.1298)\n",
      "3016 Traning Loss: tensor(0.1312)\n",
      "3017 Traning Loss: tensor(0.1303)\n",
      "3018 Traning Loss: tensor(0.1309)\n",
      "3019 Traning Loss: tensor(0.1310)\n",
      "3020 Traning Loss: tensor(0.1311)\n",
      "3021 Traning Loss: tensor(0.1318)\n",
      "3022 Traning Loss: tensor(0.1315)\n",
      "3023 Traning Loss: tensor(0.1313)\n",
      "3024 Traning Loss: tensor(0.1294)\n",
      "3025 Traning Loss: tensor(0.1306)\n",
      "3026 Traning Loss: tensor(0.1299)\n",
      "3027 Traning Loss: tensor(0.1306)\n",
      "3028 Traning Loss: tensor(0.1311)\n",
      "3029 Traning Loss: tensor(0.1312)\n",
      "3030 Traning Loss: tensor(0.1294)\n",
      "3031 Traning Loss: tensor(0.1314)\n",
      "3032 Traning Loss: tensor(0.1304)\n",
      "3033 Traning Loss: tensor(0.1308)\n",
      "3034 Traning Loss: tensor(0.1298)\n",
      "3035 Traning Loss: tensor(0.1315)\n",
      "3036 Traning Loss: tensor(0.1311)\n",
      "3037 Traning Loss: tensor(0.1320)\n",
      "3038 Traning Loss: tensor(0.1306)\n",
      "3039 Traning Loss: tensor(0.1311)\n",
      "3040 Traning Loss: tensor(0.1312)\n",
      "3041 Traning Loss: tensor(0.1302)\n",
      "3042 Traning Loss: tensor(0.1295)\n",
      "3043 Traning Loss: tensor(0.1295)\n",
      "3044 Traning Loss: tensor(0.1305)\n",
      "3045 Traning Loss: tensor(0.1302)\n",
      "3046 Traning Loss: tensor(0.1302)\n",
      "3047 Traning Loss: tensor(0.1307)\n",
      "3048 Traning Loss: tensor(0.1301)\n",
      "3049 Traning Loss: tensor(0.1305)\n",
      "3050 Traning Loss: tensor(0.1300)\n",
      "3051 Traning Loss: tensor(0.1307)\n",
      "3052 Traning Loss: tensor(0.1294)\n",
      "3053 Traning Loss: tensor(0.1306)\n",
      "3054 Traning Loss: tensor(0.1296)\n",
      "3055 Traning Loss: tensor(0.1289)\n",
      "3056 Traning Loss: tensor(0.1303)\n",
      "3057 Traning Loss: tensor(0.1297)\n",
      "3058 Traning Loss: tensor(0.1289)\n",
      "3059 Traning Loss: tensor(0.1297)\n",
      "3060 Traning Loss: tensor(0.1299)\n",
      "3061 Traning Loss: tensor(0.1301)\n",
      "3062 Traning Loss: tensor(0.1290)\n",
      "3063 Traning Loss: tensor(0.1298)\n",
      "3064 Traning Loss: tensor(0.1304)\n",
      "3065 Traning Loss: tensor(0.1299)\n",
      "3066 Traning Loss: tensor(0.1303)\n",
      "3067 Traning Loss: tensor(0.1306)\n",
      "3068 Traning Loss: tensor(0.1287)\n",
      "3069 Traning Loss: tensor(0.1309)\n",
      "3070 Traning Loss: tensor(0.1299)\n",
      "3071 Traning Loss: tensor(0.1292)\n",
      "3072 Traning Loss: tensor(0.1299)\n",
      "3073 Traning Loss: tensor(0.1312)\n",
      "3074 Traning Loss: tensor(0.1295)\n",
      "3075 Traning Loss: tensor(0.1297)\n",
      "3076 Traning Loss: tensor(0.1306)\n",
      "3077 Traning Loss: tensor(0.1310)\n",
      "3078 Traning Loss: tensor(0.1299)\n",
      "3079 Traning Loss: tensor(0.1291)\n",
      "3080 Traning Loss: tensor(0.1299)\n",
      "3081 Traning Loss: tensor(0.1305)\n",
      "3082 Traning Loss: tensor(0.1291)\n",
      "3083 Traning Loss: tensor(0.1295)\n",
      "3084 Traning Loss: tensor(0.1293)\n",
      "3085 Traning Loss: tensor(0.1302)\n",
      "3086 Traning Loss: tensor(0.1299)\n",
      "3087 Traning Loss: tensor(0.1300)\n",
      "3088 Traning Loss: tensor(0.1310)\n",
      "3089 Traning Loss: tensor(0.1296)\n",
      "3090 Traning Loss: tensor(0.1310)\n",
      "3091 Traning Loss: tensor(0.1292)\n",
      "3092 Traning Loss: tensor(0.1302)\n",
      "3093 Traning Loss: tensor(0.1288)\n",
      "3094 Traning Loss: tensor(0.1300)\n",
      "3095 Traning Loss: tensor(0.1291)\n",
      "3096 Traning Loss: tensor(0.1298)\n",
      "3097 Traning Loss: tensor(0.1287)\n",
      "3098 Traning Loss: tensor(0.1281)\n",
      "3099 Traning Loss: tensor(0.1291)\n",
      "3100 Traning Loss: tensor(0.1302)\n",
      "3101 Traning Loss: tensor(0.1302)\n",
      "3102 Traning Loss: tensor(0.1294)\n",
      "3103 Traning Loss: tensor(0.1295)\n",
      "3104 Traning Loss: tensor(0.1294)\n",
      "3105 Traning Loss: tensor(0.1295)\n",
      "3106 Traning Loss: tensor(0.1294)\n",
      "3107 Traning Loss: tensor(0.1298)\n",
      "3108 Traning Loss: tensor(0.1281)\n",
      "3109 Traning Loss: tensor(0.1289)\n",
      "3110 Traning Loss: tensor(0.1305)\n",
      "3111 Traning Loss: tensor(0.1294)\n",
      "3112 Traning Loss: tensor(0.1296)\n",
      "3113 Traning Loss: tensor(0.1302)\n",
      "3114 Traning Loss: tensor(0.1292)\n",
      "3115 Traning Loss: tensor(0.1287)\n",
      "3116 Traning Loss: tensor(0.1302)\n",
      "3117 Traning Loss: tensor(0.1290)\n",
      "3118 Traning Loss: tensor(0.1294)\n",
      "3119 Traning Loss: tensor(0.1283)\n",
      "3120 Traning Loss: tensor(0.1290)\n",
      "3121 Traning Loss: tensor(0.1299)\n",
      "3122 Traning Loss: tensor(0.1285)\n",
      "3123 Traning Loss: tensor(0.1291)\n",
      "3124 Traning Loss: tensor(0.1286)\n",
      "3125 Traning Loss: tensor(0.1298)\n",
      "3126 Traning Loss: tensor(0.1292)\n",
      "3127 Traning Loss: tensor(0.1294)\n",
      "3128 Traning Loss: tensor(0.1287)\n",
      "3129 Traning Loss: tensor(0.1294)\n",
      "3130 Traning Loss: tensor(0.1283)\n",
      "3131 Traning Loss: tensor(0.1280)\n",
      "3132 Traning Loss: tensor(0.1295)\n",
      "3133 Traning Loss: tensor(0.1278)\n",
      "3134 Traning Loss: tensor(0.1300)\n",
      "3135 Traning Loss: tensor(0.1305)\n",
      "3136 Traning Loss: tensor(0.1301)\n",
      "3137 Traning Loss: tensor(0.1297)\n",
      "3138 Traning Loss: tensor(0.1278)\n",
      "3139 Traning Loss: tensor(0.1291)\n",
      "3140 Traning Loss: tensor(0.1285)\n",
      "3141 Traning Loss: tensor(0.1293)\n",
      "3142 Traning Loss: tensor(0.1306)\n",
      "3143 Traning Loss: tensor(0.1289)\n",
      "3144 Traning Loss: tensor(0.1299)\n",
      "3145 Traning Loss: tensor(0.1292)\n",
      "3146 Traning Loss: tensor(0.1283)\n",
      "3147 Traning Loss: tensor(0.1288)\n",
      "3148 Traning Loss: tensor(0.1282)\n",
      "3149 Traning Loss: tensor(0.1283)\n",
      "3150 Traning Loss: tensor(0.1288)\n",
      "3151 Traning Loss: tensor(0.1283)\n",
      "3152 Traning Loss: tensor(0.1284)\n",
      "3153 Traning Loss: tensor(0.1279)\n",
      "3154 Traning Loss: tensor(0.1286)\n",
      "3155 Traning Loss: tensor(0.1293)\n",
      "3156 Traning Loss: tensor(0.1290)\n",
      "3157 Traning Loss: tensor(0.1281)\n",
      "3158 Traning Loss: tensor(0.1284)\n",
      "3159 Traning Loss: tensor(0.1282)\n",
      "3160 Traning Loss: tensor(0.1289)\n",
      "3161 Traning Loss: tensor(0.1271)\n",
      "3162 Traning Loss: tensor(0.1298)\n",
      "3163 Traning Loss: tensor(0.1286)\n",
      "3164 Traning Loss: tensor(0.1279)\n",
      "3165 Traning Loss: tensor(0.1285)\n",
      "3166 Traning Loss: tensor(0.1295)\n",
      "3167 Traning Loss: tensor(0.1280)\n",
      "3168 Traning Loss: tensor(0.1280)\n",
      "3169 Traning Loss: tensor(0.1283)\n",
      "3170 Traning Loss: tensor(0.1282)\n",
      "3171 Traning Loss: tensor(0.1292)\n",
      "3172 Traning Loss: tensor(0.1290)\n",
      "3173 Traning Loss: tensor(0.1292)\n",
      "3174 Traning Loss: tensor(0.1290)\n",
      "3175 Traning Loss: tensor(0.1298)\n",
      "3176 Traning Loss: tensor(0.1286)\n",
      "3177 Traning Loss: tensor(0.1285)\n",
      "3178 Traning Loss: tensor(0.1289)\n",
      "3179 Traning Loss: tensor(0.1284)\n",
      "3180 Traning Loss: tensor(0.1295)\n",
      "3181 Traning Loss: tensor(0.1293)\n",
      "3182 Traning Loss: tensor(0.1287)\n",
      "3183 Traning Loss: tensor(0.1274)\n",
      "3184 Traning Loss: tensor(0.1285)\n",
      "3185 Traning Loss: tensor(0.1278)\n",
      "3186 Traning Loss: tensor(0.1287)\n",
      "3187 Traning Loss: tensor(0.1291)\n",
      "3188 Traning Loss: tensor(0.1288)\n",
      "3189 Traning Loss: tensor(0.1279)\n",
      "3190 Traning Loss: tensor(0.1291)\n",
      "3191 Traning Loss: tensor(0.1273)\n",
      "3192 Traning Loss: tensor(0.1275)\n",
      "3193 Traning Loss: tensor(0.1280)\n",
      "3194 Traning Loss: tensor(0.1290)\n",
      "3195 Traning Loss: tensor(0.1273)\n",
      "3196 Traning Loss: tensor(0.1285)\n",
      "3197 Traning Loss: tensor(0.1283)\n",
      "3198 Traning Loss: tensor(0.1290)\n",
      "3199 Traning Loss: tensor(0.1280)\n",
      "3200 Traning Loss: tensor(0.1276)\n",
      "3201 Traning Loss: tensor(0.1279)\n",
      "3202 Traning Loss: tensor(0.1274)\n",
      "3203 Traning Loss: tensor(0.1287)\n",
      "3204 Traning Loss: tensor(0.1292)\n",
      "3205 Traning Loss: tensor(0.1267)\n",
      "3206 Traning Loss: tensor(0.1286)\n",
      "3207 Traning Loss: tensor(0.1279)\n",
      "3208 Traning Loss: tensor(0.1287)\n",
      "3209 Traning Loss: tensor(0.1267)\n",
      "3210 Traning Loss: tensor(0.1285)\n",
      "3211 Traning Loss: tensor(0.1293)\n",
      "3212 Traning Loss: tensor(0.1273)\n",
      "3213 Traning Loss: tensor(0.1278)\n",
      "3214 Traning Loss: tensor(0.1281)\n",
      "3215 Traning Loss: tensor(0.1277)\n",
      "3216 Traning Loss: tensor(0.1276)\n",
      "3217 Traning Loss: tensor(0.1285)\n",
      "3218 Traning Loss: tensor(0.1287)\n",
      "3219 Traning Loss: tensor(0.1278)\n",
      "3220 Traning Loss: tensor(0.1271)\n",
      "3221 Traning Loss: tensor(0.1287)\n",
      "3222 Traning Loss: tensor(0.1277)\n",
      "3223 Traning Loss: tensor(0.1286)\n",
      "3224 Traning Loss: tensor(0.1290)\n",
      "3225 Traning Loss: tensor(0.1272)\n",
      "3226 Traning Loss: tensor(0.1267)\n",
      "3227 Traning Loss: tensor(0.1273)\n",
      "3228 Traning Loss: tensor(0.1283)\n",
      "3229 Traning Loss: tensor(0.1281)\n",
      "3230 Traning Loss: tensor(0.1268)\n",
      "3231 Traning Loss: tensor(0.1285)\n",
      "3232 Traning Loss: tensor(0.1266)\n",
      "3233 Traning Loss: tensor(0.1282)\n",
      "3234 Traning Loss: tensor(0.1266)\n",
      "3235 Traning Loss: tensor(0.1276)\n",
      "3236 Traning Loss: tensor(0.1277)\n",
      "3237 Traning Loss: tensor(0.1279)\n",
      "3238 Traning Loss: tensor(0.1274)\n",
      "3239 Traning Loss: tensor(0.1274)\n",
      "3240 Traning Loss: tensor(0.1268)\n",
      "3241 Traning Loss: tensor(0.1286)\n",
      "3242 Traning Loss: tensor(0.1273)\n",
      "3243 Traning Loss: tensor(0.1265)\n",
      "3244 Traning Loss: tensor(0.1289)\n",
      "3245 Traning Loss: tensor(0.1284)\n",
      "3246 Traning Loss: tensor(0.1282)\n",
      "3247 Traning Loss: tensor(0.1278)\n",
      "3248 Traning Loss: tensor(0.1277)\n",
      "3249 Traning Loss: tensor(0.1274)\n",
      "3250 Traning Loss: tensor(0.1271)\n",
      "3251 Traning Loss: tensor(0.1292)\n",
      "3252 Traning Loss: tensor(0.1269)\n",
      "3253 Traning Loss: tensor(0.1271)\n",
      "3254 Traning Loss: tensor(0.1276)\n",
      "3255 Traning Loss: tensor(0.1277)\n",
      "3256 Traning Loss: tensor(0.1270)\n",
      "3257 Traning Loss: tensor(0.1278)\n",
      "3258 Traning Loss: tensor(0.1267)\n",
      "3259 Traning Loss: tensor(0.1272)\n",
      "3260 Traning Loss: tensor(0.1273)\n",
      "3261 Traning Loss: tensor(0.1271)\n",
      "3262 Traning Loss: tensor(0.1264)\n",
      "3263 Traning Loss: tensor(0.1275)\n",
      "3264 Traning Loss: tensor(0.1279)\n",
      "3265 Traning Loss: tensor(0.1269)\n",
      "3266 Traning Loss: tensor(0.1282)\n",
      "3267 Traning Loss: tensor(0.1274)\n",
      "3268 Traning Loss: tensor(0.1260)\n",
      "3269 Traning Loss: tensor(0.1271)\n",
      "3270 Traning Loss: tensor(0.1261)\n",
      "3271 Traning Loss: tensor(0.1260)\n",
      "3272 Traning Loss: tensor(0.1266)\n",
      "3273 Traning Loss: tensor(0.1263)\n",
      "3274 Traning Loss: tensor(0.1266)\n",
      "3275 Traning Loss: tensor(0.1268)\n",
      "3276 Traning Loss: tensor(0.1269)\n",
      "3277 Traning Loss: tensor(0.1273)\n",
      "3278 Traning Loss: tensor(0.1274)\n",
      "3279 Traning Loss: tensor(0.1256)\n",
      "3280 Traning Loss: tensor(0.1268)\n",
      "3281 Traning Loss: tensor(0.1267)\n",
      "3282 Traning Loss: tensor(0.1273)\n",
      "3283 Traning Loss: tensor(0.1270)\n",
      "3284 Traning Loss: tensor(0.1266)\n",
      "3285 Traning Loss: tensor(0.1271)\n",
      "3286 Traning Loss: tensor(0.1274)\n",
      "3287 Traning Loss: tensor(0.1277)\n",
      "3288 Traning Loss: tensor(0.1272)\n",
      "3289 Traning Loss: tensor(0.1263)\n",
      "3290 Traning Loss: tensor(0.1266)\n",
      "3291 Traning Loss: tensor(0.1257)\n",
      "3292 Traning Loss: tensor(0.1274)\n",
      "3293 Traning Loss: tensor(0.1270)\n",
      "3294 Traning Loss: tensor(0.1267)\n",
      "3295 Traning Loss: tensor(0.1263)\n",
      "3296 Traning Loss: tensor(0.1275)\n",
      "3297 Traning Loss: tensor(0.1272)\n",
      "3298 Traning Loss: tensor(0.1274)\n",
      "3299 Traning Loss: tensor(0.1273)\n",
      "3300 Traning Loss: tensor(0.1267)\n",
      "3301 Traning Loss: tensor(0.1269)\n",
      "3302 Traning Loss: tensor(0.1270)\n",
      "3303 Traning Loss: tensor(0.1274)\n",
      "3304 Traning Loss: tensor(0.1266)\n",
      "3305 Traning Loss: tensor(0.1268)\n",
      "3306 Traning Loss: tensor(0.1261)\n",
      "3307 Traning Loss: tensor(0.1263)\n",
      "3308 Traning Loss: tensor(0.1263)\n",
      "3309 Traning Loss: tensor(0.1261)\n",
      "3310 Traning Loss: tensor(0.1265)\n",
      "3311 Traning Loss: tensor(0.1266)\n",
      "3312 Traning Loss: tensor(0.1264)\n",
      "3313 Traning Loss: tensor(0.1262)\n",
      "3314 Traning Loss: tensor(0.1261)\n",
      "3315 Traning Loss: tensor(0.1250)\n",
      "3316 Traning Loss: tensor(0.1270)\n",
      "3317 Traning Loss: tensor(0.1266)\n",
      "3318 Traning Loss: tensor(0.1264)\n",
      "3319 Traning Loss: tensor(0.1267)\n",
      "3320 Traning Loss: tensor(0.1263)\n",
      "3321 Traning Loss: tensor(0.1270)\n",
      "3322 Traning Loss: tensor(0.1257)\n",
      "3323 Traning Loss: tensor(0.1265)\n",
      "3324 Traning Loss: tensor(0.1263)\n",
      "3325 Traning Loss: tensor(0.1263)\n",
      "3326 Traning Loss: tensor(0.1252)\n",
      "3327 Traning Loss: tensor(0.1271)\n",
      "3328 Traning Loss: tensor(0.1265)\n",
      "3329 Traning Loss: tensor(0.1266)\n",
      "3330 Traning Loss: tensor(0.1262)\n",
      "3331 Traning Loss: tensor(0.1264)\n",
      "3332 Traning Loss: tensor(0.1254)\n",
      "3333 Traning Loss: tensor(0.1258)\n",
      "3334 Traning Loss: tensor(0.1260)\n",
      "3335 Traning Loss: tensor(0.1262)\n",
      "3336 Traning Loss: tensor(0.1269)\n",
      "3337 Traning Loss: tensor(0.1257)\n",
      "3338 Traning Loss: tensor(0.1273)\n",
      "3339 Traning Loss: tensor(0.1258)\n",
      "3340 Traning Loss: tensor(0.1248)\n",
      "3341 Traning Loss: tensor(0.1264)\n",
      "3342 Traning Loss: tensor(0.1266)\n",
      "3343 Traning Loss: tensor(0.1246)\n",
      "3344 Traning Loss: tensor(0.1258)\n",
      "3345 Traning Loss: tensor(0.1252)\n",
      "3346 Traning Loss: tensor(0.1250)\n",
      "3347 Traning Loss: tensor(0.1261)\n",
      "3348 Traning Loss: tensor(0.1268)\n",
      "3349 Traning Loss: tensor(0.1267)\n",
      "3350 Traning Loss: tensor(0.1269)\n",
      "3351 Traning Loss: tensor(0.1247)\n",
      "3352 Traning Loss: tensor(0.1254)\n",
      "3353 Traning Loss: tensor(0.1260)\n",
      "3354 Traning Loss: tensor(0.1252)\n",
      "3355 Traning Loss: tensor(0.1257)\n",
      "3356 Traning Loss: tensor(0.1251)\n",
      "3357 Traning Loss: tensor(0.1249)\n",
      "3358 Traning Loss: tensor(0.1254)\n",
      "3359 Traning Loss: tensor(0.1265)\n",
      "3360 Traning Loss: tensor(0.1257)\n",
      "3361 Traning Loss: tensor(0.1265)\n",
      "3362 Traning Loss: tensor(0.1262)\n",
      "3363 Traning Loss: tensor(0.1254)\n",
      "3364 Traning Loss: tensor(0.1264)\n",
      "3365 Traning Loss: tensor(0.1249)\n",
      "3366 Traning Loss: tensor(0.1252)\n",
      "3367 Traning Loss: tensor(0.1260)\n",
      "3368 Traning Loss: tensor(0.1250)\n",
      "3369 Traning Loss: tensor(0.1261)\n",
      "3370 Traning Loss: tensor(0.1262)\n",
      "3371 Traning Loss: tensor(0.1251)\n",
      "3372 Traning Loss: tensor(0.1258)\n",
      "3373 Traning Loss: tensor(0.1259)\n",
      "3374 Traning Loss: tensor(0.1248)\n",
      "3375 Traning Loss: tensor(0.1258)\n",
      "3376 Traning Loss: tensor(0.1249)\n",
      "3377 Traning Loss: tensor(0.1266)\n",
      "3378 Traning Loss: tensor(0.1251)\n",
      "3379 Traning Loss: tensor(0.1251)\n",
      "3380 Traning Loss: tensor(0.1263)\n",
      "3381 Traning Loss: tensor(0.1255)\n",
      "3382 Traning Loss: tensor(0.1251)\n",
      "3383 Traning Loss: tensor(0.1257)\n",
      "3384 Traning Loss: tensor(0.1250)\n",
      "3385 Traning Loss: tensor(0.1259)\n",
      "3386 Traning Loss: tensor(0.1256)\n",
      "3387 Traning Loss: tensor(0.1254)\n",
      "3388 Traning Loss: tensor(0.1254)\n",
      "3389 Traning Loss: tensor(0.1257)\n",
      "3390 Traning Loss: tensor(0.1253)\n",
      "3391 Traning Loss: tensor(0.1249)\n",
      "3392 Traning Loss: tensor(0.1249)\n",
      "3393 Traning Loss: tensor(0.1243)\n",
      "3394 Traning Loss: tensor(0.1246)\n",
      "3395 Traning Loss: tensor(0.1261)\n",
      "3396 Traning Loss: tensor(0.1258)\n",
      "3397 Traning Loss: tensor(0.1251)\n",
      "3398 Traning Loss: tensor(0.1242)\n",
      "3399 Traning Loss: tensor(0.1255)\n",
      "3400 Traning Loss: tensor(0.1247)\n",
      "3401 Traning Loss: tensor(0.1251)\n",
      "3402 Traning Loss: tensor(0.1238)\n",
      "3403 Traning Loss: tensor(0.1239)\n",
      "3404 Traning Loss: tensor(0.1245)\n",
      "3405 Traning Loss: tensor(0.1247)\n",
      "3406 Traning Loss: tensor(0.1253)\n",
      "3407 Traning Loss: tensor(0.1246)\n",
      "3408 Traning Loss: tensor(0.1254)\n",
      "3409 Traning Loss: tensor(0.1250)\n",
      "3410 Traning Loss: tensor(0.1252)\n",
      "3411 Traning Loss: tensor(0.1231)\n",
      "3412 Traning Loss: tensor(0.1254)\n",
      "3413 Traning Loss: tensor(0.1254)\n",
      "3414 Traning Loss: tensor(0.1237)\n",
      "3415 Traning Loss: tensor(0.1250)\n",
      "3416 Traning Loss: tensor(0.1247)\n",
      "3417 Traning Loss: tensor(0.1251)\n",
      "3418 Traning Loss: tensor(0.1242)\n",
      "3419 Traning Loss: tensor(0.1248)\n",
      "3420 Traning Loss: tensor(0.1242)\n",
      "3421 Traning Loss: tensor(0.1250)\n",
      "3422 Traning Loss: tensor(0.1238)\n",
      "3423 Traning Loss: tensor(0.1251)\n",
      "3424 Traning Loss: tensor(0.1250)\n",
      "3425 Traning Loss: tensor(0.1248)\n",
      "3426 Traning Loss: tensor(0.1250)\n",
      "3427 Traning Loss: tensor(0.1252)\n",
      "3428 Traning Loss: tensor(0.1247)\n",
      "3429 Traning Loss: tensor(0.1242)\n",
      "3430 Traning Loss: tensor(0.1244)\n",
      "3431 Traning Loss: tensor(0.1239)\n",
      "3432 Traning Loss: tensor(0.1249)\n",
      "3433 Traning Loss: tensor(0.1258)\n",
      "3434 Traning Loss: tensor(0.1237)\n",
      "3435 Traning Loss: tensor(0.1249)\n",
      "3436 Traning Loss: tensor(0.1246)\n",
      "3437 Traning Loss: tensor(0.1249)\n",
      "3438 Traning Loss: tensor(0.1240)\n",
      "3439 Traning Loss: tensor(0.1246)\n",
      "3440 Traning Loss: tensor(0.1258)\n",
      "3441 Traning Loss: tensor(0.1244)\n",
      "3442 Traning Loss: tensor(0.1242)\n",
      "3443 Traning Loss: tensor(0.1251)\n",
      "3444 Traning Loss: tensor(0.1236)\n",
      "3445 Traning Loss: tensor(0.1237)\n",
      "3446 Traning Loss: tensor(0.1243)\n",
      "3447 Traning Loss: tensor(0.1235)\n",
      "3448 Traning Loss: tensor(0.1242)\n",
      "3449 Traning Loss: tensor(0.1250)\n",
      "3450 Traning Loss: tensor(0.1244)\n",
      "3451 Traning Loss: tensor(0.1245)\n",
      "3452 Traning Loss: tensor(0.1245)\n",
      "3453 Traning Loss: tensor(0.1248)\n",
      "3454 Traning Loss: tensor(0.1247)\n",
      "3455 Traning Loss: tensor(0.1239)\n",
      "3456 Traning Loss: tensor(0.1246)\n",
      "3457 Traning Loss: tensor(0.1243)\n",
      "3458 Traning Loss: tensor(0.1227)\n",
      "3459 Traning Loss: tensor(0.1232)\n",
      "3460 Traning Loss: tensor(0.1240)\n",
      "3461 Traning Loss: tensor(0.1225)\n",
      "3462 Traning Loss: tensor(0.1251)\n",
      "3463 Traning Loss: tensor(0.1238)\n",
      "3464 Traning Loss: tensor(0.1222)\n",
      "3465 Traning Loss: tensor(0.1241)\n",
      "3466 Traning Loss: tensor(0.1236)\n",
      "3467 Traning Loss: tensor(0.1243)\n",
      "3468 Traning Loss: tensor(0.1235)\n",
      "3469 Traning Loss: tensor(0.1243)\n",
      "3470 Traning Loss: tensor(0.1244)\n",
      "3471 Traning Loss: tensor(0.1242)\n",
      "3472 Traning Loss: tensor(0.1253)\n",
      "3473 Traning Loss: tensor(0.1230)\n",
      "3474 Traning Loss: tensor(0.1233)\n",
      "3475 Traning Loss: tensor(0.1237)\n",
      "3476 Traning Loss: tensor(0.1230)\n",
      "3477 Traning Loss: tensor(0.1233)\n",
      "3478 Traning Loss: tensor(0.1237)\n",
      "3479 Traning Loss: tensor(0.1227)\n",
      "3480 Traning Loss: tensor(0.1236)\n",
      "3481 Traning Loss: tensor(0.1248)\n",
      "3482 Traning Loss: tensor(0.1236)\n",
      "3483 Traning Loss: tensor(0.1237)\n",
      "3484 Traning Loss: tensor(0.1240)\n",
      "3485 Traning Loss: tensor(0.1235)\n",
      "3486 Traning Loss: tensor(0.1232)\n",
      "3487 Traning Loss: tensor(0.1242)\n",
      "3488 Traning Loss: tensor(0.1240)\n",
      "3489 Traning Loss: tensor(0.1236)\n",
      "3490 Traning Loss: tensor(0.1230)\n",
      "3491 Traning Loss: tensor(0.1229)\n",
      "3492 Traning Loss: tensor(0.1228)\n",
      "3493 Traning Loss: tensor(0.1213)\n",
      "3494 Traning Loss: tensor(0.1228)\n",
      "3495 Traning Loss: tensor(0.1222)\n",
      "3496 Traning Loss: tensor(0.1232)\n",
      "3497 Traning Loss: tensor(0.1237)\n",
      "3498 Traning Loss: tensor(0.1230)\n",
      "3499 Traning Loss: tensor(0.1235)\n",
      "3500 Traning Loss: tensor(0.1228)\n",
      "3501 Traning Loss: tensor(0.1235)\n",
      "3502 Traning Loss: tensor(0.1235)\n",
      "3503 Traning Loss: tensor(0.1226)\n",
      "3504 Traning Loss: tensor(0.1228)\n",
      "3505 Traning Loss: tensor(0.1223)\n",
      "3506 Traning Loss: tensor(0.1225)\n",
      "3507 Traning Loss: tensor(0.1239)\n",
      "3508 Traning Loss: tensor(0.1237)\n",
      "3509 Traning Loss: tensor(0.1240)\n",
      "3510 Traning Loss: tensor(0.1240)\n",
      "3511 Traning Loss: tensor(0.1242)\n",
      "3512 Traning Loss: tensor(0.1224)\n",
      "3513 Traning Loss: tensor(0.1232)\n",
      "3514 Traning Loss: tensor(0.1228)\n",
      "3515 Traning Loss: tensor(0.1227)\n",
      "3516 Traning Loss: tensor(0.1241)\n",
      "3517 Traning Loss: tensor(0.1236)\n",
      "3518 Traning Loss: tensor(0.1232)\n",
      "3519 Traning Loss: tensor(0.1234)\n",
      "3520 Traning Loss: tensor(0.1233)\n",
      "3521 Traning Loss: tensor(0.1225)\n",
      "3522 Traning Loss: tensor(0.1220)\n",
      "3523 Traning Loss: tensor(0.1228)\n",
      "3524 Traning Loss: tensor(0.1230)\n",
      "3525 Traning Loss: tensor(0.1220)\n",
      "3526 Traning Loss: tensor(0.1232)\n",
      "3527 Traning Loss: tensor(0.1228)\n",
      "3528 Traning Loss: tensor(0.1225)\n",
      "3529 Traning Loss: tensor(0.1229)\n",
      "3530 Traning Loss: tensor(0.1211)\n",
      "3531 Traning Loss: tensor(0.1229)\n",
      "3532 Traning Loss: tensor(0.1228)\n",
      "3533 Traning Loss: tensor(0.1214)\n",
      "3534 Traning Loss: tensor(0.1223)\n",
      "3535 Traning Loss: tensor(0.1227)\n",
      "3536 Traning Loss: tensor(0.1219)\n",
      "3537 Traning Loss: tensor(0.1217)\n",
      "3538 Traning Loss: tensor(0.1226)\n",
      "3539 Traning Loss: tensor(0.1228)\n",
      "3540 Traning Loss: tensor(0.1214)\n",
      "3541 Traning Loss: tensor(0.1225)\n",
      "3542 Traning Loss: tensor(0.1218)\n",
      "3543 Traning Loss: tensor(0.1215)\n",
      "3544 Traning Loss: tensor(0.1218)\n",
      "3545 Traning Loss: tensor(0.1224)\n",
      "3546 Traning Loss: tensor(0.1220)\n",
      "3547 Traning Loss: tensor(0.1232)\n",
      "3548 Traning Loss: tensor(0.1223)\n",
      "3549 Traning Loss: tensor(0.1220)\n",
      "3550 Traning Loss: tensor(0.1225)\n",
      "3551 Traning Loss: tensor(0.1216)\n",
      "3552 Traning Loss: tensor(0.1221)\n",
      "3553 Traning Loss: tensor(0.1220)\n",
      "3554 Traning Loss: tensor(0.1210)\n",
      "3555 Traning Loss: tensor(0.1214)\n",
      "3556 Traning Loss: tensor(0.1220)\n",
      "3557 Traning Loss: tensor(0.1221)\n",
      "3558 Traning Loss: tensor(0.1218)\n",
      "3559 Traning Loss: tensor(0.1219)\n",
      "3560 Traning Loss: tensor(0.1226)\n",
      "3561 Traning Loss: tensor(0.1217)\n",
      "3562 Traning Loss: tensor(0.1224)\n",
      "3563 Traning Loss: tensor(0.1227)\n",
      "3564 Traning Loss: tensor(0.1230)\n",
      "3565 Traning Loss: tensor(0.1220)\n",
      "3566 Traning Loss: tensor(0.1233)\n",
      "3567 Traning Loss: tensor(0.1214)\n",
      "3568 Traning Loss: tensor(0.1218)\n",
      "3569 Traning Loss: tensor(0.1216)\n",
      "3570 Traning Loss: tensor(0.1224)\n",
      "3571 Traning Loss: tensor(0.1223)\n",
      "3572 Traning Loss: tensor(0.1229)\n",
      "3573 Traning Loss: tensor(0.1229)\n",
      "3574 Traning Loss: tensor(0.1215)\n",
      "3575 Traning Loss: tensor(0.1210)\n",
      "3576 Traning Loss: tensor(0.1215)\n",
      "3577 Traning Loss: tensor(0.1217)\n",
      "3578 Traning Loss: tensor(0.1228)\n",
      "3579 Traning Loss: tensor(0.1218)\n",
      "3580 Traning Loss: tensor(0.1224)\n",
      "3581 Traning Loss: tensor(0.1213)\n",
      "3582 Traning Loss: tensor(0.1221)\n",
      "3583 Traning Loss: tensor(0.1218)\n",
      "3584 Traning Loss: tensor(0.1224)\n",
      "3585 Traning Loss: tensor(0.1212)\n",
      "3586 Traning Loss: tensor(0.1218)\n",
      "3587 Traning Loss: tensor(0.1219)\n",
      "3588 Traning Loss: tensor(0.1202)\n",
      "3589 Traning Loss: tensor(0.1204)\n",
      "3590 Traning Loss: tensor(0.1226)\n",
      "3591 Traning Loss: tensor(0.1218)\n",
      "3592 Traning Loss: tensor(0.1221)\n",
      "3593 Traning Loss: tensor(0.1219)\n",
      "3594 Traning Loss: tensor(0.1216)\n",
      "3595 Traning Loss: tensor(0.1213)\n",
      "3596 Traning Loss: tensor(0.1226)\n",
      "3597 Traning Loss: tensor(0.1205)\n",
      "3598 Traning Loss: tensor(0.1202)\n",
      "3599 Traning Loss: tensor(0.1213)\n",
      "3600 Traning Loss: tensor(0.1218)\n",
      "3601 Traning Loss: tensor(0.1215)\n",
      "3602 Traning Loss: tensor(0.1210)\n",
      "3603 Traning Loss: tensor(0.1220)\n",
      "3604 Traning Loss: tensor(0.1213)\n",
      "3605 Traning Loss: tensor(0.1207)\n",
      "3606 Traning Loss: tensor(0.1213)\n",
      "3607 Traning Loss: tensor(0.1217)\n",
      "3608 Traning Loss: tensor(0.1211)\n",
      "3609 Traning Loss: tensor(0.1219)\n",
      "3610 Traning Loss: tensor(0.1215)\n",
      "3611 Traning Loss: tensor(0.1226)\n",
      "3612 Traning Loss: tensor(0.1212)\n",
      "3613 Traning Loss: tensor(0.1207)\n",
      "3614 Traning Loss: tensor(0.1200)\n",
      "3615 Traning Loss: tensor(0.1199)\n",
      "3616 Traning Loss: tensor(0.1210)\n",
      "3617 Traning Loss: tensor(0.1215)\n",
      "3618 Traning Loss: tensor(0.1220)\n",
      "3619 Traning Loss: tensor(0.1205)\n",
      "3620 Traning Loss: tensor(0.1214)\n",
      "3621 Traning Loss: tensor(0.1201)\n",
      "3622 Traning Loss: tensor(0.1223)\n",
      "3623 Traning Loss: tensor(0.1213)\n",
      "3624 Traning Loss: tensor(0.1217)\n",
      "3625 Traning Loss: tensor(0.1212)\n",
      "3626 Traning Loss: tensor(0.1214)\n",
      "3627 Traning Loss: tensor(0.1207)\n",
      "3628 Traning Loss: tensor(0.1218)\n",
      "3629 Traning Loss: tensor(0.1206)\n",
      "3630 Traning Loss: tensor(0.1207)\n",
      "3631 Traning Loss: tensor(0.1203)\n",
      "3632 Traning Loss: tensor(0.1211)\n",
      "3633 Traning Loss: tensor(0.1212)\n",
      "3634 Traning Loss: tensor(0.1217)\n",
      "3635 Traning Loss: tensor(0.1201)\n",
      "3636 Traning Loss: tensor(0.1215)\n",
      "3637 Traning Loss: tensor(0.1197)\n",
      "3638 Traning Loss: tensor(0.1211)\n",
      "3639 Traning Loss: tensor(0.1211)\n",
      "3640 Traning Loss: tensor(0.1205)\n",
      "3641 Traning Loss: tensor(0.1206)\n",
      "3642 Traning Loss: tensor(0.1205)\n",
      "3643 Traning Loss: tensor(0.1202)\n",
      "3644 Traning Loss: tensor(0.1207)\n",
      "3645 Traning Loss: tensor(0.1208)\n",
      "3646 Traning Loss: tensor(0.1210)\n",
      "3647 Traning Loss: tensor(0.1203)\n",
      "3648 Traning Loss: tensor(0.1202)\n",
      "3649 Traning Loss: tensor(0.1202)\n",
      "3650 Traning Loss: tensor(0.1208)\n",
      "3651 Traning Loss: tensor(0.1204)\n",
      "3652 Traning Loss: tensor(0.1206)\n",
      "3653 Traning Loss: tensor(0.1202)\n",
      "3654 Traning Loss: tensor(0.1208)\n",
      "3655 Traning Loss: tensor(0.1207)\n",
      "3656 Traning Loss: tensor(0.1205)\n",
      "3657 Traning Loss: tensor(0.1209)\n",
      "3658 Traning Loss: tensor(0.1204)\n",
      "3659 Traning Loss: tensor(0.1197)\n",
      "3660 Traning Loss: tensor(0.1206)\n",
      "3661 Traning Loss: tensor(0.1210)\n",
      "3662 Traning Loss: tensor(0.1197)\n",
      "3663 Traning Loss: tensor(0.1210)\n",
      "3664 Traning Loss: tensor(0.1202)\n",
      "3665 Traning Loss: tensor(0.1194)\n",
      "3666 Traning Loss: tensor(0.1203)\n",
      "3667 Traning Loss: tensor(0.1202)\n",
      "3668 Traning Loss: tensor(0.1197)\n",
      "3669 Traning Loss: tensor(0.1199)\n",
      "3670 Traning Loss: tensor(0.1209)\n",
      "3671 Traning Loss: tensor(0.1202)\n",
      "3672 Traning Loss: tensor(0.1213)\n",
      "3673 Traning Loss: tensor(0.1202)\n",
      "3674 Traning Loss: tensor(0.1196)\n",
      "3675 Traning Loss: tensor(0.1200)\n",
      "3676 Traning Loss: tensor(0.1187)\n",
      "3677 Traning Loss: tensor(0.1206)\n",
      "3678 Traning Loss: tensor(0.1202)\n",
      "3679 Traning Loss: tensor(0.1195)\n",
      "3680 Traning Loss: tensor(0.1204)\n",
      "3681 Traning Loss: tensor(0.1202)\n",
      "3682 Traning Loss: tensor(0.1195)\n",
      "3683 Traning Loss: tensor(0.1202)\n",
      "3684 Traning Loss: tensor(0.1201)\n",
      "3685 Traning Loss: tensor(0.1208)\n",
      "3686 Traning Loss: tensor(0.1195)\n",
      "3687 Traning Loss: tensor(0.1198)\n",
      "3688 Traning Loss: tensor(0.1211)\n",
      "3689 Traning Loss: tensor(0.1205)\n",
      "3690 Traning Loss: tensor(0.1207)\n",
      "3691 Traning Loss: tensor(0.1192)\n",
      "3692 Traning Loss: tensor(0.1182)\n",
      "3693 Traning Loss: tensor(0.1197)\n",
      "3694 Traning Loss: tensor(0.1203)\n",
      "3695 Traning Loss: tensor(0.1193)\n",
      "3696 Traning Loss: tensor(0.1199)\n",
      "3697 Traning Loss: tensor(0.1202)\n",
      "3698 Traning Loss: tensor(0.1201)\n",
      "3699 Traning Loss: tensor(0.1188)\n",
      "3700 Traning Loss: tensor(0.1199)\n",
      "3701 Traning Loss: tensor(0.1193)\n",
      "3702 Traning Loss: tensor(0.1195)\n",
      "3703 Traning Loss: tensor(0.1196)\n",
      "3704 Traning Loss: tensor(0.1197)\n",
      "3705 Traning Loss: tensor(0.1201)\n",
      "3706 Traning Loss: tensor(0.1196)\n",
      "3707 Traning Loss: tensor(0.1188)\n",
      "3708 Traning Loss: tensor(0.1197)\n",
      "3709 Traning Loss: tensor(0.1203)\n",
      "3710 Traning Loss: tensor(0.1198)\n",
      "3711 Traning Loss: tensor(0.1195)\n",
      "3712 Traning Loss: tensor(0.1195)\n",
      "3713 Traning Loss: tensor(0.1194)\n",
      "3714 Traning Loss: tensor(0.1188)\n",
      "3715 Traning Loss: tensor(0.1183)\n",
      "3716 Traning Loss: tensor(0.1193)\n",
      "3717 Traning Loss: tensor(0.1182)\n",
      "3718 Traning Loss: tensor(0.1205)\n",
      "3719 Traning Loss: tensor(0.1195)\n",
      "3720 Traning Loss: tensor(0.1189)\n",
      "3721 Traning Loss: tensor(0.1188)\n",
      "3722 Traning Loss: tensor(0.1198)\n",
      "3723 Traning Loss: tensor(0.1186)\n",
      "3724 Traning Loss: tensor(0.1185)\n",
      "3725 Traning Loss: tensor(0.1185)\n",
      "3726 Traning Loss: tensor(0.1205)\n",
      "3727 Traning Loss: tensor(0.1197)\n",
      "3728 Traning Loss: tensor(0.1201)\n",
      "3729 Traning Loss: tensor(0.1189)\n",
      "3730 Traning Loss: tensor(0.1190)\n",
      "3731 Traning Loss: tensor(0.1191)\n",
      "3732 Traning Loss: tensor(0.1191)\n",
      "3733 Traning Loss: tensor(0.1191)\n",
      "3734 Traning Loss: tensor(0.1188)\n",
      "3735 Traning Loss: tensor(0.1196)\n",
      "3736 Traning Loss: tensor(0.1187)\n",
      "3737 Traning Loss: tensor(0.1187)\n",
      "3738 Traning Loss: tensor(0.1188)\n",
      "3739 Traning Loss: tensor(0.1187)\n",
      "3740 Traning Loss: tensor(0.1184)\n",
      "3741 Traning Loss: tensor(0.1196)\n",
      "3742 Traning Loss: tensor(0.1180)\n",
      "3743 Traning Loss: tensor(0.1185)\n",
      "3744 Traning Loss: tensor(0.1185)\n",
      "3745 Traning Loss: tensor(0.1185)\n",
      "3746 Traning Loss: tensor(0.1198)\n",
      "3747 Traning Loss: tensor(0.1192)\n",
      "3748 Traning Loss: tensor(0.1184)\n",
      "3749 Traning Loss: tensor(0.1204)\n",
      "3750 Traning Loss: tensor(0.1197)\n",
      "3751 Traning Loss: tensor(0.1194)\n",
      "3752 Traning Loss: tensor(0.1190)\n",
      "3753 Traning Loss: tensor(0.1182)\n",
      "3754 Traning Loss: tensor(0.1193)\n",
      "3755 Traning Loss: tensor(0.1185)\n",
      "3756 Traning Loss: tensor(0.1184)\n",
      "3757 Traning Loss: tensor(0.1184)\n",
      "3758 Traning Loss: tensor(0.1189)\n",
      "3759 Traning Loss: tensor(0.1194)\n",
      "3760 Traning Loss: tensor(0.1174)\n",
      "3761 Traning Loss: tensor(0.1184)\n",
      "3762 Traning Loss: tensor(0.1185)\n",
      "3763 Traning Loss: tensor(0.1187)\n",
      "3764 Traning Loss: tensor(0.1184)\n",
      "3765 Traning Loss: tensor(0.1178)\n",
      "3766 Traning Loss: tensor(0.1190)\n",
      "3767 Traning Loss: tensor(0.1190)\n",
      "3768 Traning Loss: tensor(0.1181)\n",
      "3769 Traning Loss: tensor(0.1181)\n",
      "3770 Traning Loss: tensor(0.1175)\n",
      "3771 Traning Loss: tensor(0.1182)\n",
      "3772 Traning Loss: tensor(0.1183)\n",
      "3773 Traning Loss: tensor(0.1184)\n",
      "3774 Traning Loss: tensor(0.1190)\n",
      "3775 Traning Loss: tensor(0.1175)\n",
      "3776 Traning Loss: tensor(0.1185)\n",
      "3777 Traning Loss: tensor(0.1178)\n",
      "3778 Traning Loss: tensor(0.1185)\n",
      "3779 Traning Loss: tensor(0.1182)\n",
      "3780 Traning Loss: tensor(0.1178)\n",
      "3781 Traning Loss: tensor(0.1182)\n",
      "3782 Traning Loss: tensor(0.1170)\n",
      "3783 Traning Loss: tensor(0.1182)\n",
      "3784 Traning Loss: tensor(0.1172)\n",
      "3785 Traning Loss: tensor(0.1171)\n",
      "3786 Traning Loss: tensor(0.1184)\n",
      "3787 Traning Loss: tensor(0.1187)\n",
      "3788 Traning Loss: tensor(0.1167)\n",
      "3789 Traning Loss: tensor(0.1170)\n",
      "3790 Traning Loss: tensor(0.1177)\n",
      "3791 Traning Loss: tensor(0.1166)\n",
      "3792 Traning Loss: tensor(0.1169)\n",
      "3793 Traning Loss: tensor(0.1192)\n",
      "3794 Traning Loss: tensor(0.1187)\n",
      "3795 Traning Loss: tensor(0.1178)\n",
      "3796 Traning Loss: tensor(0.1177)\n",
      "3797 Traning Loss: tensor(0.1182)\n",
      "3798 Traning Loss: tensor(0.1180)\n",
      "3799 Traning Loss: tensor(0.1179)\n",
      "3800 Traning Loss: tensor(0.1178)\n",
      "3801 Traning Loss: tensor(0.1174)\n",
      "3802 Traning Loss: tensor(0.1188)\n",
      "3803 Traning Loss: tensor(0.1177)\n",
      "3804 Traning Loss: tensor(0.1166)\n",
      "3805 Traning Loss: tensor(0.1171)\n",
      "3806 Traning Loss: tensor(0.1182)\n",
      "3807 Traning Loss: tensor(0.1171)\n",
      "3808 Traning Loss: tensor(0.1177)\n",
      "3809 Traning Loss: tensor(0.1166)\n",
      "3810 Traning Loss: tensor(0.1175)\n",
      "3811 Traning Loss: tensor(0.1162)\n",
      "3812 Traning Loss: tensor(0.1170)\n",
      "3813 Traning Loss: tensor(0.1178)\n",
      "3814 Traning Loss: tensor(0.1191)\n",
      "3815 Traning Loss: tensor(0.1171)\n",
      "3816 Traning Loss: tensor(0.1178)\n",
      "3817 Traning Loss: tensor(0.1181)\n",
      "3818 Traning Loss: tensor(0.1178)\n",
      "3819 Traning Loss: tensor(0.1174)\n",
      "3820 Traning Loss: tensor(0.1176)\n",
      "3821 Traning Loss: tensor(0.1166)\n",
      "3822 Traning Loss: tensor(0.1174)\n",
      "3823 Traning Loss: tensor(0.1175)\n",
      "3824 Traning Loss: tensor(0.1177)\n",
      "3825 Traning Loss: tensor(0.1167)\n",
      "3826 Traning Loss: tensor(0.1186)\n",
      "3827 Traning Loss: tensor(0.1174)\n",
      "3828 Traning Loss: tensor(0.1174)\n",
      "3829 Traning Loss: tensor(0.1169)\n",
      "3830 Traning Loss: tensor(0.1167)\n",
      "3831 Traning Loss: tensor(0.1178)\n",
      "3832 Traning Loss: tensor(0.1162)\n",
      "3833 Traning Loss: tensor(0.1165)\n",
      "3834 Traning Loss: tensor(0.1180)\n",
      "3835 Traning Loss: tensor(0.1167)\n",
      "3836 Traning Loss: tensor(0.1180)\n",
      "3837 Traning Loss: tensor(0.1165)\n",
      "3838 Traning Loss: tensor(0.1164)\n",
      "3839 Traning Loss: tensor(0.1187)\n",
      "3840 Traning Loss: tensor(0.1172)\n",
      "3841 Traning Loss: tensor(0.1165)\n",
      "3842 Traning Loss: tensor(0.1176)\n",
      "3843 Traning Loss: tensor(0.1172)\n",
      "3844 Traning Loss: tensor(0.1167)\n",
      "3845 Traning Loss: tensor(0.1167)\n",
      "3846 Traning Loss: tensor(0.1180)\n",
      "3847 Traning Loss: tensor(0.1164)\n",
      "3848 Traning Loss: tensor(0.1176)\n",
      "3849 Traning Loss: tensor(0.1155)\n",
      "3850 Traning Loss: tensor(0.1166)\n",
      "3851 Traning Loss: tensor(0.1171)\n",
      "3852 Traning Loss: tensor(0.1179)\n",
      "3853 Traning Loss: tensor(0.1164)\n",
      "3854 Traning Loss: tensor(0.1171)\n",
      "3855 Traning Loss: tensor(0.1162)\n",
      "3856 Traning Loss: tensor(0.1163)\n",
      "3857 Traning Loss: tensor(0.1163)\n",
      "3858 Traning Loss: tensor(0.1158)\n",
      "3859 Traning Loss: tensor(0.1164)\n",
      "3860 Traning Loss: tensor(0.1166)\n",
      "3861 Traning Loss: tensor(0.1169)\n",
      "3862 Traning Loss: tensor(0.1169)\n",
      "3863 Traning Loss: tensor(0.1169)\n",
      "3864 Traning Loss: tensor(0.1166)\n",
      "3865 Traning Loss: tensor(0.1168)\n",
      "3866 Traning Loss: tensor(0.1155)\n",
      "3867 Traning Loss: tensor(0.1159)\n",
      "3868 Traning Loss: tensor(0.1163)\n",
      "3869 Traning Loss: tensor(0.1157)\n",
      "3870 Traning Loss: tensor(0.1166)\n",
      "3871 Traning Loss: tensor(0.1171)\n",
      "3872 Traning Loss: tensor(0.1165)\n",
      "3873 Traning Loss: tensor(0.1165)\n",
      "3874 Traning Loss: tensor(0.1167)\n",
      "3875 Traning Loss: tensor(0.1161)\n",
      "3876 Traning Loss: tensor(0.1145)\n",
      "3877 Traning Loss: tensor(0.1152)\n",
      "3878 Traning Loss: tensor(0.1160)\n",
      "3879 Traning Loss: tensor(0.1162)\n",
      "3880 Traning Loss: tensor(0.1170)\n",
      "3881 Traning Loss: tensor(0.1157)\n",
      "3882 Traning Loss: tensor(0.1157)\n",
      "3883 Traning Loss: tensor(0.1164)\n",
      "3884 Traning Loss: tensor(0.1163)\n",
      "3885 Traning Loss: tensor(0.1159)\n",
      "3886 Traning Loss: tensor(0.1159)\n",
      "3887 Traning Loss: tensor(0.1166)\n",
      "3888 Traning Loss: tensor(0.1149)\n",
      "3889 Traning Loss: tensor(0.1162)\n",
      "3890 Traning Loss: tensor(0.1162)\n",
      "3891 Traning Loss: tensor(0.1152)\n",
      "3892 Traning Loss: tensor(0.1164)\n",
      "3893 Traning Loss: tensor(0.1155)\n",
      "3894 Traning Loss: tensor(0.1162)\n",
      "3895 Traning Loss: tensor(0.1158)\n",
      "3896 Traning Loss: tensor(0.1161)\n",
      "3897 Traning Loss: tensor(0.1150)\n",
      "3898 Traning Loss: tensor(0.1147)\n",
      "3899 Traning Loss: tensor(0.1155)\n",
      "3900 Traning Loss: tensor(0.1155)\n",
      "3901 Traning Loss: tensor(0.1167)\n",
      "3902 Traning Loss: tensor(0.1159)\n",
      "3903 Traning Loss: tensor(0.1157)\n",
      "3904 Traning Loss: tensor(0.1155)\n",
      "3905 Traning Loss: tensor(0.1166)\n",
      "3906 Traning Loss: tensor(0.1153)\n",
      "3907 Traning Loss: tensor(0.1162)\n",
      "3908 Traning Loss: tensor(0.1155)\n",
      "3909 Traning Loss: tensor(0.1151)\n",
      "3910 Traning Loss: tensor(0.1159)\n",
      "3911 Traning Loss: tensor(0.1154)\n",
      "3912 Traning Loss: tensor(0.1163)\n",
      "3913 Traning Loss: tensor(0.1158)\n",
      "3914 Traning Loss: tensor(0.1151)\n",
      "3915 Traning Loss: tensor(0.1147)\n",
      "3916 Traning Loss: tensor(0.1146)\n",
      "3917 Traning Loss: tensor(0.1146)\n",
      "3918 Traning Loss: tensor(0.1163)\n",
      "3919 Traning Loss: tensor(0.1145)\n",
      "3920 Traning Loss: tensor(0.1159)\n",
      "3921 Traning Loss: tensor(0.1150)\n",
      "3922 Traning Loss: tensor(0.1154)\n",
      "3923 Traning Loss: tensor(0.1161)\n",
      "3924 Traning Loss: tensor(0.1156)\n",
      "3925 Traning Loss: tensor(0.1148)\n",
      "3926 Traning Loss: tensor(0.1146)\n",
      "3927 Traning Loss: tensor(0.1153)\n",
      "3928 Traning Loss: tensor(0.1158)\n",
      "3929 Traning Loss: tensor(0.1150)\n",
      "3930 Traning Loss: tensor(0.1162)\n",
      "3931 Traning Loss: tensor(0.1142)\n",
      "3932 Traning Loss: tensor(0.1159)\n",
      "3933 Traning Loss: tensor(0.1156)\n",
      "3934 Traning Loss: tensor(0.1154)\n",
      "3935 Traning Loss: tensor(0.1144)\n",
      "3936 Traning Loss: tensor(0.1147)\n",
      "3937 Traning Loss: tensor(0.1160)\n",
      "3938 Traning Loss: tensor(0.1150)\n",
      "3939 Traning Loss: tensor(0.1153)\n",
      "3940 Traning Loss: tensor(0.1150)\n",
      "3941 Traning Loss: tensor(0.1156)\n",
      "3942 Traning Loss: tensor(0.1160)\n",
      "3943 Traning Loss: tensor(0.1150)\n",
      "3944 Traning Loss: tensor(0.1150)\n",
      "3945 Traning Loss: tensor(0.1134)\n",
      "3946 Traning Loss: tensor(0.1154)\n",
      "3947 Traning Loss: tensor(0.1143)\n",
      "3948 Traning Loss: tensor(0.1142)\n",
      "3949 Traning Loss: tensor(0.1148)\n",
      "3950 Traning Loss: tensor(0.1162)\n",
      "3951 Traning Loss: tensor(0.1144)\n",
      "3952 Traning Loss: tensor(0.1144)\n",
      "3953 Traning Loss: tensor(0.1153)\n",
      "3954 Traning Loss: tensor(0.1150)\n",
      "3955 Traning Loss: tensor(0.1142)\n",
      "3956 Traning Loss: tensor(0.1150)\n",
      "3957 Traning Loss: tensor(0.1154)\n",
      "3958 Traning Loss: tensor(0.1156)\n",
      "3959 Traning Loss: tensor(0.1144)\n",
      "3960 Traning Loss: tensor(0.1140)\n",
      "3961 Traning Loss: tensor(0.1144)\n",
      "3962 Traning Loss: tensor(0.1156)\n",
      "3963 Traning Loss: tensor(0.1142)\n",
      "3964 Traning Loss: tensor(0.1144)\n",
      "3965 Traning Loss: tensor(0.1150)\n",
      "3966 Traning Loss: tensor(0.1141)\n",
      "3967 Traning Loss: tensor(0.1138)\n",
      "3968 Traning Loss: tensor(0.1152)\n",
      "3969 Traning Loss: tensor(0.1150)\n",
      "3970 Traning Loss: tensor(0.1150)\n",
      "3971 Traning Loss: tensor(0.1159)\n",
      "3972 Traning Loss: tensor(0.1138)\n",
      "3973 Traning Loss: tensor(0.1140)\n",
      "3974 Traning Loss: tensor(0.1148)\n",
      "3975 Traning Loss: tensor(0.1127)\n",
      "3976 Traning Loss: tensor(0.1140)\n",
      "3977 Traning Loss: tensor(0.1144)\n",
      "3978 Traning Loss: tensor(0.1136)\n",
      "3979 Traning Loss: tensor(0.1142)\n",
      "3980 Traning Loss: tensor(0.1131)\n",
      "3981 Traning Loss: tensor(0.1140)\n",
      "3982 Traning Loss: tensor(0.1140)\n",
      "3983 Traning Loss: tensor(0.1149)\n",
      "3984 Traning Loss: tensor(0.1132)\n",
      "3985 Traning Loss: tensor(0.1148)\n",
      "3986 Traning Loss: tensor(0.1143)\n",
      "3987 Traning Loss: tensor(0.1144)\n",
      "3988 Traning Loss: tensor(0.1142)\n",
      "3989 Traning Loss: tensor(0.1141)\n",
      "3990 Traning Loss: tensor(0.1141)\n",
      "3991 Traning Loss: tensor(0.1142)\n",
      "3992 Traning Loss: tensor(0.1135)\n",
      "3993 Traning Loss: tensor(0.1136)\n",
      "3994 Traning Loss: tensor(0.1128)\n",
      "3995 Traning Loss: tensor(0.1133)\n",
      "3996 Traning Loss: tensor(0.1137)\n",
      "3997 Traning Loss: tensor(0.1143)\n",
      "3998 Traning Loss: tensor(0.1139)\n",
      "3999 Traning Loss: tensor(0.1142)\n",
      "4000 Traning Loss: tensor(0.1140)\n",
      "4001 Traning Loss: tensor(0.1133)\n",
      "4002 Traning Loss: tensor(0.1141)\n",
      "4003 Traning Loss: tensor(0.1133)\n",
      "4004 Traning Loss: tensor(0.1131)\n",
      "4005 Traning Loss: tensor(0.1139)\n",
      "4006 Traning Loss: tensor(0.1142)\n",
      "4007 Traning Loss: tensor(0.1140)\n",
      "4008 Traning Loss: tensor(0.1142)\n",
      "4009 Traning Loss: tensor(0.1129)\n",
      "4010 Traning Loss: tensor(0.1144)\n",
      "4011 Traning Loss: tensor(0.1138)\n",
      "4012 Traning Loss: tensor(0.1145)\n",
      "4013 Traning Loss: tensor(0.1125)\n",
      "4014 Traning Loss: tensor(0.1137)\n",
      "4015 Traning Loss: tensor(0.1133)\n",
      "4016 Traning Loss: tensor(0.1146)\n",
      "4017 Traning Loss: tensor(0.1143)\n",
      "4018 Traning Loss: tensor(0.1140)\n",
      "4019 Traning Loss: tensor(0.1133)\n",
      "4020 Traning Loss: tensor(0.1135)\n",
      "4021 Traning Loss: tensor(0.1132)\n",
      "4022 Traning Loss: tensor(0.1130)\n",
      "4023 Traning Loss: tensor(0.1134)\n",
      "4024 Traning Loss: tensor(0.1136)\n",
      "4025 Traning Loss: tensor(0.1128)\n",
      "4026 Traning Loss: tensor(0.1142)\n",
      "4027 Traning Loss: tensor(0.1137)\n",
      "4028 Traning Loss: tensor(0.1140)\n",
      "4029 Traning Loss: tensor(0.1128)\n",
      "4030 Traning Loss: tensor(0.1131)\n",
      "4031 Traning Loss: tensor(0.1125)\n",
      "4032 Traning Loss: tensor(0.1132)\n",
      "4033 Traning Loss: tensor(0.1144)\n",
      "4034 Traning Loss: tensor(0.1131)\n",
      "4035 Traning Loss: tensor(0.1145)\n",
      "4036 Traning Loss: tensor(0.1143)\n",
      "4037 Traning Loss: tensor(0.1122)\n",
      "4038 Traning Loss: tensor(0.1120)\n",
      "4039 Traning Loss: tensor(0.1137)\n",
      "4040 Traning Loss: tensor(0.1120)\n",
      "4041 Traning Loss: tensor(0.1132)\n",
      "4042 Traning Loss: tensor(0.1135)\n",
      "4043 Traning Loss: tensor(0.1124)\n",
      "4044 Traning Loss: tensor(0.1123)\n",
      "4045 Traning Loss: tensor(0.1115)\n",
      "4046 Traning Loss: tensor(0.1131)\n",
      "4047 Traning Loss: tensor(0.1125)\n",
      "4048 Traning Loss: tensor(0.1135)\n",
      "4049 Traning Loss: tensor(0.1134)\n",
      "4050 Traning Loss: tensor(0.1134)\n",
      "4051 Traning Loss: tensor(0.1131)\n",
      "4052 Traning Loss: tensor(0.1134)\n",
      "4053 Traning Loss: tensor(0.1131)\n",
      "4054 Traning Loss: tensor(0.1125)\n",
      "4055 Traning Loss: tensor(0.1125)\n",
      "4056 Traning Loss: tensor(0.1133)\n",
      "4057 Traning Loss: tensor(0.1121)\n",
      "4058 Traning Loss: tensor(0.1130)\n",
      "4059 Traning Loss: tensor(0.1127)\n",
      "4060 Traning Loss: tensor(0.1133)\n",
      "4061 Traning Loss: tensor(0.1118)\n",
      "4062 Traning Loss: tensor(0.1120)\n",
      "4063 Traning Loss: tensor(0.1117)\n",
      "4064 Traning Loss: tensor(0.1108)\n",
      "4065 Traning Loss: tensor(0.1115)\n",
      "4066 Traning Loss: tensor(0.1115)\n",
      "4067 Traning Loss: tensor(0.1126)\n",
      "4068 Traning Loss: tensor(0.1114)\n",
      "4069 Traning Loss: tensor(0.1120)\n",
      "4070 Traning Loss: tensor(0.1129)\n",
      "4071 Traning Loss: tensor(0.1120)\n",
      "4072 Traning Loss: tensor(0.1122)\n",
      "4073 Traning Loss: tensor(0.1126)\n",
      "4074 Traning Loss: tensor(0.1127)\n",
      "4075 Traning Loss: tensor(0.1110)\n",
      "4076 Traning Loss: tensor(0.1136)\n",
      "4077 Traning Loss: tensor(0.1121)\n",
      "4078 Traning Loss: tensor(0.1125)\n",
      "4079 Traning Loss: tensor(0.1122)\n",
      "4080 Traning Loss: tensor(0.1129)\n",
      "4081 Traning Loss: tensor(0.1122)\n",
      "4082 Traning Loss: tensor(0.1119)\n",
      "4083 Traning Loss: tensor(0.1121)\n",
      "4084 Traning Loss: tensor(0.1116)\n",
      "4085 Traning Loss: tensor(0.1122)\n",
      "4086 Traning Loss: tensor(0.1134)\n",
      "4087 Traning Loss: tensor(0.1130)\n",
      "4088 Traning Loss: tensor(0.1113)\n",
      "4089 Traning Loss: tensor(0.1123)\n",
      "4090 Traning Loss: tensor(0.1122)\n",
      "4091 Traning Loss: tensor(0.1120)\n",
      "4092 Traning Loss: tensor(0.1127)\n",
      "4093 Traning Loss: tensor(0.1117)\n",
      "4094 Traning Loss: tensor(0.1124)\n",
      "4095 Traning Loss: tensor(0.1114)\n",
      "4096 Traning Loss: tensor(0.1119)\n",
      "4097 Traning Loss: tensor(0.1119)\n",
      "4098 Traning Loss: tensor(0.1120)\n",
      "4099 Traning Loss: tensor(0.1126)\n",
      "4100 Traning Loss: tensor(0.1120)\n",
      "4101 Traning Loss: tensor(0.1116)\n",
      "4102 Traning Loss: tensor(0.1115)\n",
      "4103 Traning Loss: tensor(0.1124)\n",
      "4104 Traning Loss: tensor(0.1114)\n",
      "4105 Traning Loss: tensor(0.1107)\n",
      "4106 Traning Loss: tensor(0.1104)\n",
      "4107 Traning Loss: tensor(0.1114)\n",
      "4108 Traning Loss: tensor(0.1107)\n",
      "4109 Traning Loss: tensor(0.1112)\n",
      "4110 Traning Loss: tensor(0.1107)\n",
      "4111 Traning Loss: tensor(0.1122)\n",
      "4112 Traning Loss: tensor(0.1110)\n",
      "4113 Traning Loss: tensor(0.1108)\n",
      "4114 Traning Loss: tensor(0.1114)\n",
      "4115 Traning Loss: tensor(0.1113)\n",
      "4116 Traning Loss: tensor(0.1123)\n",
      "4117 Traning Loss: tensor(0.1119)\n",
      "4118 Traning Loss: tensor(0.1105)\n",
      "4119 Traning Loss: tensor(0.1106)\n",
      "4120 Traning Loss: tensor(0.1113)\n",
      "4121 Traning Loss: tensor(0.1120)\n",
      "4122 Traning Loss: tensor(0.1125)\n",
      "4123 Traning Loss: tensor(0.1114)\n",
      "4124 Traning Loss: tensor(0.1112)\n",
      "4125 Traning Loss: tensor(0.1113)\n",
      "4126 Traning Loss: tensor(0.1108)\n",
      "4127 Traning Loss: tensor(0.1125)\n",
      "4128 Traning Loss: tensor(0.1120)\n",
      "4129 Traning Loss: tensor(0.1117)\n",
      "4130 Traning Loss: tensor(0.1117)\n",
      "4131 Traning Loss: tensor(0.1107)\n",
      "4132 Traning Loss: tensor(0.1106)\n",
      "4133 Traning Loss: tensor(0.1109)\n",
      "4134 Traning Loss: tensor(0.1113)\n",
      "4135 Traning Loss: tensor(0.1114)\n",
      "4136 Traning Loss: tensor(0.1112)\n",
      "4137 Traning Loss: tensor(0.1109)\n",
      "4138 Traning Loss: tensor(0.1114)\n",
      "4139 Traning Loss: tensor(0.1110)\n",
      "4140 Traning Loss: tensor(0.1110)\n",
      "4141 Traning Loss: tensor(0.1104)\n",
      "4142 Traning Loss: tensor(0.1110)\n",
      "4143 Traning Loss: tensor(0.1091)\n",
      "4144 Traning Loss: tensor(0.1110)\n",
      "4145 Traning Loss: tensor(0.1114)\n",
      "4146 Traning Loss: tensor(0.1103)\n",
      "4147 Traning Loss: tensor(0.1107)\n",
      "4148 Traning Loss: tensor(0.1097)\n",
      "4149 Traning Loss: tensor(0.1119)\n",
      "4150 Traning Loss: tensor(0.1111)\n",
      "4151 Traning Loss: tensor(0.1099)\n",
      "4152 Traning Loss: tensor(0.1108)\n",
      "4153 Traning Loss: tensor(0.1119)\n",
      "4154 Traning Loss: tensor(0.1106)\n",
      "4155 Traning Loss: tensor(0.1094)\n",
      "4156 Traning Loss: tensor(0.1101)\n",
      "4157 Traning Loss: tensor(0.1100)\n",
      "4158 Traning Loss: tensor(0.1120)\n",
      "4159 Traning Loss: tensor(0.1112)\n",
      "4160 Traning Loss: tensor(0.1107)\n",
      "4161 Traning Loss: tensor(0.1107)\n",
      "4162 Traning Loss: tensor(0.1100)\n",
      "4163 Traning Loss: tensor(0.1086)\n",
      "4164 Traning Loss: tensor(0.1102)\n",
      "4165 Traning Loss: tensor(0.1111)\n",
      "4166 Traning Loss: tensor(0.1109)\n",
      "4167 Traning Loss: tensor(0.1109)\n",
      "4168 Traning Loss: tensor(0.1107)\n",
      "4169 Traning Loss: tensor(0.1109)\n",
      "4170 Traning Loss: tensor(0.1097)\n",
      "4171 Traning Loss: tensor(0.1103)\n",
      "4172 Traning Loss: tensor(0.1094)\n",
      "4173 Traning Loss: tensor(0.1102)\n",
      "4174 Traning Loss: tensor(0.1094)\n",
      "4175 Traning Loss: tensor(0.1115)\n",
      "4176 Traning Loss: tensor(0.1103)\n",
      "4177 Traning Loss: tensor(0.1094)\n",
      "4178 Traning Loss: tensor(0.1105)\n",
      "4179 Traning Loss: tensor(0.1092)\n",
      "4180 Traning Loss: tensor(0.1095)\n",
      "4181 Traning Loss: tensor(0.1098)\n",
      "4182 Traning Loss: tensor(0.1097)\n",
      "4183 Traning Loss: tensor(0.1097)\n",
      "4184 Traning Loss: tensor(0.1092)\n",
      "4185 Traning Loss: tensor(0.1090)\n",
      "4186 Traning Loss: tensor(0.1118)\n",
      "4187 Traning Loss: tensor(0.1096)\n",
      "4188 Traning Loss: tensor(0.1103)\n",
      "4189 Traning Loss: tensor(0.1105)\n",
      "4190 Traning Loss: tensor(0.1111)\n",
      "4191 Traning Loss: tensor(0.1093)\n",
      "4192 Traning Loss: tensor(0.1095)\n",
      "4193 Traning Loss: tensor(0.1096)\n",
      "4194 Traning Loss: tensor(0.1092)\n",
      "4195 Traning Loss: tensor(0.1105)\n",
      "4196 Traning Loss: tensor(0.1097)\n",
      "4197 Traning Loss: tensor(0.1082)\n",
      "4198 Traning Loss: tensor(0.1098)\n",
      "4199 Traning Loss: tensor(0.1100)\n",
      "4200 Traning Loss: tensor(0.1096)\n",
      "4201 Traning Loss: tensor(0.1103)\n",
      "4202 Traning Loss: tensor(0.1091)\n",
      "4203 Traning Loss: tensor(0.1090)\n",
      "4204 Traning Loss: tensor(0.1096)\n",
      "4205 Traning Loss: tensor(0.1097)\n",
      "4206 Traning Loss: tensor(0.1081)\n",
      "4207 Traning Loss: tensor(0.1103)\n",
      "4208 Traning Loss: tensor(0.1087)\n",
      "4209 Traning Loss: tensor(0.1097)\n",
      "4210 Traning Loss: tensor(0.1097)\n",
      "4211 Traning Loss: tensor(0.1096)\n",
      "4212 Traning Loss: tensor(0.1090)\n",
      "4213 Traning Loss: tensor(0.1088)\n",
      "4214 Traning Loss: tensor(0.1089)\n",
      "4215 Traning Loss: tensor(0.1098)\n",
      "4216 Traning Loss: tensor(0.1094)\n",
      "4217 Traning Loss: tensor(0.1088)\n",
      "4218 Traning Loss: tensor(0.1087)\n",
      "4219 Traning Loss: tensor(0.1091)\n",
      "4220 Traning Loss: tensor(0.1081)\n",
      "4221 Traning Loss: tensor(0.1088)\n",
      "4222 Traning Loss: tensor(0.1090)\n",
      "4223 Traning Loss: tensor(0.1090)\n",
      "4224 Traning Loss: tensor(0.1093)\n",
      "4225 Traning Loss: tensor(0.1093)\n",
      "4226 Traning Loss: tensor(0.1094)\n",
      "4227 Traning Loss: tensor(0.1092)\n",
      "4228 Traning Loss: tensor(0.1089)\n",
      "4229 Traning Loss: tensor(0.1071)\n",
      "4230 Traning Loss: tensor(0.1093)\n",
      "4231 Traning Loss: tensor(0.1089)\n",
      "4232 Traning Loss: tensor(0.1080)\n",
      "4233 Traning Loss: tensor(0.1089)\n",
      "4234 Traning Loss: tensor(0.1093)\n",
      "4235 Traning Loss: tensor(0.1095)\n",
      "4236 Traning Loss: tensor(0.1096)\n",
      "4237 Traning Loss: tensor(0.1090)\n",
      "4238 Traning Loss: tensor(0.1082)\n",
      "4239 Traning Loss: tensor(0.1087)\n",
      "4240 Traning Loss: tensor(0.1091)\n",
      "4241 Traning Loss: tensor(0.1086)\n",
      "4242 Traning Loss: tensor(0.1092)\n",
      "4243 Traning Loss: tensor(0.1104)\n",
      "4244 Traning Loss: tensor(0.1085)\n",
      "4245 Traning Loss: tensor(0.1083)\n",
      "4246 Traning Loss: tensor(0.1083)\n",
      "4247 Traning Loss: tensor(0.1084)\n",
      "4248 Traning Loss: tensor(0.1089)\n",
      "4249 Traning Loss: tensor(0.1093)\n",
      "4250 Traning Loss: tensor(0.1079)\n",
      "4251 Traning Loss: tensor(0.1086)\n",
      "4252 Traning Loss: tensor(0.1069)\n",
      "4253 Traning Loss: tensor(0.1082)\n",
      "4254 Traning Loss: tensor(0.1093)\n",
      "4255 Traning Loss: tensor(0.1083)\n",
      "4256 Traning Loss: tensor(0.1076)\n",
      "4257 Traning Loss: tensor(0.1074)\n",
      "4258 Traning Loss: tensor(0.1074)\n",
      "4259 Traning Loss: tensor(0.1090)\n",
      "4260 Traning Loss: tensor(0.1092)\n",
      "4261 Traning Loss: tensor(0.1087)\n",
      "4262 Traning Loss: tensor(0.1071)\n",
      "4263 Traning Loss: tensor(0.1071)\n",
      "4264 Traning Loss: tensor(0.1085)\n",
      "4265 Traning Loss: tensor(0.1083)\n",
      "4266 Traning Loss: tensor(0.1078)\n",
      "4267 Traning Loss: tensor(0.1071)\n",
      "4268 Traning Loss: tensor(0.1080)\n",
      "4269 Traning Loss: tensor(0.1086)\n",
      "4270 Traning Loss: tensor(0.1085)\n",
      "4271 Traning Loss: tensor(0.1099)\n",
      "4272 Traning Loss: tensor(0.1077)\n",
      "4273 Traning Loss: tensor(0.1074)\n",
      "4274 Traning Loss: tensor(0.1078)\n",
      "4275 Traning Loss: tensor(0.1091)\n",
      "4276 Traning Loss: tensor(0.1085)\n",
      "4277 Traning Loss: tensor(0.1071)\n",
      "4278 Traning Loss: tensor(0.1071)\n",
      "4279 Traning Loss: tensor(0.1074)\n",
      "4280 Traning Loss: tensor(0.1081)\n",
      "4281 Traning Loss: tensor(0.1080)\n",
      "4282 Traning Loss: tensor(0.1075)\n",
      "4283 Traning Loss: tensor(0.1074)\n",
      "4284 Traning Loss: tensor(0.1070)\n",
      "4285 Traning Loss: tensor(0.1074)\n",
      "4286 Traning Loss: tensor(0.1071)\n",
      "4287 Traning Loss: tensor(0.1074)\n",
      "4288 Traning Loss: tensor(0.1076)\n",
      "4289 Traning Loss: tensor(0.1080)\n",
      "4290 Traning Loss: tensor(0.1072)\n",
      "4291 Traning Loss: tensor(0.1076)\n",
      "4292 Traning Loss: tensor(0.1081)\n",
      "4293 Traning Loss: tensor(0.1086)\n",
      "4294 Traning Loss: tensor(0.1075)\n",
      "4295 Traning Loss: tensor(0.1069)\n",
      "4296 Traning Loss: tensor(0.1077)\n",
      "4297 Traning Loss: tensor(0.1079)\n",
      "4298 Traning Loss: tensor(0.1077)\n",
      "4299 Traning Loss: tensor(0.1075)\n",
      "4300 Traning Loss: tensor(0.1071)\n",
      "4301 Traning Loss: tensor(0.1074)\n",
      "4302 Traning Loss: tensor(0.1079)\n",
      "4303 Traning Loss: tensor(0.1074)\n",
      "4304 Traning Loss: tensor(0.1078)\n",
      "4305 Traning Loss: tensor(0.1078)\n",
      "4306 Traning Loss: tensor(0.1070)\n",
      "4307 Traning Loss: tensor(0.1074)\n",
      "4308 Traning Loss: tensor(0.1076)\n",
      "4309 Traning Loss: tensor(0.1071)\n",
      "4310 Traning Loss: tensor(0.1066)\n",
      "4311 Traning Loss: tensor(0.1068)\n",
      "4312 Traning Loss: tensor(0.1065)\n",
      "4313 Traning Loss: tensor(0.1066)\n",
      "4314 Traning Loss: tensor(0.1078)\n",
      "4315 Traning Loss: tensor(0.1061)\n",
      "4316 Traning Loss: tensor(0.1069)\n",
      "4317 Traning Loss: tensor(0.1079)\n",
      "4318 Traning Loss: tensor(0.1071)\n",
      "4319 Traning Loss: tensor(0.1054)\n",
      "4320 Traning Loss: tensor(0.1067)\n",
      "4321 Traning Loss: tensor(0.1069)\n",
      "4322 Traning Loss: tensor(0.1064)\n",
      "4323 Traning Loss: tensor(0.1071)\n",
      "4324 Traning Loss: tensor(0.1060)\n",
      "4325 Traning Loss: tensor(0.1073)\n",
      "4326 Traning Loss: tensor(0.1070)\n",
      "4327 Traning Loss: tensor(0.1069)\n",
      "4328 Traning Loss: tensor(0.1069)\n",
      "4329 Traning Loss: tensor(0.1072)\n",
      "4330 Traning Loss: tensor(0.1061)\n",
      "4331 Traning Loss: tensor(0.1074)\n",
      "4332 Traning Loss: tensor(0.1079)\n",
      "4333 Traning Loss: tensor(0.1056)\n",
      "4334 Traning Loss: tensor(0.1073)\n",
      "4335 Traning Loss: tensor(0.1068)\n",
      "4336 Traning Loss: tensor(0.1070)\n",
      "4337 Traning Loss: tensor(0.1071)\n",
      "4338 Traning Loss: tensor(0.1067)\n",
      "4339 Traning Loss: tensor(0.1060)\n",
      "4340 Traning Loss: tensor(0.1067)\n",
      "4341 Traning Loss: tensor(0.1064)\n",
      "4342 Traning Loss: tensor(0.1069)\n",
      "4343 Traning Loss: tensor(0.1066)\n",
      "4344 Traning Loss: tensor(0.1065)\n",
      "4345 Traning Loss: tensor(0.1061)\n",
      "4346 Traning Loss: tensor(0.1067)\n",
      "4347 Traning Loss: tensor(0.1068)\n",
      "4348 Traning Loss: tensor(0.1067)\n",
      "4349 Traning Loss: tensor(0.1067)\n",
      "4350 Traning Loss: tensor(0.1067)\n",
      "4351 Traning Loss: tensor(0.1064)\n",
      "4352 Traning Loss: tensor(0.1066)\n",
      "4353 Traning Loss: tensor(0.1072)\n",
      "4354 Traning Loss: tensor(0.1065)\n",
      "4355 Traning Loss: tensor(0.1051)\n",
      "4356 Traning Loss: tensor(0.1065)\n",
      "4357 Traning Loss: tensor(0.1068)\n",
      "4358 Traning Loss: tensor(0.1061)\n",
      "4359 Traning Loss: tensor(0.1053)\n",
      "4360 Traning Loss: tensor(0.1069)\n",
      "4361 Traning Loss: tensor(0.1061)\n",
      "4362 Traning Loss: tensor(0.1051)\n",
      "4363 Traning Loss: tensor(0.1062)\n",
      "4364 Traning Loss: tensor(0.1050)\n",
      "4365 Traning Loss: tensor(0.1065)\n",
      "4366 Traning Loss: tensor(0.1071)\n",
      "4367 Traning Loss: tensor(0.1048)\n",
      "4368 Traning Loss: tensor(0.1054)\n",
      "4369 Traning Loss: tensor(0.1063)\n",
      "4370 Traning Loss: tensor(0.1053)\n",
      "4371 Traning Loss: tensor(0.1054)\n",
      "4372 Traning Loss: tensor(0.1059)\n",
      "4373 Traning Loss: tensor(0.1063)\n",
      "4374 Traning Loss: tensor(0.1055)\n",
      "4375 Traning Loss: tensor(0.1055)\n",
      "4376 Traning Loss: tensor(0.1054)\n",
      "4377 Traning Loss: tensor(0.1065)\n",
      "4378 Traning Loss: tensor(0.1048)\n",
      "4379 Traning Loss: tensor(0.1044)\n",
      "4380 Traning Loss: tensor(0.1057)\n",
      "4381 Traning Loss: tensor(0.1048)\n",
      "4382 Traning Loss: tensor(0.1051)\n",
      "4383 Traning Loss: tensor(0.1064)\n",
      "4384 Traning Loss: tensor(0.1060)\n",
      "4385 Traning Loss: tensor(0.1067)\n",
      "4386 Traning Loss: tensor(0.1052)\n",
      "4387 Traning Loss: tensor(0.1055)\n",
      "4388 Traning Loss: tensor(0.1053)\n",
      "4389 Traning Loss: tensor(0.1055)\n",
      "4390 Traning Loss: tensor(0.1053)\n",
      "4391 Traning Loss: tensor(0.1060)\n",
      "4392 Traning Loss: tensor(0.1043)\n",
      "4393 Traning Loss: tensor(0.1048)\n",
      "4394 Traning Loss: tensor(0.1052)\n",
      "4395 Traning Loss: tensor(0.1048)\n",
      "4396 Traning Loss: tensor(0.1053)\n",
      "4397 Traning Loss: tensor(0.1060)\n",
      "4398 Traning Loss: tensor(0.1054)\n",
      "4399 Traning Loss: tensor(0.1055)\n",
      "4400 Traning Loss: tensor(0.1044)\n",
      "4401 Traning Loss: tensor(0.1050)\n",
      "4402 Traning Loss: tensor(0.1060)\n",
      "4403 Traning Loss: tensor(0.1046)\n",
      "4404 Traning Loss: tensor(0.1054)\n",
      "4405 Traning Loss: tensor(0.1053)\n",
      "4406 Traning Loss: tensor(0.1039)\n",
      "4407 Traning Loss: tensor(0.1047)\n",
      "4408 Traning Loss: tensor(0.1041)\n",
      "4409 Traning Loss: tensor(0.1042)\n",
      "4410 Traning Loss: tensor(0.1045)\n",
      "4411 Traning Loss: tensor(0.1049)\n",
      "4412 Traning Loss: tensor(0.1051)\n",
      "4413 Traning Loss: tensor(0.1049)\n",
      "4414 Traning Loss: tensor(0.1041)\n",
      "4415 Traning Loss: tensor(0.1049)\n",
      "4416 Traning Loss: tensor(0.1057)\n",
      "4417 Traning Loss: tensor(0.1059)\n",
      "4418 Traning Loss: tensor(0.1037)\n",
      "4419 Traning Loss: tensor(0.1047)\n",
      "4420 Traning Loss: tensor(0.1044)\n",
      "4421 Traning Loss: tensor(0.1061)\n",
      "4422 Traning Loss: tensor(0.1048)\n",
      "4423 Traning Loss: tensor(0.1048)\n",
      "4424 Traning Loss: tensor(0.1040)\n",
      "4425 Traning Loss: tensor(0.1035)\n",
      "4426 Traning Loss: tensor(0.1053)\n",
      "4427 Traning Loss: tensor(0.1041)\n",
      "4428 Traning Loss: tensor(0.1053)\n",
      "4429 Traning Loss: tensor(0.1046)\n",
      "4430 Traning Loss: tensor(0.1047)\n",
      "4431 Traning Loss: tensor(0.1042)\n",
      "4432 Traning Loss: tensor(0.1047)\n",
      "4433 Traning Loss: tensor(0.1041)\n",
      "4434 Traning Loss: tensor(0.1044)\n",
      "4435 Traning Loss: tensor(0.1049)\n",
      "4436 Traning Loss: tensor(0.1035)\n",
      "4437 Traning Loss: tensor(0.1049)\n",
      "4438 Traning Loss: tensor(0.1032)\n",
      "4439 Traning Loss: tensor(0.1040)\n",
      "4440 Traning Loss: tensor(0.1047)\n",
      "4441 Traning Loss: tensor(0.1047)\n",
      "4442 Traning Loss: tensor(0.1048)\n",
      "4443 Traning Loss: tensor(0.1036)\n",
      "4444 Traning Loss: tensor(0.1048)\n",
      "4445 Traning Loss: tensor(0.1047)\n",
      "4446 Traning Loss: tensor(0.1038)\n",
      "4447 Traning Loss: tensor(0.1049)\n",
      "4448 Traning Loss: tensor(0.1045)\n",
      "4449 Traning Loss: tensor(0.1041)\n",
      "4450 Traning Loss: tensor(0.1040)\n",
      "4451 Traning Loss: tensor(0.1043)\n",
      "4452 Traning Loss: tensor(0.1041)\n",
      "4453 Traning Loss: tensor(0.1039)\n",
      "4454 Traning Loss: tensor(0.1042)\n",
      "4455 Traning Loss: tensor(0.1018)\n",
      "4456 Traning Loss: tensor(0.1046)\n",
      "4457 Traning Loss: tensor(0.1016)\n",
      "4458 Traning Loss: tensor(0.1040)\n",
      "4459 Traning Loss: tensor(0.1034)\n",
      "4460 Traning Loss: tensor(0.1044)\n",
      "4461 Traning Loss: tensor(0.1042)\n",
      "4462 Traning Loss: tensor(0.1049)\n",
      "4463 Traning Loss: tensor(0.1047)\n",
      "4464 Traning Loss: tensor(0.1038)\n",
      "4465 Traning Loss: tensor(0.1031)\n",
      "4466 Traning Loss: tensor(0.1040)\n",
      "4467 Traning Loss: tensor(0.1044)\n",
      "4468 Traning Loss: tensor(0.1034)\n",
      "4469 Traning Loss: tensor(0.1038)\n",
      "4470 Traning Loss: tensor(0.1028)\n",
      "4471 Traning Loss: tensor(0.1045)\n",
      "4472 Traning Loss: tensor(0.1026)\n",
      "4473 Traning Loss: tensor(0.1026)\n",
      "4474 Traning Loss: tensor(0.1053)\n",
      "4475 Traning Loss: tensor(0.1030)\n",
      "4476 Traning Loss: tensor(0.1042)\n",
      "4477 Traning Loss: tensor(0.1026)\n",
      "4478 Traning Loss: tensor(0.1045)\n",
      "4479 Traning Loss: tensor(0.1043)\n",
      "4480 Traning Loss: tensor(0.1035)\n",
      "4481 Traning Loss: tensor(0.1028)\n",
      "4482 Traning Loss: tensor(0.1042)\n",
      "4483 Traning Loss: tensor(0.1030)\n",
      "4484 Traning Loss: tensor(0.1037)\n",
      "4485 Traning Loss: tensor(0.1034)\n",
      "4486 Traning Loss: tensor(0.1047)\n",
      "4487 Traning Loss: tensor(0.1032)\n",
      "4488 Traning Loss: tensor(0.1028)\n",
      "4489 Traning Loss: tensor(0.1029)\n",
      "4490 Traning Loss: tensor(0.1055)\n",
      "4491 Traning Loss: tensor(0.1034)\n",
      "4492 Traning Loss: tensor(0.1023)\n",
      "4493 Traning Loss: tensor(0.1032)\n",
      "4494 Traning Loss: tensor(0.1025)\n",
      "4495 Traning Loss: tensor(0.1024)\n",
      "4496 Traning Loss: tensor(0.1025)\n",
      "4497 Traning Loss: tensor(0.1030)\n",
      "4498 Traning Loss: tensor(0.1045)\n",
      "4499 Traning Loss: tensor(0.1038)\n",
      "4500 Traning Loss: tensor(0.1022)\n",
      "4501 Traning Loss: tensor(0.1021)\n",
      "4502 Traning Loss: tensor(0.1030)\n",
      "4503 Traning Loss: tensor(0.1027)\n",
      "4504 Traning Loss: tensor(0.1024)\n",
      "4505 Traning Loss: tensor(0.1019)\n",
      "4506 Traning Loss: tensor(0.1026)\n",
      "4507 Traning Loss: tensor(0.1034)\n",
      "4508 Traning Loss: tensor(0.1023)\n",
      "4509 Traning Loss: tensor(0.1024)\n",
      "4510 Traning Loss: tensor(0.1033)\n",
      "4511 Traning Loss: tensor(0.1021)\n",
      "4512 Traning Loss: tensor(0.1030)\n",
      "4513 Traning Loss: tensor(0.1013)\n",
      "4514 Traning Loss: tensor(0.1023)\n",
      "4515 Traning Loss: tensor(0.1030)\n",
      "4516 Traning Loss: tensor(0.1023)\n",
      "4517 Traning Loss: tensor(0.1031)\n",
      "4518 Traning Loss: tensor(0.1019)\n",
      "4519 Traning Loss: tensor(0.1030)\n",
      "4520 Traning Loss: tensor(0.1019)\n",
      "4521 Traning Loss: tensor(0.1028)\n",
      "4522 Traning Loss: tensor(0.1021)\n",
      "4523 Traning Loss: tensor(0.1019)\n",
      "4524 Traning Loss: tensor(0.1035)\n",
      "4525 Traning Loss: tensor(0.1027)\n",
      "4526 Traning Loss: tensor(0.1023)\n",
      "4527 Traning Loss: tensor(0.1036)\n",
      "4528 Traning Loss: tensor(0.1032)\n",
      "4529 Traning Loss: tensor(0.1024)\n",
      "4530 Traning Loss: tensor(0.1029)\n",
      "4531 Traning Loss: tensor(0.1019)\n",
      "4532 Traning Loss: tensor(0.1011)\n",
      "4533 Traning Loss: tensor(0.1018)\n",
      "4534 Traning Loss: tensor(0.1019)\n",
      "4535 Traning Loss: tensor(0.1025)\n",
      "4536 Traning Loss: tensor(0.1022)\n",
      "4537 Traning Loss: tensor(0.1018)\n",
      "4538 Traning Loss: tensor(0.1016)\n",
      "4539 Traning Loss: tensor(0.1026)\n",
      "4540 Traning Loss: tensor(0.1021)\n",
      "4541 Traning Loss: tensor(0.1009)\n",
      "4542 Traning Loss: tensor(0.1020)\n",
      "4543 Traning Loss: tensor(0.1009)\n",
      "4544 Traning Loss: tensor(0.1029)\n",
      "4545 Traning Loss: tensor(0.1021)\n",
      "4546 Traning Loss: tensor(0.1018)\n",
      "4547 Traning Loss: tensor(0.1022)\n",
      "4548 Traning Loss: tensor(0.1008)\n",
      "4549 Traning Loss: tensor(0.1023)\n",
      "4550 Traning Loss: tensor(0.1032)\n",
      "4551 Traning Loss: tensor(0.1017)\n",
      "4552 Traning Loss: tensor(0.1023)\n",
      "4553 Traning Loss: tensor(0.1008)\n",
      "4554 Traning Loss: tensor(0.1021)\n",
      "4555 Traning Loss: tensor(0.1018)\n",
      "4556 Traning Loss: tensor(0.1018)\n",
      "4557 Traning Loss: tensor(0.1011)\n",
      "4558 Traning Loss: tensor(0.1014)\n",
      "4559 Traning Loss: tensor(0.1016)\n",
      "4560 Traning Loss: tensor(0.1022)\n",
      "4561 Traning Loss: tensor(0.1019)\n",
      "4562 Traning Loss: tensor(0.1026)\n",
      "4563 Traning Loss: tensor(0.1010)\n",
      "4564 Traning Loss: tensor(0.1015)\n",
      "4565 Traning Loss: tensor(0.1010)\n",
      "4566 Traning Loss: tensor(0.1014)\n",
      "4567 Traning Loss: tensor(0.1015)\n",
      "4568 Traning Loss: tensor(0.1012)\n",
      "4569 Traning Loss: tensor(0.1016)\n",
      "4570 Traning Loss: tensor(0.1028)\n",
      "4571 Traning Loss: tensor(0.1011)\n",
      "4572 Traning Loss: tensor(0.1023)\n",
      "4573 Traning Loss: tensor(0.1020)\n",
      "4574 Traning Loss: tensor(0.1003)\n",
      "4575 Traning Loss: tensor(0.1011)\n",
      "4576 Traning Loss: tensor(0.1000)\n",
      "4577 Traning Loss: tensor(0.1012)\n",
      "4578 Traning Loss: tensor(0.1011)\n",
      "4579 Traning Loss: tensor(0.1010)\n",
      "4580 Traning Loss: tensor(0.1003)\n",
      "4581 Traning Loss: tensor(0.1016)\n",
      "4582 Traning Loss: tensor(0.1020)\n",
      "4583 Traning Loss: tensor(0.1012)\n",
      "4584 Traning Loss: tensor(0.1019)\n",
      "4585 Traning Loss: tensor(0.1011)\n",
      "4586 Traning Loss: tensor(0.1017)\n",
      "4587 Traning Loss: tensor(0.1017)\n",
      "4588 Traning Loss: tensor(0.1021)\n",
      "4589 Traning Loss: tensor(0.1016)\n",
      "4590 Traning Loss: tensor(0.1020)\n",
      "4591 Traning Loss: tensor(0.1012)\n",
      "4592 Traning Loss: tensor(0.1010)\n",
      "4593 Traning Loss: tensor(0.1009)\n",
      "4594 Traning Loss: tensor(0.1012)\n",
      "4595 Traning Loss: tensor(0.1008)\n",
      "4596 Traning Loss: tensor(0.0999)\n",
      "4597 Traning Loss: tensor(0.1002)\n",
      "4598 Traning Loss: tensor(0.1013)\n",
      "4599 Traning Loss: tensor(0.1010)\n",
      "4600 Traning Loss: tensor(0.1008)\n",
      "4601 Traning Loss: tensor(0.1016)\n",
      "4602 Traning Loss: tensor(0.1020)\n",
      "4603 Traning Loss: tensor(0.1013)\n",
      "4604 Traning Loss: tensor(0.1006)\n",
      "4605 Traning Loss: tensor(0.1000)\n",
      "4606 Traning Loss: tensor(0.1011)\n",
      "4607 Traning Loss: tensor(0.1002)\n",
      "4608 Traning Loss: tensor(0.1003)\n",
      "4609 Traning Loss: tensor(0.1006)\n",
      "4610 Traning Loss: tensor(0.1006)\n",
      "4611 Traning Loss: tensor(0.1011)\n",
      "4612 Traning Loss: tensor(0.1002)\n",
      "4613 Traning Loss: tensor(0.0997)\n",
      "4614 Traning Loss: tensor(0.1011)\n",
      "4615 Traning Loss: tensor(0.1003)\n",
      "4616 Traning Loss: tensor(0.1007)\n",
      "4617 Traning Loss: tensor(0.0994)\n",
      "4618 Traning Loss: tensor(0.1005)\n",
      "4619 Traning Loss: tensor(0.0998)\n",
      "4620 Traning Loss: tensor(0.1017)\n",
      "4621 Traning Loss: tensor(0.1013)\n",
      "4622 Traning Loss: tensor(0.0998)\n",
      "4623 Traning Loss: tensor(0.1007)\n",
      "4624 Traning Loss: tensor(0.1001)\n",
      "4625 Traning Loss: tensor(0.1009)\n",
      "4626 Traning Loss: tensor(0.1005)\n",
      "4627 Traning Loss: tensor(0.1014)\n",
      "4628 Traning Loss: tensor(0.1009)\n",
      "4629 Traning Loss: tensor(0.1001)\n",
      "4630 Traning Loss: tensor(0.1015)\n",
      "4631 Traning Loss: tensor(0.1010)\n",
      "4632 Traning Loss: tensor(0.1016)\n",
      "4633 Traning Loss: tensor(0.1013)\n",
      "4634 Traning Loss: tensor(0.1001)\n",
      "4635 Traning Loss: tensor(0.1003)\n",
      "4636 Traning Loss: tensor(0.1015)\n",
      "4637 Traning Loss: tensor(0.0998)\n",
      "4638 Traning Loss: tensor(0.1015)\n",
      "4639 Traning Loss: tensor(0.1013)\n",
      "4640 Traning Loss: tensor(0.0996)\n",
      "4641 Traning Loss: tensor(0.1002)\n",
      "4642 Traning Loss: tensor(0.1007)\n",
      "4643 Traning Loss: tensor(0.1009)\n",
      "4644 Traning Loss: tensor(0.0998)\n",
      "4645 Traning Loss: tensor(0.1006)\n",
      "4646 Traning Loss: tensor(0.0988)\n",
      "4647 Traning Loss: tensor(0.1004)\n",
      "4648 Traning Loss: tensor(0.0999)\n",
      "4649 Traning Loss: tensor(0.1001)\n",
      "4650 Traning Loss: tensor(0.1001)\n",
      "4651 Traning Loss: tensor(0.1002)\n",
      "4652 Traning Loss: tensor(0.1000)\n",
      "4653 Traning Loss: tensor(0.0998)\n",
      "4654 Traning Loss: tensor(0.0998)\n",
      "4655 Traning Loss: tensor(0.1004)\n",
      "4656 Traning Loss: tensor(0.0992)\n",
      "4657 Traning Loss: tensor(0.0997)\n",
      "4658 Traning Loss: tensor(0.0995)\n",
      "4659 Traning Loss: tensor(0.1008)\n",
      "4660 Traning Loss: tensor(0.0999)\n",
      "4661 Traning Loss: tensor(0.0993)\n",
      "4662 Traning Loss: tensor(0.0992)\n",
      "4663 Traning Loss: tensor(0.0983)\n",
      "4664 Traning Loss: tensor(0.1004)\n",
      "4665 Traning Loss: tensor(0.0986)\n",
      "4666 Traning Loss: tensor(0.0985)\n",
      "4667 Traning Loss: tensor(0.0990)\n",
      "4668 Traning Loss: tensor(0.0991)\n",
      "4669 Traning Loss: tensor(0.0996)\n",
      "4670 Traning Loss: tensor(0.0996)\n",
      "4671 Traning Loss: tensor(0.0997)\n",
      "4672 Traning Loss: tensor(0.0988)\n",
      "4673 Traning Loss: tensor(0.0995)\n",
      "4674 Traning Loss: tensor(0.1004)\n",
      "4675 Traning Loss: tensor(0.0999)\n",
      "4676 Traning Loss: tensor(0.0992)\n",
      "4677 Traning Loss: tensor(0.1000)\n",
      "4678 Traning Loss: tensor(0.1005)\n",
      "4679 Traning Loss: tensor(0.0990)\n",
      "4680 Traning Loss: tensor(0.0973)\n",
      "4681 Traning Loss: tensor(0.1000)\n",
      "4682 Traning Loss: tensor(0.0994)\n",
      "4683 Traning Loss: tensor(0.0990)\n",
      "4684 Traning Loss: tensor(0.1010)\n",
      "4685 Traning Loss: tensor(0.0997)\n",
      "4686 Traning Loss: tensor(0.1000)\n",
      "4687 Traning Loss: tensor(0.0994)\n",
      "4688 Traning Loss: tensor(0.0990)\n",
      "4689 Traning Loss: tensor(0.0986)\n",
      "4690 Traning Loss: tensor(0.0985)\n",
      "4691 Traning Loss: tensor(0.0993)\n",
      "4692 Traning Loss: tensor(0.0992)\n",
      "4693 Traning Loss: tensor(0.1005)\n",
      "4694 Traning Loss: tensor(0.0988)\n",
      "4695 Traning Loss: tensor(0.0992)\n",
      "4696 Traning Loss: tensor(0.0994)\n",
      "4697 Traning Loss: tensor(0.0997)\n",
      "4698 Traning Loss: tensor(0.0992)\n",
      "4699 Traning Loss: tensor(0.0981)\n",
      "4700 Traning Loss: tensor(0.0979)\n",
      "4701 Traning Loss: tensor(0.1000)\n",
      "4702 Traning Loss: tensor(0.0987)\n",
      "4703 Traning Loss: tensor(0.0997)\n",
      "4704 Traning Loss: tensor(0.1001)\n",
      "4705 Traning Loss: tensor(0.0989)\n",
      "4706 Traning Loss: tensor(0.0978)\n",
      "4707 Traning Loss: tensor(0.0990)\n",
      "4708 Traning Loss: tensor(0.0994)\n",
      "4709 Traning Loss: tensor(0.0990)\n",
      "4710 Traning Loss: tensor(0.0988)\n",
      "4711 Traning Loss: tensor(0.0988)\n",
      "4712 Traning Loss: tensor(0.0996)\n",
      "4713 Traning Loss: tensor(0.0983)\n",
      "4714 Traning Loss: tensor(0.0994)\n",
      "4715 Traning Loss: tensor(0.0980)\n",
      "4716 Traning Loss: tensor(0.0993)\n",
      "4717 Traning Loss: tensor(0.0980)\n",
      "4718 Traning Loss: tensor(0.0973)\n",
      "4719 Traning Loss: tensor(0.0980)\n",
      "4720 Traning Loss: tensor(0.0988)\n",
      "4721 Traning Loss: tensor(0.0996)\n",
      "4722 Traning Loss: tensor(0.0984)\n",
      "4723 Traning Loss: tensor(0.0986)\n",
      "4724 Traning Loss: tensor(0.0997)\n",
      "4725 Traning Loss: tensor(0.0990)\n",
      "4726 Traning Loss: tensor(0.0996)\n",
      "4727 Traning Loss: tensor(0.0984)\n",
      "4728 Traning Loss: tensor(0.0986)\n",
      "4729 Traning Loss: tensor(0.0975)\n",
      "4730 Traning Loss: tensor(0.0995)\n",
      "4731 Traning Loss: tensor(0.0986)\n",
      "4732 Traning Loss: tensor(0.0989)\n",
      "4733 Traning Loss: tensor(0.0980)\n",
      "4734 Traning Loss: tensor(0.0982)\n",
      "4735 Traning Loss: tensor(0.0984)\n",
      "4736 Traning Loss: tensor(0.0995)\n",
      "4737 Traning Loss: tensor(0.0985)\n",
      "4738 Traning Loss: tensor(0.0984)\n",
      "4739 Traning Loss: tensor(0.0984)\n",
      "4740 Traning Loss: tensor(0.0986)\n",
      "4741 Traning Loss: tensor(0.0986)\n",
      "4742 Traning Loss: tensor(0.0977)\n",
      "4743 Traning Loss: tensor(0.0991)\n",
      "4744 Traning Loss: tensor(0.0985)\n",
      "4745 Traning Loss: tensor(0.0970)\n",
      "4746 Traning Loss: tensor(0.0977)\n",
      "4747 Traning Loss: tensor(0.0978)\n",
      "4748 Traning Loss: tensor(0.0995)\n",
      "4749 Traning Loss: tensor(0.0983)\n",
      "4750 Traning Loss: tensor(0.0981)\n",
      "4751 Traning Loss: tensor(0.0982)\n",
      "4752 Traning Loss: tensor(0.0990)\n",
      "4753 Traning Loss: tensor(0.0989)\n",
      "4754 Traning Loss: tensor(0.0985)\n",
      "4755 Traning Loss: tensor(0.0971)\n",
      "4756 Traning Loss: tensor(0.0980)\n",
      "4757 Traning Loss: tensor(0.0974)\n",
      "4758 Traning Loss: tensor(0.0991)\n",
      "4759 Traning Loss: tensor(0.0991)\n",
      "4760 Traning Loss: tensor(0.0979)\n",
      "4761 Traning Loss: tensor(0.0983)\n",
      "4762 Traning Loss: tensor(0.0988)\n",
      "4763 Traning Loss: tensor(0.0987)\n",
      "4764 Traning Loss: tensor(0.0983)\n",
      "4765 Traning Loss: tensor(0.0971)\n",
      "4766 Traning Loss: tensor(0.0993)\n",
      "4767 Traning Loss: tensor(0.0986)\n",
      "4768 Traning Loss: tensor(0.0985)\n",
      "4769 Traning Loss: tensor(0.0988)\n",
      "4770 Traning Loss: tensor(0.0983)\n",
      "4771 Traning Loss: tensor(0.0976)\n",
      "4772 Traning Loss: tensor(0.0972)\n",
      "4773 Traning Loss: tensor(0.0981)\n",
      "4774 Traning Loss: tensor(0.0984)\n",
      "4775 Traning Loss: tensor(0.0986)\n",
      "4776 Traning Loss: tensor(0.0982)\n",
      "4777 Traning Loss: tensor(0.0982)\n",
      "4778 Traning Loss: tensor(0.0975)\n",
      "4779 Traning Loss: tensor(0.0977)\n",
      "4780 Traning Loss: tensor(0.0982)\n",
      "4781 Traning Loss: tensor(0.0960)\n",
      "4782 Traning Loss: tensor(0.0975)\n",
      "4783 Traning Loss: tensor(0.0973)\n",
      "4784 Traning Loss: tensor(0.0974)\n",
      "4785 Traning Loss: tensor(0.0976)\n",
      "4786 Traning Loss: tensor(0.0987)\n",
      "4787 Traning Loss: tensor(0.0978)\n",
      "4788 Traning Loss: tensor(0.0985)\n",
      "4789 Traning Loss: tensor(0.0977)\n",
      "4790 Traning Loss: tensor(0.0983)\n",
      "4791 Traning Loss: tensor(0.0979)\n",
      "4792 Traning Loss: tensor(0.0978)\n",
      "4793 Traning Loss: tensor(0.0977)\n",
      "4794 Traning Loss: tensor(0.0973)\n",
      "4795 Traning Loss: tensor(0.0973)\n",
      "4796 Traning Loss: tensor(0.0980)\n",
      "4797 Traning Loss: tensor(0.0974)\n",
      "4798 Traning Loss: tensor(0.0984)\n",
      "4799 Traning Loss: tensor(0.0980)\n",
      "4800 Traning Loss: tensor(0.0973)\n",
      "4801 Traning Loss: tensor(0.0973)\n",
      "4802 Traning Loss: tensor(0.0978)\n",
      "4803 Traning Loss: tensor(0.0976)\n",
      "4804 Traning Loss: tensor(0.0971)\n",
      "4805 Traning Loss: tensor(0.0979)\n",
      "4806 Traning Loss: tensor(0.0976)\n",
      "4807 Traning Loss: tensor(0.0974)\n",
      "4808 Traning Loss: tensor(0.0973)\n",
      "4809 Traning Loss: tensor(0.0984)\n",
      "4810 Traning Loss: tensor(0.0963)\n",
      "4811 Traning Loss: tensor(0.0978)\n",
      "4812 Traning Loss: tensor(0.0980)\n",
      "4813 Traning Loss: tensor(0.0972)\n",
      "4814 Traning Loss: tensor(0.0977)\n",
      "4815 Traning Loss: tensor(0.0965)\n",
      "4816 Traning Loss: tensor(0.0969)\n",
      "4817 Traning Loss: tensor(0.0974)\n",
      "4818 Traning Loss: tensor(0.0980)\n",
      "4819 Traning Loss: tensor(0.0969)\n",
      "4820 Traning Loss: tensor(0.0980)\n",
      "4821 Traning Loss: tensor(0.0975)\n",
      "4822 Traning Loss: tensor(0.0973)\n",
      "4823 Traning Loss: tensor(0.0967)\n",
      "4824 Traning Loss: tensor(0.0968)\n",
      "4825 Traning Loss: tensor(0.0971)\n",
      "4826 Traning Loss: tensor(0.0962)\n",
      "4827 Traning Loss: tensor(0.0965)\n",
      "4828 Traning Loss: tensor(0.0971)\n",
      "4829 Traning Loss: tensor(0.0969)\n",
      "4830 Traning Loss: tensor(0.0973)\n",
      "4831 Traning Loss: tensor(0.0971)\n",
      "4832 Traning Loss: tensor(0.0974)\n",
      "4833 Traning Loss: tensor(0.0976)\n",
      "4834 Traning Loss: tensor(0.0973)\n",
      "4835 Traning Loss: tensor(0.0973)\n",
      "4836 Traning Loss: tensor(0.0961)\n",
      "4837 Traning Loss: tensor(0.0971)\n",
      "4838 Traning Loss: tensor(0.0964)\n",
      "4839 Traning Loss: tensor(0.0969)\n",
      "4840 Traning Loss: tensor(0.0968)\n",
      "4841 Traning Loss: tensor(0.0971)\n",
      "4842 Traning Loss: tensor(0.0971)\n",
      "4843 Traning Loss: tensor(0.0964)\n",
      "4844 Traning Loss: tensor(0.0977)\n",
      "4845 Traning Loss: tensor(0.0963)\n",
      "4846 Traning Loss: tensor(0.0969)\n",
      "4847 Traning Loss: tensor(0.0973)\n",
      "4848 Traning Loss: tensor(0.0965)\n",
      "4849 Traning Loss: tensor(0.0966)\n",
      "4850 Traning Loss: tensor(0.0968)\n",
      "4851 Traning Loss: tensor(0.0967)\n",
      "4852 Traning Loss: tensor(0.0966)\n",
      "4853 Traning Loss: tensor(0.0956)\n",
      "4854 Traning Loss: tensor(0.0969)\n",
      "4855 Traning Loss: tensor(0.0978)\n",
      "4856 Traning Loss: tensor(0.0971)\n",
      "4857 Traning Loss: tensor(0.0959)\n",
      "4858 Traning Loss: tensor(0.0982)\n",
      "4859 Traning Loss: tensor(0.0971)\n",
      "4860 Traning Loss: tensor(0.0969)\n",
      "4861 Traning Loss: tensor(0.0965)\n",
      "4862 Traning Loss: tensor(0.0966)\n",
      "4863 Traning Loss: tensor(0.0980)\n",
      "4864 Traning Loss: tensor(0.0969)\n",
      "4865 Traning Loss: tensor(0.0958)\n",
      "4866 Traning Loss: tensor(0.0973)\n",
      "4867 Traning Loss: tensor(0.0960)\n",
      "4868 Traning Loss: tensor(0.0958)\n",
      "4869 Traning Loss: tensor(0.0968)\n",
      "4870 Traning Loss: tensor(0.0960)\n",
      "4871 Traning Loss: tensor(0.0969)\n",
      "4872 Traning Loss: tensor(0.0949)\n",
      "4873 Traning Loss: tensor(0.0972)\n",
      "4874 Traning Loss: tensor(0.0971)\n",
      "4875 Traning Loss: tensor(0.0956)\n",
      "4876 Traning Loss: tensor(0.0959)\n",
      "4877 Traning Loss: tensor(0.0957)\n",
      "4878 Traning Loss: tensor(0.0969)\n",
      "4879 Traning Loss: tensor(0.0966)\n",
      "4880 Traning Loss: tensor(0.0953)\n",
      "4881 Traning Loss: tensor(0.0965)\n",
      "4882 Traning Loss: tensor(0.0957)\n",
      "4883 Traning Loss: tensor(0.0964)\n",
      "4884 Traning Loss: tensor(0.0955)\n",
      "4885 Traning Loss: tensor(0.0965)\n",
      "4886 Traning Loss: tensor(0.0963)\n",
      "4887 Traning Loss: tensor(0.0954)\n",
      "4888 Traning Loss: tensor(0.0960)\n",
      "4889 Traning Loss: tensor(0.0968)\n",
      "4890 Traning Loss: tensor(0.0965)\n",
      "4891 Traning Loss: tensor(0.0963)\n",
      "4892 Traning Loss: tensor(0.0962)\n",
      "4893 Traning Loss: tensor(0.0960)\n",
      "4894 Traning Loss: tensor(0.0963)\n",
      "4895 Traning Loss: tensor(0.0968)\n",
      "4896 Traning Loss: tensor(0.0966)\n",
      "4897 Traning Loss: tensor(0.0958)\n",
      "4898 Traning Loss: tensor(0.0956)\n",
      "4899 Traning Loss: tensor(0.0948)\n",
      "4900 Traning Loss: tensor(0.0969)\n",
      "4901 Traning Loss: tensor(0.0967)\n",
      "4902 Traning Loss: tensor(0.0964)\n",
      "4903 Traning Loss: tensor(0.0950)\n",
      "4904 Traning Loss: tensor(0.0952)\n",
      "4905 Traning Loss: tensor(0.0960)\n",
      "4906 Traning Loss: tensor(0.0957)\n",
      "4907 Traning Loss: tensor(0.0961)\n",
      "4908 Traning Loss: tensor(0.0960)\n",
      "4909 Traning Loss: tensor(0.0959)\n",
      "4910 Traning Loss: tensor(0.0966)\n",
      "4911 Traning Loss: tensor(0.0958)\n",
      "4912 Traning Loss: tensor(0.0960)\n",
      "4913 Traning Loss: tensor(0.0952)\n",
      "4914 Traning Loss: tensor(0.0963)\n",
      "4915 Traning Loss: tensor(0.0950)\n",
      "4916 Traning Loss: tensor(0.0961)\n",
      "4917 Traning Loss: tensor(0.0951)\n",
      "4918 Traning Loss: tensor(0.0966)\n",
      "4919 Traning Loss: tensor(0.0942)\n",
      "4920 Traning Loss: tensor(0.0963)\n",
      "4921 Traning Loss: tensor(0.0955)\n",
      "4922 Traning Loss: tensor(0.0950)\n",
      "4923 Traning Loss: tensor(0.0951)\n",
      "4924 Traning Loss: tensor(0.0951)\n",
      "4925 Traning Loss: tensor(0.0968)\n",
      "4926 Traning Loss: tensor(0.0947)\n",
      "4927 Traning Loss: tensor(0.0964)\n",
      "4928 Traning Loss: tensor(0.0953)\n",
      "4929 Traning Loss: tensor(0.0974)\n",
      "4930 Traning Loss: tensor(0.0958)\n",
      "4931 Traning Loss: tensor(0.0951)\n",
      "4932 Traning Loss: tensor(0.0951)\n",
      "4933 Traning Loss: tensor(0.0956)\n",
      "4934 Traning Loss: tensor(0.0956)\n",
      "4935 Traning Loss: tensor(0.0954)\n",
      "4936 Traning Loss: tensor(0.0950)\n",
      "4937 Traning Loss: tensor(0.0952)\n",
      "4938 Traning Loss: tensor(0.0951)\n",
      "4939 Traning Loss: tensor(0.0948)\n",
      "4940 Traning Loss: tensor(0.0951)\n",
      "4941 Traning Loss: tensor(0.0952)\n",
      "4942 Traning Loss: tensor(0.0958)\n",
      "4943 Traning Loss: tensor(0.0953)\n",
      "4944 Traning Loss: tensor(0.0954)\n",
      "4945 Traning Loss: tensor(0.0944)\n",
      "4946 Traning Loss: tensor(0.0950)\n",
      "4947 Traning Loss: tensor(0.0947)\n",
      "4948 Traning Loss: tensor(0.0947)\n",
      "4949 Traning Loss: tensor(0.0942)\n",
      "4950 Traning Loss: tensor(0.0946)\n",
      "4951 Traning Loss: tensor(0.0948)\n",
      "4952 Traning Loss: tensor(0.0956)\n",
      "4953 Traning Loss: tensor(0.0957)\n",
      "4954 Traning Loss: tensor(0.0956)\n",
      "4955 Traning Loss: tensor(0.0951)\n",
      "4956 Traning Loss: tensor(0.0953)\n",
      "4957 Traning Loss: tensor(0.0953)\n",
      "4958 Traning Loss: tensor(0.0964)\n",
      "4959 Traning Loss: tensor(0.0953)\n",
      "4960 Traning Loss: tensor(0.0954)\n",
      "4961 Traning Loss: tensor(0.0945)\n",
      "4962 Traning Loss: tensor(0.0962)\n",
      "4963 Traning Loss: tensor(0.0952)\n",
      "4964 Traning Loss: tensor(0.0946)\n",
      "4965 Traning Loss: tensor(0.0950)\n",
      "4966 Traning Loss: tensor(0.0951)\n",
      "4967 Traning Loss: tensor(0.0957)\n",
      "4968 Traning Loss: tensor(0.0950)\n",
      "4969 Traning Loss: tensor(0.0952)\n",
      "4970 Traning Loss: tensor(0.0952)\n",
      "4971 Traning Loss: tensor(0.0955)\n",
      "4972 Traning Loss: tensor(0.0940)\n",
      "4973 Traning Loss: tensor(0.0948)\n",
      "4974 Traning Loss: tensor(0.0949)\n",
      "4975 Traning Loss: tensor(0.0950)\n",
      "4976 Traning Loss: tensor(0.0949)\n",
      "4977 Traning Loss: tensor(0.0945)\n",
      "4978 Traning Loss: tensor(0.0948)\n",
      "4979 Traning Loss: tensor(0.0950)\n",
      "4980 Traning Loss: tensor(0.0951)\n",
      "4981 Traning Loss: tensor(0.0950)\n",
      "4982 Traning Loss: tensor(0.0933)\n",
      "4983 Traning Loss: tensor(0.0960)\n",
      "4984 Traning Loss: tensor(0.0942)\n",
      "4985 Traning Loss: tensor(0.0939)\n",
      "4986 Traning Loss: tensor(0.0958)\n",
      "4987 Traning Loss: tensor(0.0966)\n",
      "4988 Traning Loss: tensor(0.0955)\n",
      "4989 Traning Loss: tensor(0.0941)\n",
      "4990 Traning Loss: tensor(0.0936)\n",
      "4991 Traning Loss: tensor(0.0946)\n",
      "4992 Traning Loss: tensor(0.0942)\n",
      "4993 Traning Loss: tensor(0.0961)\n",
      "4994 Traning Loss: tensor(0.0947)\n",
      "4995 Traning Loss: tensor(0.0941)\n",
      "4996 Traning Loss: tensor(0.0962)\n",
      "4997 Traning Loss: tensor(0.0952)\n",
      "4998 Traning Loss: tensor(0.0941)\n",
      "4999 Traning Loss: tensor(0.0935)\n",
      "5000 Traning Loss: tensor(0.0942)\n",
      "5001 Traning Loss: tensor(0.0945)\n",
      "5002 Traning Loss: tensor(0.0939)\n",
      "5003 Traning Loss: tensor(0.0947)\n",
      "5004 Traning Loss: tensor(0.0955)\n",
      "5005 Traning Loss: tensor(0.0951)\n",
      "5006 Traning Loss: tensor(0.0933)\n",
      "5007 Traning Loss: tensor(0.0936)\n",
      "5008 Traning Loss: tensor(0.0942)\n",
      "5009 Traning Loss: tensor(0.0942)\n",
      "5010 Traning Loss: tensor(0.0949)\n",
      "5011 Traning Loss: tensor(0.0958)\n",
      "5012 Traning Loss: tensor(0.0951)\n",
      "5013 Traning Loss: tensor(0.0951)\n",
      "5014 Traning Loss: tensor(0.0941)\n",
      "5015 Traning Loss: tensor(0.0948)\n",
      "5016 Traning Loss: tensor(0.0940)\n",
      "5017 Traning Loss: tensor(0.0943)\n",
      "5018 Traning Loss: tensor(0.0944)\n",
      "5019 Traning Loss: tensor(0.0942)\n",
      "5020 Traning Loss: tensor(0.0939)\n",
      "5021 Traning Loss: tensor(0.0942)\n",
      "5022 Traning Loss: tensor(0.0948)\n",
      "5023 Traning Loss: tensor(0.0941)\n",
      "5024 Traning Loss: tensor(0.0944)\n",
      "5025 Traning Loss: tensor(0.0944)\n",
      "5026 Traning Loss: tensor(0.0942)\n",
      "5027 Traning Loss: tensor(0.0940)\n",
      "5028 Traning Loss: tensor(0.0944)\n",
      "5029 Traning Loss: tensor(0.0940)\n",
      "5030 Traning Loss: tensor(0.0934)\n",
      "5031 Traning Loss: tensor(0.0946)\n",
      "5032 Traning Loss: tensor(0.0937)\n",
      "5033 Traning Loss: tensor(0.0938)\n",
      "5034 Traning Loss: tensor(0.0943)\n",
      "5035 Traning Loss: tensor(0.0933)\n",
      "5036 Traning Loss: tensor(0.0935)\n",
      "5037 Traning Loss: tensor(0.0941)\n",
      "5038 Traning Loss: tensor(0.0938)\n",
      "5039 Traning Loss: tensor(0.0937)\n",
      "5040 Traning Loss: tensor(0.0943)\n",
      "5041 Traning Loss: tensor(0.0935)\n",
      "5042 Traning Loss: tensor(0.0939)\n",
      "5043 Traning Loss: tensor(0.0936)\n",
      "5044 Traning Loss: tensor(0.0936)\n",
      "5045 Traning Loss: tensor(0.0943)\n",
      "5046 Traning Loss: tensor(0.0935)\n",
      "5047 Traning Loss: tensor(0.0934)\n",
      "5048 Traning Loss: tensor(0.0934)\n",
      "5049 Traning Loss: tensor(0.0941)\n",
      "5050 Traning Loss: tensor(0.0932)\n",
      "5051 Traning Loss: tensor(0.0927)\n",
      "5052 Traning Loss: tensor(0.0945)\n",
      "5053 Traning Loss: tensor(0.0923)\n",
      "5054 Traning Loss: tensor(0.0930)\n",
      "5055 Traning Loss: tensor(0.0935)\n",
      "5056 Traning Loss: tensor(0.0945)\n",
      "5057 Traning Loss: tensor(0.0945)\n",
      "5058 Traning Loss: tensor(0.0933)\n",
      "5059 Traning Loss: tensor(0.0940)\n",
      "5060 Traning Loss: tensor(0.0941)\n",
      "5061 Traning Loss: tensor(0.0935)\n",
      "5062 Traning Loss: tensor(0.0930)\n",
      "5063 Traning Loss: tensor(0.0933)\n",
      "5064 Traning Loss: tensor(0.0949)\n",
      "5065 Traning Loss: tensor(0.0939)\n",
      "5066 Traning Loss: tensor(0.0935)\n",
      "5067 Traning Loss: tensor(0.0925)\n",
      "5068 Traning Loss: tensor(0.0936)\n",
      "5069 Traning Loss: tensor(0.0934)\n",
      "5070 Traning Loss: tensor(0.0935)\n",
      "5071 Traning Loss: tensor(0.0925)\n",
      "5072 Traning Loss: tensor(0.0936)\n",
      "5073 Traning Loss: tensor(0.0947)\n",
      "5074 Traning Loss: tensor(0.0940)\n",
      "5075 Traning Loss: tensor(0.0926)\n",
      "5076 Traning Loss: tensor(0.0945)\n",
      "5077 Traning Loss: tensor(0.0924)\n",
      "5078 Traning Loss: tensor(0.0928)\n",
      "5079 Traning Loss: tensor(0.0934)\n",
      "5080 Traning Loss: tensor(0.0931)\n",
      "5081 Traning Loss: tensor(0.0943)\n",
      "5082 Traning Loss: tensor(0.0937)\n",
      "5083 Traning Loss: tensor(0.0943)\n",
      "5084 Traning Loss: tensor(0.0939)\n",
      "5085 Traning Loss: tensor(0.0929)\n",
      "5086 Traning Loss: tensor(0.0927)\n",
      "5087 Traning Loss: tensor(0.0933)\n",
      "5088 Traning Loss: tensor(0.0935)\n",
      "5089 Traning Loss: tensor(0.0938)\n",
      "5090 Traning Loss: tensor(0.0937)\n",
      "5091 Traning Loss: tensor(0.0930)\n",
      "5092 Traning Loss: tensor(0.0926)\n",
      "5093 Traning Loss: tensor(0.0922)\n",
      "5094 Traning Loss: tensor(0.0927)\n",
      "5095 Traning Loss: tensor(0.0933)\n",
      "5096 Traning Loss: tensor(0.0930)\n",
      "5097 Traning Loss: tensor(0.0937)\n",
      "5098 Traning Loss: tensor(0.0930)\n",
      "5099 Traning Loss: tensor(0.0928)\n",
      "5100 Traning Loss: tensor(0.0931)\n",
      "5101 Traning Loss: tensor(0.0927)\n",
      "5102 Traning Loss: tensor(0.0928)\n",
      "5103 Traning Loss: tensor(0.0937)\n",
      "5104 Traning Loss: tensor(0.0932)\n",
      "5105 Traning Loss: tensor(0.0924)\n",
      "5106 Traning Loss: tensor(0.0934)\n",
      "5107 Traning Loss: tensor(0.0923)\n",
      "5108 Traning Loss: tensor(0.0942)\n",
      "5109 Traning Loss: tensor(0.0923)\n",
      "5110 Traning Loss: tensor(0.0930)\n",
      "5111 Traning Loss: tensor(0.0929)\n",
      "5112 Traning Loss: tensor(0.0924)\n",
      "5113 Traning Loss: tensor(0.0932)\n",
      "5114 Traning Loss: tensor(0.0916)\n",
      "5115 Traning Loss: tensor(0.0930)\n",
      "5116 Traning Loss: tensor(0.0924)\n",
      "5117 Traning Loss: tensor(0.0928)\n",
      "5118 Traning Loss: tensor(0.0929)\n",
      "5119 Traning Loss: tensor(0.0917)\n",
      "5120 Traning Loss: tensor(0.0927)\n",
      "5121 Traning Loss: tensor(0.0923)\n",
      "5122 Traning Loss: tensor(0.0919)\n",
      "5123 Traning Loss: tensor(0.0925)\n",
      "5124 Traning Loss: tensor(0.0918)\n",
      "5125 Traning Loss: tensor(0.0922)\n",
      "5126 Traning Loss: tensor(0.0927)\n",
      "5127 Traning Loss: tensor(0.0919)\n",
      "5128 Traning Loss: tensor(0.0922)\n",
      "5129 Traning Loss: tensor(0.0921)\n",
      "5130 Traning Loss: tensor(0.0938)\n",
      "5131 Traning Loss: tensor(0.0934)\n",
      "5132 Traning Loss: tensor(0.0931)\n",
      "5133 Traning Loss: tensor(0.0925)\n",
      "5134 Traning Loss: tensor(0.0924)\n",
      "5135 Traning Loss: tensor(0.0925)\n",
      "5136 Traning Loss: tensor(0.0927)\n",
      "5137 Traning Loss: tensor(0.0917)\n",
      "5138 Traning Loss: tensor(0.0923)\n",
      "5139 Traning Loss: tensor(0.0926)\n",
      "5140 Traning Loss: tensor(0.0932)\n",
      "5141 Traning Loss: tensor(0.0917)\n",
      "5142 Traning Loss: tensor(0.0918)\n",
      "5143 Traning Loss: tensor(0.0924)\n",
      "5144 Traning Loss: tensor(0.0919)\n",
      "5145 Traning Loss: tensor(0.0930)\n",
      "5146 Traning Loss: tensor(0.0923)\n",
      "5147 Traning Loss: tensor(0.0919)\n",
      "5148 Traning Loss: tensor(0.0915)\n",
      "5149 Traning Loss: tensor(0.0923)\n",
      "5150 Traning Loss: tensor(0.0920)\n",
      "5151 Traning Loss: tensor(0.0923)\n",
      "5152 Traning Loss: tensor(0.0920)\n",
      "5153 Traning Loss: tensor(0.0926)\n",
      "5154 Traning Loss: tensor(0.0915)\n",
      "5155 Traning Loss: tensor(0.0919)\n",
      "5156 Traning Loss: tensor(0.0926)\n",
      "5157 Traning Loss: tensor(0.0922)\n",
      "5158 Traning Loss: tensor(0.0918)\n",
      "5159 Traning Loss: tensor(0.0914)\n",
      "5160 Traning Loss: tensor(0.0925)\n",
      "5161 Traning Loss: tensor(0.0920)\n",
      "5162 Traning Loss: tensor(0.0923)\n",
      "5163 Traning Loss: tensor(0.0919)\n",
      "5164 Traning Loss: tensor(0.0917)\n",
      "5165 Traning Loss: tensor(0.0930)\n",
      "5166 Traning Loss: tensor(0.0922)\n",
      "5167 Traning Loss: tensor(0.0916)\n",
      "5168 Traning Loss: tensor(0.0915)\n",
      "5169 Traning Loss: tensor(0.0915)\n",
      "5170 Traning Loss: tensor(0.0920)\n",
      "5171 Traning Loss: tensor(0.0916)\n",
      "5172 Traning Loss: tensor(0.0914)\n",
      "5173 Traning Loss: tensor(0.0915)\n",
      "5174 Traning Loss: tensor(0.0911)\n",
      "5175 Traning Loss: tensor(0.0915)\n",
      "5176 Traning Loss: tensor(0.0909)\n",
      "5177 Traning Loss: tensor(0.0920)\n",
      "5178 Traning Loss: tensor(0.0922)\n",
      "5179 Traning Loss: tensor(0.0918)\n",
      "5180 Traning Loss: tensor(0.0915)\n",
      "5181 Traning Loss: tensor(0.0920)\n",
      "5182 Traning Loss: tensor(0.0918)\n",
      "5183 Traning Loss: tensor(0.0914)\n",
      "5184 Traning Loss: tensor(0.0905)\n",
      "5185 Traning Loss: tensor(0.0922)\n",
      "5186 Traning Loss: tensor(0.0909)\n",
      "5187 Traning Loss: tensor(0.0909)\n",
      "5188 Traning Loss: tensor(0.0916)\n",
      "5189 Traning Loss: tensor(0.0920)\n",
      "5190 Traning Loss: tensor(0.0917)\n",
      "5191 Traning Loss: tensor(0.0918)\n",
      "5192 Traning Loss: tensor(0.0920)\n",
      "5193 Traning Loss: tensor(0.0918)\n",
      "5194 Traning Loss: tensor(0.0913)\n",
      "5195 Traning Loss: tensor(0.0912)\n",
      "5196 Traning Loss: tensor(0.0914)\n",
      "5197 Traning Loss: tensor(0.0920)\n",
      "5198 Traning Loss: tensor(0.0914)\n",
      "5199 Traning Loss: tensor(0.0918)\n",
      "5200 Traning Loss: tensor(0.0916)\n",
      "5201 Traning Loss: tensor(0.0922)\n",
      "5202 Traning Loss: tensor(0.0914)\n",
      "5203 Traning Loss: tensor(0.0904)\n",
      "5204 Traning Loss: tensor(0.0917)\n",
      "5205 Traning Loss: tensor(0.0913)\n",
      "5206 Traning Loss: tensor(0.0917)\n",
      "5207 Traning Loss: tensor(0.0917)\n",
      "5208 Traning Loss: tensor(0.0907)\n",
      "5209 Traning Loss: tensor(0.0900)\n",
      "5210 Traning Loss: tensor(0.0907)\n",
      "5211 Traning Loss: tensor(0.0915)\n",
      "5212 Traning Loss: tensor(0.0914)\n",
      "5213 Traning Loss: tensor(0.0907)\n",
      "5214 Traning Loss: tensor(0.0914)\n",
      "5215 Traning Loss: tensor(0.0910)\n",
      "5216 Traning Loss: tensor(0.0899)\n",
      "5217 Traning Loss: tensor(0.0914)\n",
      "5218 Traning Loss: tensor(0.0904)\n",
      "5219 Traning Loss: tensor(0.0909)\n",
      "5220 Traning Loss: tensor(0.0911)\n",
      "5221 Traning Loss: tensor(0.0911)\n",
      "5222 Traning Loss: tensor(0.0910)\n",
      "5223 Traning Loss: tensor(0.0922)\n",
      "5224 Traning Loss: tensor(0.0910)\n",
      "5225 Traning Loss: tensor(0.0897)\n",
      "5226 Traning Loss: tensor(0.0910)\n",
      "5227 Traning Loss: tensor(0.0912)\n",
      "5228 Traning Loss: tensor(0.0917)\n",
      "5229 Traning Loss: tensor(0.0920)\n",
      "5230 Traning Loss: tensor(0.0913)\n",
      "5231 Traning Loss: tensor(0.0904)\n",
      "5232 Traning Loss: tensor(0.0915)\n",
      "5233 Traning Loss: tensor(0.0918)\n",
      "5234 Traning Loss: tensor(0.0903)\n",
      "5235 Traning Loss: tensor(0.0907)\n",
      "5236 Traning Loss: tensor(0.0903)\n",
      "5237 Traning Loss: tensor(0.0907)\n",
      "5238 Traning Loss: tensor(0.0910)\n",
      "5239 Traning Loss: tensor(0.0907)\n",
      "5240 Traning Loss: tensor(0.0912)\n",
      "5241 Traning Loss: tensor(0.0906)\n",
      "5242 Traning Loss: tensor(0.0916)\n",
      "5243 Traning Loss: tensor(0.0905)\n",
      "5244 Traning Loss: tensor(0.0910)\n",
      "5245 Traning Loss: tensor(0.0904)\n",
      "5246 Traning Loss: tensor(0.0906)\n",
      "5247 Traning Loss: tensor(0.0914)\n",
      "5248 Traning Loss: tensor(0.0912)\n",
      "5249 Traning Loss: tensor(0.0905)\n",
      "5250 Traning Loss: tensor(0.0911)\n",
      "5251 Traning Loss: tensor(0.0909)\n",
      "5252 Traning Loss: tensor(0.0902)\n",
      "5253 Traning Loss: tensor(0.0907)\n",
      "5254 Traning Loss: tensor(0.0910)\n",
      "5255 Traning Loss: tensor(0.0907)\n",
      "5256 Traning Loss: tensor(0.0907)\n",
      "5257 Traning Loss: tensor(0.0909)\n",
      "5258 Traning Loss: tensor(0.0897)\n",
      "5259 Traning Loss: tensor(0.0896)\n",
      "5260 Traning Loss: tensor(0.0905)\n",
      "5261 Traning Loss: tensor(0.0900)\n",
      "5262 Traning Loss: tensor(0.0904)\n",
      "5263 Traning Loss: tensor(0.0901)\n",
      "5264 Traning Loss: tensor(0.0906)\n",
      "5265 Traning Loss: tensor(0.0910)\n",
      "5266 Traning Loss: tensor(0.0910)\n",
      "5267 Traning Loss: tensor(0.0907)\n",
      "5268 Traning Loss: tensor(0.0896)\n",
      "5269 Traning Loss: tensor(0.0897)\n",
      "5270 Traning Loss: tensor(0.0900)\n",
      "5271 Traning Loss: tensor(0.0909)\n",
      "5272 Traning Loss: tensor(0.0908)\n",
      "5273 Traning Loss: tensor(0.0904)\n",
      "5274 Traning Loss: tensor(0.0908)\n",
      "5275 Traning Loss: tensor(0.0895)\n",
      "5276 Traning Loss: tensor(0.0904)\n",
      "5277 Traning Loss: tensor(0.0901)\n",
      "5278 Traning Loss: tensor(0.0897)\n",
      "5279 Traning Loss: tensor(0.0898)\n",
      "5280 Traning Loss: tensor(0.0908)\n",
      "5281 Traning Loss: tensor(0.0894)\n",
      "5282 Traning Loss: tensor(0.0898)\n",
      "5283 Traning Loss: tensor(0.0902)\n",
      "5284 Traning Loss: tensor(0.0905)\n",
      "5285 Traning Loss: tensor(0.0903)\n",
      "5286 Traning Loss: tensor(0.0906)\n",
      "5287 Traning Loss: tensor(0.0905)\n",
      "5288 Traning Loss: tensor(0.0911)\n",
      "5289 Traning Loss: tensor(0.0902)\n",
      "5290 Traning Loss: tensor(0.0908)\n",
      "5291 Traning Loss: tensor(0.0899)\n",
      "5292 Traning Loss: tensor(0.0895)\n",
      "5293 Traning Loss: tensor(0.0888)\n",
      "5294 Traning Loss: tensor(0.0897)\n",
      "5295 Traning Loss: tensor(0.0912)\n",
      "5296 Traning Loss: tensor(0.0902)\n",
      "5297 Traning Loss: tensor(0.0894)\n",
      "5298 Traning Loss: tensor(0.0899)\n",
      "5299 Traning Loss: tensor(0.0889)\n",
      "5300 Traning Loss: tensor(0.0899)\n",
      "5301 Traning Loss: tensor(0.0884)\n",
      "5302 Traning Loss: tensor(0.0892)\n",
      "5303 Traning Loss: tensor(0.0898)\n",
      "5304 Traning Loss: tensor(0.0901)\n",
      "5305 Traning Loss: tensor(0.0900)\n",
      "5306 Traning Loss: tensor(0.0885)\n",
      "5307 Traning Loss: tensor(0.0905)\n",
      "5308 Traning Loss: tensor(0.0884)\n",
      "5309 Traning Loss: tensor(0.0897)\n",
      "5310 Traning Loss: tensor(0.0898)\n",
      "5311 Traning Loss: tensor(0.0910)\n",
      "5312 Traning Loss: tensor(0.0904)\n",
      "5313 Traning Loss: tensor(0.0905)\n",
      "5314 Traning Loss: tensor(0.0897)\n",
      "5315 Traning Loss: tensor(0.0900)\n",
      "5316 Traning Loss: tensor(0.0900)\n",
      "5317 Traning Loss: tensor(0.0901)\n",
      "5318 Traning Loss: tensor(0.0908)\n",
      "5319 Traning Loss: tensor(0.0888)\n",
      "5320 Traning Loss: tensor(0.0906)\n",
      "5321 Traning Loss: tensor(0.0894)\n",
      "5322 Traning Loss: tensor(0.0886)\n",
      "5323 Traning Loss: tensor(0.0884)\n",
      "5324 Traning Loss: tensor(0.0895)\n",
      "5325 Traning Loss: tensor(0.0901)\n",
      "5326 Traning Loss: tensor(0.0883)\n",
      "5327 Traning Loss: tensor(0.0892)\n",
      "5328 Traning Loss: tensor(0.0888)\n",
      "5329 Traning Loss: tensor(0.0898)\n",
      "5330 Traning Loss: tensor(0.0898)\n",
      "5331 Traning Loss: tensor(0.0892)\n",
      "5332 Traning Loss: tensor(0.0889)\n",
      "5333 Traning Loss: tensor(0.0898)\n",
      "5334 Traning Loss: tensor(0.0890)\n",
      "5335 Traning Loss: tensor(0.0892)\n",
      "5336 Traning Loss: tensor(0.0887)\n",
      "5337 Traning Loss: tensor(0.0901)\n",
      "5338 Traning Loss: tensor(0.0890)\n",
      "5339 Traning Loss: tensor(0.0890)\n",
      "5340 Traning Loss: tensor(0.0880)\n",
      "5341 Traning Loss: tensor(0.0898)\n",
      "5342 Traning Loss: tensor(0.0897)\n",
      "5343 Traning Loss: tensor(0.0899)\n",
      "5344 Traning Loss: tensor(0.0886)\n",
      "5345 Traning Loss: tensor(0.0893)\n",
      "5346 Traning Loss: tensor(0.0893)\n",
      "5347 Traning Loss: tensor(0.0896)\n",
      "5348 Traning Loss: tensor(0.0887)\n",
      "5349 Traning Loss: tensor(0.0892)\n",
      "5350 Traning Loss: tensor(0.0887)\n",
      "5351 Traning Loss: tensor(0.0894)\n",
      "5352 Traning Loss: tensor(0.0889)\n",
      "5353 Traning Loss: tensor(0.0888)\n",
      "5354 Traning Loss: tensor(0.0893)\n",
      "5355 Traning Loss: tensor(0.0881)\n",
      "5356 Traning Loss: tensor(0.0894)\n",
      "5357 Traning Loss: tensor(0.0891)\n",
      "5358 Traning Loss: tensor(0.0905)\n",
      "5359 Traning Loss: tensor(0.0893)\n",
      "5360 Traning Loss: tensor(0.0900)\n",
      "5361 Traning Loss: tensor(0.0884)\n",
      "5362 Traning Loss: tensor(0.0887)\n",
      "5363 Traning Loss: tensor(0.0877)\n",
      "5364 Traning Loss: tensor(0.0889)\n",
      "5365 Traning Loss: tensor(0.0885)\n",
      "5366 Traning Loss: tensor(0.0888)\n",
      "5367 Traning Loss: tensor(0.0888)\n",
      "5368 Traning Loss: tensor(0.0896)\n",
      "5369 Traning Loss: tensor(0.0892)\n",
      "5370 Traning Loss: tensor(0.0888)\n",
      "5371 Traning Loss: tensor(0.0885)\n",
      "5372 Traning Loss: tensor(0.0891)\n",
      "5373 Traning Loss: tensor(0.0887)\n",
      "5374 Traning Loss: tensor(0.0886)\n",
      "5375 Traning Loss: tensor(0.0894)\n",
      "5376 Traning Loss: tensor(0.0883)\n",
      "5377 Traning Loss: tensor(0.0895)\n",
      "5378 Traning Loss: tensor(0.0892)\n",
      "5379 Traning Loss: tensor(0.0889)\n",
      "5380 Traning Loss: tensor(0.0895)\n",
      "5381 Traning Loss: tensor(0.0882)\n",
      "5382 Traning Loss: tensor(0.0894)\n",
      "5383 Traning Loss: tensor(0.0887)\n",
      "5384 Traning Loss: tensor(0.0880)\n",
      "5385 Traning Loss: tensor(0.0871)\n",
      "5386 Traning Loss: tensor(0.0887)\n",
      "5387 Traning Loss: tensor(0.0884)\n",
      "5388 Traning Loss: tensor(0.0889)\n",
      "5389 Traning Loss: tensor(0.0893)\n",
      "5390 Traning Loss: tensor(0.0891)\n",
      "5391 Traning Loss: tensor(0.0887)\n",
      "5392 Traning Loss: tensor(0.0888)\n",
      "5393 Traning Loss: tensor(0.0893)\n",
      "5394 Traning Loss: tensor(0.0890)\n",
      "5395 Traning Loss: tensor(0.0891)\n",
      "5396 Traning Loss: tensor(0.0889)\n",
      "5397 Traning Loss: tensor(0.0879)\n",
      "5398 Traning Loss: tensor(0.0892)\n",
      "5399 Traning Loss: tensor(0.0894)\n",
      "5400 Traning Loss: tensor(0.0881)\n",
      "5401 Traning Loss: tensor(0.0884)\n",
      "5402 Traning Loss: tensor(0.0892)\n",
      "5403 Traning Loss: tensor(0.0887)\n",
      "5404 Traning Loss: tensor(0.0890)\n",
      "5405 Traning Loss: tensor(0.0883)\n",
      "5406 Traning Loss: tensor(0.0885)\n",
      "5407 Traning Loss: tensor(0.0886)\n",
      "5408 Traning Loss: tensor(0.0871)\n",
      "5409 Traning Loss: tensor(0.0886)\n",
      "5410 Traning Loss: tensor(0.0884)\n",
      "5411 Traning Loss: tensor(0.0901)\n",
      "5412 Traning Loss: tensor(0.0892)\n",
      "5413 Traning Loss: tensor(0.0865)\n",
      "5414 Traning Loss: tensor(0.0884)\n",
      "5415 Traning Loss: tensor(0.0887)\n",
      "5416 Traning Loss: tensor(0.0887)\n",
      "5417 Traning Loss: tensor(0.0878)\n",
      "5418 Traning Loss: tensor(0.0886)\n",
      "5419 Traning Loss: tensor(0.0884)\n",
      "5420 Traning Loss: tensor(0.0883)\n",
      "5421 Traning Loss: tensor(0.0880)\n",
      "5422 Traning Loss: tensor(0.0881)\n",
      "5423 Traning Loss: tensor(0.0881)\n",
      "5424 Traning Loss: tensor(0.0889)\n",
      "5425 Traning Loss: tensor(0.0875)\n",
      "5426 Traning Loss: tensor(0.0886)\n",
      "5427 Traning Loss: tensor(0.0878)\n",
      "5428 Traning Loss: tensor(0.0881)\n",
      "5429 Traning Loss: tensor(0.0881)\n",
      "5430 Traning Loss: tensor(0.0883)\n",
      "5431 Traning Loss: tensor(0.0870)\n",
      "5432 Traning Loss: tensor(0.0885)\n",
      "5433 Traning Loss: tensor(0.0891)\n",
      "5434 Traning Loss: tensor(0.0879)\n",
      "5435 Traning Loss: tensor(0.0887)\n",
      "5436 Traning Loss: tensor(0.0879)\n",
      "5437 Traning Loss: tensor(0.0883)\n",
      "5438 Traning Loss: tensor(0.0887)\n",
      "5439 Traning Loss: tensor(0.0880)\n",
      "5440 Traning Loss: tensor(0.0881)\n",
      "5441 Traning Loss: tensor(0.0880)\n",
      "5442 Traning Loss: tensor(0.0887)\n",
      "5443 Traning Loss: tensor(0.0886)\n",
      "5444 Traning Loss: tensor(0.0883)\n",
      "5445 Traning Loss: tensor(0.0873)\n",
      "5446 Traning Loss: tensor(0.0878)\n",
      "5447 Traning Loss: tensor(0.0878)\n",
      "5448 Traning Loss: tensor(0.0876)\n",
      "5449 Traning Loss: tensor(0.0875)\n",
      "5450 Traning Loss: tensor(0.0883)\n",
      "5451 Traning Loss: tensor(0.0885)\n",
      "5452 Traning Loss: tensor(0.0879)\n",
      "5453 Traning Loss: tensor(0.0867)\n",
      "5454 Traning Loss: tensor(0.0873)\n",
      "5455 Traning Loss: tensor(0.0881)\n",
      "5456 Traning Loss: tensor(0.0879)\n",
      "5457 Traning Loss: tensor(0.0873)\n",
      "5458 Traning Loss: tensor(0.0878)\n",
      "5459 Traning Loss: tensor(0.0883)\n",
      "5460 Traning Loss: tensor(0.0877)\n",
      "5461 Traning Loss: tensor(0.0877)\n",
      "5462 Traning Loss: tensor(0.0879)\n",
      "5463 Traning Loss: tensor(0.0873)\n",
      "5464 Traning Loss: tensor(0.0868)\n",
      "5465 Traning Loss: tensor(0.0879)\n",
      "5466 Traning Loss: tensor(0.0882)\n",
      "5467 Traning Loss: tensor(0.0880)\n",
      "5468 Traning Loss: tensor(0.0879)\n",
      "5469 Traning Loss: tensor(0.0879)\n",
      "5470 Traning Loss: tensor(0.0879)\n",
      "5471 Traning Loss: tensor(0.0873)\n",
      "5472 Traning Loss: tensor(0.0885)\n",
      "5473 Traning Loss: tensor(0.0876)\n",
      "5474 Traning Loss: tensor(0.0873)\n",
      "5475 Traning Loss: tensor(0.0867)\n",
      "5476 Traning Loss: tensor(0.0883)\n",
      "5477 Traning Loss: tensor(0.0872)\n",
      "5478 Traning Loss: tensor(0.0884)\n",
      "5479 Traning Loss: tensor(0.0873)\n",
      "5480 Traning Loss: tensor(0.0881)\n",
      "5481 Traning Loss: tensor(0.0871)\n",
      "5482 Traning Loss: tensor(0.0873)\n",
      "5483 Traning Loss: tensor(0.0872)\n",
      "5484 Traning Loss: tensor(0.0876)\n",
      "5485 Traning Loss: tensor(0.0880)\n",
      "5486 Traning Loss: tensor(0.0876)\n",
      "5487 Traning Loss: tensor(0.0865)\n",
      "5488 Traning Loss: tensor(0.0876)\n",
      "5489 Traning Loss: tensor(0.0878)\n",
      "5490 Traning Loss: tensor(0.0873)\n",
      "5491 Traning Loss: tensor(0.0870)\n",
      "5492 Traning Loss: tensor(0.0878)\n",
      "5493 Traning Loss: tensor(0.0878)\n",
      "5494 Traning Loss: tensor(0.0880)\n",
      "5495 Traning Loss: tensor(0.0875)\n",
      "5496 Traning Loss: tensor(0.0871)\n",
      "5497 Traning Loss: tensor(0.0879)\n",
      "5498 Traning Loss: tensor(0.0876)\n",
      "5499 Traning Loss: tensor(0.0865)\n",
      "5500 Traning Loss: tensor(0.0875)\n",
      "5501 Traning Loss: tensor(0.0874)\n",
      "5502 Traning Loss: tensor(0.0869)\n",
      "5503 Traning Loss: tensor(0.0880)\n",
      "5504 Traning Loss: tensor(0.0873)\n",
      "5505 Traning Loss: tensor(0.0874)\n",
      "5506 Traning Loss: tensor(0.0886)\n",
      "5507 Traning Loss: tensor(0.0876)\n",
      "5508 Traning Loss: tensor(0.0875)\n",
      "5509 Traning Loss: tensor(0.0879)\n",
      "5510 Traning Loss: tensor(0.0876)\n",
      "5511 Traning Loss: tensor(0.0872)\n",
      "5512 Traning Loss: tensor(0.0878)\n",
      "5513 Traning Loss: tensor(0.0864)\n",
      "5514 Traning Loss: tensor(0.0873)\n",
      "5515 Traning Loss: tensor(0.0874)\n",
      "5516 Traning Loss: tensor(0.0876)\n",
      "5517 Traning Loss: tensor(0.0877)\n",
      "5518 Traning Loss: tensor(0.0868)\n",
      "5519 Traning Loss: tensor(0.0876)\n",
      "5520 Traning Loss: tensor(0.0866)\n",
      "5521 Traning Loss: tensor(0.0879)\n",
      "5522 Traning Loss: tensor(0.0876)\n",
      "5523 Traning Loss: tensor(0.0871)\n",
      "5524 Traning Loss: tensor(0.0872)\n",
      "5525 Traning Loss: tensor(0.0879)\n",
      "5526 Traning Loss: tensor(0.0872)\n",
      "5527 Traning Loss: tensor(0.0866)\n",
      "5528 Traning Loss: tensor(0.0864)\n",
      "5529 Traning Loss: tensor(0.0869)\n",
      "5530 Traning Loss: tensor(0.0875)\n",
      "5531 Traning Loss: tensor(0.0873)\n",
      "5532 Traning Loss: tensor(0.0874)\n",
      "5533 Traning Loss: tensor(0.0877)\n",
      "5534 Traning Loss: tensor(0.0874)\n",
      "5535 Traning Loss: tensor(0.0872)\n",
      "5536 Traning Loss: tensor(0.0874)\n",
      "5537 Traning Loss: tensor(0.0879)\n",
      "5538 Traning Loss: tensor(0.0880)\n",
      "5539 Traning Loss: tensor(0.0866)\n",
      "5540 Traning Loss: tensor(0.0869)\n",
      "5541 Traning Loss: tensor(0.0865)\n",
      "5542 Traning Loss: tensor(0.0875)\n",
      "5543 Traning Loss: tensor(0.0875)\n",
      "5544 Traning Loss: tensor(0.0865)\n",
      "5545 Traning Loss: tensor(0.0863)\n",
      "5546 Traning Loss: tensor(0.0872)\n",
      "5547 Traning Loss: tensor(0.0866)\n",
      "5548 Traning Loss: tensor(0.0885)\n",
      "5549 Traning Loss: tensor(0.0865)\n",
      "5550 Traning Loss: tensor(0.0867)\n",
      "5551 Traning Loss: tensor(0.0876)\n",
      "5552 Traning Loss: tensor(0.0874)\n",
      "5553 Traning Loss: tensor(0.0869)\n",
      "5554 Traning Loss: tensor(0.0868)\n",
      "5555 Traning Loss: tensor(0.0866)\n",
      "5556 Traning Loss: tensor(0.0860)\n",
      "5557 Traning Loss: tensor(0.0862)\n",
      "5558 Traning Loss: tensor(0.0878)\n",
      "5559 Traning Loss: tensor(0.0869)\n",
      "5560 Traning Loss: tensor(0.0866)\n",
      "5561 Traning Loss: tensor(0.0871)\n",
      "5562 Traning Loss: tensor(0.0874)\n",
      "5563 Traning Loss: tensor(0.0867)\n",
      "5564 Traning Loss: tensor(0.0869)\n",
      "5565 Traning Loss: tensor(0.0865)\n",
      "5566 Traning Loss: tensor(0.0865)\n",
      "5567 Traning Loss: tensor(0.0873)\n",
      "5568 Traning Loss: tensor(0.0878)\n",
      "5569 Traning Loss: tensor(0.0864)\n",
      "5570 Traning Loss: tensor(0.0875)\n",
      "5571 Traning Loss: tensor(0.0859)\n",
      "5572 Traning Loss: tensor(0.0860)\n",
      "5573 Traning Loss: tensor(0.0871)\n",
      "5574 Traning Loss: tensor(0.0867)\n",
      "5575 Traning Loss: tensor(0.0860)\n",
      "5576 Traning Loss: tensor(0.0860)\n",
      "5577 Traning Loss: tensor(0.0857)\n",
      "5578 Traning Loss: tensor(0.0871)\n",
      "5579 Traning Loss: tensor(0.0866)\n",
      "5580 Traning Loss: tensor(0.0872)\n",
      "5581 Traning Loss: tensor(0.0860)\n",
      "5582 Traning Loss: tensor(0.0869)\n",
      "5583 Traning Loss: tensor(0.0864)\n",
      "5584 Traning Loss: tensor(0.0862)\n",
      "5585 Traning Loss: tensor(0.0868)\n",
      "5586 Traning Loss: tensor(0.0868)\n",
      "5587 Traning Loss: tensor(0.0860)\n",
      "5588 Traning Loss: tensor(0.0870)\n",
      "5589 Traning Loss: tensor(0.0868)\n",
      "5590 Traning Loss: tensor(0.0864)\n",
      "5591 Traning Loss: tensor(0.0868)\n",
      "5592 Traning Loss: tensor(0.0870)\n",
      "5593 Traning Loss: tensor(0.0867)\n",
      "5594 Traning Loss: tensor(0.0868)\n",
      "5595 Traning Loss: tensor(0.0863)\n",
      "5596 Traning Loss: tensor(0.0859)\n",
      "5597 Traning Loss: tensor(0.0868)\n",
      "5598 Traning Loss: tensor(0.0864)\n",
      "5599 Traning Loss: tensor(0.0861)\n",
      "5600 Traning Loss: tensor(0.0857)\n",
      "5601 Traning Loss: tensor(0.0861)\n",
      "5602 Traning Loss: tensor(0.0866)\n",
      "5603 Traning Loss: tensor(0.0845)\n",
      "5604 Traning Loss: tensor(0.0861)\n",
      "5605 Traning Loss: tensor(0.0873)\n",
      "5606 Traning Loss: tensor(0.0865)\n",
      "5607 Traning Loss: tensor(0.0870)\n",
      "5608 Traning Loss: tensor(0.0864)\n",
      "5609 Traning Loss: tensor(0.0867)\n",
      "5610 Traning Loss: tensor(0.0863)\n",
      "5611 Traning Loss: tensor(0.0855)\n",
      "5612 Traning Loss: tensor(0.0865)\n",
      "5613 Traning Loss: tensor(0.0860)\n",
      "5614 Traning Loss: tensor(0.0861)\n",
      "5615 Traning Loss: tensor(0.0864)\n",
      "5616 Traning Loss: tensor(0.0866)\n",
      "5617 Traning Loss: tensor(0.0858)\n",
      "5618 Traning Loss: tensor(0.0869)\n",
      "5619 Traning Loss: tensor(0.0865)\n",
      "5620 Traning Loss: tensor(0.0863)\n",
      "5621 Traning Loss: tensor(0.0856)\n",
      "5622 Traning Loss: tensor(0.0864)\n",
      "5623 Traning Loss: tensor(0.0859)\n",
      "5624 Traning Loss: tensor(0.0857)\n",
      "5625 Traning Loss: tensor(0.0859)\n",
      "5626 Traning Loss: tensor(0.0866)\n",
      "5627 Traning Loss: tensor(0.0865)\n",
      "5628 Traning Loss: tensor(0.0862)\n",
      "5629 Traning Loss: tensor(0.0861)\n",
      "5630 Traning Loss: tensor(0.0851)\n",
      "5631 Traning Loss: tensor(0.0861)\n",
      "5632 Traning Loss: tensor(0.0842)\n",
      "5633 Traning Loss: tensor(0.0857)\n",
      "5634 Traning Loss: tensor(0.0848)\n",
      "5635 Traning Loss: tensor(0.0862)\n",
      "5636 Traning Loss: tensor(0.0867)\n",
      "5637 Traning Loss: tensor(0.0867)\n",
      "5638 Traning Loss: tensor(0.0859)\n",
      "5639 Traning Loss: tensor(0.0856)\n",
      "5640 Traning Loss: tensor(0.0856)\n",
      "5641 Traning Loss: tensor(0.0859)\n",
      "5642 Traning Loss: tensor(0.0866)\n",
      "5643 Traning Loss: tensor(0.0849)\n",
      "5644 Traning Loss: tensor(0.0856)\n",
      "5645 Traning Loss: tensor(0.0863)\n",
      "5646 Traning Loss: tensor(0.0858)\n",
      "5647 Traning Loss: tensor(0.0844)\n",
      "5648 Traning Loss: tensor(0.0855)\n",
      "5649 Traning Loss: tensor(0.0869)\n",
      "5650 Traning Loss: tensor(0.0866)\n",
      "5651 Traning Loss: tensor(0.0861)\n",
      "5652 Traning Loss: tensor(0.0865)\n",
      "5653 Traning Loss: tensor(0.0852)\n",
      "5654 Traning Loss: tensor(0.0857)\n",
      "5655 Traning Loss: tensor(0.0854)\n",
      "5656 Traning Loss: tensor(0.0861)\n",
      "5657 Traning Loss: tensor(0.0850)\n",
      "5658 Traning Loss: tensor(0.0864)\n",
      "5659 Traning Loss: tensor(0.0854)\n",
      "5660 Traning Loss: tensor(0.0854)\n",
      "5661 Traning Loss: tensor(0.0850)\n",
      "5662 Traning Loss: tensor(0.0855)\n",
      "5663 Traning Loss: tensor(0.0860)\n",
      "5664 Traning Loss: tensor(0.0857)\n",
      "5665 Traning Loss: tensor(0.0858)\n",
      "5666 Traning Loss: tensor(0.0862)\n",
      "5667 Traning Loss: tensor(0.0851)\n",
      "5668 Traning Loss: tensor(0.0852)\n",
      "5669 Traning Loss: tensor(0.0860)\n",
      "5670 Traning Loss: tensor(0.0849)\n",
      "5671 Traning Loss: tensor(0.0849)\n",
      "5672 Traning Loss: tensor(0.0864)\n",
      "5673 Traning Loss: tensor(0.0862)\n",
      "5674 Traning Loss: tensor(0.0862)\n",
      "5675 Traning Loss: tensor(0.0858)\n",
      "5676 Traning Loss: tensor(0.0856)\n",
      "5677 Traning Loss: tensor(0.0858)\n",
      "5678 Traning Loss: tensor(0.0854)\n",
      "5679 Traning Loss: tensor(0.0859)\n",
      "5680 Traning Loss: tensor(0.0859)\n",
      "5681 Traning Loss: tensor(0.0850)\n",
      "5682 Traning Loss: tensor(0.0853)\n",
      "5683 Traning Loss: tensor(0.0847)\n",
      "5684 Traning Loss: tensor(0.0858)\n",
      "5685 Traning Loss: tensor(0.0857)\n",
      "5686 Traning Loss: tensor(0.0845)\n",
      "5687 Traning Loss: tensor(0.0854)\n",
      "5688 Traning Loss: tensor(0.0866)\n",
      "5689 Traning Loss: tensor(0.0848)\n",
      "5690 Traning Loss: tensor(0.0855)\n",
      "5691 Traning Loss: tensor(0.0845)\n",
      "5692 Traning Loss: tensor(0.0855)\n",
      "5693 Traning Loss: tensor(0.0854)\n",
      "5694 Traning Loss: tensor(0.0851)\n",
      "5695 Traning Loss: tensor(0.0852)\n",
      "5696 Traning Loss: tensor(0.0855)\n",
      "5697 Traning Loss: tensor(0.0857)\n",
      "5698 Traning Loss: tensor(0.0854)\n",
      "5699 Traning Loss: tensor(0.0854)\n",
      "5700 Traning Loss: tensor(0.0860)\n",
      "5701 Traning Loss: tensor(0.0857)\n",
      "5702 Traning Loss: tensor(0.0852)\n",
      "5703 Traning Loss: tensor(0.0855)\n",
      "5704 Traning Loss: tensor(0.0852)\n",
      "5705 Traning Loss: tensor(0.0844)\n",
      "5706 Traning Loss: tensor(0.0850)\n",
      "5707 Traning Loss: tensor(0.0850)\n",
      "5708 Traning Loss: tensor(0.0860)\n",
      "5709 Traning Loss: tensor(0.0853)\n",
      "5710 Traning Loss: tensor(0.0851)\n",
      "5711 Traning Loss: tensor(0.0860)\n",
      "5712 Traning Loss: tensor(0.0853)\n",
      "5713 Traning Loss: tensor(0.0854)\n",
      "5714 Traning Loss: tensor(0.0857)\n",
      "5715 Traning Loss: tensor(0.0850)\n",
      "5716 Traning Loss: tensor(0.0858)\n",
      "5717 Traning Loss: tensor(0.0852)\n",
      "5718 Traning Loss: tensor(0.0845)\n",
      "5719 Traning Loss: tensor(0.0849)\n",
      "5720 Traning Loss: tensor(0.0851)\n",
      "5721 Traning Loss: tensor(0.0849)\n",
      "5722 Traning Loss: tensor(0.0850)\n",
      "5723 Traning Loss: tensor(0.0857)\n",
      "5724 Traning Loss: tensor(0.0856)\n",
      "5725 Traning Loss: tensor(0.0851)\n",
      "5726 Traning Loss: tensor(0.0858)\n",
      "5727 Traning Loss: tensor(0.0856)\n",
      "5728 Traning Loss: tensor(0.0855)\n",
      "5729 Traning Loss: tensor(0.0856)\n",
      "5730 Traning Loss: tensor(0.0864)\n",
      "5731 Traning Loss: tensor(0.0849)\n",
      "5732 Traning Loss: tensor(0.0857)\n",
      "5733 Traning Loss: tensor(0.0846)\n",
      "5734 Traning Loss: tensor(0.0852)\n",
      "5735 Traning Loss: tensor(0.0852)\n",
      "5736 Traning Loss: tensor(0.0847)\n",
      "5737 Traning Loss: tensor(0.0848)\n",
      "5738 Traning Loss: tensor(0.0846)\n",
      "5739 Traning Loss: tensor(0.0849)\n",
      "5740 Traning Loss: tensor(0.0850)\n",
      "5741 Traning Loss: tensor(0.0852)\n",
      "5742 Traning Loss: tensor(0.0853)\n",
      "5743 Traning Loss: tensor(0.0852)\n",
      "5744 Traning Loss: tensor(0.0857)\n",
      "5745 Traning Loss: tensor(0.0851)\n",
      "5746 Traning Loss: tensor(0.0853)\n",
      "5747 Traning Loss: tensor(0.0855)\n",
      "5748 Traning Loss: tensor(0.0853)\n",
      "5749 Traning Loss: tensor(0.0855)\n",
      "5750 Traning Loss: tensor(0.0855)\n",
      "5751 Traning Loss: tensor(0.0848)\n",
      "5752 Traning Loss: tensor(0.0856)\n",
      "5753 Traning Loss: tensor(0.0843)\n",
      "5754 Traning Loss: tensor(0.0843)\n",
      "5755 Traning Loss: tensor(0.0849)\n",
      "5756 Traning Loss: tensor(0.0841)\n",
      "5757 Traning Loss: tensor(0.0839)\n",
      "5758 Traning Loss: tensor(0.0852)\n",
      "5759 Traning Loss: tensor(0.0859)\n",
      "5760 Traning Loss: tensor(0.0853)\n",
      "5761 Traning Loss: tensor(0.0839)\n",
      "5762 Traning Loss: tensor(0.0845)\n",
      "5763 Traning Loss: tensor(0.0859)\n",
      "5764 Traning Loss: tensor(0.0834)\n",
      "5765 Traning Loss: tensor(0.0847)\n",
      "5766 Traning Loss: tensor(0.0853)\n",
      "5767 Traning Loss: tensor(0.0851)\n",
      "5768 Traning Loss: tensor(0.0843)\n",
      "5769 Traning Loss: tensor(0.0847)\n",
      "5770 Traning Loss: tensor(0.0842)\n",
      "5771 Traning Loss: tensor(0.0846)\n",
      "5772 Traning Loss: tensor(0.0839)\n",
      "5773 Traning Loss: tensor(0.0839)\n",
      "5774 Traning Loss: tensor(0.0850)\n",
      "5775 Traning Loss: tensor(0.0838)\n",
      "5776 Traning Loss: tensor(0.0844)\n",
      "5777 Traning Loss: tensor(0.0838)\n",
      "5778 Traning Loss: tensor(0.0845)\n",
      "5779 Traning Loss: tensor(0.0844)\n",
      "5780 Traning Loss: tensor(0.0849)\n",
      "5781 Traning Loss: tensor(0.0844)\n",
      "5782 Traning Loss: tensor(0.0840)\n",
      "5783 Traning Loss: tensor(0.0842)\n",
      "5784 Traning Loss: tensor(0.0841)\n",
      "5785 Traning Loss: tensor(0.0845)\n",
      "5786 Traning Loss: tensor(0.0844)\n",
      "5787 Traning Loss: tensor(0.0848)\n",
      "5788 Traning Loss: tensor(0.0842)\n",
      "5789 Traning Loss: tensor(0.0854)\n",
      "5790 Traning Loss: tensor(0.0847)\n",
      "5791 Traning Loss: tensor(0.0834)\n",
      "5792 Traning Loss: tensor(0.0855)\n",
      "5793 Traning Loss: tensor(0.0850)\n",
      "5794 Traning Loss: tensor(0.0846)\n",
      "5795 Traning Loss: tensor(0.0849)\n",
      "5796 Traning Loss: tensor(0.0854)\n",
      "5797 Traning Loss: tensor(0.0851)\n",
      "5798 Traning Loss: tensor(0.0849)\n",
      "5799 Traning Loss: tensor(0.0833)\n",
      "5800 Traning Loss: tensor(0.0842)\n",
      "5801 Traning Loss: tensor(0.0842)\n",
      "5802 Traning Loss: tensor(0.0838)\n",
      "5803 Traning Loss: tensor(0.0845)\n",
      "5804 Traning Loss: tensor(0.0843)\n",
      "5805 Traning Loss: tensor(0.0844)\n",
      "5806 Traning Loss: tensor(0.0852)\n",
      "5807 Traning Loss: tensor(0.0855)\n",
      "5808 Traning Loss: tensor(0.0847)\n",
      "5809 Traning Loss: tensor(0.0844)\n",
      "5810 Traning Loss: tensor(0.0835)\n",
      "5811 Traning Loss: tensor(0.0853)\n",
      "5812 Traning Loss: tensor(0.0847)\n",
      "5813 Traning Loss: tensor(0.0836)\n",
      "5814 Traning Loss: tensor(0.0855)\n",
      "5815 Traning Loss: tensor(0.0837)\n",
      "5816 Traning Loss: tensor(0.0833)\n",
      "5817 Traning Loss: tensor(0.0849)\n",
      "5818 Traning Loss: tensor(0.0846)\n",
      "5819 Traning Loss: tensor(0.0845)\n",
      "5820 Traning Loss: tensor(0.0838)\n",
      "5821 Traning Loss: tensor(0.0847)\n",
      "5822 Traning Loss: tensor(0.0845)\n",
      "5823 Traning Loss: tensor(0.0846)\n",
      "5824 Traning Loss: tensor(0.0847)\n",
      "5825 Traning Loss: tensor(0.0843)\n",
      "5826 Traning Loss: tensor(0.0841)\n",
      "5827 Traning Loss: tensor(0.0839)\n",
      "5828 Traning Loss: tensor(0.0842)\n",
      "5829 Traning Loss: tensor(0.0844)\n",
      "5830 Traning Loss: tensor(0.0850)\n",
      "5831 Traning Loss: tensor(0.0845)\n",
      "5832 Traning Loss: tensor(0.0842)\n",
      "5833 Traning Loss: tensor(0.0846)\n",
      "5834 Traning Loss: tensor(0.0843)\n",
      "5835 Traning Loss: tensor(0.0842)\n",
      "5836 Traning Loss: tensor(0.0844)\n",
      "5837 Traning Loss: tensor(0.0845)\n",
      "5838 Traning Loss: tensor(0.0840)\n",
      "5839 Traning Loss: tensor(0.0835)\n",
      "5840 Traning Loss: tensor(0.0838)\n",
      "5841 Traning Loss: tensor(0.0842)\n",
      "5842 Traning Loss: tensor(0.0840)\n",
      "5843 Traning Loss: tensor(0.0845)\n",
      "5844 Traning Loss: tensor(0.0845)\n",
      "5845 Traning Loss: tensor(0.0842)\n",
      "5846 Traning Loss: tensor(0.0842)\n",
      "5847 Traning Loss: tensor(0.0835)\n",
      "5848 Traning Loss: tensor(0.0846)\n",
      "5849 Traning Loss: tensor(0.0843)\n",
      "5850 Traning Loss: tensor(0.0839)\n",
      "5851 Traning Loss: tensor(0.0845)\n",
      "5852 Traning Loss: tensor(0.0845)\n",
      "5853 Traning Loss: tensor(0.0842)\n",
      "5854 Traning Loss: tensor(0.0834)\n",
      "5855 Traning Loss: tensor(0.0851)\n",
      "5856 Traning Loss: tensor(0.0842)\n",
      "5857 Traning Loss: tensor(0.0835)\n",
      "5858 Traning Loss: tensor(0.0840)\n",
      "5859 Traning Loss: tensor(0.0843)\n",
      "5860 Traning Loss: tensor(0.0840)\n",
      "5861 Traning Loss: tensor(0.0835)\n",
      "5862 Traning Loss: tensor(0.0842)\n",
      "5863 Traning Loss: tensor(0.0834)\n",
      "5864 Traning Loss: tensor(0.0831)\n",
      "5865 Traning Loss: tensor(0.0843)\n",
      "5866 Traning Loss: tensor(0.0834)\n",
      "5867 Traning Loss: tensor(0.0837)\n",
      "5868 Traning Loss: tensor(0.0839)\n",
      "5869 Traning Loss: tensor(0.0839)\n",
      "5870 Traning Loss: tensor(0.0844)\n",
      "5871 Traning Loss: tensor(0.0832)\n",
      "5872 Traning Loss: tensor(0.0848)\n",
      "5873 Traning Loss: tensor(0.0836)\n",
      "5874 Traning Loss: tensor(0.0840)\n",
      "5875 Traning Loss: tensor(0.0843)\n",
      "5876 Traning Loss: tensor(0.0841)\n",
      "5877 Traning Loss: tensor(0.0840)\n",
      "5878 Traning Loss: tensor(0.0841)\n",
      "5879 Traning Loss: tensor(0.0841)\n",
      "5880 Traning Loss: tensor(0.0828)\n",
      "5881 Traning Loss: tensor(0.0844)\n",
      "5882 Traning Loss: tensor(0.0839)\n",
      "5883 Traning Loss: tensor(0.0844)\n",
      "5884 Traning Loss: tensor(0.0833)\n",
      "5885 Traning Loss: tensor(0.0829)\n",
      "5886 Traning Loss: tensor(0.0836)\n",
      "5887 Traning Loss: tensor(0.0837)\n",
      "5888 Traning Loss: tensor(0.0852)\n",
      "5889 Traning Loss: tensor(0.0826)\n",
      "5890 Traning Loss: tensor(0.0835)\n",
      "5891 Traning Loss: tensor(0.0843)\n",
      "5892 Traning Loss: tensor(0.0847)\n",
      "5893 Traning Loss: tensor(0.0831)\n",
      "5894 Traning Loss: tensor(0.0837)\n",
      "5895 Traning Loss: tensor(0.0836)\n",
      "5896 Traning Loss: tensor(0.0835)\n",
      "5897 Traning Loss: tensor(0.0835)\n",
      "5898 Traning Loss: tensor(0.0830)\n",
      "5899 Traning Loss: tensor(0.0846)\n",
      "5900 Traning Loss: tensor(0.0839)\n",
      "5901 Traning Loss: tensor(0.0842)\n",
      "5902 Traning Loss: tensor(0.0834)\n",
      "5903 Traning Loss: tensor(0.0830)\n",
      "5904 Traning Loss: tensor(0.0832)\n",
      "5905 Traning Loss: tensor(0.0842)\n",
      "5906 Traning Loss: tensor(0.0845)\n",
      "5907 Traning Loss: tensor(0.0838)\n",
      "5908 Traning Loss: tensor(0.0833)\n",
      "5909 Traning Loss: tensor(0.0830)\n",
      "5910 Traning Loss: tensor(0.0844)\n",
      "5911 Traning Loss: tensor(0.0831)\n",
      "5912 Traning Loss: tensor(0.0842)\n",
      "5913 Traning Loss: tensor(0.0839)\n",
      "5914 Traning Loss: tensor(0.0831)\n",
      "5915 Traning Loss: tensor(0.0837)\n",
      "5916 Traning Loss: tensor(0.0835)\n",
      "5917 Traning Loss: tensor(0.0844)\n",
      "5918 Traning Loss: tensor(0.0850)\n",
      "5919 Traning Loss: tensor(0.0845)\n",
      "5920 Traning Loss: tensor(0.0835)\n",
      "5921 Traning Loss: tensor(0.0836)\n",
      "5922 Traning Loss: tensor(0.0840)\n",
      "5923 Traning Loss: tensor(0.0840)\n",
      "5924 Traning Loss: tensor(0.0826)\n",
      "5925 Traning Loss: tensor(0.0837)\n",
      "5926 Traning Loss: tensor(0.0837)\n",
      "5927 Traning Loss: tensor(0.0839)\n",
      "5928 Traning Loss: tensor(0.0833)\n",
      "5929 Traning Loss: tensor(0.0821)\n",
      "5930 Traning Loss: tensor(0.0837)\n",
      "5931 Traning Loss: tensor(0.0836)\n",
      "5932 Traning Loss: tensor(0.0838)\n",
      "5933 Traning Loss: tensor(0.0825)\n",
      "5934 Traning Loss: tensor(0.0832)\n",
      "5935 Traning Loss: tensor(0.0834)\n",
      "5936 Traning Loss: tensor(0.0841)\n",
      "5937 Traning Loss: tensor(0.0836)\n",
      "5938 Traning Loss: tensor(0.0845)\n",
      "5939 Traning Loss: tensor(0.0836)\n",
      "5940 Traning Loss: tensor(0.0835)\n",
      "5941 Traning Loss: tensor(0.0830)\n",
      "5942 Traning Loss: tensor(0.0832)\n",
      "5943 Traning Loss: tensor(0.0832)\n",
      "5944 Traning Loss: tensor(0.0834)\n",
      "5945 Traning Loss: tensor(0.0827)\n",
      "5946 Traning Loss: tensor(0.0830)\n",
      "5947 Traning Loss: tensor(0.0839)\n",
      "5948 Traning Loss: tensor(0.0822)\n",
      "5949 Traning Loss: tensor(0.0832)\n",
      "5950 Traning Loss: tensor(0.0840)\n",
      "5951 Traning Loss: tensor(0.0839)\n",
      "5952 Traning Loss: tensor(0.0835)\n",
      "5953 Traning Loss: tensor(0.0842)\n",
      "5954 Traning Loss: tensor(0.0826)\n",
      "5955 Traning Loss: tensor(0.0842)\n",
      "5956 Traning Loss: tensor(0.0830)\n",
      "5957 Traning Loss: tensor(0.0826)\n",
      "5958 Traning Loss: tensor(0.0821)\n",
      "5959 Traning Loss: tensor(0.0831)\n",
      "5960 Traning Loss: tensor(0.0833)\n",
      "5961 Traning Loss: tensor(0.0823)\n",
      "5962 Traning Loss: tensor(0.0829)\n",
      "5963 Traning Loss: tensor(0.0842)\n",
      "5964 Traning Loss: tensor(0.0841)\n",
      "5965 Traning Loss: tensor(0.0835)\n",
      "5966 Traning Loss: tensor(0.0832)\n",
      "5967 Traning Loss: tensor(0.0827)\n",
      "5968 Traning Loss: tensor(0.0835)\n",
      "5969 Traning Loss: tensor(0.0827)\n",
      "5970 Traning Loss: tensor(0.0834)\n",
      "5971 Traning Loss: tensor(0.0825)\n",
      "5972 Traning Loss: tensor(0.0832)\n",
      "5973 Traning Loss: tensor(0.0830)\n",
      "5974 Traning Loss: tensor(0.0832)\n",
      "5975 Traning Loss: tensor(0.0832)\n",
      "5976 Traning Loss: tensor(0.0825)\n",
      "5977 Traning Loss: tensor(0.0842)\n",
      "5978 Traning Loss: tensor(0.0832)\n",
      "5979 Traning Loss: tensor(0.0834)\n",
      "5980 Traning Loss: tensor(0.0828)\n",
      "5981 Traning Loss: tensor(0.0834)\n",
      "5982 Traning Loss: tensor(0.0833)\n",
      "5983 Traning Loss: tensor(0.0824)\n",
      "5984 Traning Loss: tensor(0.0834)\n",
      "5985 Traning Loss: tensor(0.0835)\n",
      "5986 Traning Loss: tensor(0.0830)\n",
      "5987 Traning Loss: tensor(0.0829)\n",
      "5988 Traning Loss: tensor(0.0817)\n",
      "5989 Traning Loss: tensor(0.0822)\n",
      "5990 Traning Loss: tensor(0.0836)\n",
      "5991 Traning Loss: tensor(0.0829)\n",
      "5992 Traning Loss: tensor(0.0816)\n",
      "5993 Traning Loss: tensor(0.0834)\n",
      "5994 Traning Loss: tensor(0.0832)\n",
      "5995 Traning Loss: tensor(0.0832)\n",
      "5996 Traning Loss: tensor(0.0834)\n",
      "5997 Traning Loss: tensor(0.0833)\n",
      "5998 Traning Loss: tensor(0.0819)\n",
      "5999 Traning Loss: tensor(0.0834)\n",
      "6000 Traning Loss: tensor(0.0829)\n",
      "6001 Traning Loss: tensor(0.0831)\n",
      "6002 Traning Loss: tensor(0.0827)\n",
      "6003 Traning Loss: tensor(0.0832)\n",
      "6004 Traning Loss: tensor(0.0844)\n",
      "6005 Traning Loss: tensor(0.0831)\n",
      "6006 Traning Loss: tensor(0.0824)\n",
      "6007 Traning Loss: tensor(0.0824)\n",
      "6008 Traning Loss: tensor(0.0823)\n",
      "6009 Traning Loss: tensor(0.0835)\n",
      "6010 Traning Loss: tensor(0.0829)\n",
      "6011 Traning Loss: tensor(0.0843)\n",
      "6012 Traning Loss: tensor(0.0830)\n",
      "6013 Traning Loss: tensor(0.0835)\n",
      "6014 Traning Loss: tensor(0.0829)\n",
      "6015 Traning Loss: tensor(0.0831)\n",
      "6016 Traning Loss: tensor(0.0825)\n",
      "6017 Traning Loss: tensor(0.0834)\n",
      "6018 Traning Loss: tensor(0.0827)\n",
      "6019 Traning Loss: tensor(0.0826)\n",
      "6020 Traning Loss: tensor(0.0829)\n",
      "6021 Traning Loss: tensor(0.0829)\n",
      "6022 Traning Loss: tensor(0.0832)\n",
      "6023 Traning Loss: tensor(0.0835)\n",
      "6024 Traning Loss: tensor(0.0829)\n",
      "6025 Traning Loss: tensor(0.0827)\n",
      "6026 Traning Loss: tensor(0.0822)\n",
      "6027 Traning Loss: tensor(0.0832)\n",
      "6028 Traning Loss: tensor(0.0828)\n",
      "6029 Traning Loss: tensor(0.0825)\n",
      "6030 Traning Loss: tensor(0.0825)\n",
      "6031 Traning Loss: tensor(0.0837)\n",
      "6032 Traning Loss: tensor(0.0831)\n",
      "6033 Traning Loss: tensor(0.0834)\n",
      "6034 Traning Loss: tensor(0.0826)\n",
      "6035 Traning Loss: tensor(0.0820)\n",
      "6036 Traning Loss: tensor(0.0827)\n",
      "6037 Traning Loss: tensor(0.0828)\n",
      "6038 Traning Loss: tensor(0.0818)\n",
      "6039 Traning Loss: tensor(0.0837)\n",
      "6040 Traning Loss: tensor(0.0828)\n",
      "6041 Traning Loss: tensor(0.0826)\n",
      "6042 Traning Loss: tensor(0.0833)\n",
      "6043 Traning Loss: tensor(0.0818)\n",
      "6044 Traning Loss: tensor(0.0811)\n",
      "6045 Traning Loss: tensor(0.0834)\n",
      "6046 Traning Loss: tensor(0.0832)\n",
      "6047 Traning Loss: tensor(0.0829)\n",
      "6048 Traning Loss: tensor(0.0825)\n",
      "6049 Traning Loss: tensor(0.0818)\n",
      "6050 Traning Loss: tensor(0.0828)\n",
      "6051 Traning Loss: tensor(0.0824)\n",
      "6052 Traning Loss: tensor(0.0826)\n",
      "6053 Traning Loss: tensor(0.0811)\n",
      "6054 Traning Loss: tensor(0.0832)\n",
      "6055 Traning Loss: tensor(0.0830)\n",
      "6056 Traning Loss: tensor(0.0835)\n",
      "6057 Traning Loss: tensor(0.0828)\n",
      "6058 Traning Loss: tensor(0.0826)\n",
      "6059 Traning Loss: tensor(0.0826)\n",
      "6060 Traning Loss: tensor(0.0826)\n",
      "6061 Traning Loss: tensor(0.0824)\n",
      "6062 Traning Loss: tensor(0.0831)\n",
      "6063 Traning Loss: tensor(0.0821)\n",
      "6064 Traning Loss: tensor(0.0826)\n",
      "6065 Traning Loss: tensor(0.0827)\n",
      "6066 Traning Loss: tensor(0.0819)\n",
      "6067 Traning Loss: tensor(0.0815)\n",
      "6068 Traning Loss: tensor(0.0814)\n",
      "6069 Traning Loss: tensor(0.0835)\n",
      "6070 Traning Loss: tensor(0.0821)\n",
      "6071 Traning Loss: tensor(0.0829)\n",
      "6072 Traning Loss: tensor(0.0819)\n",
      "6073 Traning Loss: tensor(0.0819)\n",
      "6074 Traning Loss: tensor(0.0819)\n",
      "6075 Traning Loss: tensor(0.0826)\n",
      "6076 Traning Loss: tensor(0.0824)\n",
      "6077 Traning Loss: tensor(0.0825)\n",
      "6078 Traning Loss: tensor(0.0823)\n",
      "6079 Traning Loss: tensor(0.0820)\n",
      "6080 Traning Loss: tensor(0.0824)\n",
      "6081 Traning Loss: tensor(0.0823)\n",
      "6082 Traning Loss: tensor(0.0826)\n",
      "6083 Traning Loss: tensor(0.0825)\n",
      "6084 Traning Loss: tensor(0.0822)\n",
      "6085 Traning Loss: tensor(0.0818)\n",
      "6086 Traning Loss: tensor(0.0829)\n",
      "6087 Traning Loss: tensor(0.0834)\n",
      "6088 Traning Loss: tensor(0.0827)\n",
      "6089 Traning Loss: tensor(0.0827)\n",
      "6090 Traning Loss: tensor(0.0816)\n",
      "6091 Traning Loss: tensor(0.0816)\n",
      "6092 Traning Loss: tensor(0.0822)\n",
      "6093 Traning Loss: tensor(0.0825)\n",
      "6094 Traning Loss: tensor(0.0832)\n",
      "6095 Traning Loss: tensor(0.0824)\n",
      "6096 Traning Loss: tensor(0.0822)\n",
      "6097 Traning Loss: tensor(0.0811)\n",
      "6098 Traning Loss: tensor(0.0822)\n",
      "6099 Traning Loss: tensor(0.0820)\n",
      "6100 Traning Loss: tensor(0.0814)\n",
      "6101 Traning Loss: tensor(0.0821)\n",
      "6102 Traning Loss: tensor(0.0820)\n",
      "6103 Traning Loss: tensor(0.0828)\n",
      "6104 Traning Loss: tensor(0.0824)\n",
      "6105 Traning Loss: tensor(0.0824)\n",
      "6106 Traning Loss: tensor(0.0819)\n",
      "6107 Traning Loss: tensor(0.0823)\n",
      "6108 Traning Loss: tensor(0.0834)\n",
      "6109 Traning Loss: tensor(0.0810)\n",
      "6110 Traning Loss: tensor(0.0819)\n",
      "6111 Traning Loss: tensor(0.0826)\n",
      "6112 Traning Loss: tensor(0.0806)\n",
      "6113 Traning Loss: tensor(0.0820)\n",
      "6114 Traning Loss: tensor(0.0829)\n",
      "6115 Traning Loss: tensor(0.0821)\n",
      "6116 Traning Loss: tensor(0.0825)\n",
      "6117 Traning Loss: tensor(0.0811)\n",
      "6118 Traning Loss: tensor(0.0819)\n",
      "6119 Traning Loss: tensor(0.0831)\n",
      "6120 Traning Loss: tensor(0.0820)\n",
      "6121 Traning Loss: tensor(0.0819)\n",
      "6122 Traning Loss: tensor(0.0825)\n",
      "6123 Traning Loss: tensor(0.0825)\n",
      "6124 Traning Loss: tensor(0.0820)\n",
      "6125 Traning Loss: tensor(0.0832)\n",
      "6126 Traning Loss: tensor(0.0819)\n",
      "6127 Traning Loss: tensor(0.0817)\n",
      "6128 Traning Loss: tensor(0.0830)\n",
      "6129 Traning Loss: tensor(0.0823)\n",
      "6130 Traning Loss: tensor(0.0822)\n",
      "6131 Traning Loss: tensor(0.0823)\n",
      "6132 Traning Loss: tensor(0.0831)\n",
      "6133 Traning Loss: tensor(0.0823)\n",
      "6134 Traning Loss: tensor(0.0818)\n",
      "6135 Traning Loss: tensor(0.0822)\n",
      "6136 Traning Loss: tensor(0.0814)\n",
      "6137 Traning Loss: tensor(0.0822)\n",
      "6138 Traning Loss: tensor(0.0826)\n",
      "6139 Traning Loss: tensor(0.0809)\n",
      "6140 Traning Loss: tensor(0.0818)\n",
      "6141 Traning Loss: tensor(0.0826)\n",
      "6142 Traning Loss: tensor(0.0814)\n",
      "6143 Traning Loss: tensor(0.0821)\n",
      "6144 Traning Loss: tensor(0.0819)\n",
      "6145 Traning Loss: tensor(0.0829)\n",
      "6146 Traning Loss: tensor(0.0811)\n",
      "6147 Traning Loss: tensor(0.0812)\n",
      "6148 Traning Loss: tensor(0.0815)\n",
      "6149 Traning Loss: tensor(0.0818)\n",
      "6150 Traning Loss: tensor(0.0809)\n",
      "6151 Traning Loss: tensor(0.0821)\n",
      "6152 Traning Loss: tensor(0.0823)\n",
      "6153 Traning Loss: tensor(0.0814)\n",
      "6154 Traning Loss: tensor(0.0817)\n",
      "6155 Traning Loss: tensor(0.0819)\n",
      "6156 Traning Loss: tensor(0.0808)\n",
      "6157 Traning Loss: tensor(0.0831)\n",
      "6158 Traning Loss: tensor(0.0822)\n",
      "6159 Traning Loss: tensor(0.0819)\n",
      "6160 Traning Loss: tensor(0.0817)\n",
      "6161 Traning Loss: tensor(0.0819)\n",
      "6162 Traning Loss: tensor(0.0805)\n",
      "6163 Traning Loss: tensor(0.0822)\n",
      "6164 Traning Loss: tensor(0.0822)\n",
      "6165 Traning Loss: tensor(0.0814)\n",
      "6166 Traning Loss: tensor(0.0813)\n",
      "6167 Traning Loss: tensor(0.0827)\n",
      "6168 Traning Loss: tensor(0.0828)\n",
      "6169 Traning Loss: tensor(0.0819)\n",
      "6170 Traning Loss: tensor(0.0819)\n",
      "6171 Traning Loss: tensor(0.0815)\n",
      "6172 Traning Loss: tensor(0.0816)\n",
      "6173 Traning Loss: tensor(0.0832)\n",
      "6174 Traning Loss: tensor(0.0812)\n",
      "6175 Traning Loss: tensor(0.0813)\n",
      "6176 Traning Loss: tensor(0.0822)\n",
      "6177 Traning Loss: tensor(0.0824)\n",
      "6178 Traning Loss: tensor(0.0822)\n",
      "6179 Traning Loss: tensor(0.0822)\n",
      "6180 Traning Loss: tensor(0.0801)\n",
      "6181 Traning Loss: tensor(0.0826)\n",
      "6182 Traning Loss: tensor(0.0815)\n",
      "6183 Traning Loss: tensor(0.0829)\n",
      "6184 Traning Loss: tensor(0.0818)\n",
      "6185 Traning Loss: tensor(0.0819)\n",
      "6186 Traning Loss: tensor(0.0817)\n",
      "6187 Traning Loss: tensor(0.0822)\n",
      "6188 Traning Loss: tensor(0.0819)\n",
      "6189 Traning Loss: tensor(0.0810)\n",
      "6190 Traning Loss: tensor(0.0812)\n",
      "6191 Traning Loss: tensor(0.0816)\n",
      "6192 Traning Loss: tensor(0.0822)\n",
      "6193 Traning Loss: tensor(0.0820)\n",
      "6194 Traning Loss: tensor(0.0811)\n",
      "6195 Traning Loss: tensor(0.0816)\n",
      "6196 Traning Loss: tensor(0.0819)\n",
      "6197 Traning Loss: tensor(0.0811)\n",
      "6198 Traning Loss: tensor(0.0815)\n",
      "6199 Traning Loss: tensor(0.0817)\n",
      "6200 Traning Loss: tensor(0.0817)\n",
      "6201 Traning Loss: tensor(0.0809)\n",
      "6202 Traning Loss: tensor(0.0805)\n",
      "6203 Traning Loss: tensor(0.0814)\n",
      "6204 Traning Loss: tensor(0.0816)\n",
      "6205 Traning Loss: tensor(0.0816)\n",
      "6206 Traning Loss: tensor(0.0799)\n",
      "6207 Traning Loss: tensor(0.0819)\n",
      "6208 Traning Loss: tensor(0.0816)\n",
      "6209 Traning Loss: tensor(0.0815)\n",
      "6210 Traning Loss: tensor(0.0821)\n",
      "6211 Traning Loss: tensor(0.0818)\n",
      "6212 Traning Loss: tensor(0.0821)\n",
      "6213 Traning Loss: tensor(0.0811)\n",
      "6214 Traning Loss: tensor(0.0807)\n",
      "6215 Traning Loss: tensor(0.0819)\n",
      "6216 Traning Loss: tensor(0.0809)\n",
      "6217 Traning Loss: tensor(0.0817)\n",
      "6218 Traning Loss: tensor(0.0807)\n",
      "6219 Traning Loss: tensor(0.0811)\n",
      "6220 Traning Loss: tensor(0.0816)\n",
      "6221 Traning Loss: tensor(0.0814)\n",
      "6222 Traning Loss: tensor(0.0817)\n",
      "6223 Traning Loss: tensor(0.0817)\n",
      "6224 Traning Loss: tensor(0.0811)\n",
      "6225 Traning Loss: tensor(0.0807)\n",
      "6226 Traning Loss: tensor(0.0821)\n",
      "6227 Traning Loss: tensor(0.0811)\n",
      "6228 Traning Loss: tensor(0.0813)\n",
      "6229 Traning Loss: tensor(0.0811)\n",
      "6230 Traning Loss: tensor(0.0806)\n",
      "6231 Traning Loss: tensor(0.0812)\n",
      "6232 Traning Loss: tensor(0.0810)\n",
      "6233 Traning Loss: tensor(0.0818)\n",
      "6234 Traning Loss: tensor(0.0812)\n",
      "6235 Traning Loss: tensor(0.0812)\n",
      "6236 Traning Loss: tensor(0.0817)\n",
      "6237 Traning Loss: tensor(0.0797)\n",
      "6238 Traning Loss: tensor(0.0819)\n",
      "6239 Traning Loss: tensor(0.0809)\n",
      "6240 Traning Loss: tensor(0.0817)\n",
      "6241 Traning Loss: tensor(0.0805)\n",
      "6242 Traning Loss: tensor(0.0811)\n",
      "6243 Traning Loss: tensor(0.0818)\n",
      "6244 Traning Loss: tensor(0.0824)\n",
      "6245 Traning Loss: tensor(0.0816)\n",
      "6246 Traning Loss: tensor(0.0810)\n",
      "6247 Traning Loss: tensor(0.0809)\n",
      "6248 Traning Loss: tensor(0.0815)\n",
      "6249 Traning Loss: tensor(0.0806)\n",
      "6250 Traning Loss: tensor(0.0812)\n",
      "6251 Traning Loss: tensor(0.0818)\n",
      "6252 Traning Loss: tensor(0.0821)\n",
      "6253 Traning Loss: tensor(0.0814)\n",
      "6254 Traning Loss: tensor(0.0828)\n",
      "6255 Traning Loss: tensor(0.0813)\n",
      "6256 Traning Loss: tensor(0.0806)\n",
      "6257 Traning Loss: tensor(0.0818)\n",
      "6258 Traning Loss: tensor(0.0812)\n",
      "6259 Traning Loss: tensor(0.0810)\n",
      "6260 Traning Loss: tensor(0.0816)\n",
      "6261 Traning Loss: tensor(0.0824)\n",
      "6262 Traning Loss: tensor(0.0815)\n",
      "6263 Traning Loss: tensor(0.0812)\n",
      "6264 Traning Loss: tensor(0.0822)\n",
      "6265 Traning Loss: tensor(0.0812)\n",
      "6266 Traning Loss: tensor(0.0821)\n",
      "6267 Traning Loss: tensor(0.0823)\n",
      "6268 Traning Loss: tensor(0.0816)\n",
      "6269 Traning Loss: tensor(0.0812)\n",
      "6270 Traning Loss: tensor(0.0809)\n",
      "6271 Traning Loss: tensor(0.0809)\n",
      "6272 Traning Loss: tensor(0.0813)\n",
      "6273 Traning Loss: tensor(0.0804)\n",
      "6274 Traning Loss: tensor(0.0815)\n",
      "6275 Traning Loss: tensor(0.0814)\n",
      "6276 Traning Loss: tensor(0.0806)\n",
      "6277 Traning Loss: tensor(0.0809)\n",
      "6278 Traning Loss: tensor(0.0810)\n",
      "6279 Traning Loss: tensor(0.0811)\n",
      "6280 Traning Loss: tensor(0.0804)\n",
      "6281 Traning Loss: tensor(0.0813)\n",
      "6282 Traning Loss: tensor(0.0798)\n",
      "6283 Traning Loss: tensor(0.0806)\n",
      "6284 Traning Loss: tensor(0.0815)\n",
      "6285 Traning Loss: tensor(0.0806)\n",
      "6286 Traning Loss: tensor(0.0810)\n",
      "6287 Traning Loss: tensor(0.0801)\n",
      "6288 Traning Loss: tensor(0.0817)\n",
      "6289 Traning Loss: tensor(0.0809)\n",
      "6290 Traning Loss: tensor(0.0811)\n",
      "6291 Traning Loss: tensor(0.0810)\n",
      "6292 Traning Loss: tensor(0.0816)\n",
      "6293 Traning Loss: tensor(0.0812)\n",
      "6294 Traning Loss: tensor(0.0798)\n",
      "6295 Traning Loss: tensor(0.0803)\n",
      "6296 Traning Loss: tensor(0.0818)\n",
      "6297 Traning Loss: tensor(0.0806)\n",
      "6298 Traning Loss: tensor(0.0806)\n",
      "6299 Traning Loss: tensor(0.0810)\n",
      "6300 Traning Loss: tensor(0.0809)\n",
      "6301 Traning Loss: tensor(0.0818)\n",
      "6302 Traning Loss: tensor(0.0811)\n",
      "6303 Traning Loss: tensor(0.0812)\n",
      "6304 Traning Loss: tensor(0.0811)\n",
      "6305 Traning Loss: tensor(0.0801)\n",
      "6306 Traning Loss: tensor(0.0811)\n",
      "6307 Traning Loss: tensor(0.0807)\n",
      "6308 Traning Loss: tensor(0.0799)\n",
      "6309 Traning Loss: tensor(0.0810)\n",
      "6310 Traning Loss: tensor(0.0810)\n",
      "6311 Traning Loss: tensor(0.0805)\n",
      "6312 Traning Loss: tensor(0.0810)\n",
      "6313 Traning Loss: tensor(0.0809)\n",
      "6314 Traning Loss: tensor(0.0806)\n",
      "6315 Traning Loss: tensor(0.0813)\n",
      "6316 Traning Loss: tensor(0.0806)\n",
      "6317 Traning Loss: tensor(0.0807)\n",
      "6318 Traning Loss: tensor(0.0813)\n",
      "6319 Traning Loss: tensor(0.0815)\n",
      "6320 Traning Loss: tensor(0.0817)\n",
      "6321 Traning Loss: tensor(0.0819)\n",
      "6322 Traning Loss: tensor(0.0808)\n",
      "6323 Traning Loss: tensor(0.0801)\n",
      "6324 Traning Loss: tensor(0.0815)\n",
      "6325 Traning Loss: tensor(0.0814)\n",
      "6326 Traning Loss: tensor(0.0814)\n",
      "6327 Traning Loss: tensor(0.0804)\n",
      "6328 Traning Loss: tensor(0.0805)\n",
      "6329 Traning Loss: tensor(0.0808)\n",
      "6330 Traning Loss: tensor(0.0824)\n",
      "6331 Traning Loss: tensor(0.0808)\n",
      "6332 Traning Loss: tensor(0.0807)\n",
      "6333 Traning Loss: tensor(0.0814)\n",
      "6334 Traning Loss: tensor(0.0804)\n",
      "6335 Traning Loss: tensor(0.0811)\n",
      "6336 Traning Loss: tensor(0.0810)\n",
      "6337 Traning Loss: tensor(0.0812)\n",
      "6338 Traning Loss: tensor(0.0821)\n",
      "6339 Traning Loss: tensor(0.0812)\n",
      "6340 Traning Loss: tensor(0.0797)\n",
      "6341 Traning Loss: tensor(0.0808)\n",
      "6342 Traning Loss: tensor(0.0805)\n",
      "6343 Traning Loss: tensor(0.0809)\n",
      "6344 Traning Loss: tensor(0.0806)\n",
      "6345 Traning Loss: tensor(0.0802)\n",
      "6346 Traning Loss: tensor(0.0810)\n",
      "6347 Traning Loss: tensor(0.0804)\n",
      "6348 Traning Loss: tensor(0.0809)\n",
      "6349 Traning Loss: tensor(0.0809)\n",
      "6350 Traning Loss: tensor(0.0805)\n",
      "6351 Traning Loss: tensor(0.0807)\n",
      "6352 Traning Loss: tensor(0.0796)\n",
      "6353 Traning Loss: tensor(0.0808)\n",
      "6354 Traning Loss: tensor(0.0808)\n",
      "6355 Traning Loss: tensor(0.0815)\n",
      "6356 Traning Loss: tensor(0.0809)\n",
      "6357 Traning Loss: tensor(0.0802)\n",
      "6358 Traning Loss: tensor(0.0804)\n",
      "6359 Traning Loss: tensor(0.0819)\n",
      "6360 Traning Loss: tensor(0.0807)\n",
      "6361 Traning Loss: tensor(0.0809)\n",
      "6362 Traning Loss: tensor(0.0809)\n",
      "6363 Traning Loss: tensor(0.0815)\n",
      "6364 Traning Loss: tensor(0.0814)\n",
      "6365 Traning Loss: tensor(0.0822)\n",
      "6366 Traning Loss: tensor(0.0802)\n",
      "6367 Traning Loss: tensor(0.0798)\n",
      "6368 Traning Loss: tensor(0.0804)\n",
      "6369 Traning Loss: tensor(0.0810)\n",
      "6370 Traning Loss: tensor(0.0808)\n",
      "6371 Traning Loss: tensor(0.0810)\n",
      "6372 Traning Loss: tensor(0.0816)\n",
      "6373 Traning Loss: tensor(0.0812)\n",
      "6374 Traning Loss: tensor(0.0807)\n",
      "6375 Traning Loss: tensor(0.0803)\n",
      "6376 Traning Loss: tensor(0.0802)\n",
      "6377 Traning Loss: tensor(0.0806)\n",
      "6378 Traning Loss: tensor(0.0798)\n",
      "6379 Traning Loss: tensor(0.0814)\n",
      "6380 Traning Loss: tensor(0.0810)\n",
      "6381 Traning Loss: tensor(0.0810)\n",
      "6382 Traning Loss: tensor(0.0807)\n",
      "6383 Traning Loss: tensor(0.0815)\n",
      "6384 Traning Loss: tensor(0.0822)\n",
      "6385 Traning Loss: tensor(0.0803)\n",
      "6386 Traning Loss: tensor(0.0815)\n",
      "6387 Traning Loss: tensor(0.0799)\n",
      "6388 Traning Loss: tensor(0.0808)\n",
      "6389 Traning Loss: tensor(0.0809)\n",
      "6390 Traning Loss: tensor(0.0807)\n",
      "6391 Traning Loss: tensor(0.0795)\n",
      "6392 Traning Loss: tensor(0.0807)\n",
      "6393 Traning Loss: tensor(0.0805)\n",
      "6394 Traning Loss: tensor(0.0806)\n",
      "6395 Traning Loss: tensor(0.0806)\n",
      "6396 Traning Loss: tensor(0.0816)\n",
      "6397 Traning Loss: tensor(0.0798)\n",
      "6398 Traning Loss: tensor(0.0799)\n",
      "6399 Traning Loss: tensor(0.0817)\n",
      "6400 Traning Loss: tensor(0.0810)\n",
      "6401 Traning Loss: tensor(0.0803)\n",
      "6402 Traning Loss: tensor(0.0792)\n",
      "6403 Traning Loss: tensor(0.0807)\n",
      "6404 Traning Loss: tensor(0.0814)\n",
      "6405 Traning Loss: tensor(0.0804)\n",
      "6406 Traning Loss: tensor(0.0802)\n",
      "6407 Traning Loss: tensor(0.0807)\n",
      "6408 Traning Loss: tensor(0.0798)\n",
      "6409 Traning Loss: tensor(0.0805)\n",
      "6410 Traning Loss: tensor(0.0798)\n",
      "6411 Traning Loss: tensor(0.0811)\n",
      "6412 Traning Loss: tensor(0.0811)\n",
      "6413 Traning Loss: tensor(0.0801)\n",
      "6414 Traning Loss: tensor(0.0801)\n",
      "6415 Traning Loss: tensor(0.0811)\n",
      "6416 Traning Loss: tensor(0.0808)\n",
      "6417 Traning Loss: tensor(0.0797)\n",
      "6418 Traning Loss: tensor(0.0805)\n",
      "6419 Traning Loss: tensor(0.0809)\n",
      "6420 Traning Loss: tensor(0.0811)\n",
      "6421 Traning Loss: tensor(0.0803)\n",
      "6422 Traning Loss: tensor(0.0802)\n",
      "6423 Traning Loss: tensor(0.0803)\n",
      "6424 Traning Loss: tensor(0.0796)\n",
      "6425 Traning Loss: tensor(0.0814)\n",
      "6426 Traning Loss: tensor(0.0808)\n",
      "6427 Traning Loss: tensor(0.0803)\n",
      "6428 Traning Loss: tensor(0.0802)\n",
      "6429 Traning Loss: tensor(0.0794)\n",
      "6430 Traning Loss: tensor(0.0812)\n",
      "6431 Traning Loss: tensor(0.0802)\n",
      "6432 Traning Loss: tensor(0.0808)\n",
      "6433 Traning Loss: tensor(0.0807)\n",
      "6434 Traning Loss: tensor(0.0803)\n",
      "6435 Traning Loss: tensor(0.0795)\n",
      "6436 Traning Loss: tensor(0.0799)\n",
      "6437 Traning Loss: tensor(0.0811)\n",
      "6438 Traning Loss: tensor(0.0792)\n",
      "6439 Traning Loss: tensor(0.0802)\n",
      "6440 Traning Loss: tensor(0.0805)\n",
      "6441 Traning Loss: tensor(0.0801)\n",
      "6442 Traning Loss: tensor(0.0810)\n",
      "6443 Traning Loss: tensor(0.0805)\n",
      "6444 Traning Loss: tensor(0.0812)\n",
      "6445 Traning Loss: tensor(0.0808)\n",
      "6446 Traning Loss: tensor(0.0799)\n",
      "6447 Traning Loss: tensor(0.0793)\n",
      "6448 Traning Loss: tensor(0.0804)\n",
      "6449 Traning Loss: tensor(0.0804)\n",
      "6450 Traning Loss: tensor(0.0799)\n",
      "6451 Traning Loss: tensor(0.0795)\n",
      "6452 Traning Loss: tensor(0.0798)\n",
      "6453 Traning Loss: tensor(0.0802)\n",
      "6454 Traning Loss: tensor(0.0799)\n",
      "6455 Traning Loss: tensor(0.0799)\n",
      "6456 Traning Loss: tensor(0.0800)\n",
      "6457 Traning Loss: tensor(0.0804)\n",
      "6458 Traning Loss: tensor(0.0801)\n",
      "6459 Traning Loss: tensor(0.0795)\n",
      "6460 Traning Loss: tensor(0.0800)\n",
      "6461 Traning Loss: tensor(0.0808)\n",
      "6462 Traning Loss: tensor(0.0798)\n",
      "6463 Traning Loss: tensor(0.0811)\n",
      "6464 Traning Loss: tensor(0.0805)\n",
      "6465 Traning Loss: tensor(0.0800)\n",
      "6466 Traning Loss: tensor(0.0803)\n",
      "6467 Traning Loss: tensor(0.0797)\n",
      "6468 Traning Loss: tensor(0.0799)\n",
      "6469 Traning Loss: tensor(0.0796)\n",
      "6470 Traning Loss: tensor(0.0789)\n",
      "6471 Traning Loss: tensor(0.0808)\n",
      "6472 Traning Loss: tensor(0.0807)\n",
      "6473 Traning Loss: tensor(0.0805)\n",
      "6474 Traning Loss: tensor(0.0798)\n",
      "6475 Traning Loss: tensor(0.0799)\n",
      "6476 Traning Loss: tensor(0.0799)\n",
      "6477 Traning Loss: tensor(0.0799)\n",
      "6478 Traning Loss: tensor(0.0803)\n",
      "6479 Traning Loss: tensor(0.0800)\n",
      "6480 Traning Loss: tensor(0.0803)\n",
      "6481 Traning Loss: tensor(0.0785)\n",
      "6482 Traning Loss: tensor(0.0796)\n",
      "6483 Traning Loss: tensor(0.0805)\n",
      "6484 Traning Loss: tensor(0.0806)\n",
      "6485 Traning Loss: tensor(0.0802)\n",
      "6486 Traning Loss: tensor(0.0801)\n",
      "6487 Traning Loss: tensor(0.0804)\n",
      "6488 Traning Loss: tensor(0.0802)\n",
      "6489 Traning Loss: tensor(0.0808)\n",
      "6490 Traning Loss: tensor(0.0800)\n",
      "6491 Traning Loss: tensor(0.0806)\n",
      "6492 Traning Loss: tensor(0.0800)\n",
      "6493 Traning Loss: tensor(0.0793)\n",
      "6494 Traning Loss: tensor(0.0805)\n",
      "6495 Traning Loss: tensor(0.0794)\n",
      "6496 Traning Loss: tensor(0.0797)\n",
      "6497 Traning Loss: tensor(0.0798)\n",
      "6498 Traning Loss: tensor(0.0802)\n",
      "6499 Traning Loss: tensor(0.0798)\n",
      "6500 Traning Loss: tensor(0.0808)\n",
      "6501 Traning Loss: tensor(0.0795)\n",
      "6502 Traning Loss: tensor(0.0800)\n",
      "6503 Traning Loss: tensor(0.0795)\n",
      "6504 Traning Loss: tensor(0.0803)\n",
      "6505 Traning Loss: tensor(0.0795)\n",
      "6506 Traning Loss: tensor(0.0806)\n",
      "6507 Traning Loss: tensor(0.0803)\n",
      "6508 Traning Loss: tensor(0.0806)\n",
      "6509 Traning Loss: tensor(0.0809)\n",
      "6510 Traning Loss: tensor(0.0799)\n",
      "6511 Traning Loss: tensor(0.0794)\n",
      "6512 Traning Loss: tensor(0.0799)\n",
      "6513 Traning Loss: tensor(0.0799)\n",
      "6514 Traning Loss: tensor(0.0804)\n",
      "6515 Traning Loss: tensor(0.0797)\n",
      "6516 Traning Loss: tensor(0.0789)\n",
      "6517 Traning Loss: tensor(0.0805)\n",
      "6518 Traning Loss: tensor(0.0795)\n",
      "6519 Traning Loss: tensor(0.0797)\n",
      "6520 Traning Loss: tensor(0.0801)\n",
      "6521 Traning Loss: tensor(0.0802)\n",
      "6522 Traning Loss: tensor(0.0805)\n",
      "6523 Traning Loss: tensor(0.0798)\n",
      "6524 Traning Loss: tensor(0.0802)\n",
      "6525 Traning Loss: tensor(0.0805)\n",
      "6526 Traning Loss: tensor(0.0805)\n",
      "6527 Traning Loss: tensor(0.0792)\n",
      "6528 Traning Loss: tensor(0.0801)\n",
      "6529 Traning Loss: tensor(0.0803)\n",
      "6530 Traning Loss: tensor(0.0800)\n",
      "6531 Traning Loss: tensor(0.0802)\n",
      "6532 Traning Loss: tensor(0.0804)\n",
      "6533 Traning Loss: tensor(0.0798)\n",
      "6534 Traning Loss: tensor(0.0811)\n",
      "6535 Traning Loss: tensor(0.0803)\n",
      "6536 Traning Loss: tensor(0.0800)\n",
      "6537 Traning Loss: tensor(0.0799)\n",
      "6538 Traning Loss: tensor(0.0798)\n",
      "6539 Traning Loss: tensor(0.0803)\n",
      "6540 Traning Loss: tensor(0.0793)\n",
      "6541 Traning Loss: tensor(0.0799)\n",
      "6542 Traning Loss: tensor(0.0801)\n",
      "6543 Traning Loss: tensor(0.0802)\n",
      "6544 Traning Loss: tensor(0.0801)\n",
      "6545 Traning Loss: tensor(0.0806)\n",
      "6546 Traning Loss: tensor(0.0802)\n",
      "6547 Traning Loss: tensor(0.0801)\n",
      "6548 Traning Loss: tensor(0.0795)\n",
      "6549 Traning Loss: tensor(0.0797)\n",
      "6550 Traning Loss: tensor(0.0799)\n",
      "6551 Traning Loss: tensor(0.0794)\n",
      "6552 Traning Loss: tensor(0.0809)\n",
      "6553 Traning Loss: tensor(0.0793)\n",
      "6554 Traning Loss: tensor(0.0794)\n",
      "6555 Traning Loss: tensor(0.0793)\n",
      "6556 Traning Loss: tensor(0.0796)\n",
      "6557 Traning Loss: tensor(0.0805)\n",
      "6558 Traning Loss: tensor(0.0788)\n",
      "6559 Traning Loss: tensor(0.0799)\n",
      "6560 Traning Loss: tensor(0.0794)\n",
      "6561 Traning Loss: tensor(0.0797)\n",
      "6562 Traning Loss: tensor(0.0795)\n",
      "6563 Traning Loss: tensor(0.0807)\n",
      "6564 Traning Loss: tensor(0.0789)\n",
      "6565 Traning Loss: tensor(0.0806)\n",
      "6566 Traning Loss: tensor(0.0807)\n",
      "6567 Traning Loss: tensor(0.0790)\n",
      "6568 Traning Loss: tensor(0.0794)\n",
      "6569 Traning Loss: tensor(0.0805)\n",
      "6570 Traning Loss: tensor(0.0789)\n",
      "6571 Traning Loss: tensor(0.0802)\n",
      "6572 Traning Loss: tensor(0.0803)\n",
      "6573 Traning Loss: tensor(0.0801)\n",
      "6574 Traning Loss: tensor(0.0802)\n",
      "6575 Traning Loss: tensor(0.0797)\n",
      "6576 Traning Loss: tensor(0.0800)\n",
      "6577 Traning Loss: tensor(0.0795)\n",
      "6578 Traning Loss: tensor(0.0807)\n",
      "6579 Traning Loss: tensor(0.0797)\n",
      "6580 Traning Loss: tensor(0.0789)\n",
      "6581 Traning Loss: tensor(0.0803)\n",
      "6582 Traning Loss: tensor(0.0798)\n",
      "6583 Traning Loss: tensor(0.0800)\n",
      "6584 Traning Loss: tensor(0.0790)\n",
      "6585 Traning Loss: tensor(0.0791)\n",
      "6586 Traning Loss: tensor(0.0805)\n",
      "6587 Traning Loss: tensor(0.0792)\n",
      "6588 Traning Loss: tensor(0.0795)\n",
      "6589 Traning Loss: tensor(0.0804)\n",
      "6590 Traning Loss: tensor(0.0801)\n",
      "6591 Traning Loss: tensor(0.0794)\n",
      "6592 Traning Loss: tensor(0.0789)\n",
      "6593 Traning Loss: tensor(0.0790)\n",
      "6594 Traning Loss: tensor(0.0791)\n",
      "6595 Traning Loss: tensor(0.0796)\n",
      "6596 Traning Loss: tensor(0.0801)\n",
      "6597 Traning Loss: tensor(0.0793)\n",
      "6598 Traning Loss: tensor(0.0793)\n",
      "6599 Traning Loss: tensor(0.0793)\n",
      "6600 Traning Loss: tensor(0.0789)\n",
      "6601 Traning Loss: tensor(0.0797)\n",
      "6602 Traning Loss: tensor(0.0787)\n",
      "6603 Traning Loss: tensor(0.0795)\n",
      "6604 Traning Loss: tensor(0.0807)\n",
      "6605 Traning Loss: tensor(0.0808)\n",
      "6606 Traning Loss: tensor(0.0798)\n",
      "6607 Traning Loss: tensor(0.0803)\n",
      "6608 Traning Loss: tensor(0.0795)\n",
      "6609 Traning Loss: tensor(0.0792)\n",
      "6610 Traning Loss: tensor(0.0802)\n",
      "6611 Traning Loss: tensor(0.0797)\n",
      "6612 Traning Loss: tensor(0.0795)\n",
      "6613 Traning Loss: tensor(0.0807)\n",
      "6614 Traning Loss: tensor(0.0797)\n",
      "6615 Traning Loss: tensor(0.0795)\n",
      "6616 Traning Loss: tensor(0.0784)\n",
      "6617 Traning Loss: tensor(0.0792)\n",
      "6618 Traning Loss: tensor(0.0796)\n",
      "6619 Traning Loss: tensor(0.0793)\n",
      "6620 Traning Loss: tensor(0.0804)\n",
      "6621 Traning Loss: tensor(0.0796)\n",
      "6622 Traning Loss: tensor(0.0795)\n",
      "6623 Traning Loss: tensor(0.0790)\n",
      "6624 Traning Loss: tensor(0.0796)\n",
      "6625 Traning Loss: tensor(0.0795)\n",
      "6626 Traning Loss: tensor(0.0789)\n",
      "6627 Traning Loss: tensor(0.0797)\n",
      "6628 Traning Loss: tensor(0.0794)\n",
      "6629 Traning Loss: tensor(0.0792)\n",
      "6630 Traning Loss: tensor(0.0792)\n",
      "6631 Traning Loss: tensor(0.0790)\n",
      "6632 Traning Loss: tensor(0.0781)\n",
      "6633 Traning Loss: tensor(0.0801)\n",
      "6634 Traning Loss: tensor(0.0796)\n",
      "6635 Traning Loss: tensor(0.0799)\n",
      "6636 Traning Loss: tensor(0.0794)\n",
      "6637 Traning Loss: tensor(0.0789)\n",
      "6638 Traning Loss: tensor(0.0794)\n",
      "6639 Traning Loss: tensor(0.0794)\n",
      "6640 Traning Loss: tensor(0.0800)\n",
      "6641 Traning Loss: tensor(0.0789)\n",
      "6642 Traning Loss: tensor(0.0797)\n",
      "6643 Traning Loss: tensor(0.0793)\n",
      "6644 Traning Loss: tensor(0.0788)\n",
      "6645 Traning Loss: tensor(0.0794)\n",
      "6646 Traning Loss: tensor(0.0791)\n",
      "6647 Traning Loss: tensor(0.0799)\n",
      "6648 Traning Loss: tensor(0.0788)\n",
      "6649 Traning Loss: tensor(0.0794)\n",
      "6650 Traning Loss: tensor(0.0790)\n",
      "6651 Traning Loss: tensor(0.0782)\n",
      "6652 Traning Loss: tensor(0.0802)\n",
      "6653 Traning Loss: tensor(0.0797)\n",
      "6654 Traning Loss: tensor(0.0788)\n",
      "6655 Traning Loss: tensor(0.0788)\n",
      "6656 Traning Loss: tensor(0.0806)\n",
      "6657 Traning Loss: tensor(0.0800)\n",
      "6658 Traning Loss: tensor(0.0801)\n",
      "6659 Traning Loss: tensor(0.0799)\n",
      "6660 Traning Loss: tensor(0.0799)\n",
      "6661 Traning Loss: tensor(0.0795)\n",
      "6662 Traning Loss: tensor(0.0798)\n",
      "6663 Traning Loss: tensor(0.0795)\n",
      "6664 Traning Loss: tensor(0.0793)\n",
      "6665 Traning Loss: tensor(0.0801)\n",
      "6666 Traning Loss: tensor(0.0792)\n",
      "6667 Traning Loss: tensor(0.0787)\n",
      "6668 Traning Loss: tensor(0.0796)\n",
      "6669 Traning Loss: tensor(0.0797)\n",
      "6670 Traning Loss: tensor(0.0794)\n",
      "6671 Traning Loss: tensor(0.0784)\n",
      "6672 Traning Loss: tensor(0.0789)\n",
      "6673 Traning Loss: tensor(0.0794)\n",
      "6674 Traning Loss: tensor(0.0790)\n",
      "6675 Traning Loss: tensor(0.0798)\n",
      "6676 Traning Loss: tensor(0.0802)\n",
      "6677 Traning Loss: tensor(0.0799)\n",
      "6678 Traning Loss: tensor(0.0796)\n",
      "6679 Traning Loss: tensor(0.0788)\n",
      "6680 Traning Loss: tensor(0.0795)\n",
      "6681 Traning Loss: tensor(0.0777)\n",
      "6682 Traning Loss: tensor(0.0801)\n",
      "6683 Traning Loss: tensor(0.0792)\n",
      "6684 Traning Loss: tensor(0.0788)\n",
      "6685 Traning Loss: tensor(0.0788)\n",
      "6686 Traning Loss: tensor(0.0795)\n",
      "6687 Traning Loss: tensor(0.0795)\n",
      "6688 Traning Loss: tensor(0.0789)\n",
      "6689 Traning Loss: tensor(0.0797)\n",
      "6690 Traning Loss: tensor(0.0789)\n",
      "6691 Traning Loss: tensor(0.0798)\n",
      "6692 Traning Loss: tensor(0.0793)\n",
      "6693 Traning Loss: tensor(0.0798)\n",
      "6694 Traning Loss: tensor(0.0800)\n",
      "6695 Traning Loss: tensor(0.0786)\n",
      "6696 Traning Loss: tensor(0.0801)\n",
      "6697 Traning Loss: tensor(0.0788)\n",
      "6698 Traning Loss: tensor(0.0790)\n",
      "6699 Traning Loss: tensor(0.0784)\n",
      "6700 Traning Loss: tensor(0.0789)\n",
      "6701 Traning Loss: tensor(0.0785)\n",
      "6702 Traning Loss: tensor(0.0801)\n",
      "6703 Traning Loss: tensor(0.0790)\n",
      "6704 Traning Loss: tensor(0.0790)\n",
      "6705 Traning Loss: tensor(0.0785)\n",
      "6706 Traning Loss: tensor(0.0792)\n",
      "6707 Traning Loss: tensor(0.0797)\n",
      "6708 Traning Loss: tensor(0.0797)\n",
      "6709 Traning Loss: tensor(0.0798)\n",
      "6710 Traning Loss: tensor(0.0800)\n",
      "6711 Traning Loss: tensor(0.0797)\n",
      "6712 Traning Loss: tensor(0.0799)\n",
      "6713 Traning Loss: tensor(0.0790)\n",
      "6714 Traning Loss: tensor(0.0783)\n",
      "6715 Traning Loss: tensor(0.0791)\n",
      "6716 Traning Loss: tensor(0.0792)\n",
      "6717 Traning Loss: tensor(0.0785)\n",
      "6718 Traning Loss: tensor(0.0791)\n",
      "6719 Traning Loss: tensor(0.0800)\n",
      "6720 Traning Loss: tensor(0.0799)\n",
      "6721 Traning Loss: tensor(0.0792)\n",
      "6722 Traning Loss: tensor(0.0784)\n",
      "6723 Traning Loss: tensor(0.0777)\n",
      "6724 Traning Loss: tensor(0.0786)\n",
      "6725 Traning Loss: tensor(0.0790)\n",
      "6726 Traning Loss: tensor(0.0787)\n",
      "6727 Traning Loss: tensor(0.0791)\n",
      "6728 Traning Loss: tensor(0.0795)\n",
      "6729 Traning Loss: tensor(0.0789)\n",
      "6730 Traning Loss: tensor(0.0789)\n",
      "6731 Traning Loss: tensor(0.0786)\n",
      "6732 Traning Loss: tensor(0.0779)\n",
      "6733 Traning Loss: tensor(0.0793)\n",
      "6734 Traning Loss: tensor(0.0779)\n",
      "6735 Traning Loss: tensor(0.0793)\n",
      "6736 Traning Loss: tensor(0.0787)\n",
      "6737 Traning Loss: tensor(0.0789)\n",
      "6738 Traning Loss: tensor(0.0798)\n",
      "6739 Traning Loss: tensor(0.0786)\n",
      "6740 Traning Loss: tensor(0.0790)\n",
      "6741 Traning Loss: tensor(0.0782)\n",
      "6742 Traning Loss: tensor(0.0796)\n",
      "6743 Traning Loss: tensor(0.0788)\n",
      "6744 Traning Loss: tensor(0.0792)\n",
      "6745 Traning Loss: tensor(0.0788)\n",
      "6746 Traning Loss: tensor(0.0781)\n",
      "6747 Traning Loss: tensor(0.0784)\n",
      "6748 Traning Loss: tensor(0.0790)\n",
      "6749 Traning Loss: tensor(0.0787)\n",
      "6750 Traning Loss: tensor(0.0784)\n",
      "6751 Traning Loss: tensor(0.0788)\n",
      "6752 Traning Loss: tensor(0.0794)\n",
      "6753 Traning Loss: tensor(0.0786)\n",
      "6754 Traning Loss: tensor(0.0787)\n",
      "6755 Traning Loss: tensor(0.0800)\n",
      "6756 Traning Loss: tensor(0.0797)\n",
      "6757 Traning Loss: tensor(0.0781)\n",
      "6758 Traning Loss: tensor(0.0793)\n",
      "6759 Traning Loss: tensor(0.0786)\n",
      "6760 Traning Loss: tensor(0.0791)\n",
      "6761 Traning Loss: tensor(0.0778)\n",
      "6762 Traning Loss: tensor(0.0788)\n",
      "6763 Traning Loss: tensor(0.0797)\n",
      "6764 Traning Loss: tensor(0.0777)\n",
      "6765 Traning Loss: tensor(0.0788)\n",
      "6766 Traning Loss: tensor(0.0783)\n",
      "6767 Traning Loss: tensor(0.0781)\n",
      "6768 Traning Loss: tensor(0.0792)\n",
      "6769 Traning Loss: tensor(0.0783)\n",
      "6770 Traning Loss: tensor(0.0795)\n",
      "6771 Traning Loss: tensor(0.0773)\n",
      "6772 Traning Loss: tensor(0.0783)\n",
      "6773 Traning Loss: tensor(0.0791)\n",
      "6774 Traning Loss: tensor(0.0795)\n",
      "6775 Traning Loss: tensor(0.0787)\n",
      "6776 Traning Loss: tensor(0.0773)\n",
      "6777 Traning Loss: tensor(0.0793)\n",
      "6778 Traning Loss: tensor(0.0785)\n",
      "6779 Traning Loss: tensor(0.0779)\n",
      "6780 Traning Loss: tensor(0.0784)\n",
      "6781 Traning Loss: tensor(0.0788)\n",
      "6782 Traning Loss: tensor(0.0786)\n",
      "6783 Traning Loss: tensor(0.0791)\n",
      "6784 Traning Loss: tensor(0.0794)\n",
      "6785 Traning Loss: tensor(0.0786)\n",
      "6786 Traning Loss: tensor(0.0789)\n",
      "6787 Traning Loss: tensor(0.0798)\n",
      "6788 Traning Loss: tensor(0.0783)\n",
      "6789 Traning Loss: tensor(0.0784)\n",
      "6790 Traning Loss: tensor(0.0783)\n",
      "6791 Traning Loss: tensor(0.0785)\n",
      "6792 Traning Loss: tensor(0.0788)\n",
      "6793 Traning Loss: tensor(0.0793)\n",
      "6794 Traning Loss: tensor(0.0780)\n",
      "6795 Traning Loss: tensor(0.0782)\n",
      "6796 Traning Loss: tensor(0.0785)\n",
      "6797 Traning Loss: tensor(0.0787)\n",
      "6798 Traning Loss: tensor(0.0788)\n",
      "6799 Traning Loss: tensor(0.0784)\n",
      "6800 Traning Loss: tensor(0.0782)\n",
      "6801 Traning Loss: tensor(0.0785)\n",
      "6802 Traning Loss: tensor(0.0782)\n",
      "6803 Traning Loss: tensor(0.0794)\n",
      "6804 Traning Loss: tensor(0.0790)\n",
      "6805 Traning Loss: tensor(0.0791)\n",
      "6806 Traning Loss: tensor(0.0796)\n",
      "6807 Traning Loss: tensor(0.0782)\n",
      "6808 Traning Loss: tensor(0.0789)\n",
      "6809 Traning Loss: tensor(0.0773)\n",
      "6810 Traning Loss: tensor(0.0776)\n",
      "6811 Traning Loss: tensor(0.0787)\n",
      "6812 Traning Loss: tensor(0.0787)\n",
      "6813 Traning Loss: tensor(0.0782)\n",
      "6814 Traning Loss: tensor(0.0783)\n",
      "6815 Traning Loss: tensor(0.0787)\n",
      "6816 Traning Loss: tensor(0.0787)\n",
      "6817 Traning Loss: tensor(0.0778)\n",
      "6818 Traning Loss: tensor(0.0784)\n",
      "6819 Traning Loss: tensor(0.0783)\n",
      "6820 Traning Loss: tensor(0.0780)\n",
      "6821 Traning Loss: tensor(0.0792)\n",
      "6822 Traning Loss: tensor(0.0791)\n",
      "6823 Traning Loss: tensor(0.0789)\n",
      "6824 Traning Loss: tensor(0.0788)\n",
      "6825 Traning Loss: tensor(0.0791)\n",
      "6826 Traning Loss: tensor(0.0788)\n",
      "6827 Traning Loss: tensor(0.0774)\n",
      "6828 Traning Loss: tensor(0.0782)\n",
      "6829 Traning Loss: tensor(0.0790)\n",
      "6830 Traning Loss: tensor(0.0787)\n",
      "6831 Traning Loss: tensor(0.0786)\n",
      "6832 Traning Loss: tensor(0.0790)\n",
      "6833 Traning Loss: tensor(0.0774)\n",
      "6834 Traning Loss: tensor(0.0783)\n",
      "6835 Traning Loss: tensor(0.0792)\n",
      "6836 Traning Loss: tensor(0.0784)\n",
      "6837 Traning Loss: tensor(0.0779)\n",
      "6838 Traning Loss: tensor(0.0784)\n",
      "6839 Traning Loss: tensor(0.0787)\n",
      "6840 Traning Loss: tensor(0.0796)\n",
      "6841 Traning Loss: tensor(0.0789)\n",
      "6842 Traning Loss: tensor(0.0790)\n",
      "6843 Traning Loss: tensor(0.0794)\n",
      "6844 Traning Loss: tensor(0.0779)\n",
      "6845 Traning Loss: tensor(0.0783)\n",
      "6846 Traning Loss: tensor(0.0781)\n",
      "6847 Traning Loss: tensor(0.0783)\n",
      "6848 Traning Loss: tensor(0.0777)\n",
      "6849 Traning Loss: tensor(0.0785)\n",
      "6850 Traning Loss: tensor(0.0789)\n",
      "6851 Traning Loss: tensor(0.0783)\n",
      "6852 Traning Loss: tensor(0.0779)\n",
      "6853 Traning Loss: tensor(0.0786)\n",
      "6854 Traning Loss: tensor(0.0782)\n",
      "6855 Traning Loss: tensor(0.0794)\n",
      "6856 Traning Loss: tensor(0.0783)\n",
      "6857 Traning Loss: tensor(0.0780)\n",
      "6858 Traning Loss: tensor(0.0782)\n",
      "6859 Traning Loss: tensor(0.0792)\n",
      "6860 Traning Loss: tensor(0.0782)\n",
      "6861 Traning Loss: tensor(0.0780)\n",
      "6862 Traning Loss: tensor(0.0773)\n",
      "6863 Traning Loss: tensor(0.0789)\n",
      "6864 Traning Loss: tensor(0.0793)\n",
      "6865 Traning Loss: tensor(0.0783)\n",
      "6866 Traning Loss: tensor(0.0780)\n",
      "6867 Traning Loss: tensor(0.0781)\n",
      "6868 Traning Loss: tensor(0.0792)\n",
      "6869 Traning Loss: tensor(0.0788)\n",
      "6870 Traning Loss: tensor(0.0779)\n",
      "6871 Traning Loss: tensor(0.0788)\n",
      "6872 Traning Loss: tensor(0.0786)\n",
      "6873 Traning Loss: tensor(0.0770)\n",
      "6874 Traning Loss: tensor(0.0782)\n",
      "6875 Traning Loss: tensor(0.0778)\n",
      "6876 Traning Loss: tensor(0.0783)\n",
      "6877 Traning Loss: tensor(0.0788)\n",
      "6878 Traning Loss: tensor(0.0775)\n",
      "6879 Traning Loss: tensor(0.0781)\n",
      "6880 Traning Loss: tensor(0.0775)\n",
      "6881 Traning Loss: tensor(0.0786)\n",
      "6882 Traning Loss: tensor(0.0783)\n",
      "6883 Traning Loss: tensor(0.0785)\n",
      "6884 Traning Loss: tensor(0.0786)\n",
      "6885 Traning Loss: tensor(0.0779)\n",
      "6886 Traning Loss: tensor(0.0787)\n",
      "6887 Traning Loss: tensor(0.0784)\n",
      "6888 Traning Loss: tensor(0.0774)\n",
      "6889 Traning Loss: tensor(0.0787)\n",
      "6890 Traning Loss: tensor(0.0786)\n",
      "6891 Traning Loss: tensor(0.0785)\n",
      "6892 Traning Loss: tensor(0.0786)\n",
      "6893 Traning Loss: tensor(0.0779)\n",
      "6894 Traning Loss: tensor(0.0777)\n",
      "6895 Traning Loss: tensor(0.0789)\n",
      "6896 Traning Loss: tensor(0.0777)\n",
      "6897 Traning Loss: tensor(0.0788)\n",
      "6898 Traning Loss: tensor(0.0786)\n",
      "6899 Traning Loss: tensor(0.0782)\n",
      "6900 Traning Loss: tensor(0.0782)\n",
      "6901 Traning Loss: tensor(0.0785)\n",
      "6902 Traning Loss: tensor(0.0789)\n",
      "6903 Traning Loss: tensor(0.0780)\n",
      "6904 Traning Loss: tensor(0.0787)\n",
      "6905 Traning Loss: tensor(0.0789)\n",
      "6906 Traning Loss: tensor(0.0786)\n",
      "6907 Traning Loss: tensor(0.0779)\n",
      "6908 Traning Loss: tensor(0.0788)\n",
      "6909 Traning Loss: tensor(0.0777)\n",
      "6910 Traning Loss: tensor(0.0774)\n",
      "6911 Traning Loss: tensor(0.0781)\n",
      "6912 Traning Loss: tensor(0.0774)\n",
      "6913 Traning Loss: tensor(0.0787)\n",
      "6914 Traning Loss: tensor(0.0780)\n",
      "6915 Traning Loss: tensor(0.0783)\n",
      "6916 Traning Loss: tensor(0.0779)\n",
      "6917 Traning Loss: tensor(0.0782)\n",
      "6918 Traning Loss: tensor(0.0785)\n",
      "6919 Traning Loss: tensor(0.0773)\n",
      "6920 Traning Loss: tensor(0.0780)\n",
      "6921 Traning Loss: tensor(0.0774)\n",
      "6922 Traning Loss: tensor(0.0782)\n",
      "6923 Traning Loss: tensor(0.0787)\n",
      "6924 Traning Loss: tensor(0.0783)\n",
      "6925 Traning Loss: tensor(0.0789)\n",
      "6926 Traning Loss: tensor(0.0778)\n",
      "6927 Traning Loss: tensor(0.0782)\n",
      "6928 Traning Loss: tensor(0.0776)\n",
      "6929 Traning Loss: tensor(0.0779)\n",
      "6930 Traning Loss: tensor(0.0784)\n",
      "6931 Traning Loss: tensor(0.0785)\n",
      "6932 Traning Loss: tensor(0.0785)\n",
      "6933 Traning Loss: tensor(0.0788)\n",
      "6934 Traning Loss: tensor(0.0781)\n",
      "6935 Traning Loss: tensor(0.0780)\n",
      "6936 Traning Loss: tensor(0.0779)\n",
      "6937 Traning Loss: tensor(0.0781)\n",
      "6938 Traning Loss: tensor(0.0767)\n",
      "6939 Traning Loss: tensor(0.0780)\n",
      "6940 Traning Loss: tensor(0.0773)\n",
      "6941 Traning Loss: tensor(0.0779)\n",
      "6942 Traning Loss: tensor(0.0787)\n",
      "6943 Traning Loss: tensor(0.0781)\n",
      "6944 Traning Loss: tensor(0.0783)\n",
      "6945 Traning Loss: tensor(0.0786)\n",
      "6946 Traning Loss: tensor(0.0782)\n",
      "6947 Traning Loss: tensor(0.0776)\n",
      "6948 Traning Loss: tensor(0.0789)\n",
      "6949 Traning Loss: tensor(0.0772)\n",
      "6950 Traning Loss: tensor(0.0779)\n",
      "6951 Traning Loss: tensor(0.0779)\n",
      "6952 Traning Loss: tensor(0.0780)\n",
      "6953 Traning Loss: tensor(0.0789)\n",
      "6954 Traning Loss: tensor(0.0780)\n",
      "6955 Traning Loss: tensor(0.0774)\n",
      "6956 Traning Loss: tensor(0.0780)\n",
      "6957 Traning Loss: tensor(0.0774)\n",
      "6958 Traning Loss: tensor(0.0784)\n",
      "6959 Traning Loss: tensor(0.0779)\n",
      "6960 Traning Loss: tensor(0.0777)\n",
      "6961 Traning Loss: tensor(0.0766)\n",
      "6962 Traning Loss: tensor(0.0786)\n",
      "6963 Traning Loss: tensor(0.0771)\n",
      "6964 Traning Loss: tensor(0.0788)\n",
      "6965 Traning Loss: tensor(0.0785)\n",
      "6966 Traning Loss: tensor(0.0768)\n",
      "6967 Traning Loss: tensor(0.0775)\n",
      "6968 Traning Loss: tensor(0.0782)\n",
      "6969 Traning Loss: tensor(0.0781)\n",
      "6970 Traning Loss: tensor(0.0767)\n",
      "6971 Traning Loss: tensor(0.0779)\n",
      "6972 Traning Loss: tensor(0.0773)\n",
      "6973 Traning Loss: tensor(0.0778)\n",
      "6974 Traning Loss: tensor(0.0782)\n",
      "6975 Traning Loss: tensor(0.0787)\n",
      "6976 Traning Loss: tensor(0.0792)\n",
      "6977 Traning Loss: tensor(0.0786)\n",
      "6978 Traning Loss: tensor(0.0791)\n",
      "6979 Traning Loss: tensor(0.0782)\n",
      "6980 Traning Loss: tensor(0.0775)\n",
      "6981 Traning Loss: tensor(0.0785)\n",
      "6982 Traning Loss: tensor(0.0781)\n",
      "6983 Traning Loss: tensor(0.0774)\n",
      "6984 Traning Loss: tensor(0.0782)\n",
      "6985 Traning Loss: tensor(0.0781)\n",
      "6986 Traning Loss: tensor(0.0781)\n",
      "6987 Traning Loss: tensor(0.0772)\n",
      "6988 Traning Loss: tensor(0.0784)\n",
      "6989 Traning Loss: tensor(0.0770)\n",
      "6990 Traning Loss: tensor(0.0779)\n",
      "6991 Traning Loss: tensor(0.0780)\n",
      "6992 Traning Loss: tensor(0.0779)\n",
      "6993 Traning Loss: tensor(0.0769)\n",
      "6994 Traning Loss: tensor(0.0786)\n",
      "6995 Traning Loss: tensor(0.0767)\n",
      "6996 Traning Loss: tensor(0.0784)\n",
      "6997 Traning Loss: tensor(0.0777)\n",
      "6998 Traning Loss: tensor(0.0782)\n",
      "6999 Traning Loss: tensor(0.0769)\n",
      "7000 Traning Loss: tensor(0.0781)\n",
      "7001 Traning Loss: tensor(0.0774)\n",
      "7002 Traning Loss: tensor(0.0773)\n",
      "7003 Traning Loss: tensor(0.0786)\n",
      "7004 Traning Loss: tensor(0.0769)\n",
      "7005 Traning Loss: tensor(0.0779)\n",
      "7006 Traning Loss: tensor(0.0776)\n",
      "7007 Traning Loss: tensor(0.0786)\n",
      "7008 Traning Loss: tensor(0.0772)\n",
      "7009 Traning Loss: tensor(0.0779)\n",
      "7010 Traning Loss: tensor(0.0770)\n",
      "7011 Traning Loss: tensor(0.0778)\n",
      "7012 Traning Loss: tensor(0.0772)\n",
      "7013 Traning Loss: tensor(0.0773)\n",
      "7014 Traning Loss: tensor(0.0777)\n",
      "7015 Traning Loss: tensor(0.0788)\n",
      "7016 Traning Loss: tensor(0.0784)\n",
      "7017 Traning Loss: tensor(0.0785)\n",
      "7018 Traning Loss: tensor(0.0776)\n",
      "7019 Traning Loss: tensor(0.0779)\n",
      "7020 Traning Loss: tensor(0.0780)\n",
      "7021 Traning Loss: tensor(0.0769)\n",
      "7022 Traning Loss: tensor(0.0776)\n",
      "7023 Traning Loss: tensor(0.0779)\n",
      "7024 Traning Loss: tensor(0.0788)\n",
      "7025 Traning Loss: tensor(0.0778)\n",
      "7026 Traning Loss: tensor(0.0782)\n",
      "7027 Traning Loss: tensor(0.0778)\n",
      "7028 Traning Loss: tensor(0.0779)\n",
      "7029 Traning Loss: tensor(0.0779)\n",
      "7030 Traning Loss: tensor(0.0766)\n",
      "7031 Traning Loss: tensor(0.0779)\n",
      "7032 Traning Loss: tensor(0.0766)\n",
      "7033 Traning Loss: tensor(0.0780)\n",
      "7034 Traning Loss: tensor(0.0771)\n",
      "7035 Traning Loss: tensor(0.0778)\n",
      "7036 Traning Loss: tensor(0.0779)\n",
      "7037 Traning Loss: tensor(0.0785)\n",
      "7038 Traning Loss: tensor(0.0775)\n",
      "7039 Traning Loss: tensor(0.0781)\n",
      "7040 Traning Loss: tensor(0.0778)\n",
      "7041 Traning Loss: tensor(0.0779)\n",
      "7042 Traning Loss: tensor(0.0783)\n",
      "7043 Traning Loss: tensor(0.0765)\n",
      "7044 Traning Loss: tensor(0.0778)\n",
      "7045 Traning Loss: tensor(0.0774)\n",
      "7046 Traning Loss: tensor(0.0776)\n",
      "7047 Traning Loss: tensor(0.0777)\n",
      "7048 Traning Loss: tensor(0.0773)\n",
      "7049 Traning Loss: tensor(0.0768)\n",
      "7050 Traning Loss: tensor(0.0768)\n",
      "7051 Traning Loss: tensor(0.0778)\n",
      "7052 Traning Loss: tensor(0.0785)\n",
      "7053 Traning Loss: tensor(0.0778)\n",
      "7054 Traning Loss: tensor(0.0768)\n",
      "7055 Traning Loss: tensor(0.0770)\n",
      "7056 Traning Loss: tensor(0.0773)\n",
      "7057 Traning Loss: tensor(0.0771)\n",
      "7058 Traning Loss: tensor(0.0775)\n",
      "7059 Traning Loss: tensor(0.0779)\n",
      "7060 Traning Loss: tensor(0.0771)\n",
      "7061 Traning Loss: tensor(0.0772)\n",
      "7062 Traning Loss: tensor(0.0787)\n",
      "7063 Traning Loss: tensor(0.0773)\n",
      "7064 Traning Loss: tensor(0.0772)\n",
      "7065 Traning Loss: tensor(0.0779)\n",
      "7066 Traning Loss: tensor(0.0777)\n",
      "7067 Traning Loss: tensor(0.0778)\n",
      "7068 Traning Loss: tensor(0.0778)\n",
      "7069 Traning Loss: tensor(0.0782)\n",
      "7070 Traning Loss: tensor(0.0778)\n",
      "7071 Traning Loss: tensor(0.0765)\n",
      "7072 Traning Loss: tensor(0.0781)\n",
      "7073 Traning Loss: tensor(0.0779)\n",
      "7074 Traning Loss: tensor(0.0775)\n",
      "7075 Traning Loss: tensor(0.0786)\n",
      "7076 Traning Loss: tensor(0.0780)\n",
      "7077 Traning Loss: tensor(0.0775)\n",
      "7078 Traning Loss: tensor(0.0783)\n",
      "7079 Traning Loss: tensor(0.0775)\n",
      "7080 Traning Loss: tensor(0.0774)\n",
      "7081 Traning Loss: tensor(0.0773)\n",
      "7082 Traning Loss: tensor(0.0773)\n",
      "7083 Traning Loss: tensor(0.0770)\n",
      "7084 Traning Loss: tensor(0.0767)\n",
      "7085 Traning Loss: tensor(0.0770)\n",
      "7086 Traning Loss: tensor(0.0785)\n",
      "7087 Traning Loss: tensor(0.0789)\n",
      "7088 Traning Loss: tensor(0.0772)\n",
      "7089 Traning Loss: tensor(0.0782)\n",
      "7090 Traning Loss: tensor(0.0779)\n",
      "7091 Traning Loss: tensor(0.0776)\n",
      "7092 Traning Loss: tensor(0.0777)\n",
      "7093 Traning Loss: tensor(0.0776)\n",
      "7094 Traning Loss: tensor(0.0767)\n",
      "7095 Traning Loss: tensor(0.0768)\n",
      "7096 Traning Loss: tensor(0.0776)\n",
      "7097 Traning Loss: tensor(0.0773)\n",
      "7098 Traning Loss: tensor(0.0773)\n",
      "7099 Traning Loss: tensor(0.0767)\n",
      "7100 Traning Loss: tensor(0.0777)\n",
      "7101 Traning Loss: tensor(0.0767)\n",
      "7102 Traning Loss: tensor(0.0779)\n",
      "7103 Traning Loss: tensor(0.0772)\n",
      "7104 Traning Loss: tensor(0.0766)\n",
      "7105 Traning Loss: tensor(0.0776)\n",
      "7106 Traning Loss: tensor(0.0782)\n",
      "7107 Traning Loss: tensor(0.0767)\n",
      "7108 Traning Loss: tensor(0.0778)\n",
      "7109 Traning Loss: tensor(0.0772)\n",
      "7110 Traning Loss: tensor(0.0769)\n",
      "7111 Traning Loss: tensor(0.0778)\n",
      "7112 Traning Loss: tensor(0.0770)\n",
      "7113 Traning Loss: tensor(0.0763)\n",
      "7114 Traning Loss: tensor(0.0767)\n",
      "7115 Traning Loss: tensor(0.0759)\n",
      "7116 Traning Loss: tensor(0.0775)\n",
      "7117 Traning Loss: tensor(0.0765)\n",
      "7118 Traning Loss: tensor(0.0763)\n",
      "7119 Traning Loss: tensor(0.0764)\n",
      "7120 Traning Loss: tensor(0.0767)\n",
      "7121 Traning Loss: tensor(0.0777)\n",
      "7122 Traning Loss: tensor(0.0779)\n",
      "7123 Traning Loss: tensor(0.0765)\n",
      "7124 Traning Loss: tensor(0.0774)\n",
      "7125 Traning Loss: tensor(0.0769)\n",
      "7126 Traning Loss: tensor(0.0776)\n",
      "7127 Traning Loss: tensor(0.0770)\n",
      "7128 Traning Loss: tensor(0.0777)\n",
      "7129 Traning Loss: tensor(0.0777)\n",
      "7130 Traning Loss: tensor(0.0778)\n",
      "7131 Traning Loss: tensor(0.0776)\n",
      "7132 Traning Loss: tensor(0.0774)\n",
      "7133 Traning Loss: tensor(0.0775)\n",
      "7134 Traning Loss: tensor(0.0767)\n",
      "7135 Traning Loss: tensor(0.0778)\n",
      "7136 Traning Loss: tensor(0.0777)\n",
      "7137 Traning Loss: tensor(0.0779)\n",
      "7138 Traning Loss: tensor(0.0777)\n",
      "7139 Traning Loss: tensor(0.0777)\n",
      "7140 Traning Loss: tensor(0.0775)\n",
      "7141 Traning Loss: tensor(0.0772)\n",
      "7142 Traning Loss: tensor(0.0769)\n",
      "7143 Traning Loss: tensor(0.0779)\n",
      "7144 Traning Loss: tensor(0.0776)\n",
      "7145 Traning Loss: tensor(0.0778)\n",
      "7146 Traning Loss: tensor(0.0781)\n",
      "7147 Traning Loss: tensor(0.0772)\n",
      "7148 Traning Loss: tensor(0.0771)\n",
      "7149 Traning Loss: tensor(0.0769)\n",
      "7150 Traning Loss: tensor(0.0762)\n",
      "7151 Traning Loss: tensor(0.0774)\n",
      "7152 Traning Loss: tensor(0.0771)\n",
      "7153 Traning Loss: tensor(0.0777)\n",
      "7154 Traning Loss: tensor(0.0774)\n",
      "7155 Traning Loss: tensor(0.0778)\n",
      "7156 Traning Loss: tensor(0.0775)\n",
      "7157 Traning Loss: tensor(0.0764)\n",
      "7158 Traning Loss: tensor(0.0778)\n",
      "7159 Traning Loss: tensor(0.0769)\n",
      "7160 Traning Loss: tensor(0.0777)\n",
      "7161 Traning Loss: tensor(0.0775)\n",
      "7162 Traning Loss: tensor(0.0773)\n",
      "7163 Traning Loss: tensor(0.0772)\n",
      "7164 Traning Loss: tensor(0.0782)\n",
      "7165 Traning Loss: tensor(0.0774)\n",
      "7166 Traning Loss: tensor(0.0781)\n",
      "7167 Traning Loss: tensor(0.0774)\n",
      "7168 Traning Loss: tensor(0.0767)\n",
      "7169 Traning Loss: tensor(0.0773)\n",
      "7170 Traning Loss: tensor(0.0770)\n",
      "7171 Traning Loss: tensor(0.0767)\n",
      "7172 Traning Loss: tensor(0.0775)\n",
      "7173 Traning Loss: tensor(0.0768)\n",
      "7174 Traning Loss: tensor(0.0769)\n",
      "7175 Traning Loss: tensor(0.0780)\n",
      "7176 Traning Loss: tensor(0.0776)\n",
      "7177 Traning Loss: tensor(0.0788)\n",
      "7178 Traning Loss: tensor(0.0783)\n",
      "7179 Traning Loss: tensor(0.0772)\n",
      "7180 Traning Loss: tensor(0.0761)\n",
      "7181 Traning Loss: tensor(0.0771)\n",
      "7182 Traning Loss: tensor(0.0772)\n",
      "7183 Traning Loss: tensor(0.0760)\n",
      "7184 Traning Loss: tensor(0.0767)\n",
      "7185 Traning Loss: tensor(0.0769)\n",
      "7186 Traning Loss: tensor(0.0776)\n",
      "7187 Traning Loss: tensor(0.0772)\n",
      "7188 Traning Loss: tensor(0.0773)\n",
      "7189 Traning Loss: tensor(0.0757)\n",
      "7190 Traning Loss: tensor(0.0778)\n",
      "7191 Traning Loss: tensor(0.0763)\n",
      "7192 Traning Loss: tensor(0.0770)\n",
      "7193 Traning Loss: tensor(0.0769)\n",
      "7194 Traning Loss: tensor(0.0765)\n",
      "7195 Traning Loss: tensor(0.0777)\n",
      "7196 Traning Loss: tensor(0.0777)\n",
      "7197 Traning Loss: tensor(0.0761)\n",
      "7198 Traning Loss: tensor(0.0769)\n",
      "7199 Traning Loss: tensor(0.0767)\n",
      "7200 Traning Loss: tensor(0.0786)\n",
      "7201 Traning Loss: tensor(0.0763)\n",
      "7202 Traning Loss: tensor(0.0769)\n",
      "7203 Traning Loss: tensor(0.0770)\n",
      "7204 Traning Loss: tensor(0.0775)\n",
      "7205 Traning Loss: tensor(0.0763)\n",
      "7206 Traning Loss: tensor(0.0772)\n",
      "7207 Traning Loss: tensor(0.0768)\n",
      "7208 Traning Loss: tensor(0.0768)\n",
      "7209 Traning Loss: tensor(0.0770)\n",
      "7210 Traning Loss: tensor(0.0775)\n",
      "7211 Traning Loss: tensor(0.0765)\n",
      "7212 Traning Loss: tensor(0.0775)\n",
      "7213 Traning Loss: tensor(0.0771)\n",
      "7214 Traning Loss: tensor(0.0775)\n",
      "7215 Traning Loss: tensor(0.0765)\n",
      "7216 Traning Loss: tensor(0.0775)\n",
      "7217 Traning Loss: tensor(0.0771)\n",
      "7218 Traning Loss: tensor(0.0779)\n",
      "7219 Traning Loss: tensor(0.0776)\n",
      "7220 Traning Loss: tensor(0.0774)\n",
      "7221 Traning Loss: tensor(0.0770)\n",
      "7222 Traning Loss: tensor(0.0770)\n",
      "7223 Traning Loss: tensor(0.0768)\n",
      "7224 Traning Loss: tensor(0.0775)\n",
      "7225 Traning Loss: tensor(0.0769)\n",
      "7226 Traning Loss: tensor(0.0778)\n",
      "7227 Traning Loss: tensor(0.0766)\n",
      "7228 Traning Loss: tensor(0.0769)\n",
      "7229 Traning Loss: tensor(0.0775)\n",
      "7230 Traning Loss: tensor(0.0768)\n",
      "7231 Traning Loss: tensor(0.0767)\n",
      "7232 Traning Loss: tensor(0.0769)\n",
      "7233 Traning Loss: tensor(0.0778)\n",
      "7234 Traning Loss: tensor(0.0777)\n",
      "7235 Traning Loss: tensor(0.0767)\n",
      "7236 Traning Loss: tensor(0.0774)\n",
      "7237 Traning Loss: tensor(0.0772)\n",
      "7238 Traning Loss: tensor(0.0772)\n",
      "7239 Traning Loss: tensor(0.0772)\n",
      "7240 Traning Loss: tensor(0.0766)\n",
      "7241 Traning Loss: tensor(0.0773)\n",
      "7242 Traning Loss: tensor(0.0762)\n",
      "7243 Traning Loss: tensor(0.0774)\n",
      "7244 Traning Loss: tensor(0.0767)\n",
      "7245 Traning Loss: tensor(0.0776)\n",
      "7246 Traning Loss: tensor(0.0776)\n",
      "7247 Traning Loss: tensor(0.0763)\n",
      "7248 Traning Loss: tensor(0.0771)\n",
      "7249 Traning Loss: tensor(0.0764)\n",
      "7250 Traning Loss: tensor(0.0764)\n",
      "7251 Traning Loss: tensor(0.0767)\n",
      "7252 Traning Loss: tensor(0.0781)\n",
      "7253 Traning Loss: tensor(0.0775)\n",
      "7254 Traning Loss: tensor(0.0769)\n",
      "7255 Traning Loss: tensor(0.0771)\n",
      "7256 Traning Loss: tensor(0.0777)\n",
      "7257 Traning Loss: tensor(0.0769)\n",
      "7258 Traning Loss: tensor(0.0764)\n",
      "7259 Traning Loss: tensor(0.0766)\n",
      "7260 Traning Loss: tensor(0.0767)\n",
      "7261 Traning Loss: tensor(0.0759)\n",
      "7262 Traning Loss: tensor(0.0763)\n",
      "7263 Traning Loss: tensor(0.0763)\n",
      "7264 Traning Loss: tensor(0.0762)\n",
      "7265 Traning Loss: tensor(0.0764)\n",
      "7266 Traning Loss: tensor(0.0761)\n",
      "7267 Traning Loss: tensor(0.0769)\n",
      "7268 Traning Loss: tensor(0.0757)\n",
      "7269 Traning Loss: tensor(0.0765)\n",
      "7270 Traning Loss: tensor(0.0778)\n",
      "7271 Traning Loss: tensor(0.0771)\n",
      "7272 Traning Loss: tensor(0.0762)\n",
      "7273 Traning Loss: tensor(0.0765)\n",
      "7274 Traning Loss: tensor(0.0775)\n",
      "7275 Traning Loss: tensor(0.0763)\n",
      "7276 Traning Loss: tensor(0.0762)\n",
      "7277 Traning Loss: tensor(0.0762)\n",
      "7278 Traning Loss: tensor(0.0764)\n",
      "7279 Traning Loss: tensor(0.0770)\n",
      "7280 Traning Loss: tensor(0.0758)\n",
      "7281 Traning Loss: tensor(0.0766)\n",
      "7282 Traning Loss: tensor(0.0772)\n",
      "7283 Traning Loss: tensor(0.0768)\n",
      "7284 Traning Loss: tensor(0.0767)\n",
      "7285 Traning Loss: tensor(0.0768)\n",
      "7286 Traning Loss: tensor(0.0773)\n",
      "7287 Traning Loss: tensor(0.0773)\n",
      "7288 Traning Loss: tensor(0.0771)\n",
      "7289 Traning Loss: tensor(0.0763)\n",
      "7290 Traning Loss: tensor(0.0767)\n",
      "7291 Traning Loss: tensor(0.0768)\n",
      "7292 Traning Loss: tensor(0.0774)\n",
      "7293 Traning Loss: tensor(0.0771)\n",
      "7294 Traning Loss: tensor(0.0770)\n",
      "7295 Traning Loss: tensor(0.0773)\n",
      "7296 Traning Loss: tensor(0.0769)\n",
      "7297 Traning Loss: tensor(0.0784)\n",
      "7298 Traning Loss: tensor(0.0773)\n",
      "7299 Traning Loss: tensor(0.0764)\n",
      "7300 Traning Loss: tensor(0.0763)\n",
      "7301 Traning Loss: tensor(0.0768)\n",
      "7302 Traning Loss: tensor(0.0771)\n",
      "7303 Traning Loss: tensor(0.0762)\n",
      "7304 Traning Loss: tensor(0.0774)\n",
      "7305 Traning Loss: tensor(0.0770)\n",
      "7306 Traning Loss: tensor(0.0763)\n",
      "7307 Traning Loss: tensor(0.0777)\n",
      "7308 Traning Loss: tensor(0.0764)\n",
      "7309 Traning Loss: tensor(0.0771)\n",
      "7310 Traning Loss: tensor(0.0768)\n",
      "7311 Traning Loss: tensor(0.0770)\n",
      "7312 Traning Loss: tensor(0.0764)\n",
      "7313 Traning Loss: tensor(0.0771)\n",
      "7314 Traning Loss: tensor(0.0771)\n",
      "7315 Traning Loss: tensor(0.0770)\n",
      "7316 Traning Loss: tensor(0.0768)\n",
      "7317 Traning Loss: tensor(0.0763)\n",
      "7318 Traning Loss: tensor(0.0765)\n",
      "7319 Traning Loss: tensor(0.0782)\n",
      "7320 Traning Loss: tensor(0.0762)\n",
      "7321 Traning Loss: tensor(0.0762)\n",
      "7322 Traning Loss: tensor(0.0759)\n",
      "7323 Traning Loss: tensor(0.0766)\n",
      "7324 Traning Loss: tensor(0.0769)\n",
      "7325 Traning Loss: tensor(0.0752)\n",
      "7326 Traning Loss: tensor(0.0770)\n",
      "7327 Traning Loss: tensor(0.0757)\n",
      "7328 Traning Loss: tensor(0.0767)\n",
      "7329 Traning Loss: tensor(0.0769)\n",
      "7330 Traning Loss: tensor(0.0764)\n",
      "7331 Traning Loss: tensor(0.0757)\n",
      "7332 Traning Loss: tensor(0.0767)\n",
      "7333 Traning Loss: tensor(0.0762)\n",
      "7334 Traning Loss: tensor(0.0770)\n",
      "7335 Traning Loss: tensor(0.0756)\n",
      "7336 Traning Loss: tensor(0.0764)\n",
      "7337 Traning Loss: tensor(0.0758)\n",
      "7338 Traning Loss: tensor(0.0769)\n",
      "7339 Traning Loss: tensor(0.0767)\n",
      "7340 Traning Loss: tensor(0.0765)\n",
      "7341 Traning Loss: tensor(0.0771)\n",
      "7342 Traning Loss: tensor(0.0769)\n",
      "7343 Traning Loss: tensor(0.0758)\n",
      "7344 Traning Loss: tensor(0.0766)\n",
      "7345 Traning Loss: tensor(0.0768)\n",
      "7346 Traning Loss: tensor(0.0770)\n",
      "7347 Traning Loss: tensor(0.0760)\n",
      "7348 Traning Loss: tensor(0.0760)\n",
      "7349 Traning Loss: tensor(0.0770)\n",
      "7350 Traning Loss: tensor(0.0763)\n",
      "7351 Traning Loss: tensor(0.0762)\n",
      "7352 Traning Loss: tensor(0.0762)\n",
      "7353 Traning Loss: tensor(0.0769)\n",
      "7354 Traning Loss: tensor(0.0770)\n",
      "7355 Traning Loss: tensor(0.0764)\n",
      "7356 Traning Loss: tensor(0.0757)\n",
      "7357 Traning Loss: tensor(0.0768)\n",
      "7358 Traning Loss: tensor(0.0764)\n",
      "7359 Traning Loss: tensor(0.0768)\n",
      "7360 Traning Loss: tensor(0.0761)\n",
      "7361 Traning Loss: tensor(0.0772)\n",
      "7362 Traning Loss: tensor(0.0759)\n",
      "7363 Traning Loss: tensor(0.0772)\n",
      "7364 Traning Loss: tensor(0.0773)\n",
      "7365 Traning Loss: tensor(0.0750)\n",
      "7366 Traning Loss: tensor(0.0762)\n",
      "7367 Traning Loss: tensor(0.0756)\n",
      "7368 Traning Loss: tensor(0.0766)\n",
      "7369 Traning Loss: tensor(0.0761)\n",
      "7370 Traning Loss: tensor(0.0771)\n",
      "7371 Traning Loss: tensor(0.0762)\n",
      "7372 Traning Loss: tensor(0.0757)\n",
      "7373 Traning Loss: tensor(0.0765)\n",
      "7374 Traning Loss: tensor(0.0764)\n",
      "7375 Traning Loss: tensor(0.0759)\n",
      "7376 Traning Loss: tensor(0.0770)\n",
      "7377 Traning Loss: tensor(0.0774)\n",
      "7378 Traning Loss: tensor(0.0771)\n",
      "7379 Traning Loss: tensor(0.0762)\n",
      "7380 Traning Loss: tensor(0.0752)\n",
      "7381 Traning Loss: tensor(0.0770)\n",
      "7382 Traning Loss: tensor(0.0764)\n",
      "7383 Traning Loss: tensor(0.0763)\n",
      "7384 Traning Loss: tensor(0.0776)\n",
      "7385 Traning Loss: tensor(0.0765)\n",
      "7386 Traning Loss: tensor(0.0763)\n",
      "7387 Traning Loss: tensor(0.0758)\n",
      "7388 Traning Loss: tensor(0.0767)\n",
      "7389 Traning Loss: tensor(0.0760)\n",
      "7390 Traning Loss: tensor(0.0764)\n",
      "7391 Traning Loss: tensor(0.0769)\n",
      "7392 Traning Loss: tensor(0.0751)\n",
      "7393 Traning Loss: tensor(0.0767)\n",
      "7394 Traning Loss: tensor(0.0748)\n",
      "7395 Traning Loss: tensor(0.0760)\n",
      "7396 Traning Loss: tensor(0.0770)\n",
      "7397 Traning Loss: tensor(0.0759)\n",
      "7398 Traning Loss: tensor(0.0762)\n",
      "7399 Traning Loss: tensor(0.0764)\n",
      "7400 Traning Loss: tensor(0.0768)\n",
      "7401 Traning Loss: tensor(0.0762)\n",
      "7402 Traning Loss: tensor(0.0769)\n",
      "7403 Traning Loss: tensor(0.0773)\n",
      "7404 Traning Loss: tensor(0.0767)\n",
      "7405 Traning Loss: tensor(0.0752)\n",
      "7406 Traning Loss: tensor(0.0767)\n",
      "7407 Traning Loss: tensor(0.0770)\n",
      "7408 Traning Loss: tensor(0.0762)\n",
      "7409 Traning Loss: tensor(0.0761)\n",
      "7410 Traning Loss: tensor(0.0769)\n",
      "7411 Traning Loss: tensor(0.0764)\n",
      "7412 Traning Loss: tensor(0.0754)\n",
      "7413 Traning Loss: tensor(0.0755)\n",
      "7414 Traning Loss: tensor(0.0757)\n",
      "7415 Traning Loss: tensor(0.0764)\n",
      "7416 Traning Loss: tensor(0.0759)\n",
      "7417 Traning Loss: tensor(0.0764)\n",
      "7418 Traning Loss: tensor(0.0761)\n",
      "7419 Traning Loss: tensor(0.0763)\n",
      "7420 Traning Loss: tensor(0.0753)\n",
      "7421 Traning Loss: tensor(0.0760)\n",
      "7422 Traning Loss: tensor(0.0764)\n",
      "7423 Traning Loss: tensor(0.0763)\n",
      "7424 Traning Loss: tensor(0.0753)\n",
      "7425 Traning Loss: tensor(0.0745)\n",
      "7426 Traning Loss: tensor(0.0764)\n",
      "7427 Traning Loss: tensor(0.0750)\n",
      "7428 Traning Loss: tensor(0.0775)\n",
      "7429 Traning Loss: tensor(0.0765)\n",
      "7430 Traning Loss: tensor(0.0767)\n",
      "7431 Traning Loss: tensor(0.0759)\n",
      "7432 Traning Loss: tensor(0.0754)\n",
      "7433 Traning Loss: tensor(0.0765)\n",
      "7434 Traning Loss: tensor(0.0769)\n",
      "7435 Traning Loss: tensor(0.0762)\n",
      "7436 Traning Loss: tensor(0.0763)\n",
      "7437 Traning Loss: tensor(0.0756)\n",
      "7438 Traning Loss: tensor(0.0768)\n",
      "7439 Traning Loss: tensor(0.0763)\n",
      "7440 Traning Loss: tensor(0.0763)\n",
      "7441 Traning Loss: tensor(0.0770)\n",
      "7442 Traning Loss: tensor(0.0754)\n",
      "7443 Traning Loss: tensor(0.0759)\n",
      "7444 Traning Loss: tensor(0.0758)\n",
      "7445 Traning Loss: tensor(0.0765)\n",
      "7446 Traning Loss: tensor(0.0757)\n",
      "7447 Traning Loss: tensor(0.0766)\n",
      "7448 Traning Loss: tensor(0.0758)\n",
      "7449 Traning Loss: tensor(0.0758)\n",
      "7450 Traning Loss: tensor(0.0772)\n",
      "7451 Traning Loss: tensor(0.0762)\n",
      "7452 Traning Loss: tensor(0.0760)\n",
      "7453 Traning Loss: tensor(0.0754)\n",
      "7454 Traning Loss: tensor(0.0768)\n",
      "7455 Traning Loss: tensor(0.0763)\n",
      "7456 Traning Loss: tensor(0.0760)\n",
      "7457 Traning Loss: tensor(0.0763)\n",
      "7458 Traning Loss: tensor(0.0751)\n",
      "7459 Traning Loss: tensor(0.0754)\n",
      "7460 Traning Loss: tensor(0.0754)\n",
      "7461 Traning Loss: tensor(0.0756)\n",
      "7462 Traning Loss: tensor(0.0769)\n",
      "7463 Traning Loss: tensor(0.0773)\n",
      "7464 Traning Loss: tensor(0.0763)\n",
      "7465 Traning Loss: tensor(0.0757)\n",
      "7466 Traning Loss: tensor(0.0759)\n",
      "7467 Traning Loss: tensor(0.0768)\n",
      "7468 Traning Loss: tensor(0.0757)\n",
      "7469 Traning Loss: tensor(0.0754)\n",
      "7470 Traning Loss: tensor(0.0767)\n",
      "7471 Traning Loss: tensor(0.0755)\n",
      "7472 Traning Loss: tensor(0.0756)\n",
      "7473 Traning Loss: tensor(0.0758)\n",
      "7474 Traning Loss: tensor(0.0762)\n",
      "7475 Traning Loss: tensor(0.0760)\n",
      "7476 Traning Loss: tensor(0.0762)\n",
      "7477 Traning Loss: tensor(0.0762)\n",
      "7478 Traning Loss: tensor(0.0761)\n",
      "7479 Traning Loss: tensor(0.0761)\n",
      "7480 Traning Loss: tensor(0.0756)\n",
      "7481 Traning Loss: tensor(0.0767)\n",
      "7482 Traning Loss: tensor(0.0758)\n",
      "7483 Traning Loss: tensor(0.0762)\n",
      "7484 Traning Loss: tensor(0.0761)\n",
      "7485 Traning Loss: tensor(0.0761)\n",
      "7486 Traning Loss: tensor(0.0761)\n",
      "7487 Traning Loss: tensor(0.0762)\n",
      "7488 Traning Loss: tensor(0.0754)\n",
      "7489 Traning Loss: tensor(0.0760)\n",
      "7490 Traning Loss: tensor(0.0762)\n",
      "7491 Traning Loss: tensor(0.0752)\n",
      "7492 Traning Loss: tensor(0.0770)\n",
      "7493 Traning Loss: tensor(0.0758)\n",
      "7494 Traning Loss: tensor(0.0753)\n",
      "7495 Traning Loss: tensor(0.0761)\n",
      "7496 Traning Loss: tensor(0.0765)\n",
      "7497 Traning Loss: tensor(0.0767)\n",
      "7498 Traning Loss: tensor(0.0753)\n",
      "7499 Traning Loss: tensor(0.0757)\n",
      "7500 Traning Loss: tensor(0.0753)\n",
      "7501 Traning Loss: tensor(0.0764)\n",
      "7502 Traning Loss: tensor(0.0760)\n",
      "7503 Traning Loss: tensor(0.0762)\n",
      "7504 Traning Loss: tensor(0.0763)\n",
      "7505 Traning Loss: tensor(0.0756)\n",
      "7506 Traning Loss: tensor(0.0759)\n",
      "7507 Traning Loss: tensor(0.0764)\n",
      "7508 Traning Loss: tensor(0.0755)\n",
      "7509 Traning Loss: tensor(0.0768)\n",
      "7510 Traning Loss: tensor(0.0755)\n",
      "7511 Traning Loss: tensor(0.0765)\n",
      "7512 Traning Loss: tensor(0.0758)\n",
      "7513 Traning Loss: tensor(0.0770)\n",
      "7514 Traning Loss: tensor(0.0750)\n",
      "7515 Traning Loss: tensor(0.0754)\n",
      "7516 Traning Loss: tensor(0.0756)\n",
      "7517 Traning Loss: tensor(0.0757)\n",
      "7518 Traning Loss: tensor(0.0759)\n",
      "7519 Traning Loss: tensor(0.0764)\n",
      "7520 Traning Loss: tensor(0.0767)\n",
      "7521 Traning Loss: tensor(0.0752)\n",
      "7522 Traning Loss: tensor(0.0755)\n",
      "7523 Traning Loss: tensor(0.0753)\n",
      "7524 Traning Loss: tensor(0.0755)\n",
      "7525 Traning Loss: tensor(0.0753)\n",
      "7526 Traning Loss: tensor(0.0763)\n",
      "7527 Traning Loss: tensor(0.0757)\n",
      "7528 Traning Loss: tensor(0.0766)\n",
      "7529 Traning Loss: tensor(0.0762)\n",
      "7530 Traning Loss: tensor(0.0753)\n",
      "7531 Traning Loss: tensor(0.0757)\n",
      "7532 Traning Loss: tensor(0.0763)\n",
      "7533 Traning Loss: tensor(0.0758)\n",
      "7534 Traning Loss: tensor(0.0754)\n",
      "7535 Traning Loss: tensor(0.0756)\n",
      "7536 Traning Loss: tensor(0.0763)\n",
      "7537 Traning Loss: tensor(0.0761)\n",
      "7538 Traning Loss: tensor(0.0758)\n",
      "7539 Traning Loss: tensor(0.0755)\n",
      "7540 Traning Loss: tensor(0.0759)\n",
      "7541 Traning Loss: tensor(0.0766)\n",
      "7542 Traning Loss: tensor(0.0758)\n",
      "7543 Traning Loss: tensor(0.0770)\n",
      "7544 Traning Loss: tensor(0.0759)\n",
      "7545 Traning Loss: tensor(0.0753)\n",
      "7546 Traning Loss: tensor(0.0757)\n",
      "7547 Traning Loss: tensor(0.0759)\n",
      "7548 Traning Loss: tensor(0.0752)\n",
      "7549 Traning Loss: tensor(0.0753)\n",
      "7550 Traning Loss: tensor(0.0756)\n",
      "7551 Traning Loss: tensor(0.0760)\n",
      "7552 Traning Loss: tensor(0.0756)\n",
      "7553 Traning Loss: tensor(0.0760)\n",
      "7554 Traning Loss: tensor(0.0765)\n",
      "7555 Traning Loss: tensor(0.0765)\n",
      "7556 Traning Loss: tensor(0.0753)\n",
      "7557 Traning Loss: tensor(0.0764)\n",
      "7558 Traning Loss: tensor(0.0758)\n",
      "7559 Traning Loss: tensor(0.0750)\n",
      "7560 Traning Loss: tensor(0.0769)\n",
      "7561 Traning Loss: tensor(0.0763)\n",
      "7562 Traning Loss: tensor(0.0748)\n",
      "7563 Traning Loss: tensor(0.0755)\n",
      "7564 Traning Loss: tensor(0.0748)\n",
      "7565 Traning Loss: tensor(0.0759)\n",
      "7566 Traning Loss: tensor(0.0750)\n",
      "7567 Traning Loss: tensor(0.0760)\n",
      "7568 Traning Loss: tensor(0.0766)\n",
      "7569 Traning Loss: tensor(0.0746)\n",
      "7570 Traning Loss: tensor(0.0765)\n",
      "7571 Traning Loss: tensor(0.0760)\n",
      "7572 Traning Loss: tensor(0.0751)\n",
      "7573 Traning Loss: tensor(0.0759)\n",
      "7574 Traning Loss: tensor(0.0752)\n",
      "7575 Traning Loss: tensor(0.0754)\n",
      "7576 Traning Loss: tensor(0.0759)\n",
      "7577 Traning Loss: tensor(0.0753)\n",
      "7578 Traning Loss: tensor(0.0763)\n",
      "7579 Traning Loss: tensor(0.0763)\n",
      "7580 Traning Loss: tensor(0.0762)\n",
      "7581 Traning Loss: tensor(0.0750)\n",
      "7582 Traning Loss: tensor(0.0760)\n",
      "7583 Traning Loss: tensor(0.0760)\n",
      "7584 Traning Loss: tensor(0.0751)\n",
      "7585 Traning Loss: tensor(0.0757)\n",
      "7586 Traning Loss: tensor(0.0765)\n",
      "7587 Traning Loss: tensor(0.0756)\n",
      "7588 Traning Loss: tensor(0.0761)\n",
      "7589 Traning Loss: tensor(0.0753)\n",
      "7590 Traning Loss: tensor(0.0762)\n",
      "7591 Traning Loss: tensor(0.0753)\n",
      "7592 Traning Loss: tensor(0.0749)\n",
      "7593 Traning Loss: tensor(0.0753)\n",
      "7594 Traning Loss: tensor(0.0759)\n",
      "7595 Traning Loss: tensor(0.0760)\n",
      "7596 Traning Loss: tensor(0.0762)\n",
      "7597 Traning Loss: tensor(0.0746)\n",
      "7598 Traning Loss: tensor(0.0752)\n",
      "7599 Traning Loss: tensor(0.0751)\n",
      "7600 Traning Loss: tensor(0.0773)\n",
      "7601 Traning Loss: tensor(0.0753)\n",
      "7602 Traning Loss: tensor(0.0767)\n",
      "7603 Traning Loss: tensor(0.0753)\n",
      "7604 Traning Loss: tensor(0.0757)\n",
      "7605 Traning Loss: tensor(0.0759)\n",
      "7606 Traning Loss: tensor(0.0746)\n",
      "7607 Traning Loss: tensor(0.0760)\n",
      "7608 Traning Loss: tensor(0.0757)\n",
      "7609 Traning Loss: tensor(0.0760)\n",
      "7610 Traning Loss: tensor(0.0754)\n",
      "7611 Traning Loss: tensor(0.0754)\n",
      "7612 Traning Loss: tensor(0.0748)\n",
      "7613 Traning Loss: tensor(0.0750)\n",
      "7614 Traning Loss: tensor(0.0758)\n",
      "7615 Traning Loss: tensor(0.0753)\n",
      "7616 Traning Loss: tensor(0.0768)\n",
      "7617 Traning Loss: tensor(0.0763)\n",
      "7618 Traning Loss: tensor(0.0754)\n",
      "7619 Traning Loss: tensor(0.0758)\n",
      "7620 Traning Loss: tensor(0.0763)\n",
      "7621 Traning Loss: tensor(0.0755)\n",
      "7622 Traning Loss: tensor(0.0761)\n",
      "7623 Traning Loss: tensor(0.0746)\n",
      "7624 Traning Loss: tensor(0.0756)\n",
      "7625 Traning Loss: tensor(0.0747)\n",
      "7626 Traning Loss: tensor(0.0755)\n",
      "7627 Traning Loss: tensor(0.0745)\n",
      "7628 Traning Loss: tensor(0.0761)\n",
      "7629 Traning Loss: tensor(0.0756)\n",
      "7630 Traning Loss: tensor(0.0753)\n",
      "7631 Traning Loss: tensor(0.0747)\n",
      "7632 Traning Loss: tensor(0.0749)\n",
      "7633 Traning Loss: tensor(0.0762)\n",
      "7634 Traning Loss: tensor(0.0761)\n",
      "7635 Traning Loss: tensor(0.0759)\n",
      "7636 Traning Loss: tensor(0.0755)\n",
      "7637 Traning Loss: tensor(0.0752)\n",
      "7638 Traning Loss: tensor(0.0757)\n",
      "7639 Traning Loss: tensor(0.0768)\n",
      "7640 Traning Loss: tensor(0.0759)\n",
      "7641 Traning Loss: tensor(0.0759)\n",
      "7642 Traning Loss: tensor(0.0746)\n",
      "7643 Traning Loss: tensor(0.0751)\n",
      "7644 Traning Loss: tensor(0.0761)\n",
      "7645 Traning Loss: tensor(0.0749)\n",
      "7646 Traning Loss: tensor(0.0752)\n",
      "7647 Traning Loss: tensor(0.0761)\n",
      "7648 Traning Loss: tensor(0.0761)\n",
      "7649 Traning Loss: tensor(0.0753)\n",
      "7650 Traning Loss: tensor(0.0754)\n",
      "7651 Traning Loss: tensor(0.0755)\n",
      "7652 Traning Loss: tensor(0.0759)\n",
      "7653 Traning Loss: tensor(0.0756)\n",
      "7654 Traning Loss: tensor(0.0762)\n",
      "7655 Traning Loss: tensor(0.0766)\n",
      "7656 Traning Loss: tensor(0.0752)\n",
      "7657 Traning Loss: tensor(0.0749)\n",
      "7658 Traning Loss: tensor(0.0754)\n",
      "7659 Traning Loss: tensor(0.0762)\n",
      "7660 Traning Loss: tensor(0.0753)\n",
      "7661 Traning Loss: tensor(0.0747)\n",
      "7662 Traning Loss: tensor(0.0749)\n",
      "7663 Traning Loss: tensor(0.0761)\n",
      "7664 Traning Loss: tensor(0.0741)\n",
      "7665 Traning Loss: tensor(0.0763)\n",
      "7666 Traning Loss: tensor(0.0759)\n",
      "7667 Traning Loss: tensor(0.0756)\n",
      "7668 Traning Loss: tensor(0.0754)\n",
      "7669 Traning Loss: tensor(0.0755)\n",
      "7670 Traning Loss: tensor(0.0763)\n",
      "7671 Traning Loss: tensor(0.0753)\n",
      "7672 Traning Loss: tensor(0.0746)\n",
      "7673 Traning Loss: tensor(0.0754)\n",
      "7674 Traning Loss: tensor(0.0758)\n",
      "7675 Traning Loss: tensor(0.0753)\n",
      "7676 Traning Loss: tensor(0.0748)\n",
      "7677 Traning Loss: tensor(0.0752)\n",
      "7678 Traning Loss: tensor(0.0751)\n",
      "7679 Traning Loss: tensor(0.0754)\n",
      "7680 Traning Loss: tensor(0.0759)\n",
      "7681 Traning Loss: tensor(0.0745)\n",
      "7682 Traning Loss: tensor(0.0748)\n",
      "7683 Traning Loss: tensor(0.0749)\n",
      "7684 Traning Loss: tensor(0.0759)\n",
      "7685 Traning Loss: tensor(0.0754)\n",
      "7686 Traning Loss: tensor(0.0745)\n",
      "7687 Traning Loss: tensor(0.0754)\n",
      "7688 Traning Loss: tensor(0.0748)\n",
      "7689 Traning Loss: tensor(0.0747)\n",
      "7690 Traning Loss: tensor(0.0756)\n",
      "7691 Traning Loss: tensor(0.0757)\n",
      "7692 Traning Loss: tensor(0.0767)\n",
      "7693 Traning Loss: tensor(0.0754)\n",
      "7694 Traning Loss: tensor(0.0753)\n",
      "7695 Traning Loss: tensor(0.0758)\n",
      "7696 Traning Loss: tensor(0.0749)\n",
      "7697 Traning Loss: tensor(0.0756)\n",
      "7698 Traning Loss: tensor(0.0752)\n",
      "7699 Traning Loss: tensor(0.0751)\n",
      "7700 Traning Loss: tensor(0.0753)\n",
      "7701 Traning Loss: tensor(0.0765)\n",
      "7702 Traning Loss: tensor(0.0759)\n",
      "7703 Traning Loss: tensor(0.0749)\n",
      "7704 Traning Loss: tensor(0.0750)\n",
      "7705 Traning Loss: tensor(0.0747)\n",
      "7706 Traning Loss: tensor(0.0763)\n",
      "7707 Traning Loss: tensor(0.0747)\n",
      "7708 Traning Loss: tensor(0.0757)\n",
      "7709 Traning Loss: tensor(0.0753)\n",
      "7710 Traning Loss: tensor(0.0751)\n",
      "7711 Traning Loss: tensor(0.0748)\n",
      "7712 Traning Loss: tensor(0.0758)\n",
      "7713 Traning Loss: tensor(0.0740)\n",
      "7714 Traning Loss: tensor(0.0763)\n",
      "7715 Traning Loss: tensor(0.0761)\n",
      "7716 Traning Loss: tensor(0.0759)\n",
      "7717 Traning Loss: tensor(0.0764)\n",
      "7718 Traning Loss: tensor(0.0754)\n",
      "7719 Traning Loss: tensor(0.0742)\n",
      "7720 Traning Loss: tensor(0.0755)\n",
      "7721 Traning Loss: tensor(0.0748)\n",
      "7722 Traning Loss: tensor(0.0762)\n",
      "7723 Traning Loss: tensor(0.0750)\n",
      "7724 Traning Loss: tensor(0.0763)\n",
      "7725 Traning Loss: tensor(0.0752)\n",
      "7726 Traning Loss: tensor(0.0748)\n",
      "7727 Traning Loss: tensor(0.0747)\n",
      "7728 Traning Loss: tensor(0.0744)\n",
      "7729 Traning Loss: tensor(0.0758)\n",
      "7730 Traning Loss: tensor(0.0755)\n",
      "7731 Traning Loss: tensor(0.0749)\n",
      "7732 Traning Loss: tensor(0.0760)\n",
      "7733 Traning Loss: tensor(0.0747)\n",
      "7734 Traning Loss: tensor(0.0753)\n",
      "7735 Traning Loss: tensor(0.0760)\n",
      "7736 Traning Loss: tensor(0.0760)\n",
      "7737 Traning Loss: tensor(0.0753)\n",
      "7738 Traning Loss: tensor(0.0761)\n",
      "7739 Traning Loss: tensor(0.0764)\n",
      "7740 Traning Loss: tensor(0.0750)\n",
      "7741 Traning Loss: tensor(0.0750)\n",
      "7742 Traning Loss: tensor(0.0752)\n",
      "7743 Traning Loss: tensor(0.0747)\n",
      "7744 Traning Loss: tensor(0.0754)\n",
      "7745 Traning Loss: tensor(0.0747)\n",
      "7746 Traning Loss: tensor(0.0762)\n",
      "7747 Traning Loss: tensor(0.0749)\n",
      "7748 Traning Loss: tensor(0.0746)\n",
      "7749 Traning Loss: tensor(0.0746)\n",
      "7750 Traning Loss: tensor(0.0752)\n",
      "7751 Traning Loss: tensor(0.0748)\n",
      "7752 Traning Loss: tensor(0.0751)\n",
      "7753 Traning Loss: tensor(0.0753)\n",
      "7754 Traning Loss: tensor(0.0746)\n",
      "7755 Traning Loss: tensor(0.0756)\n",
      "7756 Traning Loss: tensor(0.0749)\n",
      "7757 Traning Loss: tensor(0.0747)\n",
      "7758 Traning Loss: tensor(0.0750)\n",
      "7759 Traning Loss: tensor(0.0752)\n",
      "7760 Traning Loss: tensor(0.0750)\n",
      "7761 Traning Loss: tensor(0.0753)\n",
      "7762 Traning Loss: tensor(0.0751)\n",
      "7763 Traning Loss: tensor(0.0747)\n",
      "7764 Traning Loss: tensor(0.0757)\n",
      "7765 Traning Loss: tensor(0.0739)\n",
      "7766 Traning Loss: tensor(0.0746)\n",
      "7767 Traning Loss: tensor(0.0742)\n",
      "7768 Traning Loss: tensor(0.0754)\n",
      "7769 Traning Loss: tensor(0.0746)\n",
      "7770 Traning Loss: tensor(0.0751)\n",
      "7771 Traning Loss: tensor(0.0756)\n",
      "7772 Traning Loss: tensor(0.0751)\n",
      "7773 Traning Loss: tensor(0.0745)\n",
      "7774 Traning Loss: tensor(0.0745)\n",
      "7775 Traning Loss: tensor(0.0749)\n",
      "7776 Traning Loss: tensor(0.0754)\n",
      "7777 Traning Loss: tensor(0.0751)\n",
      "7778 Traning Loss: tensor(0.0746)\n",
      "7779 Traning Loss: tensor(0.0743)\n",
      "7780 Traning Loss: tensor(0.0749)\n",
      "7781 Traning Loss: tensor(0.0747)\n",
      "7782 Traning Loss: tensor(0.0745)\n",
      "7783 Traning Loss: tensor(0.0765)\n",
      "7784 Traning Loss: tensor(0.0744)\n",
      "7785 Traning Loss: tensor(0.0751)\n",
      "7786 Traning Loss: tensor(0.0748)\n",
      "7787 Traning Loss: tensor(0.0746)\n",
      "7788 Traning Loss: tensor(0.0750)\n",
      "7789 Traning Loss: tensor(0.0749)\n",
      "7790 Traning Loss: tensor(0.0747)\n",
      "7791 Traning Loss: tensor(0.0750)\n",
      "7792 Traning Loss: tensor(0.0744)\n",
      "7793 Traning Loss: tensor(0.0759)\n",
      "7794 Traning Loss: tensor(0.0753)\n",
      "7795 Traning Loss: tensor(0.0740)\n",
      "7796 Traning Loss: tensor(0.0755)\n",
      "7797 Traning Loss: tensor(0.0746)\n",
      "7798 Traning Loss: tensor(0.0752)\n",
      "7799 Traning Loss: tensor(0.0752)\n",
      "7800 Traning Loss: tensor(0.0751)\n",
      "7801 Traning Loss: tensor(0.0760)\n",
      "7802 Traning Loss: tensor(0.0748)\n",
      "7803 Traning Loss: tensor(0.0742)\n",
      "7804 Traning Loss: tensor(0.0745)\n",
      "7805 Traning Loss: tensor(0.0749)\n",
      "7806 Traning Loss: tensor(0.0755)\n",
      "7807 Traning Loss: tensor(0.0758)\n",
      "7808 Traning Loss: tensor(0.0738)\n",
      "7809 Traning Loss: tensor(0.0750)\n",
      "7810 Traning Loss: tensor(0.0754)\n",
      "7811 Traning Loss: tensor(0.0748)\n",
      "7812 Traning Loss: tensor(0.0744)\n",
      "7813 Traning Loss: tensor(0.0753)\n",
      "7814 Traning Loss: tensor(0.0748)\n",
      "7815 Traning Loss: tensor(0.0756)\n",
      "7816 Traning Loss: tensor(0.0753)\n",
      "7817 Traning Loss: tensor(0.0741)\n",
      "7818 Traning Loss: tensor(0.0756)\n",
      "7819 Traning Loss: tensor(0.0755)\n",
      "7820 Traning Loss: tensor(0.0749)\n",
      "7821 Traning Loss: tensor(0.0751)\n",
      "7822 Traning Loss: tensor(0.0750)\n",
      "7823 Traning Loss: tensor(0.0758)\n",
      "7824 Traning Loss: tensor(0.0747)\n",
      "7825 Traning Loss: tensor(0.0757)\n",
      "7826 Traning Loss: tensor(0.0754)\n",
      "7827 Traning Loss: tensor(0.0762)\n",
      "7828 Traning Loss: tensor(0.0747)\n",
      "7829 Traning Loss: tensor(0.0755)\n",
      "7830 Traning Loss: tensor(0.0744)\n",
      "7831 Traning Loss: tensor(0.0755)\n",
      "7832 Traning Loss: tensor(0.0748)\n",
      "7833 Traning Loss: tensor(0.0751)\n",
      "7834 Traning Loss: tensor(0.0747)\n",
      "7835 Traning Loss: tensor(0.0745)\n",
      "7836 Traning Loss: tensor(0.0748)\n",
      "7837 Traning Loss: tensor(0.0742)\n",
      "7838 Traning Loss: tensor(0.0756)\n",
      "7839 Traning Loss: tensor(0.0754)\n",
      "7840 Traning Loss: tensor(0.0748)\n",
      "7841 Traning Loss: tensor(0.0743)\n",
      "7842 Traning Loss: tensor(0.0747)\n",
      "7843 Traning Loss: tensor(0.0753)\n",
      "7844 Traning Loss: tensor(0.0751)\n",
      "7845 Traning Loss: tensor(0.0737)\n",
      "7846 Traning Loss: tensor(0.0742)\n",
      "7847 Traning Loss: tensor(0.0743)\n",
      "7848 Traning Loss: tensor(0.0753)\n",
      "7849 Traning Loss: tensor(0.0749)\n",
      "7850 Traning Loss: tensor(0.0766)\n",
      "7851 Traning Loss: tensor(0.0741)\n",
      "7852 Traning Loss: tensor(0.0753)\n",
      "7853 Traning Loss: tensor(0.0740)\n",
      "7854 Traning Loss: tensor(0.0751)\n",
      "7855 Traning Loss: tensor(0.0744)\n",
      "7856 Traning Loss: tensor(0.0747)\n",
      "7857 Traning Loss: tensor(0.0750)\n",
      "7858 Traning Loss: tensor(0.0747)\n",
      "7859 Traning Loss: tensor(0.0755)\n",
      "7860 Traning Loss: tensor(0.0749)\n",
      "7861 Traning Loss: tensor(0.0751)\n",
      "7862 Traning Loss: tensor(0.0735)\n",
      "7863 Traning Loss: tensor(0.0748)\n",
      "7864 Traning Loss: tensor(0.0739)\n",
      "7865 Traning Loss: tensor(0.0745)\n",
      "7866 Traning Loss: tensor(0.0747)\n",
      "7867 Traning Loss: tensor(0.0748)\n",
      "7868 Traning Loss: tensor(0.0749)\n",
      "7869 Traning Loss: tensor(0.0741)\n",
      "7870 Traning Loss: tensor(0.0759)\n",
      "7871 Traning Loss: tensor(0.0755)\n",
      "7872 Traning Loss: tensor(0.0743)\n",
      "7873 Traning Loss: tensor(0.0758)\n",
      "7874 Traning Loss: tensor(0.0752)\n",
      "7875 Traning Loss: tensor(0.0750)\n",
      "7876 Traning Loss: tensor(0.0748)\n",
      "7877 Traning Loss: tensor(0.0741)\n",
      "7878 Traning Loss: tensor(0.0750)\n",
      "7879 Traning Loss: tensor(0.0752)\n",
      "7880 Traning Loss: tensor(0.0751)\n",
      "7881 Traning Loss: tensor(0.0745)\n",
      "7882 Traning Loss: tensor(0.0748)\n",
      "7883 Traning Loss: tensor(0.0736)\n",
      "7884 Traning Loss: tensor(0.0753)\n",
      "7885 Traning Loss: tensor(0.0750)\n",
      "7886 Traning Loss: tensor(0.0744)\n",
      "7887 Traning Loss: tensor(0.0747)\n",
      "7888 Traning Loss: tensor(0.0754)\n",
      "7889 Traning Loss: tensor(0.0760)\n",
      "7890 Traning Loss: tensor(0.0732)\n",
      "7891 Traning Loss: tensor(0.0749)\n",
      "7892 Traning Loss: tensor(0.0747)\n",
      "7893 Traning Loss: tensor(0.0751)\n",
      "7894 Traning Loss: tensor(0.0747)\n",
      "7895 Traning Loss: tensor(0.0747)\n",
      "7896 Traning Loss: tensor(0.0754)\n",
      "7897 Traning Loss: tensor(0.0746)\n",
      "7898 Traning Loss: tensor(0.0746)\n",
      "7899 Traning Loss: tensor(0.0762)\n",
      "7900 Traning Loss: tensor(0.0756)\n",
      "7901 Traning Loss: tensor(0.0744)\n",
      "7902 Traning Loss: tensor(0.0735)\n",
      "7903 Traning Loss: tensor(0.0746)\n",
      "7904 Traning Loss: tensor(0.0750)\n",
      "7905 Traning Loss: tensor(0.0757)\n",
      "7906 Traning Loss: tensor(0.0752)\n",
      "7907 Traning Loss: tensor(0.0745)\n",
      "7908 Traning Loss: tensor(0.0759)\n",
      "7909 Traning Loss: tensor(0.0746)\n",
      "7910 Traning Loss: tensor(0.0741)\n",
      "7911 Traning Loss: tensor(0.0742)\n",
      "7912 Traning Loss: tensor(0.0745)\n",
      "7913 Traning Loss: tensor(0.0750)\n",
      "7914 Traning Loss: tensor(0.0750)\n",
      "7915 Traning Loss: tensor(0.0749)\n",
      "7916 Traning Loss: tensor(0.0741)\n",
      "7917 Traning Loss: tensor(0.0749)\n",
      "7918 Traning Loss: tensor(0.0753)\n",
      "7919 Traning Loss: tensor(0.0746)\n",
      "7920 Traning Loss: tensor(0.0754)\n",
      "7921 Traning Loss: tensor(0.0744)\n",
      "7922 Traning Loss: tensor(0.0750)\n",
      "7923 Traning Loss: tensor(0.0732)\n",
      "7924 Traning Loss: tensor(0.0750)\n",
      "7925 Traning Loss: tensor(0.0740)\n",
      "7926 Traning Loss: tensor(0.0748)\n",
      "7927 Traning Loss: tensor(0.0742)\n",
      "7928 Traning Loss: tensor(0.0749)\n",
      "7929 Traning Loss: tensor(0.0747)\n",
      "7930 Traning Loss: tensor(0.0748)\n",
      "7931 Traning Loss: tensor(0.0747)\n",
      "7932 Traning Loss: tensor(0.0738)\n",
      "7933 Traning Loss: tensor(0.0730)\n",
      "7934 Traning Loss: tensor(0.0746)\n",
      "7935 Traning Loss: tensor(0.0741)\n",
      "7936 Traning Loss: tensor(0.0740)\n",
      "7937 Traning Loss: tensor(0.0753)\n",
      "7938 Traning Loss: tensor(0.0748)\n",
      "7939 Traning Loss: tensor(0.0750)\n",
      "7940 Traning Loss: tensor(0.0740)\n",
      "7941 Traning Loss: tensor(0.0736)\n",
      "7942 Traning Loss: tensor(0.0751)\n",
      "7943 Traning Loss: tensor(0.0748)\n",
      "7944 Traning Loss: tensor(0.0743)\n",
      "7945 Traning Loss: tensor(0.0752)\n",
      "7946 Traning Loss: tensor(0.0754)\n",
      "7947 Traning Loss: tensor(0.0742)\n",
      "7948 Traning Loss: tensor(0.0735)\n",
      "7949 Traning Loss: tensor(0.0744)\n",
      "7950 Traning Loss: tensor(0.0752)\n",
      "7951 Traning Loss: tensor(0.0739)\n",
      "7952 Traning Loss: tensor(0.0746)\n",
      "7953 Traning Loss: tensor(0.0746)\n",
      "7954 Traning Loss: tensor(0.0741)\n",
      "7955 Traning Loss: tensor(0.0746)\n",
      "7956 Traning Loss: tensor(0.0743)\n",
      "7957 Traning Loss: tensor(0.0741)\n",
      "7958 Traning Loss: tensor(0.0747)\n",
      "7959 Traning Loss: tensor(0.0738)\n",
      "7960 Traning Loss: tensor(0.0741)\n",
      "7961 Traning Loss: tensor(0.0738)\n",
      "7962 Traning Loss: tensor(0.0741)\n",
      "7963 Traning Loss: tensor(0.0742)\n",
      "7964 Traning Loss: tensor(0.0735)\n",
      "7965 Traning Loss: tensor(0.0746)\n",
      "7966 Traning Loss: tensor(0.0738)\n",
      "7967 Traning Loss: tensor(0.0741)\n",
      "7968 Traning Loss: tensor(0.0753)\n",
      "7969 Traning Loss: tensor(0.0750)\n",
      "7970 Traning Loss: tensor(0.0753)\n",
      "7971 Traning Loss: tensor(0.0741)\n",
      "7972 Traning Loss: tensor(0.0734)\n",
      "7973 Traning Loss: tensor(0.0743)\n",
      "7974 Traning Loss: tensor(0.0750)\n",
      "7975 Traning Loss: tensor(0.0737)\n",
      "7976 Traning Loss: tensor(0.0751)\n",
      "7977 Traning Loss: tensor(0.0753)\n",
      "7978 Traning Loss: tensor(0.0748)\n",
      "7979 Traning Loss: tensor(0.0745)\n",
      "7980 Traning Loss: tensor(0.0754)\n",
      "7981 Traning Loss: tensor(0.0744)\n",
      "7982 Traning Loss: tensor(0.0749)\n",
      "7983 Traning Loss: tensor(0.0748)\n",
      "7984 Traning Loss: tensor(0.0745)\n",
      "7985 Traning Loss: tensor(0.0740)\n",
      "7986 Traning Loss: tensor(0.0749)\n",
      "7987 Traning Loss: tensor(0.0736)\n",
      "7988 Traning Loss: tensor(0.0737)\n",
      "7989 Traning Loss: tensor(0.0743)\n",
      "7990 Traning Loss: tensor(0.0757)\n",
      "7991 Traning Loss: tensor(0.0745)\n",
      "7992 Traning Loss: tensor(0.0752)\n",
      "7993 Traning Loss: tensor(0.0747)\n",
      "7994 Traning Loss: tensor(0.0746)\n",
      "7995 Traning Loss: tensor(0.0748)\n",
      "7996 Traning Loss: tensor(0.0744)\n",
      "7997 Traning Loss: tensor(0.0740)\n",
      "7998 Traning Loss: tensor(0.0745)\n",
      "7999 Traning Loss: tensor(0.0745)\n",
      "8000 Traning Loss: tensor(0.0746)\n",
      "8001 Traning Loss: tensor(0.0739)\n",
      "8002 Traning Loss: tensor(0.0739)\n",
      "8003 Traning Loss: tensor(0.0738)\n",
      "8004 Traning Loss: tensor(0.0752)\n",
      "8005 Traning Loss: tensor(0.0747)\n",
      "8006 Traning Loss: tensor(0.0750)\n",
      "8007 Traning Loss: tensor(0.0746)\n",
      "8008 Traning Loss: tensor(0.0744)\n",
      "8009 Traning Loss: tensor(0.0743)\n",
      "8010 Traning Loss: tensor(0.0744)\n",
      "8011 Traning Loss: tensor(0.0752)\n",
      "8012 Traning Loss: tensor(0.0745)\n",
      "8013 Traning Loss: tensor(0.0741)\n",
      "8014 Traning Loss: tensor(0.0753)\n",
      "8015 Traning Loss: tensor(0.0742)\n",
      "8016 Traning Loss: tensor(0.0751)\n",
      "8017 Traning Loss: tensor(0.0748)\n",
      "8018 Traning Loss: tensor(0.0748)\n",
      "8019 Traning Loss: tensor(0.0740)\n",
      "8020 Traning Loss: tensor(0.0743)\n",
      "8021 Traning Loss: tensor(0.0756)\n",
      "8022 Traning Loss: tensor(0.0742)\n",
      "8023 Traning Loss: tensor(0.0749)\n",
      "8024 Traning Loss: tensor(0.0734)\n",
      "8025 Traning Loss: tensor(0.0744)\n",
      "8026 Traning Loss: tensor(0.0734)\n",
      "8027 Traning Loss: tensor(0.0730)\n",
      "8028 Traning Loss: tensor(0.0739)\n",
      "8029 Traning Loss: tensor(0.0738)\n",
      "8030 Traning Loss: tensor(0.0749)\n",
      "8031 Traning Loss: tensor(0.0745)\n",
      "8032 Traning Loss: tensor(0.0758)\n",
      "8033 Traning Loss: tensor(0.0744)\n",
      "8034 Traning Loss: tensor(0.0744)\n",
      "8035 Traning Loss: tensor(0.0734)\n",
      "8036 Traning Loss: tensor(0.0747)\n",
      "8037 Traning Loss: tensor(0.0740)\n",
      "8038 Traning Loss: tensor(0.0731)\n",
      "8039 Traning Loss: tensor(0.0748)\n",
      "8040 Traning Loss: tensor(0.0748)\n",
      "8041 Traning Loss: tensor(0.0742)\n",
      "8042 Traning Loss: tensor(0.0751)\n",
      "8043 Traning Loss: tensor(0.0747)\n",
      "8044 Traning Loss: tensor(0.0736)\n",
      "8045 Traning Loss: tensor(0.0739)\n",
      "8046 Traning Loss: tensor(0.0742)\n",
      "8047 Traning Loss: tensor(0.0746)\n",
      "8048 Traning Loss: tensor(0.0744)\n",
      "8049 Traning Loss: tensor(0.0749)\n",
      "8050 Traning Loss: tensor(0.0737)\n",
      "8051 Traning Loss: tensor(0.0744)\n",
      "8052 Traning Loss: tensor(0.0742)\n",
      "8053 Traning Loss: tensor(0.0739)\n",
      "8054 Traning Loss: tensor(0.0747)\n",
      "8055 Traning Loss: tensor(0.0738)\n",
      "8056 Traning Loss: tensor(0.0744)\n",
      "8057 Traning Loss: tensor(0.0757)\n",
      "8058 Traning Loss: tensor(0.0745)\n",
      "8059 Traning Loss: tensor(0.0742)\n",
      "8060 Traning Loss: tensor(0.0735)\n",
      "8061 Traning Loss: tensor(0.0744)\n",
      "8062 Traning Loss: tensor(0.0743)\n",
      "8063 Traning Loss: tensor(0.0742)\n",
      "8064 Traning Loss: tensor(0.0738)\n",
      "8065 Traning Loss: tensor(0.0747)\n",
      "8066 Traning Loss: tensor(0.0739)\n",
      "8067 Traning Loss: tensor(0.0745)\n",
      "8068 Traning Loss: tensor(0.0731)\n",
      "8069 Traning Loss: tensor(0.0747)\n",
      "8070 Traning Loss: tensor(0.0742)\n",
      "8071 Traning Loss: tensor(0.0746)\n",
      "8072 Traning Loss: tensor(0.0742)\n",
      "8073 Traning Loss: tensor(0.0740)\n",
      "8074 Traning Loss: tensor(0.0744)\n",
      "8075 Traning Loss: tensor(0.0739)\n",
      "8076 Traning Loss: tensor(0.0753)\n",
      "8077 Traning Loss: tensor(0.0746)\n",
      "8078 Traning Loss: tensor(0.0738)\n",
      "8079 Traning Loss: tensor(0.0747)\n",
      "8080 Traning Loss: tensor(0.0739)\n",
      "8081 Traning Loss: tensor(0.0731)\n",
      "8082 Traning Loss: tensor(0.0740)\n",
      "8083 Traning Loss: tensor(0.0729)\n",
      "8084 Traning Loss: tensor(0.0739)\n",
      "8085 Traning Loss: tensor(0.0739)\n",
      "8086 Traning Loss: tensor(0.0738)\n",
      "8087 Traning Loss: tensor(0.0742)\n",
      "8088 Traning Loss: tensor(0.0745)\n",
      "8089 Traning Loss: tensor(0.0751)\n",
      "8090 Traning Loss: tensor(0.0741)\n",
      "8091 Traning Loss: tensor(0.0743)\n",
      "8092 Traning Loss: tensor(0.0742)\n",
      "8093 Traning Loss: tensor(0.0749)\n",
      "8094 Traning Loss: tensor(0.0734)\n",
      "8095 Traning Loss: tensor(0.0734)\n",
      "8096 Traning Loss: tensor(0.0747)\n",
      "8097 Traning Loss: tensor(0.0737)\n",
      "8098 Traning Loss: tensor(0.0747)\n",
      "8099 Traning Loss: tensor(0.0739)\n",
      "8100 Traning Loss: tensor(0.0750)\n",
      "8101 Traning Loss: tensor(0.0750)\n",
      "8102 Traning Loss: tensor(0.0737)\n",
      "8103 Traning Loss: tensor(0.0742)\n",
      "8104 Traning Loss: tensor(0.0743)\n",
      "8105 Traning Loss: tensor(0.0736)\n",
      "8106 Traning Loss: tensor(0.0743)\n",
      "8107 Traning Loss: tensor(0.0740)\n",
      "8108 Traning Loss: tensor(0.0744)\n",
      "8109 Traning Loss: tensor(0.0744)\n",
      "8110 Traning Loss: tensor(0.0751)\n",
      "8111 Traning Loss: tensor(0.0745)\n",
      "8112 Traning Loss: tensor(0.0743)\n",
      "8113 Traning Loss: tensor(0.0730)\n",
      "8114 Traning Loss: tensor(0.0732)\n",
      "8115 Traning Loss: tensor(0.0737)\n",
      "8116 Traning Loss: tensor(0.0736)\n",
      "8117 Traning Loss: tensor(0.0737)\n",
      "8118 Traning Loss: tensor(0.0737)\n",
      "8119 Traning Loss: tensor(0.0731)\n",
      "8120 Traning Loss: tensor(0.0734)\n",
      "8121 Traning Loss: tensor(0.0743)\n",
      "8122 Traning Loss: tensor(0.0741)\n",
      "8123 Traning Loss: tensor(0.0739)\n",
      "8124 Traning Loss: tensor(0.0742)\n",
      "8125 Traning Loss: tensor(0.0738)\n",
      "8126 Traning Loss: tensor(0.0742)\n",
      "8127 Traning Loss: tensor(0.0743)\n",
      "8128 Traning Loss: tensor(0.0744)\n",
      "8129 Traning Loss: tensor(0.0733)\n",
      "8130 Traning Loss: tensor(0.0733)\n",
      "8131 Traning Loss: tensor(0.0739)\n",
      "8132 Traning Loss: tensor(0.0746)\n",
      "8133 Traning Loss: tensor(0.0741)\n",
      "8134 Traning Loss: tensor(0.0747)\n",
      "8135 Traning Loss: tensor(0.0739)\n",
      "8136 Traning Loss: tensor(0.0751)\n",
      "8137 Traning Loss: tensor(0.0745)\n",
      "8138 Traning Loss: tensor(0.0731)\n",
      "8139 Traning Loss: tensor(0.0762)\n",
      "8140 Traning Loss: tensor(0.0741)\n",
      "8141 Traning Loss: tensor(0.0731)\n",
      "8142 Traning Loss: tensor(0.0744)\n",
      "8143 Traning Loss: tensor(0.0741)\n",
      "8144 Traning Loss: tensor(0.0733)\n",
      "8145 Traning Loss: tensor(0.0739)\n",
      "8146 Traning Loss: tensor(0.0736)\n",
      "8147 Traning Loss: tensor(0.0738)\n",
      "8148 Traning Loss: tensor(0.0732)\n",
      "8149 Traning Loss: tensor(0.0737)\n",
      "8150 Traning Loss: tensor(0.0738)\n",
      "8151 Traning Loss: tensor(0.0748)\n",
      "8152 Traning Loss: tensor(0.0734)\n",
      "8153 Traning Loss: tensor(0.0739)\n",
      "8154 Traning Loss: tensor(0.0743)\n",
      "8155 Traning Loss: tensor(0.0736)\n",
      "8156 Traning Loss: tensor(0.0741)\n",
      "8157 Traning Loss: tensor(0.0734)\n",
      "8158 Traning Loss: tensor(0.0753)\n",
      "8159 Traning Loss: tensor(0.0732)\n",
      "8160 Traning Loss: tensor(0.0735)\n",
      "8161 Traning Loss: tensor(0.0734)\n",
      "8162 Traning Loss: tensor(0.0738)\n",
      "8163 Traning Loss: tensor(0.0734)\n",
      "8164 Traning Loss: tensor(0.0743)\n",
      "8165 Traning Loss: tensor(0.0743)\n",
      "8166 Traning Loss: tensor(0.0735)\n",
      "8167 Traning Loss: tensor(0.0740)\n",
      "8168 Traning Loss: tensor(0.0742)\n",
      "8169 Traning Loss: tensor(0.0744)\n",
      "8170 Traning Loss: tensor(0.0738)\n",
      "8171 Traning Loss: tensor(0.0742)\n",
      "8172 Traning Loss: tensor(0.0740)\n",
      "8173 Traning Loss: tensor(0.0743)\n",
      "8174 Traning Loss: tensor(0.0741)\n",
      "8175 Traning Loss: tensor(0.0730)\n",
      "8176 Traning Loss: tensor(0.0737)\n",
      "8177 Traning Loss: tensor(0.0753)\n",
      "8178 Traning Loss: tensor(0.0743)\n",
      "8179 Traning Loss: tensor(0.0740)\n",
      "8180 Traning Loss: tensor(0.0738)\n",
      "8181 Traning Loss: tensor(0.0739)\n",
      "8182 Traning Loss: tensor(0.0748)\n",
      "8183 Traning Loss: tensor(0.0737)\n",
      "8184 Traning Loss: tensor(0.0749)\n",
      "8185 Traning Loss: tensor(0.0739)\n",
      "8186 Traning Loss: tensor(0.0730)\n",
      "8187 Traning Loss: tensor(0.0723)\n",
      "8188 Traning Loss: tensor(0.0737)\n",
      "8189 Traning Loss: tensor(0.0732)\n",
      "8190 Traning Loss: tensor(0.0736)\n",
      "8191 Traning Loss: tensor(0.0743)\n",
      "8192 Traning Loss: tensor(0.0741)\n",
      "8193 Traning Loss: tensor(0.0740)\n",
      "8194 Traning Loss: tensor(0.0743)\n",
      "8195 Traning Loss: tensor(0.0745)\n",
      "8196 Traning Loss: tensor(0.0750)\n",
      "8197 Traning Loss: tensor(0.0726)\n",
      "8198 Traning Loss: tensor(0.0741)\n",
      "8199 Traning Loss: tensor(0.0734)\n",
      "8200 Traning Loss: tensor(0.0737)\n",
      "8201 Traning Loss: tensor(0.0735)\n",
      "8202 Traning Loss: tensor(0.0745)\n",
      "8203 Traning Loss: tensor(0.0730)\n",
      "8204 Traning Loss: tensor(0.0746)\n",
      "8205 Traning Loss: tensor(0.0735)\n",
      "8206 Traning Loss: tensor(0.0741)\n",
      "8207 Traning Loss: tensor(0.0734)\n",
      "8208 Traning Loss: tensor(0.0732)\n",
      "8209 Traning Loss: tensor(0.0741)\n",
      "8210 Traning Loss: tensor(0.0747)\n",
      "8211 Traning Loss: tensor(0.0735)\n",
      "8212 Traning Loss: tensor(0.0743)\n",
      "8213 Traning Loss: tensor(0.0740)\n",
      "8214 Traning Loss: tensor(0.0739)\n",
      "8215 Traning Loss: tensor(0.0737)\n",
      "8216 Traning Loss: tensor(0.0737)\n",
      "8217 Traning Loss: tensor(0.0742)\n",
      "8218 Traning Loss: tensor(0.0736)\n",
      "8219 Traning Loss: tensor(0.0736)\n",
      "8220 Traning Loss: tensor(0.0733)\n",
      "8221 Traning Loss: tensor(0.0745)\n",
      "8222 Traning Loss: tensor(0.0739)\n",
      "8223 Traning Loss: tensor(0.0736)\n",
      "8224 Traning Loss: tensor(0.0744)\n",
      "8225 Traning Loss: tensor(0.0741)\n",
      "8226 Traning Loss: tensor(0.0742)\n",
      "8227 Traning Loss: tensor(0.0733)\n",
      "8228 Traning Loss: tensor(0.0734)\n",
      "8229 Traning Loss: tensor(0.0743)\n",
      "8230 Traning Loss: tensor(0.0731)\n",
      "8231 Traning Loss: tensor(0.0734)\n",
      "8232 Traning Loss: tensor(0.0726)\n",
      "8233 Traning Loss: tensor(0.0744)\n",
      "8234 Traning Loss: tensor(0.0733)\n",
      "8235 Traning Loss: tensor(0.0731)\n",
      "8236 Traning Loss: tensor(0.0740)\n",
      "8237 Traning Loss: tensor(0.0739)\n",
      "8238 Traning Loss: tensor(0.0742)\n",
      "8239 Traning Loss: tensor(0.0729)\n",
      "8240 Traning Loss: tensor(0.0734)\n",
      "8241 Traning Loss: tensor(0.0728)\n",
      "8242 Traning Loss: tensor(0.0736)\n",
      "8243 Traning Loss: tensor(0.0731)\n",
      "8244 Traning Loss: tensor(0.0755)\n",
      "8245 Traning Loss: tensor(0.0733)\n",
      "8246 Traning Loss: tensor(0.0742)\n",
      "8247 Traning Loss: tensor(0.0741)\n",
      "8248 Traning Loss: tensor(0.0730)\n",
      "8249 Traning Loss: tensor(0.0744)\n",
      "8250 Traning Loss: tensor(0.0743)\n",
      "8251 Traning Loss: tensor(0.0746)\n",
      "8252 Traning Loss: tensor(0.0728)\n",
      "8253 Traning Loss: tensor(0.0737)\n",
      "8254 Traning Loss: tensor(0.0733)\n",
      "8255 Traning Loss: tensor(0.0735)\n",
      "8256 Traning Loss: tensor(0.0735)\n",
      "8257 Traning Loss: tensor(0.0742)\n",
      "8258 Traning Loss: tensor(0.0732)\n",
      "8259 Traning Loss: tensor(0.0729)\n",
      "8260 Traning Loss: tensor(0.0737)\n",
      "8261 Traning Loss: tensor(0.0723)\n",
      "8262 Traning Loss: tensor(0.0732)\n",
      "8263 Traning Loss: tensor(0.0739)\n",
      "8264 Traning Loss: tensor(0.0740)\n",
      "8265 Traning Loss: tensor(0.0736)\n",
      "8266 Traning Loss: tensor(0.0749)\n",
      "8267 Traning Loss: tensor(0.0736)\n",
      "8268 Traning Loss: tensor(0.0732)\n",
      "8269 Traning Loss: tensor(0.0737)\n",
      "8270 Traning Loss: tensor(0.0739)\n",
      "8271 Traning Loss: tensor(0.0743)\n",
      "8272 Traning Loss: tensor(0.0736)\n",
      "8273 Traning Loss: tensor(0.0733)\n",
      "8274 Traning Loss: tensor(0.0727)\n",
      "8275 Traning Loss: tensor(0.0735)\n",
      "8276 Traning Loss: tensor(0.0745)\n",
      "8277 Traning Loss: tensor(0.0738)\n",
      "8278 Traning Loss: tensor(0.0736)\n",
      "8279 Traning Loss: tensor(0.0728)\n",
      "8280 Traning Loss: tensor(0.0736)\n",
      "8281 Traning Loss: tensor(0.0730)\n",
      "8282 Traning Loss: tensor(0.0736)\n",
      "8283 Traning Loss: tensor(0.0723)\n",
      "8284 Traning Loss: tensor(0.0735)\n",
      "8285 Traning Loss: tensor(0.0737)\n",
      "8286 Traning Loss: tensor(0.0731)\n",
      "8287 Traning Loss: tensor(0.0727)\n",
      "8288 Traning Loss: tensor(0.0735)\n",
      "8289 Traning Loss: tensor(0.0741)\n",
      "8290 Traning Loss: tensor(0.0752)\n",
      "8291 Traning Loss: tensor(0.0723)\n",
      "8292 Traning Loss: tensor(0.0731)\n",
      "8293 Traning Loss: tensor(0.0738)\n",
      "8294 Traning Loss: tensor(0.0739)\n",
      "8295 Traning Loss: tensor(0.0732)\n",
      "8296 Traning Loss: tensor(0.0736)\n",
      "8297 Traning Loss: tensor(0.0727)\n",
      "8298 Traning Loss: tensor(0.0735)\n",
      "8299 Traning Loss: tensor(0.0737)\n",
      "8300 Traning Loss: tensor(0.0733)\n",
      "8301 Traning Loss: tensor(0.0734)\n",
      "8302 Traning Loss: tensor(0.0741)\n",
      "8303 Traning Loss: tensor(0.0742)\n",
      "8304 Traning Loss: tensor(0.0743)\n",
      "8305 Traning Loss: tensor(0.0721)\n",
      "8306 Traning Loss: tensor(0.0731)\n",
      "8307 Traning Loss: tensor(0.0740)\n",
      "8308 Traning Loss: tensor(0.0728)\n",
      "8309 Traning Loss: tensor(0.0740)\n",
      "8310 Traning Loss: tensor(0.0738)\n",
      "8311 Traning Loss: tensor(0.0723)\n",
      "8312 Traning Loss: tensor(0.0734)\n",
      "8313 Traning Loss: tensor(0.0729)\n",
      "8314 Traning Loss: tensor(0.0736)\n",
      "8315 Traning Loss: tensor(0.0718)\n",
      "8316 Traning Loss: tensor(0.0727)\n",
      "8317 Traning Loss: tensor(0.0738)\n",
      "8318 Traning Loss: tensor(0.0741)\n",
      "8319 Traning Loss: tensor(0.0732)\n",
      "8320 Traning Loss: tensor(0.0720)\n",
      "8321 Traning Loss: tensor(0.0725)\n",
      "8322 Traning Loss: tensor(0.0742)\n",
      "8323 Traning Loss: tensor(0.0730)\n",
      "8324 Traning Loss: tensor(0.0734)\n",
      "8325 Traning Loss: tensor(0.0728)\n",
      "8326 Traning Loss: tensor(0.0726)\n",
      "8327 Traning Loss: tensor(0.0733)\n",
      "8328 Traning Loss: tensor(0.0743)\n",
      "8329 Traning Loss: tensor(0.0727)\n",
      "8330 Traning Loss: tensor(0.0742)\n",
      "8331 Traning Loss: tensor(0.0741)\n",
      "8332 Traning Loss: tensor(0.0724)\n",
      "8333 Traning Loss: tensor(0.0725)\n",
      "8334 Traning Loss: tensor(0.0723)\n",
      "8335 Traning Loss: tensor(0.0737)\n",
      "8336 Traning Loss: tensor(0.0726)\n",
      "8337 Traning Loss: tensor(0.0735)\n",
      "8338 Traning Loss: tensor(0.0727)\n",
      "8339 Traning Loss: tensor(0.0728)\n",
      "8340 Traning Loss: tensor(0.0739)\n",
      "8341 Traning Loss: tensor(0.0734)\n",
      "8342 Traning Loss: tensor(0.0724)\n",
      "8343 Traning Loss: tensor(0.0729)\n",
      "8344 Traning Loss: tensor(0.0722)\n",
      "8345 Traning Loss: tensor(0.0723)\n",
      "8346 Traning Loss: tensor(0.0739)\n",
      "8347 Traning Loss: tensor(0.0727)\n",
      "8348 Traning Loss: tensor(0.0736)\n",
      "8349 Traning Loss: tensor(0.0736)\n",
      "8350 Traning Loss: tensor(0.0725)\n",
      "8351 Traning Loss: tensor(0.0731)\n",
      "8352 Traning Loss: tensor(0.0735)\n",
      "8353 Traning Loss: tensor(0.0732)\n",
      "8354 Traning Loss: tensor(0.0724)\n",
      "8355 Traning Loss: tensor(0.0733)\n",
      "8356 Traning Loss: tensor(0.0724)\n",
      "8357 Traning Loss: tensor(0.0743)\n",
      "8358 Traning Loss: tensor(0.0729)\n",
      "8359 Traning Loss: tensor(0.0725)\n",
      "8360 Traning Loss: tensor(0.0727)\n",
      "8361 Traning Loss: tensor(0.0725)\n",
      "8362 Traning Loss: tensor(0.0736)\n",
      "8363 Traning Loss: tensor(0.0732)\n",
      "8364 Traning Loss: tensor(0.0726)\n",
      "8365 Traning Loss: tensor(0.0725)\n",
      "8366 Traning Loss: tensor(0.0735)\n",
      "8367 Traning Loss: tensor(0.0738)\n",
      "8368 Traning Loss: tensor(0.0734)\n",
      "8369 Traning Loss: tensor(0.0724)\n",
      "8370 Traning Loss: tensor(0.0730)\n",
      "8371 Traning Loss: tensor(0.0732)\n",
      "8372 Traning Loss: tensor(0.0731)\n",
      "8373 Traning Loss: tensor(0.0734)\n",
      "8374 Traning Loss: tensor(0.0725)\n",
      "8375 Traning Loss: tensor(0.0727)\n",
      "8376 Traning Loss: tensor(0.0729)\n",
      "8377 Traning Loss: tensor(0.0736)\n",
      "8378 Traning Loss: tensor(0.0743)\n",
      "8379 Traning Loss: tensor(0.0741)\n",
      "8380 Traning Loss: tensor(0.0731)\n",
      "8381 Traning Loss: tensor(0.0733)\n",
      "8382 Traning Loss: tensor(0.0731)\n",
      "8383 Traning Loss: tensor(0.0729)\n",
      "8384 Traning Loss: tensor(0.0733)\n",
      "8385 Traning Loss: tensor(0.0723)\n",
      "8386 Traning Loss: tensor(0.0730)\n",
      "8387 Traning Loss: tensor(0.0736)\n",
      "8388 Traning Loss: tensor(0.0734)\n",
      "8389 Traning Loss: tensor(0.0737)\n",
      "8390 Traning Loss: tensor(0.0728)\n",
      "8391 Traning Loss: tensor(0.0745)\n",
      "8392 Traning Loss: tensor(0.0738)\n",
      "8393 Traning Loss: tensor(0.0720)\n",
      "8394 Traning Loss: tensor(0.0729)\n",
      "8395 Traning Loss: tensor(0.0731)\n",
      "8396 Traning Loss: tensor(0.0733)\n",
      "8397 Traning Loss: tensor(0.0734)\n",
      "8398 Traning Loss: tensor(0.0743)\n",
      "8399 Traning Loss: tensor(0.0740)\n",
      "8400 Traning Loss: tensor(0.0723)\n",
      "8401 Traning Loss: tensor(0.0732)\n",
      "8402 Traning Loss: tensor(0.0731)\n",
      "8403 Traning Loss: tensor(0.0743)\n",
      "8404 Traning Loss: tensor(0.0730)\n",
      "8405 Traning Loss: tensor(0.0727)\n",
      "8406 Traning Loss: tensor(0.0713)\n",
      "8407 Traning Loss: tensor(0.0733)\n",
      "8408 Traning Loss: tensor(0.0730)\n",
      "8409 Traning Loss: tensor(0.0729)\n",
      "8410 Traning Loss: tensor(0.0737)\n",
      "8411 Traning Loss: tensor(0.0724)\n",
      "8412 Traning Loss: tensor(0.0728)\n",
      "8413 Traning Loss: tensor(0.0720)\n",
      "8414 Traning Loss: tensor(0.0719)\n",
      "8415 Traning Loss: tensor(0.0730)\n",
      "8416 Traning Loss: tensor(0.0734)\n",
      "8417 Traning Loss: tensor(0.0737)\n",
      "8418 Traning Loss: tensor(0.0724)\n",
      "8419 Traning Loss: tensor(0.0738)\n",
      "8420 Traning Loss: tensor(0.0723)\n",
      "8421 Traning Loss: tensor(0.0736)\n",
      "8422 Traning Loss: tensor(0.0729)\n",
      "8423 Traning Loss: tensor(0.0728)\n",
      "8424 Traning Loss: tensor(0.0743)\n",
      "8425 Traning Loss: tensor(0.0725)\n",
      "8426 Traning Loss: tensor(0.0720)\n",
      "8427 Traning Loss: tensor(0.0730)\n",
      "8428 Traning Loss: tensor(0.0738)\n",
      "8429 Traning Loss: tensor(0.0734)\n",
      "8430 Traning Loss: tensor(0.0738)\n",
      "8431 Traning Loss: tensor(0.0724)\n",
      "8432 Traning Loss: tensor(0.0735)\n",
      "8433 Traning Loss: tensor(0.0736)\n",
      "8434 Traning Loss: tensor(0.0732)\n",
      "8435 Traning Loss: tensor(0.0729)\n",
      "8436 Traning Loss: tensor(0.0735)\n",
      "8437 Traning Loss: tensor(0.0727)\n",
      "8438 Traning Loss: tensor(0.0725)\n",
      "8439 Traning Loss: tensor(0.0732)\n",
      "8440 Traning Loss: tensor(0.0721)\n",
      "8441 Traning Loss: tensor(0.0728)\n",
      "8442 Traning Loss: tensor(0.0721)\n",
      "8443 Traning Loss: tensor(0.0736)\n",
      "8444 Traning Loss: tensor(0.0737)\n",
      "8445 Traning Loss: tensor(0.0735)\n",
      "8446 Traning Loss: tensor(0.0722)\n",
      "8447 Traning Loss: tensor(0.0748)\n",
      "8448 Traning Loss: tensor(0.0726)\n",
      "8449 Traning Loss: tensor(0.0726)\n",
      "8450 Traning Loss: tensor(0.0728)\n",
      "8451 Traning Loss: tensor(0.0728)\n",
      "8452 Traning Loss: tensor(0.0725)\n",
      "8453 Traning Loss: tensor(0.0741)\n",
      "8454 Traning Loss: tensor(0.0719)\n",
      "8455 Traning Loss: tensor(0.0733)\n",
      "8456 Traning Loss: tensor(0.0723)\n",
      "8457 Traning Loss: tensor(0.0720)\n",
      "8458 Traning Loss: tensor(0.0730)\n",
      "8459 Traning Loss: tensor(0.0727)\n",
      "8460 Traning Loss: tensor(0.0729)\n",
      "8461 Traning Loss: tensor(0.0725)\n",
      "8462 Traning Loss: tensor(0.0730)\n",
      "8463 Traning Loss: tensor(0.0719)\n",
      "8464 Traning Loss: tensor(0.0738)\n",
      "8465 Traning Loss: tensor(0.0735)\n",
      "8466 Traning Loss: tensor(0.0724)\n",
      "8467 Traning Loss: tensor(0.0722)\n",
      "8468 Traning Loss: tensor(0.0727)\n",
      "8469 Traning Loss: tensor(0.0727)\n",
      "8470 Traning Loss: tensor(0.0736)\n",
      "8471 Traning Loss: tensor(0.0731)\n",
      "8472 Traning Loss: tensor(0.0726)\n",
      "8473 Traning Loss: tensor(0.0734)\n",
      "8474 Traning Loss: tensor(0.0724)\n",
      "8475 Traning Loss: tensor(0.0728)\n",
      "8476 Traning Loss: tensor(0.0731)\n",
      "8477 Traning Loss: tensor(0.0726)\n",
      "8478 Traning Loss: tensor(0.0732)\n",
      "8479 Traning Loss: tensor(0.0726)\n",
      "8480 Traning Loss: tensor(0.0733)\n",
      "8481 Traning Loss: tensor(0.0731)\n",
      "8482 Traning Loss: tensor(0.0728)\n",
      "8483 Traning Loss: tensor(0.0730)\n",
      "8484 Traning Loss: tensor(0.0724)\n",
      "8485 Traning Loss: tensor(0.0718)\n",
      "8486 Traning Loss: tensor(0.0725)\n",
      "8487 Traning Loss: tensor(0.0729)\n",
      "8488 Traning Loss: tensor(0.0730)\n",
      "8489 Traning Loss: tensor(0.0734)\n",
      "8490 Traning Loss: tensor(0.0735)\n",
      "8491 Traning Loss: tensor(0.0721)\n",
      "8492 Traning Loss: tensor(0.0725)\n",
      "8493 Traning Loss: tensor(0.0727)\n",
      "8494 Traning Loss: tensor(0.0722)\n",
      "8495 Traning Loss: tensor(0.0737)\n",
      "8496 Traning Loss: tensor(0.0731)\n",
      "8497 Traning Loss: tensor(0.0740)\n",
      "8498 Traning Loss: tensor(0.0723)\n",
      "8499 Traning Loss: tensor(0.0730)\n",
      "8500 Traning Loss: tensor(0.0720)\n",
      "8501 Traning Loss: tensor(0.0727)\n",
      "8502 Traning Loss: tensor(0.0733)\n",
      "8503 Traning Loss: tensor(0.0727)\n",
      "8504 Traning Loss: tensor(0.0713)\n",
      "8505 Traning Loss: tensor(0.0725)\n",
      "8506 Traning Loss: tensor(0.0734)\n",
      "8507 Traning Loss: tensor(0.0726)\n",
      "8508 Traning Loss: tensor(0.0731)\n",
      "8509 Traning Loss: tensor(0.0734)\n",
      "8510 Traning Loss: tensor(0.0716)\n",
      "8511 Traning Loss: tensor(0.0729)\n",
      "8512 Traning Loss: tensor(0.0715)\n",
      "8513 Traning Loss: tensor(0.0731)\n",
      "8514 Traning Loss: tensor(0.0726)\n",
      "8515 Traning Loss: tensor(0.0724)\n",
      "8516 Traning Loss: tensor(0.0733)\n",
      "8517 Traning Loss: tensor(0.0720)\n",
      "8518 Traning Loss: tensor(0.0743)\n",
      "8519 Traning Loss: tensor(0.0716)\n",
      "8520 Traning Loss: tensor(0.0740)\n",
      "8521 Traning Loss: tensor(0.0723)\n",
      "8522 Traning Loss: tensor(0.0721)\n",
      "8523 Traning Loss: tensor(0.0719)\n",
      "8524 Traning Loss: tensor(0.0718)\n",
      "8525 Traning Loss: tensor(0.0727)\n",
      "8526 Traning Loss: tensor(0.0716)\n",
      "8527 Traning Loss: tensor(0.0730)\n",
      "8528 Traning Loss: tensor(0.0720)\n",
      "8529 Traning Loss: tensor(0.0737)\n",
      "8530 Traning Loss: tensor(0.0727)\n",
      "8531 Traning Loss: tensor(0.0737)\n",
      "8532 Traning Loss: tensor(0.0724)\n",
      "8533 Traning Loss: tensor(0.0727)\n",
      "8534 Traning Loss: tensor(0.0716)\n",
      "8535 Traning Loss: tensor(0.0723)\n",
      "8536 Traning Loss: tensor(0.0734)\n",
      "8537 Traning Loss: tensor(0.0726)\n",
      "8538 Traning Loss: tensor(0.0721)\n",
      "8539 Traning Loss: tensor(0.0725)\n",
      "8540 Traning Loss: tensor(0.0730)\n",
      "8541 Traning Loss: tensor(0.0720)\n",
      "8542 Traning Loss: tensor(0.0720)\n",
      "8543 Traning Loss: tensor(0.0726)\n",
      "8544 Traning Loss: tensor(0.0726)\n",
      "8545 Traning Loss: tensor(0.0725)\n",
      "8546 Traning Loss: tensor(0.0720)\n",
      "8547 Traning Loss: tensor(0.0730)\n",
      "8548 Traning Loss: tensor(0.0729)\n",
      "8549 Traning Loss: tensor(0.0712)\n",
      "8550 Traning Loss: tensor(0.0733)\n",
      "8551 Traning Loss: tensor(0.0718)\n",
      "8552 Traning Loss: tensor(0.0731)\n",
      "8553 Traning Loss: tensor(0.0732)\n",
      "8554 Traning Loss: tensor(0.0728)\n",
      "8555 Traning Loss: tensor(0.0728)\n",
      "8556 Traning Loss: tensor(0.0727)\n",
      "8557 Traning Loss: tensor(0.0730)\n",
      "8558 Traning Loss: tensor(0.0719)\n",
      "8559 Traning Loss: tensor(0.0726)\n",
      "8560 Traning Loss: tensor(0.0720)\n",
      "8561 Traning Loss: tensor(0.0717)\n",
      "8562 Traning Loss: tensor(0.0724)\n",
      "8563 Traning Loss: tensor(0.0721)\n",
      "8564 Traning Loss: tensor(0.0716)\n",
      "8565 Traning Loss: tensor(0.0721)\n",
      "8566 Traning Loss: tensor(0.0730)\n",
      "8567 Traning Loss: tensor(0.0731)\n",
      "8568 Traning Loss: tensor(0.0719)\n",
      "8569 Traning Loss: tensor(0.0730)\n",
      "8570 Traning Loss: tensor(0.0726)\n",
      "8571 Traning Loss: tensor(0.0717)\n",
      "8572 Traning Loss: tensor(0.0720)\n",
      "8573 Traning Loss: tensor(0.0718)\n",
      "8574 Traning Loss: tensor(0.0730)\n",
      "8575 Traning Loss: tensor(0.0726)\n",
      "8576 Traning Loss: tensor(0.0740)\n",
      "8577 Traning Loss: tensor(0.0733)\n",
      "8578 Traning Loss: tensor(0.0726)\n",
      "8579 Traning Loss: tensor(0.0727)\n",
      "8580 Traning Loss: tensor(0.0717)\n",
      "8581 Traning Loss: tensor(0.0720)\n",
      "8582 Traning Loss: tensor(0.0732)\n",
      "8583 Traning Loss: tensor(0.0719)\n",
      "8584 Traning Loss: tensor(0.0730)\n",
      "8585 Traning Loss: tensor(0.0712)\n",
      "8586 Traning Loss: tensor(0.0731)\n",
      "8587 Traning Loss: tensor(0.0725)\n",
      "8588 Traning Loss: tensor(0.0717)\n",
      "8589 Traning Loss: tensor(0.0718)\n",
      "8590 Traning Loss: tensor(0.0723)\n",
      "8591 Traning Loss: tensor(0.0729)\n",
      "8592 Traning Loss: tensor(0.0715)\n",
      "8593 Traning Loss: tensor(0.0723)\n",
      "8594 Traning Loss: tensor(0.0713)\n",
      "8595 Traning Loss: tensor(0.0718)\n",
      "8596 Traning Loss: tensor(0.0732)\n",
      "8597 Traning Loss: tensor(0.0723)\n",
      "8598 Traning Loss: tensor(0.0717)\n",
      "8599 Traning Loss: tensor(0.0707)\n",
      "8600 Traning Loss: tensor(0.0721)\n",
      "8601 Traning Loss: tensor(0.0725)\n",
      "8602 Traning Loss: tensor(0.0727)\n",
      "8603 Traning Loss: tensor(0.0726)\n",
      "8604 Traning Loss: tensor(0.0716)\n",
      "8605 Traning Loss: tensor(0.0723)\n",
      "8606 Traning Loss: tensor(0.0732)\n",
      "8607 Traning Loss: tensor(0.0717)\n",
      "8608 Traning Loss: tensor(0.0717)\n",
      "8609 Traning Loss: tensor(0.0709)\n",
      "8610 Traning Loss: tensor(0.0727)\n",
      "8611 Traning Loss: tensor(0.0728)\n",
      "8612 Traning Loss: tensor(0.0730)\n",
      "8613 Traning Loss: tensor(0.0721)\n",
      "8614 Traning Loss: tensor(0.0718)\n",
      "8615 Traning Loss: tensor(0.0708)\n",
      "8616 Traning Loss: tensor(0.0721)\n",
      "8617 Traning Loss: tensor(0.0722)\n",
      "8618 Traning Loss: tensor(0.0720)\n",
      "8619 Traning Loss: tensor(0.0717)\n",
      "8620 Traning Loss: tensor(0.0722)\n",
      "8621 Traning Loss: tensor(0.0728)\n",
      "8622 Traning Loss: tensor(0.0726)\n",
      "8623 Traning Loss: tensor(0.0714)\n",
      "8624 Traning Loss: tensor(0.0735)\n",
      "8625 Traning Loss: tensor(0.0738)\n",
      "8626 Traning Loss: tensor(0.0725)\n",
      "8627 Traning Loss: tensor(0.0720)\n",
      "8628 Traning Loss: tensor(0.0730)\n",
      "8629 Traning Loss: tensor(0.0714)\n",
      "8630 Traning Loss: tensor(0.0713)\n",
      "8631 Traning Loss: tensor(0.0732)\n",
      "8632 Traning Loss: tensor(0.0729)\n",
      "8633 Traning Loss: tensor(0.0722)\n",
      "8634 Traning Loss: tensor(0.0731)\n",
      "8635 Traning Loss: tensor(0.0713)\n",
      "8636 Traning Loss: tensor(0.0728)\n",
      "8637 Traning Loss: tensor(0.0726)\n",
      "8638 Traning Loss: tensor(0.0718)\n",
      "8639 Traning Loss: tensor(0.0719)\n",
      "8640 Traning Loss: tensor(0.0718)\n",
      "8641 Traning Loss: tensor(0.0724)\n",
      "8642 Traning Loss: tensor(0.0719)\n",
      "8643 Traning Loss: tensor(0.0730)\n",
      "8644 Traning Loss: tensor(0.0715)\n",
      "8645 Traning Loss: tensor(0.0725)\n",
      "8646 Traning Loss: tensor(0.0717)\n",
      "8647 Traning Loss: tensor(0.0723)\n",
      "8648 Traning Loss: tensor(0.0723)\n",
      "8649 Traning Loss: tensor(0.0727)\n",
      "8650 Traning Loss: tensor(0.0706)\n",
      "8651 Traning Loss: tensor(0.0727)\n",
      "8652 Traning Loss: tensor(0.0723)\n",
      "8653 Traning Loss: tensor(0.0723)\n",
      "8654 Traning Loss: tensor(0.0724)\n",
      "8655 Traning Loss: tensor(0.0718)\n",
      "8656 Traning Loss: tensor(0.0720)\n",
      "8657 Traning Loss: tensor(0.0727)\n",
      "8658 Traning Loss: tensor(0.0722)\n",
      "8659 Traning Loss: tensor(0.0727)\n",
      "8660 Traning Loss: tensor(0.0723)\n",
      "8661 Traning Loss: tensor(0.0720)\n",
      "8662 Traning Loss: tensor(0.0721)\n",
      "8663 Traning Loss: tensor(0.0719)\n",
      "8664 Traning Loss: tensor(0.0720)\n",
      "8665 Traning Loss: tensor(0.0728)\n",
      "8666 Traning Loss: tensor(0.0715)\n",
      "8667 Traning Loss: tensor(0.0725)\n",
      "8668 Traning Loss: tensor(0.0726)\n",
      "8669 Traning Loss: tensor(0.0721)\n",
      "8670 Traning Loss: tensor(0.0725)\n",
      "8671 Traning Loss: tensor(0.0722)\n",
      "8672 Traning Loss: tensor(0.0724)\n",
      "8673 Traning Loss: tensor(0.0731)\n",
      "8674 Traning Loss: tensor(0.0713)\n",
      "8675 Traning Loss: tensor(0.0727)\n",
      "8676 Traning Loss: tensor(0.0731)\n",
      "8677 Traning Loss: tensor(0.0720)\n",
      "8678 Traning Loss: tensor(0.0720)\n",
      "8679 Traning Loss: tensor(0.0716)\n",
      "8680 Traning Loss: tensor(0.0719)\n",
      "8681 Traning Loss: tensor(0.0723)\n",
      "8682 Traning Loss: tensor(0.0732)\n",
      "8683 Traning Loss: tensor(0.0723)\n",
      "8684 Traning Loss: tensor(0.0732)\n",
      "8685 Traning Loss: tensor(0.0725)\n",
      "8686 Traning Loss: tensor(0.0712)\n",
      "8687 Traning Loss: tensor(0.0722)\n",
      "8688 Traning Loss: tensor(0.0726)\n",
      "8689 Traning Loss: tensor(0.0727)\n",
      "8690 Traning Loss: tensor(0.0719)\n",
      "8691 Traning Loss: tensor(0.0722)\n",
      "8692 Traning Loss: tensor(0.0716)\n",
      "8693 Traning Loss: tensor(0.0727)\n",
      "8694 Traning Loss: tensor(0.0724)\n",
      "8695 Traning Loss: tensor(0.0720)\n",
      "8696 Traning Loss: tensor(0.0723)\n",
      "8697 Traning Loss: tensor(0.0726)\n",
      "8698 Traning Loss: tensor(0.0721)\n",
      "8699 Traning Loss: tensor(0.0724)\n",
      "8700 Traning Loss: tensor(0.0725)\n",
      "8701 Traning Loss: tensor(0.0730)\n",
      "8702 Traning Loss: tensor(0.0722)\n",
      "8703 Traning Loss: tensor(0.0721)\n",
      "8704 Traning Loss: tensor(0.0726)\n",
      "8705 Traning Loss: tensor(0.0721)\n",
      "8706 Traning Loss: tensor(0.0723)\n",
      "8707 Traning Loss: tensor(0.0721)\n",
      "8708 Traning Loss: tensor(0.0715)\n",
      "8709 Traning Loss: tensor(0.0719)\n",
      "8710 Traning Loss: tensor(0.0724)\n",
      "8711 Traning Loss: tensor(0.0726)\n",
      "8712 Traning Loss: tensor(0.0723)\n",
      "8713 Traning Loss: tensor(0.0720)\n",
      "8714 Traning Loss: tensor(0.0730)\n",
      "8715 Traning Loss: tensor(0.0722)\n",
      "8716 Traning Loss: tensor(0.0715)\n",
      "8717 Traning Loss: tensor(0.0721)\n",
      "8718 Traning Loss: tensor(0.0721)\n",
      "8719 Traning Loss: tensor(0.0715)\n",
      "8720 Traning Loss: tensor(0.0714)\n",
      "8721 Traning Loss: tensor(0.0721)\n",
      "8722 Traning Loss: tensor(0.0718)\n",
      "8723 Traning Loss: tensor(0.0721)\n",
      "8724 Traning Loss: tensor(0.0723)\n",
      "8725 Traning Loss: tensor(0.0719)\n",
      "8726 Traning Loss: tensor(0.0708)\n",
      "8727 Traning Loss: tensor(0.0710)\n",
      "8728 Traning Loss: tensor(0.0713)\n",
      "8729 Traning Loss: tensor(0.0710)\n",
      "8730 Traning Loss: tensor(0.0723)\n",
      "8731 Traning Loss: tensor(0.0716)\n",
      "8732 Traning Loss: tensor(0.0721)\n",
      "8733 Traning Loss: tensor(0.0726)\n",
      "8734 Traning Loss: tensor(0.0713)\n",
      "8735 Traning Loss: tensor(0.0716)\n",
      "8736 Traning Loss: tensor(0.0710)\n",
      "8737 Traning Loss: tensor(0.0727)\n",
      "8738 Traning Loss: tensor(0.0723)\n",
      "8739 Traning Loss: tensor(0.0741)\n",
      "8740 Traning Loss: tensor(0.0725)\n",
      "8741 Traning Loss: tensor(0.0723)\n",
      "8742 Traning Loss: tensor(0.0722)\n",
      "8743 Traning Loss: tensor(0.0713)\n",
      "8744 Traning Loss: tensor(0.0721)\n",
      "8745 Traning Loss: tensor(0.0737)\n",
      "8746 Traning Loss: tensor(0.0710)\n",
      "8747 Traning Loss: tensor(0.0714)\n",
      "8748 Traning Loss: tensor(0.0719)\n",
      "8749 Traning Loss: tensor(0.0708)\n",
      "8750 Traning Loss: tensor(0.0709)\n",
      "8751 Traning Loss: tensor(0.0726)\n",
      "8752 Traning Loss: tensor(0.0714)\n",
      "8753 Traning Loss: tensor(0.0715)\n",
      "8754 Traning Loss: tensor(0.0709)\n",
      "8755 Traning Loss: tensor(0.0734)\n",
      "8756 Traning Loss: tensor(0.0725)\n",
      "8757 Traning Loss: tensor(0.0719)\n",
      "8758 Traning Loss: tensor(0.0712)\n",
      "8759 Traning Loss: tensor(0.0721)\n",
      "8760 Traning Loss: tensor(0.0719)\n",
      "8761 Traning Loss: tensor(0.0715)\n",
      "8762 Traning Loss: tensor(0.0717)\n",
      "8763 Traning Loss: tensor(0.0723)\n",
      "8764 Traning Loss: tensor(0.0704)\n",
      "8765 Traning Loss: tensor(0.0723)\n",
      "8766 Traning Loss: tensor(0.0701)\n",
      "8767 Traning Loss: tensor(0.0725)\n",
      "8768 Traning Loss: tensor(0.0713)\n",
      "8769 Traning Loss: tensor(0.0707)\n",
      "8770 Traning Loss: tensor(0.0720)\n",
      "8771 Traning Loss: tensor(0.0724)\n",
      "8772 Traning Loss: tensor(0.0715)\n",
      "8773 Traning Loss: tensor(0.0725)\n",
      "8774 Traning Loss: tensor(0.0722)\n",
      "8775 Traning Loss: tensor(0.0718)\n",
      "8776 Traning Loss: tensor(0.0725)\n",
      "8777 Traning Loss: tensor(0.0718)\n",
      "8778 Traning Loss: tensor(0.0715)\n",
      "8779 Traning Loss: tensor(0.0730)\n",
      "8780 Traning Loss: tensor(0.0712)\n",
      "8781 Traning Loss: tensor(0.0726)\n",
      "8782 Traning Loss: tensor(0.0721)\n",
      "8783 Traning Loss: tensor(0.0716)\n",
      "8784 Traning Loss: tensor(0.0714)\n",
      "8785 Traning Loss: tensor(0.0714)\n",
      "8786 Traning Loss: tensor(0.0716)\n",
      "8787 Traning Loss: tensor(0.0714)\n",
      "8788 Traning Loss: tensor(0.0720)\n",
      "8789 Traning Loss: tensor(0.0708)\n",
      "8790 Traning Loss: tensor(0.0710)\n",
      "8791 Traning Loss: tensor(0.0724)\n",
      "8792 Traning Loss: tensor(0.0721)\n",
      "8793 Traning Loss: tensor(0.0718)\n",
      "8794 Traning Loss: tensor(0.0727)\n",
      "8795 Traning Loss: tensor(0.0708)\n",
      "8796 Traning Loss: tensor(0.0718)\n",
      "8797 Traning Loss: tensor(0.0718)\n",
      "8798 Traning Loss: tensor(0.0717)\n",
      "8799 Traning Loss: tensor(0.0716)\n",
      "8800 Traning Loss: tensor(0.0721)\n",
      "8801 Traning Loss: tensor(0.0722)\n",
      "8802 Traning Loss: tensor(0.0713)\n",
      "8803 Traning Loss: tensor(0.0716)\n",
      "8804 Traning Loss: tensor(0.0714)\n",
      "8805 Traning Loss: tensor(0.0729)\n",
      "8806 Traning Loss: tensor(0.0720)\n",
      "8807 Traning Loss: tensor(0.0720)\n",
      "8808 Traning Loss: tensor(0.0715)\n",
      "8809 Traning Loss: tensor(0.0726)\n",
      "8810 Traning Loss: tensor(0.0720)\n",
      "8811 Traning Loss: tensor(0.0722)\n",
      "8812 Traning Loss: tensor(0.0719)\n",
      "8813 Traning Loss: tensor(0.0708)\n",
      "8814 Traning Loss: tensor(0.0709)\n",
      "8815 Traning Loss: tensor(0.0717)\n",
      "8816 Traning Loss: tensor(0.0737)\n",
      "8817 Traning Loss: tensor(0.0716)\n",
      "8818 Traning Loss: tensor(0.0720)\n",
      "8819 Traning Loss: tensor(0.0713)\n",
      "8820 Traning Loss: tensor(0.0723)\n",
      "8821 Traning Loss: tensor(0.0726)\n",
      "8822 Traning Loss: tensor(0.0714)\n",
      "8823 Traning Loss: tensor(0.0717)\n",
      "8824 Traning Loss: tensor(0.0721)\n",
      "8825 Traning Loss: tensor(0.0714)\n",
      "8826 Traning Loss: tensor(0.0719)\n",
      "8827 Traning Loss: tensor(0.0720)\n",
      "8828 Traning Loss: tensor(0.0712)\n",
      "8829 Traning Loss: tensor(0.0714)\n",
      "8830 Traning Loss: tensor(0.0713)\n",
      "8831 Traning Loss: tensor(0.0712)\n",
      "8832 Traning Loss: tensor(0.0726)\n",
      "8833 Traning Loss: tensor(0.0717)\n",
      "8834 Traning Loss: tensor(0.0726)\n",
      "8835 Traning Loss: tensor(0.0709)\n",
      "8836 Traning Loss: tensor(0.0721)\n",
      "8837 Traning Loss: tensor(0.0715)\n",
      "8838 Traning Loss: tensor(0.0712)\n",
      "8839 Traning Loss: tensor(0.0720)\n",
      "8840 Traning Loss: tensor(0.0719)\n",
      "8841 Traning Loss: tensor(0.0715)\n",
      "8842 Traning Loss: tensor(0.0713)\n",
      "8843 Traning Loss: tensor(0.0718)\n",
      "8844 Traning Loss: tensor(0.0723)\n",
      "8845 Traning Loss: tensor(0.0710)\n",
      "8846 Traning Loss: tensor(0.0708)\n",
      "8847 Traning Loss: tensor(0.0719)\n",
      "8848 Traning Loss: tensor(0.0719)\n",
      "8849 Traning Loss: tensor(0.0720)\n",
      "8850 Traning Loss: tensor(0.0714)\n",
      "8851 Traning Loss: tensor(0.0715)\n",
      "8852 Traning Loss: tensor(0.0718)\n",
      "8853 Traning Loss: tensor(0.0716)\n",
      "8854 Traning Loss: tensor(0.0729)\n",
      "8855 Traning Loss: tensor(0.0724)\n",
      "8856 Traning Loss: tensor(0.0709)\n",
      "8857 Traning Loss: tensor(0.0714)\n",
      "8858 Traning Loss: tensor(0.0717)\n",
      "8859 Traning Loss: tensor(0.0727)\n",
      "8860 Traning Loss: tensor(0.0726)\n",
      "8861 Traning Loss: tensor(0.0716)\n",
      "8862 Traning Loss: tensor(0.0716)\n",
      "8863 Traning Loss: tensor(0.0704)\n",
      "8864 Traning Loss: tensor(0.0711)\n",
      "8865 Traning Loss: tensor(0.0716)\n",
      "8866 Traning Loss: tensor(0.0718)\n",
      "8867 Traning Loss: tensor(0.0711)\n",
      "8868 Traning Loss: tensor(0.0717)\n",
      "8869 Traning Loss: tensor(0.0725)\n",
      "8870 Traning Loss: tensor(0.0718)\n",
      "8871 Traning Loss: tensor(0.0715)\n",
      "8872 Traning Loss: tensor(0.0717)\n",
      "8873 Traning Loss: tensor(0.0728)\n",
      "8874 Traning Loss: tensor(0.0724)\n",
      "8875 Traning Loss: tensor(0.0718)\n",
      "8876 Traning Loss: tensor(0.0724)\n",
      "8877 Traning Loss: tensor(0.0715)\n",
      "8878 Traning Loss: tensor(0.0717)\n",
      "8879 Traning Loss: tensor(0.0713)\n",
      "8880 Traning Loss: tensor(0.0715)\n",
      "8881 Traning Loss: tensor(0.0707)\n",
      "8882 Traning Loss: tensor(0.0707)\n",
      "8883 Traning Loss: tensor(0.0714)\n",
      "8884 Traning Loss: tensor(0.0719)\n",
      "8885 Traning Loss: tensor(0.0707)\n",
      "8886 Traning Loss: tensor(0.0715)\n",
      "8887 Traning Loss: tensor(0.0707)\n",
      "8888 Traning Loss: tensor(0.0708)\n",
      "8889 Traning Loss: tensor(0.0712)\n",
      "8890 Traning Loss: tensor(0.0714)\n",
      "8891 Traning Loss: tensor(0.0701)\n",
      "8892 Traning Loss: tensor(0.0704)\n",
      "8893 Traning Loss: tensor(0.0725)\n",
      "8894 Traning Loss: tensor(0.0723)\n",
      "8895 Traning Loss: tensor(0.0715)\n",
      "8896 Traning Loss: tensor(0.0723)\n",
      "8897 Traning Loss: tensor(0.0724)\n",
      "8898 Traning Loss: tensor(0.0723)\n",
      "8899 Traning Loss: tensor(0.0726)\n",
      "8900 Traning Loss: tensor(0.0718)\n",
      "8901 Traning Loss: tensor(0.0720)\n",
      "8902 Traning Loss: tensor(0.0719)\n",
      "8903 Traning Loss: tensor(0.0719)\n",
      "8904 Traning Loss: tensor(0.0706)\n",
      "8905 Traning Loss: tensor(0.0708)\n",
      "8906 Traning Loss: tensor(0.0708)\n",
      "8907 Traning Loss: tensor(0.0715)\n",
      "8908 Traning Loss: tensor(0.0717)\n",
      "8909 Traning Loss: tensor(0.0703)\n",
      "8910 Traning Loss: tensor(0.0719)\n",
      "8911 Traning Loss: tensor(0.0709)\n",
      "8912 Traning Loss: tensor(0.0711)\n",
      "8913 Traning Loss: tensor(0.0703)\n",
      "8914 Traning Loss: tensor(0.0707)\n",
      "8915 Traning Loss: tensor(0.0710)\n",
      "8916 Traning Loss: tensor(0.0718)\n",
      "8917 Traning Loss: tensor(0.0720)\n",
      "8918 Traning Loss: tensor(0.0712)\n",
      "8919 Traning Loss: tensor(0.0708)\n",
      "8920 Traning Loss: tensor(0.0714)\n",
      "8921 Traning Loss: tensor(0.0720)\n",
      "8922 Traning Loss: tensor(0.0713)\n",
      "8923 Traning Loss: tensor(0.0715)\n",
      "8924 Traning Loss: tensor(0.0713)\n",
      "8925 Traning Loss: tensor(0.0712)\n",
      "8926 Traning Loss: tensor(0.0712)\n",
      "8927 Traning Loss: tensor(0.0702)\n",
      "8928 Traning Loss: tensor(0.0709)\n",
      "8929 Traning Loss: tensor(0.0716)\n",
      "8930 Traning Loss: tensor(0.0713)\n",
      "8931 Traning Loss: tensor(0.0718)\n",
      "8932 Traning Loss: tensor(0.0694)\n",
      "8933 Traning Loss: tensor(0.0709)\n",
      "8934 Traning Loss: tensor(0.0708)\n",
      "8935 Traning Loss: tensor(0.0721)\n",
      "8936 Traning Loss: tensor(0.0715)\n",
      "8937 Traning Loss: tensor(0.0712)\n",
      "8938 Traning Loss: tensor(0.0711)\n",
      "8939 Traning Loss: tensor(0.0711)\n",
      "8940 Traning Loss: tensor(0.0715)\n",
      "8941 Traning Loss: tensor(0.0710)\n",
      "8942 Traning Loss: tensor(0.0701)\n",
      "8943 Traning Loss: tensor(0.0712)\n",
      "8944 Traning Loss: tensor(0.0719)\n",
      "8945 Traning Loss: tensor(0.0713)\n",
      "8946 Traning Loss: tensor(0.0717)\n",
      "8947 Traning Loss: tensor(0.0723)\n",
      "8948 Traning Loss: tensor(0.0707)\n",
      "8949 Traning Loss: tensor(0.0709)\n",
      "8950 Traning Loss: tensor(0.0703)\n",
      "8951 Traning Loss: tensor(0.0708)\n",
      "8952 Traning Loss: tensor(0.0712)\n",
      "8953 Traning Loss: tensor(0.0703)\n",
      "8954 Traning Loss: tensor(0.0711)\n",
      "8955 Traning Loss: tensor(0.0720)\n",
      "8956 Traning Loss: tensor(0.0712)\n",
      "8957 Traning Loss: tensor(0.0715)\n",
      "8958 Traning Loss: tensor(0.0711)\n",
      "8959 Traning Loss: tensor(0.0718)\n",
      "8960 Traning Loss: tensor(0.0713)\n",
      "8961 Traning Loss: tensor(0.0716)\n",
      "8962 Traning Loss: tensor(0.0710)\n",
      "8963 Traning Loss: tensor(0.0698)\n",
      "8964 Traning Loss: tensor(0.0712)\n",
      "8965 Traning Loss: tensor(0.0716)\n",
      "8966 Traning Loss: tensor(0.0707)\n",
      "8967 Traning Loss: tensor(0.0712)\n",
      "8968 Traning Loss: tensor(0.0706)\n",
      "8969 Traning Loss: tensor(0.0701)\n",
      "8970 Traning Loss: tensor(0.0700)\n",
      "8971 Traning Loss: tensor(0.0702)\n",
      "8972 Traning Loss: tensor(0.0708)\n",
      "8973 Traning Loss: tensor(0.0717)\n",
      "8974 Traning Loss: tensor(0.0714)\n",
      "8975 Traning Loss: tensor(0.0715)\n",
      "8976 Traning Loss: tensor(0.0720)\n",
      "8977 Traning Loss: tensor(0.0726)\n",
      "8978 Traning Loss: tensor(0.0715)\n",
      "8979 Traning Loss: tensor(0.0712)\n",
      "8980 Traning Loss: tensor(0.0719)\n",
      "8981 Traning Loss: tensor(0.0709)\n",
      "8982 Traning Loss: tensor(0.0707)\n",
      "8983 Traning Loss: tensor(0.0713)\n",
      "8984 Traning Loss: tensor(0.0701)\n",
      "8985 Traning Loss: tensor(0.0716)\n",
      "8986 Traning Loss: tensor(0.0712)\n",
      "8987 Traning Loss: tensor(0.0716)\n",
      "8988 Traning Loss: tensor(0.0698)\n",
      "8989 Traning Loss: tensor(0.0715)\n",
      "8990 Traning Loss: tensor(0.0717)\n",
      "8991 Traning Loss: tensor(0.0707)\n",
      "8992 Traning Loss: tensor(0.0706)\n",
      "8993 Traning Loss: tensor(0.0706)\n",
      "8994 Traning Loss: tensor(0.0703)\n",
      "8995 Traning Loss: tensor(0.0710)\n",
      "8996 Traning Loss: tensor(0.0716)\n",
      "8997 Traning Loss: tensor(0.0706)\n",
      "8998 Traning Loss: tensor(0.0704)\n",
      "8999 Traning Loss: tensor(0.0710)\n",
      "9000 Traning Loss: tensor(0.0712)\n",
      "9001 Traning Loss: tensor(0.0723)\n",
      "9002 Traning Loss: tensor(0.0712)\n",
      "9003 Traning Loss: tensor(0.0710)\n",
      "9004 Traning Loss: tensor(0.0713)\n",
      "9005 Traning Loss: tensor(0.0716)\n",
      "9006 Traning Loss: tensor(0.0706)\n",
      "9007 Traning Loss: tensor(0.0707)\n",
      "9008 Traning Loss: tensor(0.0706)\n",
      "9009 Traning Loss: tensor(0.0717)\n",
      "9010 Traning Loss: tensor(0.0710)\n",
      "9011 Traning Loss: tensor(0.0715)\n",
      "9012 Traning Loss: tensor(0.0719)\n",
      "9013 Traning Loss: tensor(0.0713)\n",
      "9014 Traning Loss: tensor(0.0707)\n",
      "9015 Traning Loss: tensor(0.0705)\n",
      "9016 Traning Loss: tensor(0.0705)\n",
      "9017 Traning Loss: tensor(0.0715)\n",
      "9018 Traning Loss: tensor(0.0710)\n",
      "9019 Traning Loss: tensor(0.0707)\n",
      "9020 Traning Loss: tensor(0.0712)\n",
      "9021 Traning Loss: tensor(0.0709)\n",
      "9022 Traning Loss: tensor(0.0721)\n",
      "9023 Traning Loss: tensor(0.0691)\n",
      "9024 Traning Loss: tensor(0.0703)\n",
      "9025 Traning Loss: tensor(0.0707)\n",
      "9026 Traning Loss: tensor(0.0704)\n",
      "9027 Traning Loss: tensor(0.0707)\n",
      "9028 Traning Loss: tensor(0.0711)\n",
      "9029 Traning Loss: tensor(0.0703)\n",
      "9030 Traning Loss: tensor(0.0711)\n",
      "9031 Traning Loss: tensor(0.0711)\n",
      "9032 Traning Loss: tensor(0.0707)\n",
      "9033 Traning Loss: tensor(0.0708)\n",
      "9034 Traning Loss: tensor(0.0708)\n",
      "9035 Traning Loss: tensor(0.0718)\n",
      "9036 Traning Loss: tensor(0.0712)\n",
      "9037 Traning Loss: tensor(0.0704)\n",
      "9038 Traning Loss: tensor(0.0715)\n",
      "9039 Traning Loss: tensor(0.0705)\n",
      "9040 Traning Loss: tensor(0.0719)\n",
      "9041 Traning Loss: tensor(0.0711)\n",
      "9042 Traning Loss: tensor(0.0714)\n",
      "9043 Traning Loss: tensor(0.0708)\n",
      "9044 Traning Loss: tensor(0.0710)\n",
      "9045 Traning Loss: tensor(0.0699)\n",
      "9046 Traning Loss: tensor(0.0703)\n",
      "9047 Traning Loss: tensor(0.0710)\n",
      "9048 Traning Loss: tensor(0.0709)\n",
      "9049 Traning Loss: tensor(0.0712)\n",
      "9050 Traning Loss: tensor(0.0698)\n",
      "9051 Traning Loss: tensor(0.0707)\n",
      "9052 Traning Loss: tensor(0.0706)\n",
      "9053 Traning Loss: tensor(0.0713)\n",
      "9054 Traning Loss: tensor(0.0711)\n",
      "9055 Traning Loss: tensor(0.0721)\n",
      "9056 Traning Loss: tensor(0.0712)\n",
      "9057 Traning Loss: tensor(0.0721)\n",
      "9058 Traning Loss: tensor(0.0714)\n",
      "9059 Traning Loss: tensor(0.0715)\n",
      "9060 Traning Loss: tensor(0.0713)\n",
      "9061 Traning Loss: tensor(0.0705)\n",
      "9062 Traning Loss: tensor(0.0712)\n",
      "9063 Traning Loss: tensor(0.0707)\n",
      "9064 Traning Loss: tensor(0.0703)\n",
      "9065 Traning Loss: tensor(0.0705)\n",
      "9066 Traning Loss: tensor(0.0717)\n",
      "9067 Traning Loss: tensor(0.0701)\n",
      "9068 Traning Loss: tensor(0.0717)\n",
      "9069 Traning Loss: tensor(0.0695)\n",
      "9070 Traning Loss: tensor(0.0699)\n",
      "9071 Traning Loss: tensor(0.0707)\n",
      "9072 Traning Loss: tensor(0.0711)\n",
      "9073 Traning Loss: tensor(0.0699)\n",
      "9074 Traning Loss: tensor(0.0713)\n",
      "9075 Traning Loss: tensor(0.0718)\n",
      "9076 Traning Loss: tensor(0.0707)\n",
      "9077 Traning Loss: tensor(0.0716)\n",
      "9078 Traning Loss: tensor(0.0705)\n",
      "9079 Traning Loss: tensor(0.0699)\n",
      "9080 Traning Loss: tensor(0.0707)\n",
      "9081 Traning Loss: tensor(0.0701)\n",
      "9082 Traning Loss: tensor(0.0700)\n",
      "9083 Traning Loss: tensor(0.0709)\n",
      "9084 Traning Loss: tensor(0.0711)\n",
      "9085 Traning Loss: tensor(0.0706)\n",
      "9086 Traning Loss: tensor(0.0715)\n",
      "9087 Traning Loss: tensor(0.0706)\n",
      "9088 Traning Loss: tensor(0.0711)\n",
      "9089 Traning Loss: tensor(0.0702)\n",
      "9090 Traning Loss: tensor(0.0708)\n",
      "9091 Traning Loss: tensor(0.0714)\n",
      "9092 Traning Loss: tensor(0.0695)\n",
      "9093 Traning Loss: tensor(0.0706)\n",
      "9094 Traning Loss: tensor(0.0700)\n",
      "9095 Traning Loss: tensor(0.0693)\n",
      "9096 Traning Loss: tensor(0.0714)\n",
      "9097 Traning Loss: tensor(0.0695)\n",
      "9098 Traning Loss: tensor(0.0711)\n",
      "9099 Traning Loss: tensor(0.0712)\n",
      "9100 Traning Loss: tensor(0.0708)\n",
      "9101 Traning Loss: tensor(0.0702)\n",
      "9102 Traning Loss: tensor(0.0701)\n",
      "9103 Traning Loss: tensor(0.0709)\n",
      "9104 Traning Loss: tensor(0.0712)\n",
      "9105 Traning Loss: tensor(0.0712)\n",
      "9106 Traning Loss: tensor(0.0715)\n",
      "9107 Traning Loss: tensor(0.0699)\n",
      "9108 Traning Loss: tensor(0.0696)\n",
      "9109 Traning Loss: tensor(0.0705)\n",
      "9110 Traning Loss: tensor(0.0705)\n",
      "9111 Traning Loss: tensor(0.0715)\n",
      "9112 Traning Loss: tensor(0.0703)\n",
      "9113 Traning Loss: tensor(0.0713)\n",
      "9114 Traning Loss: tensor(0.0700)\n",
      "9115 Traning Loss: tensor(0.0715)\n",
      "9116 Traning Loss: tensor(0.0702)\n",
      "9117 Traning Loss: tensor(0.0704)\n",
      "9118 Traning Loss: tensor(0.0706)\n",
      "9119 Traning Loss: tensor(0.0703)\n",
      "9120 Traning Loss: tensor(0.0705)\n",
      "9121 Traning Loss: tensor(0.0700)\n",
      "9122 Traning Loss: tensor(0.0695)\n",
      "9123 Traning Loss: tensor(0.0698)\n",
      "9124 Traning Loss: tensor(0.0703)\n",
      "9125 Traning Loss: tensor(0.0707)\n",
      "9126 Traning Loss: tensor(0.0716)\n",
      "9127 Traning Loss: tensor(0.0706)\n",
      "9128 Traning Loss: tensor(0.0712)\n",
      "9129 Traning Loss: tensor(0.0703)\n",
      "9130 Traning Loss: tensor(0.0706)\n",
      "9131 Traning Loss: tensor(0.0712)\n",
      "9132 Traning Loss: tensor(0.0700)\n",
      "9133 Traning Loss: tensor(0.0703)\n",
      "9134 Traning Loss: tensor(0.0711)\n",
      "9135 Traning Loss: tensor(0.0706)\n",
      "9136 Traning Loss: tensor(0.0697)\n",
      "9137 Traning Loss: tensor(0.0720)\n",
      "9138 Traning Loss: tensor(0.0720)\n",
      "9139 Traning Loss: tensor(0.0700)\n",
      "9140 Traning Loss: tensor(0.0701)\n",
      "9141 Traning Loss: tensor(0.0702)\n",
      "9142 Traning Loss: tensor(0.0709)\n",
      "9143 Traning Loss: tensor(0.0703)\n",
      "9144 Traning Loss: tensor(0.0705)\n",
      "9145 Traning Loss: tensor(0.0704)\n",
      "9146 Traning Loss: tensor(0.0707)\n",
      "9147 Traning Loss: tensor(0.0720)\n",
      "9148 Traning Loss: tensor(0.0700)\n",
      "9149 Traning Loss: tensor(0.0699)\n",
      "9150 Traning Loss: tensor(0.0705)\n",
      "9151 Traning Loss: tensor(0.0703)\n",
      "9152 Traning Loss: tensor(0.0706)\n",
      "9153 Traning Loss: tensor(0.0698)\n",
      "9154 Traning Loss: tensor(0.0703)\n",
      "9155 Traning Loss: tensor(0.0703)\n",
      "9156 Traning Loss: tensor(0.0698)\n",
      "9157 Traning Loss: tensor(0.0704)\n",
      "9158 Traning Loss: tensor(0.0717)\n",
      "9159 Traning Loss: tensor(0.0694)\n",
      "9160 Traning Loss: tensor(0.0693)\n",
      "9161 Traning Loss: tensor(0.0709)\n",
      "9162 Traning Loss: tensor(0.0715)\n",
      "9163 Traning Loss: tensor(0.0712)\n",
      "9164 Traning Loss: tensor(0.0708)\n",
      "9165 Traning Loss: tensor(0.0700)\n",
      "9166 Traning Loss: tensor(0.0706)\n",
      "9167 Traning Loss: tensor(0.0699)\n",
      "9168 Traning Loss: tensor(0.0699)\n",
      "9169 Traning Loss: tensor(0.0701)\n",
      "9170 Traning Loss: tensor(0.0708)\n",
      "9171 Traning Loss: tensor(0.0699)\n",
      "9172 Traning Loss: tensor(0.0714)\n",
      "9173 Traning Loss: tensor(0.0714)\n",
      "9174 Traning Loss: tensor(0.0696)\n",
      "9175 Traning Loss: tensor(0.0703)\n",
      "9176 Traning Loss: tensor(0.0700)\n",
      "9177 Traning Loss: tensor(0.0704)\n",
      "9178 Traning Loss: tensor(0.0713)\n",
      "9179 Traning Loss: tensor(0.0703)\n",
      "9180 Traning Loss: tensor(0.0704)\n",
      "9181 Traning Loss: tensor(0.0709)\n",
      "9182 Traning Loss: tensor(0.0710)\n",
      "9183 Traning Loss: tensor(0.0709)\n",
      "9184 Traning Loss: tensor(0.0705)\n",
      "9185 Traning Loss: tensor(0.0700)\n",
      "9186 Traning Loss: tensor(0.0705)\n",
      "9187 Traning Loss: tensor(0.0697)\n",
      "9188 Traning Loss: tensor(0.0701)\n",
      "9189 Traning Loss: tensor(0.0708)\n",
      "9190 Traning Loss: tensor(0.0699)\n",
      "9191 Traning Loss: tensor(0.0710)\n",
      "9192 Traning Loss: tensor(0.0698)\n",
      "9193 Traning Loss: tensor(0.0706)\n",
      "9194 Traning Loss: tensor(0.0697)\n",
      "9195 Traning Loss: tensor(0.0702)\n",
      "9196 Traning Loss: tensor(0.0701)\n",
      "9197 Traning Loss: tensor(0.0708)\n",
      "9198 Traning Loss: tensor(0.0698)\n",
      "9199 Traning Loss: tensor(0.0709)\n",
      "9200 Traning Loss: tensor(0.0708)\n",
      "9201 Traning Loss: tensor(0.0700)\n",
      "9202 Traning Loss: tensor(0.0699)\n",
      "9203 Traning Loss: tensor(0.0710)\n",
      "9204 Traning Loss: tensor(0.0703)\n",
      "9205 Traning Loss: tensor(0.0701)\n",
      "9206 Traning Loss: tensor(0.0696)\n",
      "9207 Traning Loss: tensor(0.0705)\n",
      "9208 Traning Loss: tensor(0.0706)\n",
      "9209 Traning Loss: tensor(0.0714)\n",
      "9210 Traning Loss: tensor(0.0713)\n",
      "9211 Traning Loss: tensor(0.0694)\n",
      "9212 Traning Loss: tensor(0.0716)\n",
      "9213 Traning Loss: tensor(0.0697)\n",
      "9214 Traning Loss: tensor(0.0710)\n",
      "9215 Traning Loss: tensor(0.0703)\n",
      "9216 Traning Loss: tensor(0.0701)\n",
      "9217 Traning Loss: tensor(0.0696)\n",
      "9218 Traning Loss: tensor(0.0713)\n",
      "9219 Traning Loss: tensor(0.0699)\n",
      "9220 Traning Loss: tensor(0.0705)\n",
      "9221 Traning Loss: tensor(0.0704)\n",
      "9222 Traning Loss: tensor(0.0701)\n",
      "9223 Traning Loss: tensor(0.0706)\n",
      "9224 Traning Loss: tensor(0.0697)\n",
      "9225 Traning Loss: tensor(0.0699)\n",
      "9226 Traning Loss: tensor(0.0702)\n",
      "9227 Traning Loss: tensor(0.0704)\n",
      "9228 Traning Loss: tensor(0.0686)\n",
      "9229 Traning Loss: tensor(0.0709)\n",
      "9230 Traning Loss: tensor(0.0707)\n",
      "9231 Traning Loss: tensor(0.0699)\n",
      "9232 Traning Loss: tensor(0.0706)\n",
      "9233 Traning Loss: tensor(0.0707)\n",
      "9234 Traning Loss: tensor(0.0706)\n",
      "9235 Traning Loss: tensor(0.0695)\n",
      "9236 Traning Loss: tensor(0.0692)\n",
      "9237 Traning Loss: tensor(0.0693)\n",
      "9238 Traning Loss: tensor(0.0699)\n",
      "9239 Traning Loss: tensor(0.0709)\n",
      "9240 Traning Loss: tensor(0.0697)\n",
      "9241 Traning Loss: tensor(0.0698)\n",
      "9242 Traning Loss: tensor(0.0707)\n",
      "9243 Traning Loss: tensor(0.0702)\n",
      "9244 Traning Loss: tensor(0.0709)\n",
      "9245 Traning Loss: tensor(0.0698)\n",
      "9246 Traning Loss: tensor(0.0707)\n",
      "9247 Traning Loss: tensor(0.0700)\n",
      "9248 Traning Loss: tensor(0.0710)\n",
      "9249 Traning Loss: tensor(0.0723)\n",
      "9250 Traning Loss: tensor(0.0697)\n",
      "9251 Traning Loss: tensor(0.0698)\n",
      "9252 Traning Loss: tensor(0.0704)\n",
      "9253 Traning Loss: tensor(0.0703)\n",
      "9254 Traning Loss: tensor(0.0706)\n",
      "9255 Traning Loss: tensor(0.0709)\n",
      "9256 Traning Loss: tensor(0.0695)\n",
      "9257 Traning Loss: tensor(0.0690)\n",
      "9258 Traning Loss: tensor(0.0692)\n",
      "9259 Traning Loss: tensor(0.0690)\n",
      "9260 Traning Loss: tensor(0.0693)\n",
      "9261 Traning Loss: tensor(0.0699)\n",
      "9262 Traning Loss: tensor(0.0705)\n",
      "9263 Traning Loss: tensor(0.0710)\n",
      "9264 Traning Loss: tensor(0.0694)\n",
      "9265 Traning Loss: tensor(0.0694)\n",
      "9266 Traning Loss: tensor(0.0700)\n",
      "9267 Traning Loss: tensor(0.0685)\n",
      "9268 Traning Loss: tensor(0.0699)\n",
      "9269 Traning Loss: tensor(0.0702)\n",
      "9270 Traning Loss: tensor(0.0697)\n",
      "9271 Traning Loss: tensor(0.0685)\n",
      "9272 Traning Loss: tensor(0.0690)\n",
      "9273 Traning Loss: tensor(0.0707)\n",
      "9274 Traning Loss: tensor(0.0689)\n",
      "9275 Traning Loss: tensor(0.0696)\n",
      "9276 Traning Loss: tensor(0.0692)\n",
      "9277 Traning Loss: tensor(0.0710)\n",
      "9278 Traning Loss: tensor(0.0697)\n",
      "9279 Traning Loss: tensor(0.0711)\n",
      "9280 Traning Loss: tensor(0.0699)\n",
      "9281 Traning Loss: tensor(0.0705)\n",
      "9282 Traning Loss: tensor(0.0694)\n",
      "9283 Traning Loss: tensor(0.0702)\n",
      "9284 Traning Loss: tensor(0.0700)\n",
      "9285 Traning Loss: tensor(0.0698)\n",
      "9286 Traning Loss: tensor(0.0695)\n",
      "9287 Traning Loss: tensor(0.0697)\n",
      "9288 Traning Loss: tensor(0.0696)\n",
      "9289 Traning Loss: tensor(0.0708)\n",
      "9290 Traning Loss: tensor(0.0707)\n",
      "9291 Traning Loss: tensor(0.0703)\n",
      "9292 Traning Loss: tensor(0.0705)\n",
      "9293 Traning Loss: tensor(0.0691)\n",
      "9294 Traning Loss: tensor(0.0692)\n",
      "9295 Traning Loss: tensor(0.0699)\n",
      "9296 Traning Loss: tensor(0.0706)\n",
      "9297 Traning Loss: tensor(0.0715)\n",
      "9298 Traning Loss: tensor(0.0704)\n",
      "9299 Traning Loss: tensor(0.0692)\n",
      "9300 Traning Loss: tensor(0.0691)\n",
      "9301 Traning Loss: tensor(0.0711)\n",
      "9302 Traning Loss: tensor(0.0696)\n",
      "9303 Traning Loss: tensor(0.0691)\n",
      "9304 Traning Loss: tensor(0.0696)\n",
      "9305 Traning Loss: tensor(0.0697)\n",
      "9306 Traning Loss: tensor(0.0691)\n",
      "9307 Traning Loss: tensor(0.0695)\n",
      "9308 Traning Loss: tensor(0.0703)\n",
      "9309 Traning Loss: tensor(0.0701)\n",
      "9310 Traning Loss: tensor(0.0690)\n",
      "9311 Traning Loss: tensor(0.0695)\n",
      "9312 Traning Loss: tensor(0.0697)\n",
      "9313 Traning Loss: tensor(0.0707)\n",
      "9314 Traning Loss: tensor(0.0690)\n",
      "9315 Traning Loss: tensor(0.0687)\n",
      "9316 Traning Loss: tensor(0.0699)\n",
      "9317 Traning Loss: tensor(0.0686)\n",
      "9318 Traning Loss: tensor(0.0694)\n",
      "9319 Traning Loss: tensor(0.0699)\n",
      "9320 Traning Loss: tensor(0.0696)\n",
      "9321 Traning Loss: tensor(0.0708)\n",
      "9322 Traning Loss: tensor(0.0710)\n",
      "9323 Traning Loss: tensor(0.0692)\n",
      "9324 Traning Loss: tensor(0.0693)\n",
      "9325 Traning Loss: tensor(0.0684)\n",
      "9326 Traning Loss: tensor(0.0689)\n",
      "9327 Traning Loss: tensor(0.0699)\n",
      "9328 Traning Loss: tensor(0.0696)\n",
      "9329 Traning Loss: tensor(0.0699)\n",
      "9330 Traning Loss: tensor(0.0700)\n",
      "9331 Traning Loss: tensor(0.0701)\n",
      "9332 Traning Loss: tensor(0.0691)\n",
      "9333 Traning Loss: tensor(0.0693)\n",
      "9334 Traning Loss: tensor(0.0691)\n",
      "9335 Traning Loss: tensor(0.0694)\n",
      "9336 Traning Loss: tensor(0.0702)\n",
      "9337 Traning Loss: tensor(0.0701)\n",
      "9338 Traning Loss: tensor(0.0692)\n",
      "9339 Traning Loss: tensor(0.0703)\n",
      "9340 Traning Loss: tensor(0.0698)\n",
      "9341 Traning Loss: tensor(0.0698)\n",
      "9342 Traning Loss: tensor(0.0698)\n",
      "9343 Traning Loss: tensor(0.0693)\n",
      "9344 Traning Loss: tensor(0.0687)\n",
      "9345 Traning Loss: tensor(0.0697)\n",
      "9346 Traning Loss: tensor(0.0692)\n",
      "9347 Traning Loss: tensor(0.0705)\n",
      "9348 Traning Loss: tensor(0.0697)\n",
      "9349 Traning Loss: tensor(0.0704)\n",
      "9350 Traning Loss: tensor(0.0699)\n",
      "9351 Traning Loss: tensor(0.0700)\n",
      "9352 Traning Loss: tensor(0.0707)\n",
      "9353 Traning Loss: tensor(0.0695)\n",
      "9354 Traning Loss: tensor(0.0687)\n",
      "9355 Traning Loss: tensor(0.0695)\n",
      "9356 Traning Loss: tensor(0.0695)\n",
      "9357 Traning Loss: tensor(0.0698)\n",
      "9358 Traning Loss: tensor(0.0684)\n",
      "9359 Traning Loss: tensor(0.0693)\n",
      "9360 Traning Loss: tensor(0.0689)\n",
      "9361 Traning Loss: tensor(0.0690)\n",
      "9362 Traning Loss: tensor(0.0690)\n",
      "9363 Traning Loss: tensor(0.0698)\n",
      "9364 Traning Loss: tensor(0.0682)\n",
      "9365 Traning Loss: tensor(0.0700)\n",
      "9366 Traning Loss: tensor(0.0704)\n",
      "9367 Traning Loss: tensor(0.0690)\n",
      "9368 Traning Loss: tensor(0.0701)\n",
      "9369 Traning Loss: tensor(0.0695)\n",
      "9370 Traning Loss: tensor(0.0711)\n",
      "9371 Traning Loss: tensor(0.0685)\n",
      "9372 Traning Loss: tensor(0.0699)\n",
      "9373 Traning Loss: tensor(0.0699)\n",
      "9374 Traning Loss: tensor(0.0700)\n",
      "9375 Traning Loss: tensor(0.0695)\n",
      "9376 Traning Loss: tensor(0.0694)\n",
      "9377 Traning Loss: tensor(0.0703)\n",
      "9378 Traning Loss: tensor(0.0700)\n",
      "9379 Traning Loss: tensor(0.0691)\n",
      "9380 Traning Loss: tensor(0.0699)\n",
      "9381 Traning Loss: tensor(0.0697)\n",
      "9382 Traning Loss: tensor(0.0689)\n",
      "9383 Traning Loss: tensor(0.0694)\n",
      "9384 Traning Loss: tensor(0.0693)\n",
      "9385 Traning Loss: tensor(0.0701)\n",
      "9386 Traning Loss: tensor(0.0703)\n",
      "9387 Traning Loss: tensor(0.0702)\n",
      "9388 Traning Loss: tensor(0.0697)\n",
      "9389 Traning Loss: tensor(0.0692)\n",
      "9390 Traning Loss: tensor(0.0701)\n",
      "9391 Traning Loss: tensor(0.0698)\n",
      "9392 Traning Loss: tensor(0.0690)\n",
      "9393 Traning Loss: tensor(0.0689)\n",
      "9394 Traning Loss: tensor(0.0695)\n",
      "9395 Traning Loss: tensor(0.0711)\n",
      "9396 Traning Loss: tensor(0.0699)\n",
      "9397 Traning Loss: tensor(0.0695)\n",
      "9398 Traning Loss: tensor(0.0694)\n",
      "9399 Traning Loss: tensor(0.0679)\n",
      "9400 Traning Loss: tensor(0.0698)\n",
      "9401 Traning Loss: tensor(0.0702)\n",
      "9402 Traning Loss: tensor(0.0698)\n",
      "9403 Traning Loss: tensor(0.0706)\n",
      "9404 Traning Loss: tensor(0.0709)\n",
      "9405 Traning Loss: tensor(0.0686)\n",
      "9406 Traning Loss: tensor(0.0690)\n",
      "9407 Traning Loss: tensor(0.0692)\n",
      "9408 Traning Loss: tensor(0.0698)\n",
      "9409 Traning Loss: tensor(0.0684)\n",
      "9410 Traning Loss: tensor(0.0692)\n",
      "9411 Traning Loss: tensor(0.0683)\n",
      "9412 Traning Loss: tensor(0.0682)\n",
      "9413 Traning Loss: tensor(0.0686)\n",
      "9414 Traning Loss: tensor(0.0692)\n",
      "9415 Traning Loss: tensor(0.0688)\n",
      "9416 Traning Loss: tensor(0.0714)\n",
      "9417 Traning Loss: tensor(0.0704)\n",
      "9418 Traning Loss: tensor(0.0692)\n",
      "9419 Traning Loss: tensor(0.0698)\n",
      "9420 Traning Loss: tensor(0.0683)\n",
      "9421 Traning Loss: tensor(0.0701)\n",
      "9422 Traning Loss: tensor(0.0690)\n",
      "9423 Traning Loss: tensor(0.0697)\n",
      "9424 Traning Loss: tensor(0.0695)\n",
      "9425 Traning Loss: tensor(0.0693)\n",
      "9426 Traning Loss: tensor(0.0681)\n",
      "9427 Traning Loss: tensor(0.0698)\n",
      "9428 Traning Loss: tensor(0.0699)\n",
      "9429 Traning Loss: tensor(0.0691)\n",
      "9430 Traning Loss: tensor(0.0695)\n",
      "9431 Traning Loss: tensor(0.0700)\n",
      "9432 Traning Loss: tensor(0.0687)\n",
      "9433 Traning Loss: tensor(0.0690)\n",
      "9434 Traning Loss: tensor(0.0691)\n",
      "9435 Traning Loss: tensor(0.0695)\n",
      "9436 Traning Loss: tensor(0.0692)\n",
      "9437 Traning Loss: tensor(0.0689)\n",
      "9438 Traning Loss: tensor(0.0697)\n",
      "9439 Traning Loss: tensor(0.0695)\n",
      "9440 Traning Loss: tensor(0.0676)\n",
      "9441 Traning Loss: tensor(0.0696)\n",
      "9442 Traning Loss: tensor(0.0691)\n",
      "9443 Traning Loss: tensor(0.0700)\n",
      "9444 Traning Loss: tensor(0.0700)\n",
      "9445 Traning Loss: tensor(0.0696)\n",
      "9446 Traning Loss: tensor(0.0698)\n",
      "9447 Traning Loss: tensor(0.0691)\n",
      "9448 Traning Loss: tensor(0.0685)\n",
      "9449 Traning Loss: tensor(0.0702)\n",
      "9450 Traning Loss: tensor(0.0690)\n",
      "9451 Traning Loss: tensor(0.0690)\n",
      "9452 Traning Loss: tensor(0.0677)\n",
      "9453 Traning Loss: tensor(0.0699)\n",
      "9454 Traning Loss: tensor(0.0706)\n",
      "9455 Traning Loss: tensor(0.0701)\n",
      "9456 Traning Loss: tensor(0.0694)\n",
      "9457 Traning Loss: tensor(0.0687)\n",
      "9458 Traning Loss: tensor(0.0690)\n",
      "9459 Traning Loss: tensor(0.0688)\n",
      "9460 Traning Loss: tensor(0.0686)\n",
      "9461 Traning Loss: tensor(0.0687)\n",
      "9462 Traning Loss: tensor(0.0693)\n",
      "9463 Traning Loss: tensor(0.0701)\n",
      "9464 Traning Loss: tensor(0.0694)\n",
      "9465 Traning Loss: tensor(0.0692)\n",
      "9466 Traning Loss: tensor(0.0693)\n",
      "9467 Traning Loss: tensor(0.0687)\n",
      "9468 Traning Loss: tensor(0.0687)\n",
      "9469 Traning Loss: tensor(0.0697)\n",
      "9470 Traning Loss: tensor(0.0689)\n",
      "9471 Traning Loss: tensor(0.0686)\n",
      "9472 Traning Loss: tensor(0.0683)\n",
      "9473 Traning Loss: tensor(0.0692)\n",
      "9474 Traning Loss: tensor(0.0691)\n",
      "9475 Traning Loss: tensor(0.0697)\n",
      "9476 Traning Loss: tensor(0.0696)\n",
      "9477 Traning Loss: tensor(0.0690)\n",
      "9478 Traning Loss: tensor(0.0689)\n",
      "9479 Traning Loss: tensor(0.0695)\n",
      "9480 Traning Loss: tensor(0.0694)\n",
      "9481 Traning Loss: tensor(0.0687)\n",
      "9482 Traning Loss: tensor(0.0699)\n",
      "9483 Traning Loss: tensor(0.0695)\n",
      "9484 Traning Loss: tensor(0.0683)\n",
      "9485 Traning Loss: tensor(0.0693)\n",
      "9486 Traning Loss: tensor(0.0684)\n",
      "9487 Traning Loss: tensor(0.0692)\n",
      "9488 Traning Loss: tensor(0.0687)\n",
      "9489 Traning Loss: tensor(0.0700)\n",
      "9490 Traning Loss: tensor(0.0696)\n",
      "9491 Traning Loss: tensor(0.0692)\n",
      "9492 Traning Loss: tensor(0.0681)\n",
      "9493 Traning Loss: tensor(0.0693)\n",
      "9494 Traning Loss: tensor(0.0694)\n",
      "9495 Traning Loss: tensor(0.0691)\n",
      "9496 Traning Loss: tensor(0.0695)\n",
      "9497 Traning Loss: tensor(0.0683)\n",
      "9498 Traning Loss: tensor(0.0682)\n",
      "9499 Traning Loss: tensor(0.0691)\n",
      "9500 Traning Loss: tensor(0.0680)\n",
      "9501 Traning Loss: tensor(0.0692)\n",
      "9502 Traning Loss: tensor(0.0687)\n",
      "9503 Traning Loss: tensor(0.0696)\n",
      "9504 Traning Loss: tensor(0.0694)\n",
      "9505 Traning Loss: tensor(0.0689)\n",
      "9506 Traning Loss: tensor(0.0693)\n",
      "9507 Traning Loss: tensor(0.0692)\n",
      "9508 Traning Loss: tensor(0.0700)\n",
      "9509 Traning Loss: tensor(0.0688)\n",
      "9510 Traning Loss: tensor(0.0694)\n",
      "9511 Traning Loss: tensor(0.0694)\n",
      "9512 Traning Loss: tensor(0.0685)\n",
      "9513 Traning Loss: tensor(0.0694)\n",
      "9514 Traning Loss: tensor(0.0695)\n",
      "9515 Traning Loss: tensor(0.0690)\n",
      "9516 Traning Loss: tensor(0.0690)\n",
      "9517 Traning Loss: tensor(0.0681)\n",
      "9518 Traning Loss: tensor(0.0695)\n",
      "9519 Traning Loss: tensor(0.0680)\n",
      "9520 Traning Loss: tensor(0.0698)\n",
      "9521 Traning Loss: tensor(0.0688)\n",
      "9522 Traning Loss: tensor(0.0686)\n",
      "9523 Traning Loss: tensor(0.0693)\n",
      "9524 Traning Loss: tensor(0.0696)\n",
      "9525 Traning Loss: tensor(0.0696)\n",
      "9526 Traning Loss: tensor(0.0692)\n",
      "9527 Traning Loss: tensor(0.0687)\n",
      "9528 Traning Loss: tensor(0.0693)\n",
      "9529 Traning Loss: tensor(0.0688)\n",
      "9530 Traning Loss: tensor(0.0686)\n",
      "9531 Traning Loss: tensor(0.0684)\n",
      "9532 Traning Loss: tensor(0.0693)\n",
      "9533 Traning Loss: tensor(0.0682)\n",
      "9534 Traning Loss: tensor(0.0697)\n",
      "9535 Traning Loss: tensor(0.0683)\n",
      "9536 Traning Loss: tensor(0.0692)\n",
      "9537 Traning Loss: tensor(0.0680)\n",
      "9538 Traning Loss: tensor(0.0683)\n",
      "9539 Traning Loss: tensor(0.0688)\n",
      "9540 Traning Loss: tensor(0.0687)\n",
      "9541 Traning Loss: tensor(0.0687)\n",
      "9542 Traning Loss: tensor(0.0691)\n",
      "9543 Traning Loss: tensor(0.0691)\n",
      "9544 Traning Loss: tensor(0.0695)\n",
      "9545 Traning Loss: tensor(0.0681)\n",
      "9546 Traning Loss: tensor(0.0688)\n",
      "9547 Traning Loss: tensor(0.0686)\n",
      "9548 Traning Loss: tensor(0.0695)\n",
      "9549 Traning Loss: tensor(0.0693)\n",
      "9550 Traning Loss: tensor(0.0703)\n",
      "9551 Traning Loss: tensor(0.0693)\n",
      "9552 Traning Loss: tensor(0.0698)\n",
      "9553 Traning Loss: tensor(0.0692)\n",
      "9554 Traning Loss: tensor(0.0689)\n",
      "9555 Traning Loss: tensor(0.0689)\n",
      "9556 Traning Loss: tensor(0.0694)\n",
      "9557 Traning Loss: tensor(0.0684)\n",
      "9558 Traning Loss: tensor(0.0692)\n",
      "9559 Traning Loss: tensor(0.0686)\n",
      "9560 Traning Loss: tensor(0.0689)\n",
      "9561 Traning Loss: tensor(0.0689)\n",
      "9562 Traning Loss: tensor(0.0696)\n",
      "9563 Traning Loss: tensor(0.0686)\n",
      "9564 Traning Loss: tensor(0.0686)\n",
      "9565 Traning Loss: tensor(0.0694)\n",
      "9566 Traning Loss: tensor(0.0697)\n",
      "9567 Traning Loss: tensor(0.0689)\n",
      "9568 Traning Loss: tensor(0.0684)\n",
      "9569 Traning Loss: tensor(0.0686)\n",
      "9570 Traning Loss: tensor(0.0689)\n",
      "9571 Traning Loss: tensor(0.0688)\n",
      "9572 Traning Loss: tensor(0.0691)\n",
      "9573 Traning Loss: tensor(0.0687)\n",
      "9574 Traning Loss: tensor(0.0696)\n",
      "9575 Traning Loss: tensor(0.0687)\n",
      "9576 Traning Loss: tensor(0.0688)\n",
      "9577 Traning Loss: tensor(0.0691)\n",
      "9578 Traning Loss: tensor(0.0680)\n",
      "9579 Traning Loss: tensor(0.0682)\n",
      "9580 Traning Loss: tensor(0.0701)\n",
      "9581 Traning Loss: tensor(0.0689)\n",
      "9582 Traning Loss: tensor(0.0696)\n",
      "9583 Traning Loss: tensor(0.0681)\n",
      "9584 Traning Loss: tensor(0.0674)\n",
      "9585 Traning Loss: tensor(0.0685)\n",
      "9586 Traning Loss: tensor(0.0679)\n",
      "9587 Traning Loss: tensor(0.0679)\n",
      "9588 Traning Loss: tensor(0.0692)\n",
      "9589 Traning Loss: tensor(0.0692)\n",
      "9590 Traning Loss: tensor(0.0690)\n",
      "9591 Traning Loss: tensor(0.0687)\n",
      "9592 Traning Loss: tensor(0.0682)\n",
      "9593 Traning Loss: tensor(0.0694)\n",
      "9594 Traning Loss: tensor(0.0688)\n",
      "9595 Traning Loss: tensor(0.0692)\n",
      "9596 Traning Loss: tensor(0.0695)\n",
      "9597 Traning Loss: tensor(0.0677)\n",
      "9598 Traning Loss: tensor(0.0683)\n",
      "9599 Traning Loss: tensor(0.0691)\n",
      "9600 Traning Loss: tensor(0.0685)\n",
      "9601 Traning Loss: tensor(0.0687)\n",
      "9602 Traning Loss: tensor(0.0681)\n",
      "9603 Traning Loss: tensor(0.0682)\n",
      "9604 Traning Loss: tensor(0.0687)\n",
      "9605 Traning Loss: tensor(0.0699)\n",
      "9606 Traning Loss: tensor(0.0690)\n",
      "9607 Traning Loss: tensor(0.0685)\n",
      "9608 Traning Loss: tensor(0.0685)\n",
      "9609 Traning Loss: tensor(0.0686)\n",
      "9610 Traning Loss: tensor(0.0675)\n",
      "9611 Traning Loss: tensor(0.0692)\n",
      "9612 Traning Loss: tensor(0.0690)\n",
      "9613 Traning Loss: tensor(0.0688)\n",
      "9614 Traning Loss: tensor(0.0678)\n",
      "9615 Traning Loss: tensor(0.0684)\n",
      "9616 Traning Loss: tensor(0.0695)\n",
      "9617 Traning Loss: tensor(0.0695)\n",
      "9618 Traning Loss: tensor(0.0677)\n",
      "9619 Traning Loss: tensor(0.0678)\n",
      "9620 Traning Loss: tensor(0.0677)\n",
      "9621 Traning Loss: tensor(0.0693)\n",
      "9622 Traning Loss: tensor(0.0691)\n",
      "9623 Traning Loss: tensor(0.0682)\n",
      "9624 Traning Loss: tensor(0.0674)\n",
      "9625 Traning Loss: tensor(0.0683)\n",
      "9626 Traning Loss: tensor(0.0680)\n",
      "9627 Traning Loss: tensor(0.0681)\n",
      "9628 Traning Loss: tensor(0.0686)\n",
      "9629 Traning Loss: tensor(0.0690)\n",
      "9630 Traning Loss: tensor(0.0678)\n",
      "9631 Traning Loss: tensor(0.0678)\n",
      "9632 Traning Loss: tensor(0.0684)\n",
      "9633 Traning Loss: tensor(0.0672)\n",
      "9634 Traning Loss: tensor(0.0684)\n",
      "9635 Traning Loss: tensor(0.0682)\n",
      "9636 Traning Loss: tensor(0.0696)\n",
      "9637 Traning Loss: tensor(0.0701)\n",
      "9638 Traning Loss: tensor(0.0679)\n",
      "9639 Traning Loss: tensor(0.0689)\n",
      "9640 Traning Loss: tensor(0.0683)\n",
      "9641 Traning Loss: tensor(0.0681)\n",
      "9642 Traning Loss: tensor(0.0682)\n",
      "9643 Traning Loss: tensor(0.0675)\n",
      "9644 Traning Loss: tensor(0.0694)\n",
      "9645 Traning Loss: tensor(0.0685)\n",
      "9646 Traning Loss: tensor(0.0683)\n",
      "9647 Traning Loss: tensor(0.0687)\n",
      "9648 Traning Loss: tensor(0.0688)\n",
      "9649 Traning Loss: tensor(0.0679)\n",
      "9650 Traning Loss: tensor(0.0680)\n",
      "9651 Traning Loss: tensor(0.0676)\n",
      "9652 Traning Loss: tensor(0.0678)\n",
      "9653 Traning Loss: tensor(0.0697)\n",
      "9654 Traning Loss: tensor(0.0682)\n",
      "9655 Traning Loss: tensor(0.0676)\n",
      "9656 Traning Loss: tensor(0.0674)\n",
      "9657 Traning Loss: tensor(0.0688)\n",
      "9658 Traning Loss: tensor(0.0685)\n",
      "9659 Traning Loss: tensor(0.0671)\n",
      "9660 Traning Loss: tensor(0.0681)\n",
      "9661 Traning Loss: tensor(0.0687)\n",
      "9662 Traning Loss: tensor(0.0688)\n",
      "9663 Traning Loss: tensor(0.0675)\n",
      "9664 Traning Loss: tensor(0.0686)\n",
      "9665 Traning Loss: tensor(0.0681)\n",
      "9666 Traning Loss: tensor(0.0682)\n",
      "9667 Traning Loss: tensor(0.0685)\n",
      "9668 Traning Loss: tensor(0.0682)\n",
      "9669 Traning Loss: tensor(0.0678)\n",
      "9670 Traning Loss: tensor(0.0684)\n",
      "9671 Traning Loss: tensor(0.0677)\n",
      "9672 Traning Loss: tensor(0.0676)\n",
      "9673 Traning Loss: tensor(0.0675)\n",
      "9674 Traning Loss: tensor(0.0682)\n",
      "9675 Traning Loss: tensor(0.0676)\n",
      "9676 Traning Loss: tensor(0.0679)\n",
      "9677 Traning Loss: tensor(0.0682)\n",
      "9678 Traning Loss: tensor(0.0681)\n",
      "9679 Traning Loss: tensor(0.0676)\n",
      "9680 Traning Loss: tensor(0.0696)\n",
      "9681 Traning Loss: tensor(0.0681)\n",
      "9682 Traning Loss: tensor(0.0678)\n",
      "9683 Traning Loss: tensor(0.0686)\n",
      "9684 Traning Loss: tensor(0.0690)\n",
      "9685 Traning Loss: tensor(0.0684)\n",
      "9686 Traning Loss: tensor(0.0691)\n",
      "9687 Traning Loss: tensor(0.0696)\n",
      "9688 Traning Loss: tensor(0.0685)\n",
      "9689 Traning Loss: tensor(0.0682)\n",
      "9690 Traning Loss: tensor(0.0688)\n",
      "9691 Traning Loss: tensor(0.0680)\n",
      "9692 Traning Loss: tensor(0.0684)\n",
      "9693 Traning Loss: tensor(0.0680)\n",
      "9694 Traning Loss: tensor(0.0681)\n",
      "9695 Traning Loss: tensor(0.0692)\n",
      "9696 Traning Loss: tensor(0.0685)\n",
      "9697 Traning Loss: tensor(0.0680)\n",
      "9698 Traning Loss: tensor(0.0680)\n",
      "9699 Traning Loss: tensor(0.0670)\n",
      "9700 Traning Loss: tensor(0.0671)\n",
      "9701 Traning Loss: tensor(0.0674)\n",
      "9702 Traning Loss: tensor(0.0690)\n",
      "9703 Traning Loss: tensor(0.0685)\n",
      "9704 Traning Loss: tensor(0.0675)\n",
      "9705 Traning Loss: tensor(0.0695)\n",
      "9706 Traning Loss: tensor(0.0692)\n",
      "9707 Traning Loss: tensor(0.0682)\n",
      "9708 Traning Loss: tensor(0.0675)\n",
      "9709 Traning Loss: tensor(0.0696)\n",
      "9710 Traning Loss: tensor(0.0685)\n",
      "9711 Traning Loss: tensor(0.0689)\n",
      "9712 Traning Loss: tensor(0.0678)\n",
      "9713 Traning Loss: tensor(0.0678)\n",
      "9714 Traning Loss: tensor(0.0687)\n",
      "9715 Traning Loss: tensor(0.0684)\n",
      "9716 Traning Loss: tensor(0.0679)\n",
      "9717 Traning Loss: tensor(0.0685)\n",
      "9718 Traning Loss: tensor(0.0688)\n",
      "9719 Traning Loss: tensor(0.0677)\n",
      "9720 Traning Loss: tensor(0.0685)\n",
      "9721 Traning Loss: tensor(0.0677)\n",
      "9722 Traning Loss: tensor(0.0684)\n",
      "9723 Traning Loss: tensor(0.0683)\n",
      "9724 Traning Loss: tensor(0.0668)\n",
      "9725 Traning Loss: tensor(0.0672)\n",
      "9726 Traning Loss: tensor(0.0676)\n",
      "9727 Traning Loss: tensor(0.0684)\n",
      "9728 Traning Loss: tensor(0.0682)\n",
      "9729 Traning Loss: tensor(0.0683)\n",
      "9730 Traning Loss: tensor(0.0681)\n",
      "9731 Traning Loss: tensor(0.0690)\n",
      "9732 Traning Loss: tensor(0.0684)\n",
      "9733 Traning Loss: tensor(0.0677)\n",
      "9734 Traning Loss: tensor(0.0676)\n",
      "9735 Traning Loss: tensor(0.0686)\n",
      "9736 Traning Loss: tensor(0.0677)\n",
      "9737 Traning Loss: tensor(0.0684)\n",
      "9738 Traning Loss: tensor(0.0681)\n",
      "9739 Traning Loss: tensor(0.0674)\n",
      "9740 Traning Loss: tensor(0.0692)\n",
      "9741 Traning Loss: tensor(0.0678)\n",
      "9742 Traning Loss: tensor(0.0673)\n",
      "9743 Traning Loss: tensor(0.0681)\n",
      "9744 Traning Loss: tensor(0.0674)\n",
      "9745 Traning Loss: tensor(0.0677)\n",
      "9746 Traning Loss: tensor(0.0688)\n",
      "9747 Traning Loss: tensor(0.0684)\n",
      "9748 Traning Loss: tensor(0.0687)\n",
      "9749 Traning Loss: tensor(0.0679)\n",
      "9750 Traning Loss: tensor(0.0687)\n",
      "9751 Traning Loss: tensor(0.0679)\n",
      "9752 Traning Loss: tensor(0.0683)\n",
      "9753 Traning Loss: tensor(0.0691)\n",
      "9754 Traning Loss: tensor(0.0685)\n",
      "9755 Traning Loss: tensor(0.0677)\n",
      "9756 Traning Loss: tensor(0.0673)\n",
      "9757 Traning Loss: tensor(0.0667)\n",
      "9758 Traning Loss: tensor(0.0687)\n",
      "9759 Traning Loss: tensor(0.0680)\n",
      "9760 Traning Loss: tensor(0.0691)\n",
      "9761 Traning Loss: tensor(0.0690)\n",
      "9762 Traning Loss: tensor(0.0690)\n",
      "9763 Traning Loss: tensor(0.0682)\n",
      "9764 Traning Loss: tensor(0.0681)\n",
      "9765 Traning Loss: tensor(0.0684)\n",
      "9766 Traning Loss: tensor(0.0687)\n",
      "9767 Traning Loss: tensor(0.0684)\n",
      "9768 Traning Loss: tensor(0.0667)\n",
      "9769 Traning Loss: tensor(0.0690)\n",
      "9770 Traning Loss: tensor(0.0677)\n",
      "9771 Traning Loss: tensor(0.0682)\n",
      "9772 Traning Loss: tensor(0.0677)\n",
      "9773 Traning Loss: tensor(0.0676)\n",
      "9774 Traning Loss: tensor(0.0686)\n",
      "9775 Traning Loss: tensor(0.0678)\n",
      "9776 Traning Loss: tensor(0.0685)\n",
      "9777 Traning Loss: tensor(0.0693)\n",
      "9778 Traning Loss: tensor(0.0684)\n",
      "9779 Traning Loss: tensor(0.0692)\n",
      "9780 Traning Loss: tensor(0.0679)\n",
      "9781 Traning Loss: tensor(0.0665)\n",
      "9782 Traning Loss: tensor(0.0681)\n",
      "9783 Traning Loss: tensor(0.0678)\n",
      "9784 Traning Loss: tensor(0.0691)\n",
      "9785 Traning Loss: tensor(0.0685)\n",
      "9786 Traning Loss: tensor(0.0681)\n",
      "9787 Traning Loss: tensor(0.0679)\n",
      "9788 Traning Loss: tensor(0.0680)\n",
      "9789 Traning Loss: tensor(0.0686)\n",
      "9790 Traning Loss: tensor(0.0679)\n",
      "9791 Traning Loss: tensor(0.0677)\n",
      "9792 Traning Loss: tensor(0.0682)\n",
      "9793 Traning Loss: tensor(0.0681)\n",
      "9794 Traning Loss: tensor(0.0681)\n",
      "9795 Traning Loss: tensor(0.0675)\n",
      "9796 Traning Loss: tensor(0.0692)\n",
      "9797 Traning Loss: tensor(0.0681)\n",
      "9798 Traning Loss: tensor(0.0677)\n",
      "9799 Traning Loss: tensor(0.0671)\n",
      "9800 Traning Loss: tensor(0.0677)\n",
      "9801 Traning Loss: tensor(0.0685)\n",
      "9802 Traning Loss: tensor(0.0663)\n",
      "9803 Traning Loss: tensor(0.0677)\n",
      "9804 Traning Loss: tensor(0.0688)\n",
      "9805 Traning Loss: tensor(0.0670)\n",
      "9806 Traning Loss: tensor(0.0675)\n",
      "9807 Traning Loss: tensor(0.0674)\n",
      "9808 Traning Loss: tensor(0.0680)\n",
      "9809 Traning Loss: tensor(0.0668)\n",
      "9810 Traning Loss: tensor(0.0686)\n",
      "9811 Traning Loss: tensor(0.0669)\n",
      "9812 Traning Loss: tensor(0.0680)\n",
      "9813 Traning Loss: tensor(0.0670)\n",
      "9814 Traning Loss: tensor(0.0680)\n",
      "9815 Traning Loss: tensor(0.0667)\n",
      "9816 Traning Loss: tensor(0.0670)\n",
      "9817 Traning Loss: tensor(0.0679)\n",
      "9818 Traning Loss: tensor(0.0687)\n",
      "9819 Traning Loss: tensor(0.0678)\n",
      "9820 Traning Loss: tensor(0.0678)\n",
      "9821 Traning Loss: tensor(0.0678)\n",
      "9822 Traning Loss: tensor(0.0673)\n",
      "9823 Traning Loss: tensor(0.0671)\n",
      "9824 Traning Loss: tensor(0.0676)\n",
      "9825 Traning Loss: tensor(0.0675)\n",
      "9826 Traning Loss: tensor(0.0668)\n",
      "9827 Traning Loss: tensor(0.0676)\n",
      "9828 Traning Loss: tensor(0.0668)\n",
      "9829 Traning Loss: tensor(0.0673)\n",
      "9830 Traning Loss: tensor(0.0676)\n",
      "9831 Traning Loss: tensor(0.0676)\n",
      "9832 Traning Loss: tensor(0.0680)\n",
      "9833 Traning Loss: tensor(0.0678)\n",
      "9834 Traning Loss: tensor(0.0680)\n",
      "9835 Traning Loss: tensor(0.0672)\n",
      "9836 Traning Loss: tensor(0.0679)\n",
      "9837 Traning Loss: tensor(0.0675)\n",
      "9838 Traning Loss: tensor(0.0674)\n",
      "9839 Traning Loss: tensor(0.0682)\n",
      "9840 Traning Loss: tensor(0.0687)\n",
      "9841 Traning Loss: tensor(0.0682)\n",
      "9842 Traning Loss: tensor(0.0676)\n",
      "9843 Traning Loss: tensor(0.0678)\n",
      "9844 Traning Loss: tensor(0.0669)\n",
      "9845 Traning Loss: tensor(0.0681)\n",
      "9846 Traning Loss: tensor(0.0681)\n",
      "9847 Traning Loss: tensor(0.0678)\n",
      "9848 Traning Loss: tensor(0.0681)\n",
      "9849 Traning Loss: tensor(0.0675)\n",
      "9850 Traning Loss: tensor(0.0672)\n",
      "9851 Traning Loss: tensor(0.0672)\n",
      "9852 Traning Loss: tensor(0.0666)\n",
      "9853 Traning Loss: tensor(0.0672)\n",
      "9854 Traning Loss: tensor(0.0677)\n",
      "9855 Traning Loss: tensor(0.0670)\n",
      "9856 Traning Loss: tensor(0.0668)\n",
      "9857 Traning Loss: tensor(0.0673)\n",
      "9858 Traning Loss: tensor(0.0667)\n",
      "9859 Traning Loss: tensor(0.0673)\n",
      "9860 Traning Loss: tensor(0.0673)\n",
      "9861 Traning Loss: tensor(0.0679)\n",
      "9862 Traning Loss: tensor(0.0675)\n",
      "9863 Traning Loss: tensor(0.0690)\n",
      "9864 Traning Loss: tensor(0.0673)\n",
      "9865 Traning Loss: tensor(0.0674)\n",
      "9866 Traning Loss: tensor(0.0683)\n",
      "9867 Traning Loss: tensor(0.0680)\n",
      "9868 Traning Loss: tensor(0.0675)\n",
      "9869 Traning Loss: tensor(0.0681)\n",
      "9870 Traning Loss: tensor(0.0673)\n",
      "9871 Traning Loss: tensor(0.0671)\n",
      "9872 Traning Loss: tensor(0.0672)\n",
      "9873 Traning Loss: tensor(0.0671)\n",
      "9874 Traning Loss: tensor(0.0688)\n",
      "9875 Traning Loss: tensor(0.0672)\n",
      "9876 Traning Loss: tensor(0.0665)\n",
      "9877 Traning Loss: tensor(0.0687)\n",
      "9878 Traning Loss: tensor(0.0677)\n",
      "9879 Traning Loss: tensor(0.0677)\n",
      "9880 Traning Loss: tensor(0.0679)\n",
      "9881 Traning Loss: tensor(0.0683)\n",
      "9882 Traning Loss: tensor(0.0676)\n",
      "9883 Traning Loss: tensor(0.0675)\n",
      "9884 Traning Loss: tensor(0.0678)\n",
      "9885 Traning Loss: tensor(0.0674)\n",
      "9886 Traning Loss: tensor(0.0679)\n",
      "9887 Traning Loss: tensor(0.0668)\n",
      "9888 Traning Loss: tensor(0.0663)\n",
      "9889 Traning Loss: tensor(0.0676)\n",
      "9890 Traning Loss: tensor(0.0675)\n",
      "9891 Traning Loss: tensor(0.0673)\n",
      "9892 Traning Loss: tensor(0.0682)\n",
      "9893 Traning Loss: tensor(0.0666)\n",
      "9894 Traning Loss: tensor(0.0669)\n",
      "9895 Traning Loss: tensor(0.0676)\n",
      "9896 Traning Loss: tensor(0.0663)\n",
      "9897 Traning Loss: tensor(0.0685)\n",
      "9898 Traning Loss: tensor(0.0681)\n",
      "9899 Traning Loss: tensor(0.0671)\n",
      "9900 Traning Loss: tensor(0.0670)\n",
      "9901 Traning Loss: tensor(0.0667)\n",
      "9902 Traning Loss: tensor(0.0675)\n",
      "9903 Traning Loss: tensor(0.0672)\n",
      "9904 Traning Loss: tensor(0.0661)\n",
      "9905 Traning Loss: tensor(0.0682)\n",
      "9906 Traning Loss: tensor(0.0671)\n",
      "9907 Traning Loss: tensor(0.0677)\n",
      "9908 Traning Loss: tensor(0.0667)\n",
      "9909 Traning Loss: tensor(0.0679)\n",
      "9910 Traning Loss: tensor(0.0666)\n",
      "9911 Traning Loss: tensor(0.0677)\n",
      "9912 Traning Loss: tensor(0.0671)\n",
      "9913 Traning Loss: tensor(0.0676)\n",
      "9914 Traning Loss: tensor(0.0673)\n",
      "9915 Traning Loss: tensor(0.0681)\n",
      "9916 Traning Loss: tensor(0.0667)\n",
      "9917 Traning Loss: tensor(0.0682)\n",
      "9918 Traning Loss: tensor(0.0665)\n",
      "9919 Traning Loss: tensor(0.0671)\n",
      "9920 Traning Loss: tensor(0.0669)\n",
      "9921 Traning Loss: tensor(0.0678)\n",
      "9922 Traning Loss: tensor(0.0679)\n",
      "9923 Traning Loss: tensor(0.0670)\n",
      "9924 Traning Loss: tensor(0.0670)\n",
      "9925 Traning Loss: tensor(0.0669)\n",
      "9926 Traning Loss: tensor(0.0678)\n",
      "9927 Traning Loss: tensor(0.0676)\n",
      "9928 Traning Loss: tensor(0.0681)\n",
      "9929 Traning Loss: tensor(0.0681)\n",
      "9930 Traning Loss: tensor(0.0662)\n",
      "9931 Traning Loss: tensor(0.0672)\n",
      "9932 Traning Loss: tensor(0.0662)\n",
      "9933 Traning Loss: tensor(0.0678)\n",
      "9934 Traning Loss: tensor(0.0678)\n",
      "9935 Traning Loss: tensor(0.0677)\n",
      "9936 Traning Loss: tensor(0.0665)\n",
      "9937 Traning Loss: tensor(0.0676)\n",
      "9938 Traning Loss: tensor(0.0678)\n",
      "9939 Traning Loss: tensor(0.0663)\n",
      "9940 Traning Loss: tensor(0.0678)\n",
      "9941 Traning Loss: tensor(0.0666)\n",
      "9942 Traning Loss: tensor(0.0676)\n",
      "9943 Traning Loss: tensor(0.0676)\n",
      "9944 Traning Loss: tensor(0.0675)\n",
      "9945 Traning Loss: tensor(0.0673)\n",
      "9946 Traning Loss: tensor(0.0664)\n",
      "9947 Traning Loss: tensor(0.0676)\n",
      "9948 Traning Loss: tensor(0.0675)\n",
      "9949 Traning Loss: tensor(0.0671)\n",
      "9950 Traning Loss: tensor(0.0673)\n",
      "9951 Traning Loss: tensor(0.0673)\n",
      "9952 Traning Loss: tensor(0.0681)\n",
      "9953 Traning Loss: tensor(0.0676)\n",
      "9954 Traning Loss: tensor(0.0670)\n",
      "9955 Traning Loss: tensor(0.0679)\n",
      "9956 Traning Loss: tensor(0.0661)\n",
      "9957 Traning Loss: tensor(0.0668)\n",
      "9958 Traning Loss: tensor(0.0662)\n",
      "9959 Traning Loss: tensor(0.0668)\n",
      "9960 Traning Loss: tensor(0.0658)\n",
      "9961 Traning Loss: tensor(0.0666)\n",
      "9962 Traning Loss: tensor(0.0674)\n",
      "9963 Traning Loss: tensor(0.0674)\n",
      "9964 Traning Loss: tensor(0.0666)\n",
      "9965 Traning Loss: tensor(0.0676)\n",
      "9966 Traning Loss: tensor(0.0668)\n",
      "9967 Traning Loss: tensor(0.0668)\n",
      "9968 Traning Loss: tensor(0.0673)\n",
      "9969 Traning Loss: tensor(0.0667)\n",
      "9970 Traning Loss: tensor(0.0677)\n",
      "9971 Traning Loss: tensor(0.0672)\n",
      "9972 Traning Loss: tensor(0.0675)\n",
      "9973 Traning Loss: tensor(0.0674)\n",
      "9974 Traning Loss: tensor(0.0673)\n",
      "9975 Traning Loss: tensor(0.0680)\n",
      "9976 Traning Loss: tensor(0.0664)\n",
      "9977 Traning Loss: tensor(0.0665)\n",
      "9978 Traning Loss: tensor(0.0682)\n",
      "9979 Traning Loss: tensor(0.0663)\n",
      "9980 Traning Loss: tensor(0.0667)\n",
      "9981 Traning Loss: tensor(0.0662)\n",
      "9982 Traning Loss: tensor(0.0672)\n",
      "9983 Traning Loss: tensor(0.0671)\n",
      "9984 Traning Loss: tensor(0.0653)\n",
      "9985 Traning Loss: tensor(0.0654)\n",
      "9986 Traning Loss: tensor(0.0668)\n",
      "9987 Traning Loss: tensor(0.0677)\n",
      "9988 Traning Loss: tensor(0.0670)\n",
      "9989 Traning Loss: tensor(0.0665)\n",
      "9990 Traning Loss: tensor(0.0669)\n",
      "9991 Traning Loss: tensor(0.0666)\n",
      "9992 Traning Loss: tensor(0.0665)\n",
      "9993 Traning Loss: tensor(0.0666)\n",
      "9994 Traning Loss: tensor(0.0667)\n",
      "9995 Traning Loss: tensor(0.0664)\n",
      "9996 Traning Loss: tensor(0.0674)\n",
      "9997 Traning Loss: tensor(0.0680)\n",
      "9998 Traning Loss: tensor(0.0676)\n",
      "9999 Traning Loss: tensor(0.0671)\n",
      "10000 Traning Loss: tensor(0.0671)\n",
      "10001 Traning Loss: tensor(0.0666)\n",
      "10002 Traning Loss: tensor(0.0677)\n",
      "10003 Traning Loss: tensor(0.0671)\n",
      "10004 Traning Loss: tensor(0.0681)\n",
      "10005 Traning Loss: tensor(0.0676)\n",
      "10006 Traning Loss: tensor(0.0662)\n",
      "10007 Traning Loss: tensor(0.0669)\n",
      "10008 Traning Loss: tensor(0.0671)\n",
      "10009 Traning Loss: tensor(0.0672)\n",
      "10010 Traning Loss: tensor(0.0673)\n",
      "10011 Traning Loss: tensor(0.0659)\n",
      "10012 Traning Loss: tensor(0.0674)\n",
      "10013 Traning Loss: tensor(0.0679)\n",
      "10014 Traning Loss: tensor(0.0662)\n",
      "10015 Traning Loss: tensor(0.0678)\n",
      "10016 Traning Loss: tensor(0.0655)\n",
      "10017 Traning Loss: tensor(0.0674)\n",
      "10018 Traning Loss: tensor(0.0670)\n",
      "10019 Traning Loss: tensor(0.0671)\n",
      "10020 Traning Loss: tensor(0.0672)\n",
      "10021 Traning Loss: tensor(0.0674)\n",
      "10022 Traning Loss: tensor(0.0680)\n",
      "10023 Traning Loss: tensor(0.0681)\n",
      "10024 Traning Loss: tensor(0.0659)\n",
      "10025 Traning Loss: tensor(0.0665)\n",
      "10026 Traning Loss: tensor(0.0670)\n",
      "10027 Traning Loss: tensor(0.0678)\n",
      "10028 Traning Loss: tensor(0.0667)\n",
      "10029 Traning Loss: tensor(0.0673)\n",
      "10030 Traning Loss: tensor(0.0674)\n",
      "10031 Traning Loss: tensor(0.0670)\n",
      "10032 Traning Loss: tensor(0.0667)\n",
      "10033 Traning Loss: tensor(0.0676)\n",
      "10034 Traning Loss: tensor(0.0659)\n",
      "10035 Traning Loss: tensor(0.0660)\n",
      "10036 Traning Loss: tensor(0.0669)\n",
      "10037 Traning Loss: tensor(0.0659)\n",
      "10038 Traning Loss: tensor(0.0656)\n",
      "10039 Traning Loss: tensor(0.0672)\n",
      "10040 Traning Loss: tensor(0.0678)\n",
      "10041 Traning Loss: tensor(0.0658)\n",
      "10042 Traning Loss: tensor(0.0675)\n",
      "10043 Traning Loss: tensor(0.0678)\n",
      "10044 Traning Loss: tensor(0.0672)\n",
      "10045 Traning Loss: tensor(0.0674)\n",
      "10046 Traning Loss: tensor(0.0668)\n",
      "10047 Traning Loss: tensor(0.0663)\n",
      "10048 Traning Loss: tensor(0.0667)\n",
      "10049 Traning Loss: tensor(0.0669)\n",
      "10050 Traning Loss: tensor(0.0672)\n",
      "10051 Traning Loss: tensor(0.0658)\n",
      "10052 Traning Loss: tensor(0.0684)\n",
      "10053 Traning Loss: tensor(0.0659)\n",
      "10054 Traning Loss: tensor(0.0663)\n",
      "10055 Traning Loss: tensor(0.0657)\n",
      "10056 Traning Loss: tensor(0.0662)\n",
      "10057 Traning Loss: tensor(0.0670)\n",
      "10058 Traning Loss: tensor(0.0662)\n",
      "10059 Traning Loss: tensor(0.0664)\n",
      "10060 Traning Loss: tensor(0.0668)\n",
      "10061 Traning Loss: tensor(0.0659)\n",
      "10062 Traning Loss: tensor(0.0665)\n",
      "10063 Traning Loss: tensor(0.0666)\n",
      "10064 Traning Loss: tensor(0.0677)\n",
      "10065 Traning Loss: tensor(0.0663)\n",
      "10066 Traning Loss: tensor(0.0661)\n",
      "10067 Traning Loss: tensor(0.0670)\n",
      "10068 Traning Loss: tensor(0.0663)\n",
      "10069 Traning Loss: tensor(0.0662)\n",
      "10070 Traning Loss: tensor(0.0663)\n",
      "10071 Traning Loss: tensor(0.0656)\n",
      "10072 Traning Loss: tensor(0.0658)\n",
      "10073 Traning Loss: tensor(0.0657)\n",
      "10074 Traning Loss: tensor(0.0667)\n",
      "10075 Traning Loss: tensor(0.0679)\n",
      "10076 Traning Loss: tensor(0.0661)\n",
      "10077 Traning Loss: tensor(0.0659)\n",
      "10078 Traning Loss: tensor(0.0680)\n",
      "10079 Traning Loss: tensor(0.0660)\n",
      "10080 Traning Loss: tensor(0.0660)\n",
      "10081 Traning Loss: tensor(0.0661)\n",
      "10082 Traning Loss: tensor(0.0668)\n",
      "10083 Traning Loss: tensor(0.0668)\n",
      "10084 Traning Loss: tensor(0.0670)\n",
      "10085 Traning Loss: tensor(0.0669)\n",
      "10086 Traning Loss: tensor(0.0669)\n",
      "10087 Traning Loss: tensor(0.0666)\n",
      "10088 Traning Loss: tensor(0.0661)\n",
      "10089 Traning Loss: tensor(0.0669)\n",
      "10090 Traning Loss: tensor(0.0669)\n",
      "10091 Traning Loss: tensor(0.0679)\n",
      "10092 Traning Loss: tensor(0.0672)\n",
      "10093 Traning Loss: tensor(0.0661)\n",
      "10094 Traning Loss: tensor(0.0664)\n",
      "10095 Traning Loss: tensor(0.0660)\n",
      "10096 Traning Loss: tensor(0.0662)\n",
      "10097 Traning Loss: tensor(0.0655)\n",
      "10098 Traning Loss: tensor(0.0667)\n",
      "10099 Traning Loss: tensor(0.0661)\n",
      "10100 Traning Loss: tensor(0.0664)\n",
      "10101 Traning Loss: tensor(0.0670)\n",
      "10102 Traning Loss: tensor(0.0659)\n",
      "10103 Traning Loss: tensor(0.0677)\n",
      "10104 Traning Loss: tensor(0.0657)\n",
      "10105 Traning Loss: tensor(0.0669)\n",
      "10106 Traning Loss: tensor(0.0663)\n",
      "10107 Traning Loss: tensor(0.0670)\n",
      "10108 Traning Loss: tensor(0.0660)\n",
      "10109 Traning Loss: tensor(0.0659)\n",
      "10110 Traning Loss: tensor(0.0671)\n",
      "10111 Traning Loss: tensor(0.0666)\n",
      "10112 Traning Loss: tensor(0.0673)\n",
      "10113 Traning Loss: tensor(0.0660)\n",
      "10114 Traning Loss: tensor(0.0671)\n",
      "10115 Traning Loss: tensor(0.0665)\n",
      "10116 Traning Loss: tensor(0.0665)\n",
      "10117 Traning Loss: tensor(0.0664)\n",
      "10118 Traning Loss: tensor(0.0681)\n",
      "10119 Traning Loss: tensor(0.0660)\n",
      "10120 Traning Loss: tensor(0.0656)\n",
      "10121 Traning Loss: tensor(0.0671)\n",
      "10122 Traning Loss: tensor(0.0665)\n",
      "10123 Traning Loss: tensor(0.0662)\n",
      "10124 Traning Loss: tensor(0.0667)\n",
      "10125 Traning Loss: tensor(0.0654)\n",
      "10126 Traning Loss: tensor(0.0669)\n",
      "10127 Traning Loss: tensor(0.0665)\n",
      "10128 Traning Loss: tensor(0.0666)\n",
      "10129 Traning Loss: tensor(0.0669)\n",
      "10130 Traning Loss: tensor(0.0661)\n",
      "10131 Traning Loss: tensor(0.0675)\n",
      "10132 Traning Loss: tensor(0.0650)\n",
      "10133 Traning Loss: tensor(0.0666)\n",
      "10134 Traning Loss: tensor(0.0665)\n",
      "10135 Traning Loss: tensor(0.0663)\n",
      "10136 Traning Loss: tensor(0.0663)\n",
      "10137 Traning Loss: tensor(0.0666)\n",
      "10138 Traning Loss: tensor(0.0653)\n",
      "10139 Traning Loss: tensor(0.0658)\n",
      "10140 Traning Loss: tensor(0.0657)\n",
      "10141 Traning Loss: tensor(0.0657)\n",
      "10142 Traning Loss: tensor(0.0662)\n",
      "10143 Traning Loss: tensor(0.0660)\n",
      "10144 Traning Loss: tensor(0.0670)\n",
      "10145 Traning Loss: tensor(0.0646)\n",
      "10146 Traning Loss: tensor(0.0667)\n",
      "10147 Traning Loss: tensor(0.0665)\n",
      "10148 Traning Loss: tensor(0.0665)\n",
      "10149 Traning Loss: tensor(0.0654)\n",
      "10150 Traning Loss: tensor(0.0650)\n",
      "10151 Traning Loss: tensor(0.0668)\n",
      "10152 Traning Loss: tensor(0.0648)\n",
      "10153 Traning Loss: tensor(0.0667)\n",
      "10154 Traning Loss: tensor(0.0655)\n",
      "10155 Traning Loss: tensor(0.0671)\n",
      "10156 Traning Loss: tensor(0.0667)\n",
      "10157 Traning Loss: tensor(0.0669)\n",
      "10158 Traning Loss: tensor(0.0664)\n",
      "10159 Traning Loss: tensor(0.0667)\n",
      "10160 Traning Loss: tensor(0.0659)\n",
      "10161 Traning Loss: tensor(0.0663)\n",
      "10162 Traning Loss: tensor(0.0659)\n",
      "10163 Traning Loss: tensor(0.0664)\n",
      "10164 Traning Loss: tensor(0.0656)\n",
      "10165 Traning Loss: tensor(0.0657)\n",
      "10166 Traning Loss: tensor(0.0657)\n",
      "10167 Traning Loss: tensor(0.0664)\n",
      "10168 Traning Loss: tensor(0.0653)\n",
      "10169 Traning Loss: tensor(0.0665)\n",
      "10170 Traning Loss: tensor(0.0663)\n",
      "10171 Traning Loss: tensor(0.0669)\n",
      "10172 Traning Loss: tensor(0.0667)\n",
      "10173 Traning Loss: tensor(0.0655)\n",
      "10174 Traning Loss: tensor(0.0661)\n",
      "10175 Traning Loss: tensor(0.0672)\n",
      "10176 Traning Loss: tensor(0.0664)\n",
      "10177 Traning Loss: tensor(0.0662)\n",
      "10178 Traning Loss: tensor(0.0659)\n",
      "10179 Traning Loss: tensor(0.0667)\n",
      "10180 Traning Loss: tensor(0.0660)\n",
      "10181 Traning Loss: tensor(0.0666)\n",
      "10182 Traning Loss: tensor(0.0656)\n",
      "10183 Traning Loss: tensor(0.0659)\n",
      "10184 Traning Loss: tensor(0.0652)\n",
      "10185 Traning Loss: tensor(0.0669)\n",
      "10186 Traning Loss: tensor(0.0669)\n",
      "10187 Traning Loss: tensor(0.0658)\n",
      "10188 Traning Loss: tensor(0.0668)\n",
      "10189 Traning Loss: tensor(0.0651)\n",
      "10190 Traning Loss: tensor(0.0659)\n",
      "10191 Traning Loss: tensor(0.0657)\n",
      "10192 Traning Loss: tensor(0.0660)\n",
      "10193 Traning Loss: tensor(0.0658)\n",
      "10194 Traning Loss: tensor(0.0662)\n",
      "10195 Traning Loss: tensor(0.0657)\n",
      "10196 Traning Loss: tensor(0.0653)\n",
      "10197 Traning Loss: tensor(0.0664)\n",
      "10198 Traning Loss: tensor(0.0655)\n",
      "10199 Traning Loss: tensor(0.0657)\n",
      "10200 Traning Loss: tensor(0.0668)\n",
      "10201 Traning Loss: tensor(0.0659)\n",
      "10202 Traning Loss: tensor(0.0655)\n",
      "10203 Traning Loss: tensor(0.0660)\n",
      "10204 Traning Loss: tensor(0.0664)\n",
      "10205 Traning Loss: tensor(0.0658)\n",
      "10206 Traning Loss: tensor(0.0650)\n",
      "10207 Traning Loss: tensor(0.0659)\n",
      "10208 Traning Loss: tensor(0.0664)\n",
      "10209 Traning Loss: tensor(0.0665)\n",
      "10210 Traning Loss: tensor(0.0656)\n",
      "10211 Traning Loss: tensor(0.0654)\n",
      "10212 Traning Loss: tensor(0.0653)\n",
      "10213 Traning Loss: tensor(0.0649)\n",
      "10214 Traning Loss: tensor(0.0657)\n",
      "10215 Traning Loss: tensor(0.0665)\n",
      "10216 Traning Loss: tensor(0.0678)\n",
      "10217 Traning Loss: tensor(0.0656)\n",
      "10218 Traning Loss: tensor(0.0660)\n",
      "10219 Traning Loss: tensor(0.0651)\n",
      "10220 Traning Loss: tensor(0.0658)\n",
      "10221 Traning Loss: tensor(0.0659)\n",
      "10222 Traning Loss: tensor(0.0669)\n",
      "10223 Traning Loss: tensor(0.0660)\n",
      "10224 Traning Loss: tensor(0.0652)\n",
      "10225 Traning Loss: tensor(0.0676)\n",
      "10226 Traning Loss: tensor(0.0670)\n",
      "10227 Traning Loss: tensor(0.0673)\n",
      "10228 Traning Loss: tensor(0.0659)\n",
      "10229 Traning Loss: tensor(0.0673)\n",
      "10230 Traning Loss: tensor(0.0664)\n",
      "10231 Traning Loss: tensor(0.0670)\n",
      "10232 Traning Loss: tensor(0.0662)\n",
      "10233 Traning Loss: tensor(0.0651)\n",
      "10234 Traning Loss: tensor(0.0661)\n",
      "10235 Traning Loss: tensor(0.0653)\n",
      "10236 Traning Loss: tensor(0.0650)\n",
      "10237 Traning Loss: tensor(0.0667)\n",
      "10238 Traning Loss: tensor(0.0652)\n",
      "10239 Traning Loss: tensor(0.0650)\n",
      "10240 Traning Loss: tensor(0.0653)\n",
      "10241 Traning Loss: tensor(0.0662)\n",
      "10242 Traning Loss: tensor(0.0657)\n",
      "10243 Traning Loss: tensor(0.0660)\n",
      "10244 Traning Loss: tensor(0.0657)\n",
      "10245 Traning Loss: tensor(0.0659)\n",
      "10246 Traning Loss: tensor(0.0662)\n",
      "10247 Traning Loss: tensor(0.0672)\n",
      "10248 Traning Loss: tensor(0.0651)\n",
      "10249 Traning Loss: tensor(0.0659)\n",
      "10250 Traning Loss: tensor(0.0650)\n",
      "10251 Traning Loss: tensor(0.0640)\n",
      "10252 Traning Loss: tensor(0.0655)\n",
      "10253 Traning Loss: tensor(0.0657)\n",
      "10254 Traning Loss: tensor(0.0662)\n",
      "10255 Traning Loss: tensor(0.0661)\n",
      "10256 Traning Loss: tensor(0.0659)\n",
      "10257 Traning Loss: tensor(0.0661)\n",
      "10258 Traning Loss: tensor(0.0645)\n",
      "10259 Traning Loss: tensor(0.0659)\n",
      "10260 Traning Loss: tensor(0.0653)\n",
      "10261 Traning Loss: tensor(0.0653)\n",
      "10262 Traning Loss: tensor(0.0664)\n",
      "10263 Traning Loss: tensor(0.0654)\n",
      "10264 Traning Loss: tensor(0.0651)\n",
      "10265 Traning Loss: tensor(0.0659)\n",
      "10266 Traning Loss: tensor(0.0663)\n",
      "10267 Traning Loss: tensor(0.0658)\n",
      "10268 Traning Loss: tensor(0.0656)\n",
      "10269 Traning Loss: tensor(0.0651)\n",
      "10270 Traning Loss: tensor(0.0647)\n",
      "10271 Traning Loss: tensor(0.0669)\n",
      "10272 Traning Loss: tensor(0.0652)\n",
      "10273 Traning Loss: tensor(0.0668)\n",
      "10274 Traning Loss: tensor(0.0663)\n",
      "10275 Traning Loss: tensor(0.0653)\n",
      "10276 Traning Loss: tensor(0.0670)\n",
      "10277 Traning Loss: tensor(0.0647)\n",
      "10278 Traning Loss: tensor(0.0659)\n",
      "10279 Traning Loss: tensor(0.0654)\n",
      "10280 Traning Loss: tensor(0.0646)\n",
      "10281 Traning Loss: tensor(0.0666)\n",
      "10282 Traning Loss: tensor(0.0663)\n",
      "10283 Traning Loss: tensor(0.0661)\n",
      "10284 Traning Loss: tensor(0.0657)\n",
      "10285 Traning Loss: tensor(0.0647)\n",
      "10286 Traning Loss: tensor(0.0653)\n",
      "10287 Traning Loss: tensor(0.0656)\n",
      "10288 Traning Loss: tensor(0.0642)\n",
      "10289 Traning Loss: tensor(0.0654)\n",
      "10290 Traning Loss: tensor(0.0656)\n",
      "10291 Traning Loss: tensor(0.0659)\n",
      "10292 Traning Loss: tensor(0.0667)\n",
      "10293 Traning Loss: tensor(0.0645)\n",
      "10294 Traning Loss: tensor(0.0651)\n",
      "10295 Traning Loss: tensor(0.0665)\n",
      "10296 Traning Loss: tensor(0.0653)\n",
      "10297 Traning Loss: tensor(0.0659)\n",
      "10298 Traning Loss: tensor(0.0663)\n",
      "10299 Traning Loss: tensor(0.0638)\n",
      "10300 Traning Loss: tensor(0.0654)\n",
      "10301 Traning Loss: tensor(0.0655)\n",
      "10302 Traning Loss: tensor(0.0651)\n",
      "10303 Traning Loss: tensor(0.0665)\n",
      "10304 Traning Loss: tensor(0.0658)\n",
      "10305 Traning Loss: tensor(0.0673)\n",
      "10306 Traning Loss: tensor(0.0661)\n",
      "10307 Traning Loss: tensor(0.0655)\n",
      "10308 Traning Loss: tensor(0.0664)\n",
      "10309 Traning Loss: tensor(0.0652)\n",
      "10310 Traning Loss: tensor(0.0650)\n",
      "10311 Traning Loss: tensor(0.0660)\n",
      "10312 Traning Loss: tensor(0.0658)\n",
      "10313 Traning Loss: tensor(0.0649)\n",
      "10314 Traning Loss: tensor(0.0648)\n",
      "10315 Traning Loss: tensor(0.0660)\n",
      "10316 Traning Loss: tensor(0.0655)\n",
      "10317 Traning Loss: tensor(0.0650)\n",
      "10318 Traning Loss: tensor(0.0662)\n",
      "10319 Traning Loss: tensor(0.0646)\n",
      "10320 Traning Loss: tensor(0.0662)\n",
      "10321 Traning Loss: tensor(0.0648)\n",
      "10322 Traning Loss: tensor(0.0673)\n",
      "10323 Traning Loss: tensor(0.0654)\n",
      "10324 Traning Loss: tensor(0.0655)\n",
      "10325 Traning Loss: tensor(0.0648)\n",
      "10326 Traning Loss: tensor(0.0669)\n",
      "10327 Traning Loss: tensor(0.0647)\n",
      "10328 Traning Loss: tensor(0.0648)\n",
      "10329 Traning Loss: tensor(0.0654)\n",
      "10330 Traning Loss: tensor(0.0654)\n",
      "10331 Traning Loss: tensor(0.0656)\n",
      "10332 Traning Loss: tensor(0.0664)\n",
      "10333 Traning Loss: tensor(0.0655)\n",
      "10334 Traning Loss: tensor(0.0661)\n",
      "10335 Traning Loss: tensor(0.0660)\n",
      "10336 Traning Loss: tensor(0.0648)\n",
      "10337 Traning Loss: tensor(0.0668)\n",
      "10338 Traning Loss: tensor(0.0640)\n",
      "10339 Traning Loss: tensor(0.0645)\n",
      "10340 Traning Loss: tensor(0.0643)\n",
      "10341 Traning Loss: tensor(0.0654)\n",
      "10342 Traning Loss: tensor(0.0660)\n",
      "10343 Traning Loss: tensor(0.0646)\n",
      "10344 Traning Loss: tensor(0.0664)\n",
      "10345 Traning Loss: tensor(0.0656)\n",
      "10346 Traning Loss: tensor(0.0655)\n",
      "10347 Traning Loss: tensor(0.0641)\n",
      "10348 Traning Loss: tensor(0.0646)\n",
      "10349 Traning Loss: tensor(0.0657)\n",
      "10350 Traning Loss: tensor(0.0661)\n",
      "10351 Traning Loss: tensor(0.0649)\n",
      "10352 Traning Loss: tensor(0.0651)\n",
      "10353 Traning Loss: tensor(0.0657)\n",
      "10354 Traning Loss: tensor(0.0653)\n",
      "10355 Traning Loss: tensor(0.0652)\n",
      "10356 Traning Loss: tensor(0.0648)\n",
      "10357 Traning Loss: tensor(0.0653)\n",
      "10358 Traning Loss: tensor(0.0652)\n",
      "10359 Traning Loss: tensor(0.0650)\n",
      "10360 Traning Loss: tensor(0.0652)\n",
      "10361 Traning Loss: tensor(0.0642)\n",
      "10362 Traning Loss: tensor(0.0660)\n",
      "10363 Traning Loss: tensor(0.0663)\n",
      "10364 Traning Loss: tensor(0.0659)\n",
      "10365 Traning Loss: tensor(0.0650)\n",
      "10366 Traning Loss: tensor(0.0652)\n",
      "10367 Traning Loss: tensor(0.0649)\n",
      "10368 Traning Loss: tensor(0.0651)\n",
      "10369 Traning Loss: tensor(0.0649)\n",
      "10370 Traning Loss: tensor(0.0650)\n",
      "10371 Traning Loss: tensor(0.0658)\n",
      "10372 Traning Loss: tensor(0.0659)\n",
      "10373 Traning Loss: tensor(0.0651)\n",
      "10374 Traning Loss: tensor(0.0656)\n",
      "10375 Traning Loss: tensor(0.0660)\n",
      "10376 Traning Loss: tensor(0.0646)\n",
      "10377 Traning Loss: tensor(0.0656)\n",
      "10378 Traning Loss: tensor(0.0655)\n",
      "10379 Traning Loss: tensor(0.0644)\n",
      "10380 Traning Loss: tensor(0.0643)\n",
      "10381 Traning Loss: tensor(0.0654)\n",
      "10382 Traning Loss: tensor(0.0646)\n",
      "10383 Traning Loss: tensor(0.0643)\n",
      "10384 Traning Loss: tensor(0.0661)\n",
      "10385 Traning Loss: tensor(0.0646)\n",
      "10386 Traning Loss: tensor(0.0642)\n",
      "10387 Traning Loss: tensor(0.0660)\n",
      "10388 Traning Loss: tensor(0.0661)\n",
      "10389 Traning Loss: tensor(0.0651)\n",
      "10390 Traning Loss: tensor(0.0644)\n",
      "10391 Traning Loss: tensor(0.0654)\n",
      "10392 Traning Loss: tensor(0.0661)\n",
      "10393 Traning Loss: tensor(0.0659)\n",
      "10394 Traning Loss: tensor(0.0652)\n",
      "10395 Traning Loss: tensor(0.0636)\n",
      "10396 Traning Loss: tensor(0.0665)\n",
      "10397 Traning Loss: tensor(0.0654)\n",
      "10398 Traning Loss: tensor(0.0662)\n",
      "10399 Traning Loss: tensor(0.0656)\n",
      "10400 Traning Loss: tensor(0.0642)\n",
      "10401 Traning Loss: tensor(0.0649)\n",
      "10402 Traning Loss: tensor(0.0650)\n",
      "10403 Traning Loss: tensor(0.0645)\n",
      "10404 Traning Loss: tensor(0.0641)\n",
      "10405 Traning Loss: tensor(0.0655)\n",
      "10406 Traning Loss: tensor(0.0647)\n",
      "10407 Traning Loss: tensor(0.0653)\n",
      "10408 Traning Loss: tensor(0.0641)\n",
      "10409 Traning Loss: tensor(0.0658)\n",
      "10410 Traning Loss: tensor(0.0647)\n",
      "10411 Traning Loss: tensor(0.0657)\n",
      "10412 Traning Loss: tensor(0.0655)\n",
      "10413 Traning Loss: tensor(0.0652)\n",
      "10414 Traning Loss: tensor(0.0647)\n",
      "10415 Traning Loss: tensor(0.0657)\n",
      "10416 Traning Loss: tensor(0.0646)\n",
      "10417 Traning Loss: tensor(0.0660)\n",
      "10418 Traning Loss: tensor(0.0647)\n",
      "10419 Traning Loss: tensor(0.0652)\n",
      "10420 Traning Loss: tensor(0.0648)\n",
      "10421 Traning Loss: tensor(0.0652)\n",
      "10422 Traning Loss: tensor(0.0651)\n",
      "10423 Traning Loss: tensor(0.0655)\n",
      "10424 Traning Loss: tensor(0.0640)\n",
      "10425 Traning Loss: tensor(0.0640)\n",
      "10426 Traning Loss: tensor(0.0652)\n",
      "10427 Traning Loss: tensor(0.0659)\n",
      "10428 Traning Loss: tensor(0.0644)\n",
      "10429 Traning Loss: tensor(0.0647)\n",
      "10430 Traning Loss: tensor(0.0646)\n",
      "10431 Traning Loss: tensor(0.0641)\n",
      "10432 Traning Loss: tensor(0.0652)\n",
      "10433 Traning Loss: tensor(0.0654)\n",
      "10434 Traning Loss: tensor(0.0648)\n",
      "10435 Traning Loss: tensor(0.0650)\n",
      "10436 Traning Loss: tensor(0.0645)\n",
      "10437 Traning Loss: tensor(0.0642)\n",
      "10438 Traning Loss: tensor(0.0661)\n",
      "10439 Traning Loss: tensor(0.0636)\n",
      "10440 Traning Loss: tensor(0.0646)\n",
      "10441 Traning Loss: tensor(0.0654)\n",
      "10442 Traning Loss: tensor(0.0661)\n",
      "10443 Traning Loss: tensor(0.0654)\n",
      "10444 Traning Loss: tensor(0.0647)\n",
      "10445 Traning Loss: tensor(0.0652)\n",
      "10446 Traning Loss: tensor(0.0653)\n",
      "10447 Traning Loss: tensor(0.0644)\n",
      "10448 Traning Loss: tensor(0.0646)\n",
      "10449 Traning Loss: tensor(0.0647)\n",
      "10450 Traning Loss: tensor(0.0643)\n",
      "10451 Traning Loss: tensor(0.0657)\n",
      "10452 Traning Loss: tensor(0.0653)\n",
      "10453 Traning Loss: tensor(0.0652)\n",
      "10454 Traning Loss: tensor(0.0651)\n",
      "10455 Traning Loss: tensor(0.0649)\n",
      "10456 Traning Loss: tensor(0.0657)\n",
      "10457 Traning Loss: tensor(0.0641)\n",
      "10458 Traning Loss: tensor(0.0634)\n",
      "10459 Traning Loss: tensor(0.0637)\n",
      "10460 Traning Loss: tensor(0.0653)\n",
      "10461 Traning Loss: tensor(0.0643)\n",
      "10462 Traning Loss: tensor(0.0652)\n",
      "10463 Traning Loss: tensor(0.0650)\n",
      "10464 Traning Loss: tensor(0.0634)\n",
      "10465 Traning Loss: tensor(0.0651)\n",
      "10466 Traning Loss: tensor(0.0650)\n",
      "10467 Traning Loss: tensor(0.0653)\n",
      "10468 Traning Loss: tensor(0.0654)\n",
      "10469 Traning Loss: tensor(0.0666)\n",
      "10470 Traning Loss: tensor(0.0640)\n",
      "10471 Traning Loss: tensor(0.0653)\n",
      "10472 Traning Loss: tensor(0.0643)\n",
      "10473 Traning Loss: tensor(0.0656)\n",
      "10474 Traning Loss: tensor(0.0649)\n",
      "10475 Traning Loss: tensor(0.0648)\n",
      "10476 Traning Loss: tensor(0.0643)\n",
      "10477 Traning Loss: tensor(0.0654)\n",
      "10478 Traning Loss: tensor(0.0644)\n",
      "10479 Traning Loss: tensor(0.0651)\n",
      "10480 Traning Loss: tensor(0.0643)\n",
      "10481 Traning Loss: tensor(0.0649)\n",
      "10482 Traning Loss: tensor(0.0646)\n",
      "10483 Traning Loss: tensor(0.0655)\n",
      "10484 Traning Loss: tensor(0.0651)\n",
      "10485 Traning Loss: tensor(0.0640)\n",
      "10486 Traning Loss: tensor(0.0650)\n",
      "10487 Traning Loss: tensor(0.0652)\n",
      "10488 Traning Loss: tensor(0.0648)\n",
      "10489 Traning Loss: tensor(0.0641)\n",
      "10490 Traning Loss: tensor(0.0657)\n",
      "10491 Traning Loss: tensor(0.0656)\n",
      "10492 Traning Loss: tensor(0.0657)\n",
      "10493 Traning Loss: tensor(0.0651)\n",
      "10494 Traning Loss: tensor(0.0649)\n",
      "10495 Traning Loss: tensor(0.0643)\n",
      "10496 Traning Loss: tensor(0.0646)\n",
      "10497 Traning Loss: tensor(0.0652)\n",
      "10498 Traning Loss: tensor(0.0641)\n",
      "10499 Traning Loss: tensor(0.0643)\n",
      "10500 Traning Loss: tensor(0.0636)\n",
      "10501 Traning Loss: tensor(0.0646)\n",
      "10502 Traning Loss: tensor(0.0648)\n",
      "10503 Traning Loss: tensor(0.0659)\n",
      "10504 Traning Loss: tensor(0.0627)\n",
      "10505 Traning Loss: tensor(0.0650)\n",
      "10506 Traning Loss: tensor(0.0639)\n",
      "10507 Traning Loss: tensor(0.0651)\n",
      "10508 Traning Loss: tensor(0.0642)\n",
      "10509 Traning Loss: tensor(0.0642)\n",
      "10510 Traning Loss: tensor(0.0645)\n",
      "10511 Traning Loss: tensor(0.0660)\n",
      "10512 Traning Loss: tensor(0.0641)\n",
      "10513 Traning Loss: tensor(0.0643)\n",
      "10514 Traning Loss: tensor(0.0651)\n",
      "10515 Traning Loss: tensor(0.0648)\n",
      "10516 Traning Loss: tensor(0.0650)\n",
      "10517 Traning Loss: tensor(0.0648)\n",
      "10518 Traning Loss: tensor(0.0653)\n",
      "10519 Traning Loss: tensor(0.0641)\n",
      "10520 Traning Loss: tensor(0.0639)\n",
      "10521 Traning Loss: tensor(0.0652)\n",
      "10522 Traning Loss: tensor(0.0641)\n",
      "10523 Traning Loss: tensor(0.0649)\n",
      "10524 Traning Loss: tensor(0.0653)\n",
      "10525 Traning Loss: tensor(0.0648)\n",
      "10526 Traning Loss: tensor(0.0645)\n",
      "10527 Traning Loss: tensor(0.0641)\n",
      "10528 Traning Loss: tensor(0.0650)\n",
      "10529 Traning Loss: tensor(0.0638)\n",
      "10530 Traning Loss: tensor(0.0646)\n",
      "10531 Traning Loss: tensor(0.0650)\n",
      "10532 Traning Loss: tensor(0.0643)\n",
      "10533 Traning Loss: tensor(0.0635)\n",
      "10534 Traning Loss: tensor(0.0648)\n",
      "10535 Traning Loss: tensor(0.0640)\n",
      "10536 Traning Loss: tensor(0.0638)\n",
      "10537 Traning Loss: tensor(0.0645)\n",
      "10538 Traning Loss: tensor(0.0633)\n",
      "10539 Traning Loss: tensor(0.0640)\n",
      "10540 Traning Loss: tensor(0.0649)\n",
      "10541 Traning Loss: tensor(0.0647)\n",
      "10542 Traning Loss: tensor(0.0646)\n",
      "10543 Traning Loss: tensor(0.0650)\n",
      "10544 Traning Loss: tensor(0.0638)\n",
      "10545 Traning Loss: tensor(0.0644)\n",
      "10546 Traning Loss: tensor(0.0643)\n",
      "10547 Traning Loss: tensor(0.0642)\n",
      "10548 Traning Loss: tensor(0.0655)\n",
      "10549 Traning Loss: tensor(0.0644)\n",
      "10550 Traning Loss: tensor(0.0652)\n",
      "10551 Traning Loss: tensor(0.0641)\n",
      "10552 Traning Loss: tensor(0.0651)\n",
      "10553 Traning Loss: tensor(0.0648)\n",
      "10554 Traning Loss: tensor(0.0633)\n",
      "10555 Traning Loss: tensor(0.0637)\n",
      "10556 Traning Loss: tensor(0.0650)\n",
      "10557 Traning Loss: tensor(0.0649)\n",
      "10558 Traning Loss: tensor(0.0643)\n",
      "10559 Traning Loss: tensor(0.0633)\n",
      "10560 Traning Loss: tensor(0.0650)\n",
      "10561 Traning Loss: tensor(0.0650)\n",
      "10562 Traning Loss: tensor(0.0641)\n",
      "10563 Traning Loss: tensor(0.0635)\n",
      "10564 Traning Loss: tensor(0.0643)\n",
      "10565 Traning Loss: tensor(0.0649)\n",
      "10566 Traning Loss: tensor(0.0628)\n",
      "10567 Traning Loss: tensor(0.0639)\n",
      "10568 Traning Loss: tensor(0.0644)\n",
      "10569 Traning Loss: tensor(0.0648)\n",
      "10570 Traning Loss: tensor(0.0646)\n",
      "10571 Traning Loss: tensor(0.0647)\n",
      "10572 Traning Loss: tensor(0.0646)\n",
      "10573 Traning Loss: tensor(0.0639)\n",
      "10574 Traning Loss: tensor(0.0640)\n",
      "10575 Traning Loss: tensor(0.0646)\n",
      "10576 Traning Loss: tensor(0.0636)\n",
      "10577 Traning Loss: tensor(0.0632)\n",
      "10578 Traning Loss: tensor(0.0643)\n",
      "10579 Traning Loss: tensor(0.0647)\n",
      "10580 Traning Loss: tensor(0.0657)\n",
      "10581 Traning Loss: tensor(0.0635)\n",
      "10582 Traning Loss: tensor(0.0639)\n",
      "10583 Traning Loss: tensor(0.0651)\n",
      "10584 Traning Loss: tensor(0.0643)\n",
      "10585 Traning Loss: tensor(0.0642)\n",
      "10586 Traning Loss: tensor(0.0647)\n",
      "10587 Traning Loss: tensor(0.0641)\n",
      "10588 Traning Loss: tensor(0.0650)\n",
      "10589 Traning Loss: tensor(0.0640)\n",
      "10590 Traning Loss: tensor(0.0635)\n",
      "10591 Traning Loss: tensor(0.0637)\n",
      "10592 Traning Loss: tensor(0.0644)\n",
      "10593 Traning Loss: tensor(0.0635)\n",
      "10594 Traning Loss: tensor(0.0645)\n",
      "10595 Traning Loss: tensor(0.0636)\n",
      "10596 Traning Loss: tensor(0.0636)\n",
      "10597 Traning Loss: tensor(0.0635)\n",
      "10598 Traning Loss: tensor(0.0646)\n",
      "10599 Traning Loss: tensor(0.0630)\n",
      "10600 Traning Loss: tensor(0.0633)\n",
      "10601 Traning Loss: tensor(0.0633)\n",
      "10602 Traning Loss: tensor(0.0640)\n",
      "10603 Traning Loss: tensor(0.0637)\n",
      "10604 Traning Loss: tensor(0.0646)\n",
      "10605 Traning Loss: tensor(0.0644)\n",
      "10606 Traning Loss: tensor(0.0635)\n",
      "10607 Traning Loss: tensor(0.0640)\n",
      "10608 Traning Loss: tensor(0.0625)\n",
      "10609 Traning Loss: tensor(0.0655)\n",
      "10610 Traning Loss: tensor(0.0640)\n",
      "10611 Traning Loss: tensor(0.0630)\n",
      "10612 Traning Loss: tensor(0.0638)\n",
      "10613 Traning Loss: tensor(0.0644)\n",
      "10614 Traning Loss: tensor(0.0636)\n",
      "10615 Traning Loss: tensor(0.0648)\n",
      "10616 Traning Loss: tensor(0.0630)\n",
      "10617 Traning Loss: tensor(0.0645)\n",
      "10618 Traning Loss: tensor(0.0623)\n",
      "10619 Traning Loss: tensor(0.0649)\n",
      "10620 Traning Loss: tensor(0.0636)\n",
      "10621 Traning Loss: tensor(0.0629)\n",
      "10622 Traning Loss: tensor(0.0640)\n",
      "10623 Traning Loss: tensor(0.0637)\n",
      "10624 Traning Loss: tensor(0.0636)\n",
      "10625 Traning Loss: tensor(0.0638)\n",
      "10626 Traning Loss: tensor(0.0638)\n",
      "10627 Traning Loss: tensor(0.0637)\n",
      "10628 Traning Loss: tensor(0.0642)\n",
      "10629 Traning Loss: tensor(0.0631)\n",
      "10630 Traning Loss: tensor(0.0642)\n",
      "10631 Traning Loss: tensor(0.0637)\n",
      "10632 Traning Loss: tensor(0.0646)\n",
      "10633 Traning Loss: tensor(0.0635)\n",
      "10634 Traning Loss: tensor(0.0639)\n",
      "10635 Traning Loss: tensor(0.0641)\n",
      "10636 Traning Loss: tensor(0.0639)\n",
      "10637 Traning Loss: tensor(0.0641)\n",
      "10638 Traning Loss: tensor(0.0648)\n",
      "10639 Traning Loss: tensor(0.0643)\n",
      "10640 Traning Loss: tensor(0.0640)\n",
      "10641 Traning Loss: tensor(0.0634)\n",
      "10642 Traning Loss: tensor(0.0644)\n",
      "10643 Traning Loss: tensor(0.0643)\n",
      "10644 Traning Loss: tensor(0.0642)\n",
      "10645 Traning Loss: tensor(0.0629)\n",
      "10646 Traning Loss: tensor(0.0653)\n",
      "10647 Traning Loss: tensor(0.0646)\n",
      "10648 Traning Loss: tensor(0.0649)\n",
      "10649 Traning Loss: tensor(0.0648)\n",
      "10650 Traning Loss: tensor(0.0641)\n",
      "10651 Traning Loss: tensor(0.0637)\n",
      "10652 Traning Loss: tensor(0.0632)\n",
      "10653 Traning Loss: tensor(0.0643)\n",
      "10654 Traning Loss: tensor(0.0641)\n",
      "10655 Traning Loss: tensor(0.0638)\n",
      "10656 Traning Loss: tensor(0.0638)\n",
      "10657 Traning Loss: tensor(0.0637)\n",
      "10658 Traning Loss: tensor(0.0633)\n",
      "10659 Traning Loss: tensor(0.0639)\n",
      "10660 Traning Loss: tensor(0.0648)\n",
      "10661 Traning Loss: tensor(0.0634)\n",
      "10662 Traning Loss: tensor(0.0641)\n",
      "10663 Traning Loss: tensor(0.0638)\n",
      "10664 Traning Loss: tensor(0.0643)\n",
      "10665 Traning Loss: tensor(0.0654)\n",
      "10666 Traning Loss: tensor(0.0645)\n",
      "10667 Traning Loss: tensor(0.0634)\n",
      "10668 Traning Loss: tensor(0.0635)\n",
      "10669 Traning Loss: tensor(0.0644)\n",
      "10670 Traning Loss: tensor(0.0632)\n",
      "10671 Traning Loss: tensor(0.0638)\n",
      "10672 Traning Loss: tensor(0.0643)\n",
      "10673 Traning Loss: tensor(0.0638)\n",
      "10674 Traning Loss: tensor(0.0625)\n",
      "10675 Traning Loss: tensor(0.0631)\n",
      "10676 Traning Loss: tensor(0.0641)\n",
      "10677 Traning Loss: tensor(0.0640)\n",
      "10678 Traning Loss: tensor(0.0638)\n",
      "10679 Traning Loss: tensor(0.0644)\n",
      "10680 Traning Loss: tensor(0.0641)\n",
      "10681 Traning Loss: tensor(0.0639)\n",
      "10682 Traning Loss: tensor(0.0619)\n",
      "10683 Traning Loss: tensor(0.0631)\n",
      "10684 Traning Loss: tensor(0.0636)\n",
      "10685 Traning Loss: tensor(0.0637)\n",
      "10686 Traning Loss: tensor(0.0636)\n",
      "10687 Traning Loss: tensor(0.0629)\n",
      "10688 Traning Loss: tensor(0.0638)\n",
      "10689 Traning Loss: tensor(0.0638)\n",
      "10690 Traning Loss: tensor(0.0651)\n",
      "10691 Traning Loss: tensor(0.0628)\n",
      "10692 Traning Loss: tensor(0.0638)\n",
      "10693 Traning Loss: tensor(0.0643)\n",
      "10694 Traning Loss: tensor(0.0633)\n",
      "10695 Traning Loss: tensor(0.0636)\n",
      "10696 Traning Loss: tensor(0.0647)\n",
      "10697 Traning Loss: tensor(0.0643)\n",
      "10698 Traning Loss: tensor(0.0630)\n",
      "10699 Traning Loss: tensor(0.0634)\n",
      "10700 Traning Loss: tensor(0.0628)\n",
      "10701 Traning Loss: tensor(0.0639)\n",
      "10702 Traning Loss: tensor(0.0634)\n",
      "10703 Traning Loss: tensor(0.0634)\n",
      "10704 Traning Loss: tensor(0.0636)\n",
      "10705 Traning Loss: tensor(0.0630)\n",
      "10706 Traning Loss: tensor(0.0629)\n",
      "10707 Traning Loss: tensor(0.0638)\n",
      "10708 Traning Loss: tensor(0.0626)\n",
      "10709 Traning Loss: tensor(0.0639)\n",
      "10710 Traning Loss: tensor(0.0640)\n",
      "10711 Traning Loss: tensor(0.0636)\n",
      "10712 Traning Loss: tensor(0.0641)\n",
      "10713 Traning Loss: tensor(0.0639)\n",
      "10714 Traning Loss: tensor(0.0628)\n",
      "10715 Traning Loss: tensor(0.0636)\n",
      "10716 Traning Loss: tensor(0.0628)\n",
      "10717 Traning Loss: tensor(0.0629)\n",
      "10718 Traning Loss: tensor(0.0629)\n",
      "10719 Traning Loss: tensor(0.0630)\n",
      "10720 Traning Loss: tensor(0.0645)\n",
      "10721 Traning Loss: tensor(0.0631)\n",
      "10722 Traning Loss: tensor(0.0620)\n",
      "10723 Traning Loss: tensor(0.0635)\n",
      "10724 Traning Loss: tensor(0.0624)\n",
      "10725 Traning Loss: tensor(0.0636)\n",
      "10726 Traning Loss: tensor(0.0631)\n",
      "10727 Traning Loss: tensor(0.0636)\n",
      "10728 Traning Loss: tensor(0.0635)\n",
      "10729 Traning Loss: tensor(0.0631)\n",
      "10730 Traning Loss: tensor(0.0640)\n",
      "10731 Traning Loss: tensor(0.0626)\n",
      "10732 Traning Loss: tensor(0.0635)\n",
      "10733 Traning Loss: tensor(0.0646)\n",
      "10734 Traning Loss: tensor(0.0633)\n",
      "10735 Traning Loss: tensor(0.0632)\n",
      "10736 Traning Loss: tensor(0.0636)\n",
      "10737 Traning Loss: tensor(0.0645)\n",
      "10738 Traning Loss: tensor(0.0632)\n",
      "10739 Traning Loss: tensor(0.0643)\n",
      "10740 Traning Loss: tensor(0.0633)\n",
      "10741 Traning Loss: tensor(0.0645)\n",
      "10742 Traning Loss: tensor(0.0627)\n",
      "10743 Traning Loss: tensor(0.0643)\n",
      "10744 Traning Loss: tensor(0.0629)\n",
      "10745 Traning Loss: tensor(0.0635)\n",
      "10746 Traning Loss: tensor(0.0630)\n",
      "10747 Traning Loss: tensor(0.0638)\n",
      "10748 Traning Loss: tensor(0.0643)\n",
      "10749 Traning Loss: tensor(0.0635)\n",
      "10750 Traning Loss: tensor(0.0635)\n",
      "10751 Traning Loss: tensor(0.0631)\n",
      "10752 Traning Loss: tensor(0.0644)\n",
      "10753 Traning Loss: tensor(0.0639)\n",
      "10754 Traning Loss: tensor(0.0640)\n",
      "10755 Traning Loss: tensor(0.0622)\n",
      "10756 Traning Loss: tensor(0.0633)\n",
      "10757 Traning Loss: tensor(0.0635)\n",
      "10758 Traning Loss: tensor(0.0628)\n",
      "10759 Traning Loss: tensor(0.0632)\n",
      "10760 Traning Loss: tensor(0.0634)\n",
      "10761 Traning Loss: tensor(0.0630)\n",
      "10762 Traning Loss: tensor(0.0630)\n",
      "10763 Traning Loss: tensor(0.0629)\n",
      "10764 Traning Loss: tensor(0.0624)\n",
      "10765 Traning Loss: tensor(0.0641)\n",
      "10766 Traning Loss: tensor(0.0635)\n",
      "10767 Traning Loss: tensor(0.0632)\n",
      "10768 Traning Loss: tensor(0.0635)\n",
      "10769 Traning Loss: tensor(0.0629)\n",
      "10770 Traning Loss: tensor(0.0632)\n",
      "10771 Traning Loss: tensor(0.0623)\n",
      "10772 Traning Loss: tensor(0.0630)\n",
      "10773 Traning Loss: tensor(0.0618)\n",
      "10774 Traning Loss: tensor(0.0620)\n",
      "10775 Traning Loss: tensor(0.0657)\n",
      "10776 Traning Loss: tensor(0.0639)\n",
      "10777 Traning Loss: tensor(0.0634)\n",
      "10778 Traning Loss: tensor(0.0627)\n",
      "10779 Traning Loss: tensor(0.0628)\n",
      "10780 Traning Loss: tensor(0.0632)\n",
      "10781 Traning Loss: tensor(0.0641)\n",
      "10782 Traning Loss: tensor(0.0635)\n",
      "10783 Traning Loss: tensor(0.0641)\n",
      "10784 Traning Loss: tensor(0.0630)\n",
      "10785 Traning Loss: tensor(0.0632)\n",
      "10786 Traning Loss: tensor(0.0625)\n",
      "10787 Traning Loss: tensor(0.0624)\n",
      "10788 Traning Loss: tensor(0.0629)\n",
      "10789 Traning Loss: tensor(0.0630)\n",
      "10790 Traning Loss: tensor(0.0625)\n",
      "10791 Traning Loss: tensor(0.0635)\n",
      "10792 Traning Loss: tensor(0.0633)\n",
      "10793 Traning Loss: tensor(0.0636)\n",
      "10794 Traning Loss: tensor(0.0638)\n",
      "10795 Traning Loss: tensor(0.0626)\n",
      "10796 Traning Loss: tensor(0.0631)\n",
      "10797 Traning Loss: tensor(0.0641)\n",
      "10798 Traning Loss: tensor(0.0634)\n",
      "10799 Traning Loss: tensor(0.0632)\n",
      "10800 Traning Loss: tensor(0.0632)\n",
      "10801 Traning Loss: tensor(0.0619)\n",
      "10802 Traning Loss: tensor(0.0623)\n",
      "10803 Traning Loss: tensor(0.0632)\n",
      "10804 Traning Loss: tensor(0.0630)\n",
      "10805 Traning Loss: tensor(0.0628)\n",
      "10806 Traning Loss: tensor(0.0623)\n",
      "10807 Traning Loss: tensor(0.0618)\n",
      "10808 Traning Loss: tensor(0.0636)\n",
      "10809 Traning Loss: tensor(0.0627)\n",
      "10810 Traning Loss: tensor(0.0634)\n",
      "10811 Traning Loss: tensor(0.0614)\n",
      "10812 Traning Loss: tensor(0.0636)\n",
      "10813 Traning Loss: tensor(0.0634)\n",
      "10814 Traning Loss: tensor(0.0633)\n",
      "10815 Traning Loss: tensor(0.0623)\n",
      "10816 Traning Loss: tensor(0.0621)\n",
      "10817 Traning Loss: tensor(0.0637)\n",
      "10818 Traning Loss: tensor(0.0638)\n",
      "10819 Traning Loss: tensor(0.0631)\n",
      "10820 Traning Loss: tensor(0.0634)\n",
      "10821 Traning Loss: tensor(0.0630)\n",
      "10822 Traning Loss: tensor(0.0629)\n",
      "10823 Traning Loss: tensor(0.0632)\n",
      "10824 Traning Loss: tensor(0.0639)\n",
      "10825 Traning Loss: tensor(0.0622)\n",
      "10826 Traning Loss: tensor(0.0640)\n",
      "10827 Traning Loss: tensor(0.0638)\n",
      "10828 Traning Loss: tensor(0.0624)\n",
      "10829 Traning Loss: tensor(0.0625)\n",
      "10830 Traning Loss: tensor(0.0632)\n",
      "10831 Traning Loss: tensor(0.0632)\n",
      "10832 Traning Loss: tensor(0.0633)\n",
      "10833 Traning Loss: tensor(0.0623)\n",
      "10834 Traning Loss: tensor(0.0639)\n",
      "10835 Traning Loss: tensor(0.0629)\n",
      "10836 Traning Loss: tensor(0.0630)\n",
      "10837 Traning Loss: tensor(0.0633)\n",
      "10838 Traning Loss: tensor(0.0626)\n",
      "10839 Traning Loss: tensor(0.0632)\n",
      "10840 Traning Loss: tensor(0.0628)\n",
      "10841 Traning Loss: tensor(0.0625)\n",
      "10842 Traning Loss: tensor(0.0636)\n",
      "10843 Traning Loss: tensor(0.0639)\n",
      "10844 Traning Loss: tensor(0.0631)\n",
      "10845 Traning Loss: tensor(0.0624)\n",
      "10846 Traning Loss: tensor(0.0630)\n",
      "10847 Traning Loss: tensor(0.0636)\n",
      "10848 Traning Loss: tensor(0.0634)\n",
      "10849 Traning Loss: tensor(0.0622)\n",
      "10850 Traning Loss: tensor(0.0624)\n",
      "10851 Traning Loss: tensor(0.0625)\n",
      "10852 Traning Loss: tensor(0.0623)\n",
      "10853 Traning Loss: tensor(0.0622)\n",
      "10854 Traning Loss: tensor(0.0626)\n",
      "10855 Traning Loss: tensor(0.0630)\n",
      "10856 Traning Loss: tensor(0.0626)\n",
      "10857 Traning Loss: tensor(0.0632)\n",
      "10858 Traning Loss: tensor(0.0635)\n",
      "10859 Traning Loss: tensor(0.0621)\n",
      "10860 Traning Loss: tensor(0.0629)\n",
      "10861 Traning Loss: tensor(0.0641)\n",
      "10862 Traning Loss: tensor(0.0634)\n",
      "10863 Traning Loss: tensor(0.0636)\n",
      "10864 Traning Loss: tensor(0.0633)\n",
      "10865 Traning Loss: tensor(0.0622)\n",
      "10866 Traning Loss: tensor(0.0624)\n",
      "10867 Traning Loss: tensor(0.0624)\n",
      "10868 Traning Loss: tensor(0.0643)\n",
      "10869 Traning Loss: tensor(0.0631)\n",
      "10870 Traning Loss: tensor(0.0630)\n",
      "10871 Traning Loss: tensor(0.0635)\n",
      "10872 Traning Loss: tensor(0.0623)\n",
      "10873 Traning Loss: tensor(0.0641)\n",
      "10874 Traning Loss: tensor(0.0631)\n",
      "10875 Traning Loss: tensor(0.0646)\n",
      "10876 Traning Loss: tensor(0.0631)\n",
      "10877 Traning Loss: tensor(0.0621)\n",
      "10878 Traning Loss: tensor(0.0627)\n",
      "10879 Traning Loss: tensor(0.0632)\n",
      "10880 Traning Loss: tensor(0.0629)\n",
      "10881 Traning Loss: tensor(0.0625)\n",
      "10882 Traning Loss: tensor(0.0619)\n",
      "10883 Traning Loss: tensor(0.0632)\n",
      "10884 Traning Loss: tensor(0.0635)\n",
      "10885 Traning Loss: tensor(0.0637)\n",
      "10886 Traning Loss: tensor(0.0622)\n",
      "10887 Traning Loss: tensor(0.0627)\n",
      "10888 Traning Loss: tensor(0.0617)\n",
      "10889 Traning Loss: tensor(0.0619)\n",
      "10890 Traning Loss: tensor(0.0638)\n",
      "10891 Traning Loss: tensor(0.0625)\n",
      "10892 Traning Loss: tensor(0.0636)\n",
      "10893 Traning Loss: tensor(0.0626)\n",
      "10894 Traning Loss: tensor(0.0625)\n",
      "10895 Traning Loss: tensor(0.0615)\n",
      "10896 Traning Loss: tensor(0.0617)\n",
      "10897 Traning Loss: tensor(0.0628)\n",
      "10898 Traning Loss: tensor(0.0624)\n",
      "10899 Traning Loss: tensor(0.0629)\n",
      "10900 Traning Loss: tensor(0.0625)\n",
      "10901 Traning Loss: tensor(0.0614)\n",
      "10902 Traning Loss: tensor(0.0638)\n",
      "10903 Traning Loss: tensor(0.0621)\n",
      "10904 Traning Loss: tensor(0.0617)\n",
      "10905 Traning Loss: tensor(0.0616)\n",
      "10906 Traning Loss: tensor(0.0625)\n",
      "10907 Traning Loss: tensor(0.0625)\n",
      "10908 Traning Loss: tensor(0.0630)\n",
      "10909 Traning Loss: tensor(0.0627)\n",
      "10910 Traning Loss: tensor(0.0621)\n",
      "10911 Traning Loss: tensor(0.0618)\n",
      "10912 Traning Loss: tensor(0.0624)\n",
      "10913 Traning Loss: tensor(0.0612)\n",
      "10914 Traning Loss: tensor(0.0619)\n",
      "10915 Traning Loss: tensor(0.0625)\n",
      "10916 Traning Loss: tensor(0.0610)\n",
      "10917 Traning Loss: tensor(0.0622)\n",
      "10918 Traning Loss: tensor(0.0620)\n",
      "10919 Traning Loss: tensor(0.0631)\n",
      "10920 Traning Loss: tensor(0.0638)\n",
      "10921 Traning Loss: tensor(0.0630)\n",
      "10922 Traning Loss: tensor(0.0632)\n",
      "10923 Traning Loss: tensor(0.0616)\n",
      "10924 Traning Loss: tensor(0.0622)\n",
      "10925 Traning Loss: tensor(0.0627)\n",
      "10926 Traning Loss: tensor(0.0619)\n",
      "10927 Traning Loss: tensor(0.0624)\n",
      "10928 Traning Loss: tensor(0.0613)\n",
      "10929 Traning Loss: tensor(0.0636)\n",
      "10930 Traning Loss: tensor(0.0628)\n",
      "10931 Traning Loss: tensor(0.0626)\n",
      "10932 Traning Loss: tensor(0.0629)\n",
      "10933 Traning Loss: tensor(0.0619)\n",
      "10934 Traning Loss: tensor(0.0621)\n",
      "10935 Traning Loss: tensor(0.0617)\n",
      "10936 Traning Loss: tensor(0.0634)\n",
      "10937 Traning Loss: tensor(0.0627)\n",
      "10938 Traning Loss: tensor(0.0629)\n",
      "10939 Traning Loss: tensor(0.0626)\n",
      "10940 Traning Loss: tensor(0.0629)\n",
      "10941 Traning Loss: tensor(0.0628)\n",
      "10942 Traning Loss: tensor(0.0630)\n",
      "10943 Traning Loss: tensor(0.0630)\n",
      "10944 Traning Loss: tensor(0.0631)\n",
      "10945 Traning Loss: tensor(0.0624)\n",
      "10946 Traning Loss: tensor(0.0629)\n",
      "10947 Traning Loss: tensor(0.0635)\n",
      "10948 Traning Loss: tensor(0.0632)\n",
      "10949 Traning Loss: tensor(0.0632)\n",
      "10950 Traning Loss: tensor(0.0632)\n",
      "10951 Traning Loss: tensor(0.0611)\n",
      "10952 Traning Loss: tensor(0.0617)\n",
      "10953 Traning Loss: tensor(0.0631)\n",
      "10954 Traning Loss: tensor(0.0632)\n",
      "10955 Traning Loss: tensor(0.0633)\n",
      "10956 Traning Loss: tensor(0.0633)\n",
      "10957 Traning Loss: tensor(0.0635)\n",
      "10958 Traning Loss: tensor(0.0617)\n",
      "10959 Traning Loss: tensor(0.0631)\n",
      "10960 Traning Loss: tensor(0.0623)\n",
      "10961 Traning Loss: tensor(0.0629)\n",
      "10962 Traning Loss: tensor(0.0626)\n",
      "10963 Traning Loss: tensor(0.0625)\n",
      "10964 Traning Loss: tensor(0.0633)\n",
      "10965 Traning Loss: tensor(0.0623)\n",
      "10966 Traning Loss: tensor(0.0631)\n",
      "10967 Traning Loss: tensor(0.0620)\n",
      "10968 Traning Loss: tensor(0.0628)\n",
      "10969 Traning Loss: tensor(0.0626)\n",
      "10970 Traning Loss: tensor(0.0610)\n",
      "10971 Traning Loss: tensor(0.0614)\n",
      "10972 Traning Loss: tensor(0.0636)\n",
      "10973 Traning Loss: tensor(0.0617)\n",
      "10974 Traning Loss: tensor(0.0624)\n",
      "10975 Traning Loss: tensor(0.0617)\n",
      "10976 Traning Loss: tensor(0.0617)\n",
      "10977 Traning Loss: tensor(0.0622)\n",
      "10978 Traning Loss: tensor(0.0626)\n",
      "10979 Traning Loss: tensor(0.0631)\n",
      "10980 Traning Loss: tensor(0.0623)\n",
      "10981 Traning Loss: tensor(0.0606)\n",
      "10982 Traning Loss: tensor(0.0631)\n",
      "10983 Traning Loss: tensor(0.0628)\n",
      "10984 Traning Loss: tensor(0.0619)\n",
      "10985 Traning Loss: tensor(0.0618)\n",
      "10986 Traning Loss: tensor(0.0624)\n",
      "10987 Traning Loss: tensor(0.0622)\n",
      "10988 Traning Loss: tensor(0.0615)\n",
      "10989 Traning Loss: tensor(0.0615)\n",
      "10990 Traning Loss: tensor(0.0619)\n",
      "10991 Traning Loss: tensor(0.0637)\n",
      "10992 Traning Loss: tensor(0.0629)\n",
      "10993 Traning Loss: tensor(0.0613)\n",
      "10994 Traning Loss: tensor(0.0628)\n",
      "10995 Traning Loss: tensor(0.0618)\n",
      "10996 Traning Loss: tensor(0.0620)\n",
      "10997 Traning Loss: tensor(0.0617)\n",
      "10998 Traning Loss: tensor(0.0617)\n",
      "10999 Traning Loss: tensor(0.0623)\n",
      "11000 Traning Loss: tensor(0.0620)\n",
      "11001 Traning Loss: tensor(0.0632)\n",
      "11002 Traning Loss: tensor(0.0623)\n",
      "11003 Traning Loss: tensor(0.0637)\n",
      "11004 Traning Loss: tensor(0.0615)\n",
      "11005 Traning Loss: tensor(0.0618)\n",
      "11006 Traning Loss: tensor(0.0617)\n",
      "11007 Traning Loss: tensor(0.0618)\n",
      "11008 Traning Loss: tensor(0.0614)\n",
      "11009 Traning Loss: tensor(0.0621)\n",
      "11010 Traning Loss: tensor(0.0617)\n",
      "11011 Traning Loss: tensor(0.0626)\n",
      "11012 Traning Loss: tensor(0.0621)\n",
      "11013 Traning Loss: tensor(0.0622)\n",
      "11014 Traning Loss: tensor(0.0624)\n",
      "11015 Traning Loss: tensor(0.0626)\n",
      "11016 Traning Loss: tensor(0.0619)\n",
      "11017 Traning Loss: tensor(0.0612)\n",
      "11018 Traning Loss: tensor(0.0624)\n",
      "11019 Traning Loss: tensor(0.0623)\n",
      "11020 Traning Loss: tensor(0.0645)\n",
      "11021 Traning Loss: tensor(0.0611)\n",
      "11022 Traning Loss: tensor(0.0617)\n",
      "11023 Traning Loss: tensor(0.0610)\n",
      "11024 Traning Loss: tensor(0.0627)\n",
      "11025 Traning Loss: tensor(0.0616)\n",
      "11026 Traning Loss: tensor(0.0628)\n",
      "11027 Traning Loss: tensor(0.0611)\n",
      "11028 Traning Loss: tensor(0.0619)\n",
      "11029 Traning Loss: tensor(0.0618)\n",
      "11030 Traning Loss: tensor(0.0632)\n",
      "11031 Traning Loss: tensor(0.0636)\n",
      "11032 Traning Loss: tensor(0.0619)\n",
      "11033 Traning Loss: tensor(0.0620)\n",
      "11034 Traning Loss: tensor(0.0613)\n",
      "11035 Traning Loss: tensor(0.0625)\n",
      "11036 Traning Loss: tensor(0.0612)\n",
      "11037 Traning Loss: tensor(0.0621)\n",
      "11038 Traning Loss: tensor(0.0629)\n",
      "11039 Traning Loss: tensor(0.0632)\n",
      "11040 Traning Loss: tensor(0.0613)\n",
      "11041 Traning Loss: tensor(0.0617)\n",
      "11042 Traning Loss: tensor(0.0627)\n",
      "11043 Traning Loss: tensor(0.0625)\n",
      "11044 Traning Loss: tensor(0.0641)\n",
      "11045 Traning Loss: tensor(0.0622)\n",
      "11046 Traning Loss: tensor(0.0608)\n",
      "11047 Traning Loss: tensor(0.0607)\n",
      "11048 Traning Loss: tensor(0.0620)\n",
      "11049 Traning Loss: tensor(0.0625)\n",
      "11050 Traning Loss: tensor(0.0619)\n",
      "11051 Traning Loss: tensor(0.0619)\n",
      "11052 Traning Loss: tensor(0.0627)\n",
      "11053 Traning Loss: tensor(0.0620)\n",
      "11054 Traning Loss: tensor(0.0620)\n",
      "11055 Traning Loss: tensor(0.0616)\n",
      "11056 Traning Loss: tensor(0.0622)\n",
      "11057 Traning Loss: tensor(0.0634)\n",
      "11058 Traning Loss: tensor(0.0612)\n",
      "11059 Traning Loss: tensor(0.0623)\n",
      "11060 Traning Loss: tensor(0.0616)\n",
      "11061 Traning Loss: tensor(0.0633)\n",
      "11062 Traning Loss: tensor(0.0610)\n",
      "11063 Traning Loss: tensor(0.0610)\n",
      "11064 Traning Loss: tensor(0.0619)\n",
      "11065 Traning Loss: tensor(0.0623)\n",
      "11066 Traning Loss: tensor(0.0621)\n",
      "11067 Traning Loss: tensor(0.0626)\n",
      "11068 Traning Loss: tensor(0.0616)\n",
      "11069 Traning Loss: tensor(0.0619)\n",
      "11070 Traning Loss: tensor(0.0613)\n",
      "11071 Traning Loss: tensor(0.0617)\n",
      "11072 Traning Loss: tensor(0.0624)\n",
      "11073 Traning Loss: tensor(0.0618)\n",
      "11074 Traning Loss: tensor(0.0620)\n",
      "11075 Traning Loss: tensor(0.0615)\n",
      "11076 Traning Loss: tensor(0.0618)\n",
      "11077 Traning Loss: tensor(0.0618)\n",
      "11078 Traning Loss: tensor(0.0617)\n",
      "11079 Traning Loss: tensor(0.0617)\n",
      "11080 Traning Loss: tensor(0.0614)\n",
      "11081 Traning Loss: tensor(0.0609)\n",
      "11082 Traning Loss: tensor(0.0608)\n",
      "11083 Traning Loss: tensor(0.0611)\n",
      "11084 Traning Loss: tensor(0.0610)\n",
      "11085 Traning Loss: tensor(0.0610)\n",
      "11086 Traning Loss: tensor(0.0607)\n",
      "11087 Traning Loss: tensor(0.0612)\n",
      "11088 Traning Loss: tensor(0.0607)\n",
      "11089 Traning Loss: tensor(0.0612)\n",
      "11090 Traning Loss: tensor(0.0608)\n",
      "11091 Traning Loss: tensor(0.0610)\n",
      "11092 Traning Loss: tensor(0.0619)\n",
      "11093 Traning Loss: tensor(0.0615)\n",
      "11094 Traning Loss: tensor(0.0625)\n",
      "11095 Traning Loss: tensor(0.0605)\n",
      "11096 Traning Loss: tensor(0.0623)\n",
      "11097 Traning Loss: tensor(0.0618)\n",
      "11098 Traning Loss: tensor(0.0612)\n",
      "11099 Traning Loss: tensor(0.0625)\n",
      "11100 Traning Loss: tensor(0.0622)\n",
      "11101 Traning Loss: tensor(0.0611)\n",
      "11102 Traning Loss: tensor(0.0602)\n",
      "11103 Traning Loss: tensor(0.0622)\n",
      "11104 Traning Loss: tensor(0.0614)\n",
      "11105 Traning Loss: tensor(0.0628)\n",
      "11106 Traning Loss: tensor(0.0609)\n",
      "11107 Traning Loss: tensor(0.0616)\n",
      "11108 Traning Loss: tensor(0.0612)\n",
      "11109 Traning Loss: tensor(0.0627)\n",
      "11110 Traning Loss: tensor(0.0609)\n",
      "11111 Traning Loss: tensor(0.0615)\n",
      "11112 Traning Loss: tensor(0.0625)\n",
      "11113 Traning Loss: tensor(0.0615)\n",
      "11114 Traning Loss: tensor(0.0608)\n",
      "11115 Traning Loss: tensor(0.0627)\n",
      "11116 Traning Loss: tensor(0.0607)\n",
      "11117 Traning Loss: tensor(0.0614)\n",
      "11118 Traning Loss: tensor(0.0620)\n",
      "11119 Traning Loss: tensor(0.0625)\n",
      "11120 Traning Loss: tensor(0.0618)\n",
      "11121 Traning Loss: tensor(0.0608)\n",
      "11122 Traning Loss: tensor(0.0620)\n",
      "11123 Traning Loss: tensor(0.0612)\n",
      "11124 Traning Loss: tensor(0.0603)\n",
      "11125 Traning Loss: tensor(0.0625)\n",
      "11126 Traning Loss: tensor(0.0606)\n",
      "11127 Traning Loss: tensor(0.0611)\n",
      "11128 Traning Loss: tensor(0.0626)\n",
      "11129 Traning Loss: tensor(0.0607)\n",
      "11130 Traning Loss: tensor(0.0612)\n",
      "11131 Traning Loss: tensor(0.0602)\n",
      "11132 Traning Loss: tensor(0.0611)\n",
      "11133 Traning Loss: tensor(0.0613)\n",
      "11134 Traning Loss: tensor(0.0613)\n",
      "11135 Traning Loss: tensor(0.0612)\n",
      "11136 Traning Loss: tensor(0.0621)\n",
      "11137 Traning Loss: tensor(0.0615)\n",
      "11138 Traning Loss: tensor(0.0614)\n",
      "11139 Traning Loss: tensor(0.0612)\n",
      "11140 Traning Loss: tensor(0.0612)\n",
      "11141 Traning Loss: tensor(0.0613)\n",
      "11142 Traning Loss: tensor(0.0597)\n",
      "11143 Traning Loss: tensor(0.0612)\n",
      "11144 Traning Loss: tensor(0.0623)\n",
      "11145 Traning Loss: tensor(0.0607)\n",
      "11146 Traning Loss: tensor(0.0614)\n",
      "11147 Traning Loss: tensor(0.0608)\n",
      "11148 Traning Loss: tensor(0.0600)\n",
      "11149 Traning Loss: tensor(0.0613)\n",
      "11150 Traning Loss: tensor(0.0601)\n",
      "11151 Traning Loss: tensor(0.0597)\n",
      "11152 Traning Loss: tensor(0.0612)\n",
      "11153 Traning Loss: tensor(0.0617)\n",
      "11154 Traning Loss: tensor(0.0613)\n",
      "11155 Traning Loss: tensor(0.0639)\n",
      "11156 Traning Loss: tensor(0.0604)\n",
      "11157 Traning Loss: tensor(0.0615)\n",
      "11158 Traning Loss: tensor(0.0600)\n",
      "11159 Traning Loss: tensor(0.0605)\n",
      "11160 Traning Loss: tensor(0.0611)\n",
      "11161 Traning Loss: tensor(0.0624)\n",
      "11162 Traning Loss: tensor(0.0619)\n",
      "11163 Traning Loss: tensor(0.0612)\n",
      "11164 Traning Loss: tensor(0.0606)\n",
      "11165 Traning Loss: tensor(0.0617)\n",
      "11166 Traning Loss: tensor(0.0614)\n",
      "11167 Traning Loss: tensor(0.0613)\n",
      "11168 Traning Loss: tensor(0.0607)\n",
      "11169 Traning Loss: tensor(0.0610)\n",
      "11170 Traning Loss: tensor(0.0613)\n",
      "11171 Traning Loss: tensor(0.0605)\n",
      "11172 Traning Loss: tensor(0.0622)\n",
      "11173 Traning Loss: tensor(0.0605)\n",
      "11174 Traning Loss: tensor(0.0619)\n",
      "11175 Traning Loss: tensor(0.0635)\n",
      "11176 Traning Loss: tensor(0.0604)\n",
      "11177 Traning Loss: tensor(0.0613)\n",
      "11178 Traning Loss: tensor(0.0613)\n",
      "11179 Traning Loss: tensor(0.0612)\n",
      "11180 Traning Loss: tensor(0.0607)\n",
      "11181 Traning Loss: tensor(0.0604)\n",
      "11182 Traning Loss: tensor(0.0614)\n",
      "11183 Traning Loss: tensor(0.0619)\n",
      "11184 Traning Loss: tensor(0.0612)\n",
      "11185 Traning Loss: tensor(0.0603)\n",
      "11186 Traning Loss: tensor(0.0612)\n",
      "11187 Traning Loss: tensor(0.0610)\n",
      "11188 Traning Loss: tensor(0.0615)\n",
      "11189 Traning Loss: tensor(0.0609)\n",
      "11190 Traning Loss: tensor(0.0618)\n",
      "11191 Traning Loss: tensor(0.0611)\n",
      "11192 Traning Loss: tensor(0.0609)\n",
      "11193 Traning Loss: tensor(0.0616)\n",
      "11194 Traning Loss: tensor(0.0610)\n",
      "11195 Traning Loss: tensor(0.0613)\n",
      "11196 Traning Loss: tensor(0.0615)\n",
      "11197 Traning Loss: tensor(0.0603)\n",
      "11198 Traning Loss: tensor(0.0606)\n",
      "11199 Traning Loss: tensor(0.0600)\n",
      "11200 Traning Loss: tensor(0.0604)\n",
      "11201 Traning Loss: tensor(0.0608)\n",
      "11202 Traning Loss: tensor(0.0609)\n",
      "11203 Traning Loss: tensor(0.0611)\n",
      "11204 Traning Loss: tensor(0.0608)\n",
      "11205 Traning Loss: tensor(0.0603)\n",
      "11206 Traning Loss: tensor(0.0604)\n",
      "11207 Traning Loss: tensor(0.0604)\n",
      "11208 Traning Loss: tensor(0.0613)\n",
      "11209 Traning Loss: tensor(0.0603)\n",
      "11210 Traning Loss: tensor(0.0600)\n",
      "11211 Traning Loss: tensor(0.0620)\n",
      "11212 Traning Loss: tensor(0.0604)\n",
      "11213 Traning Loss: tensor(0.0615)\n",
      "11214 Traning Loss: tensor(0.0608)\n",
      "11215 Traning Loss: tensor(0.0626)\n",
      "11216 Traning Loss: tensor(0.0600)\n",
      "11217 Traning Loss: tensor(0.0605)\n",
      "11218 Traning Loss: tensor(0.0608)\n",
      "11219 Traning Loss: tensor(0.0619)\n",
      "11220 Traning Loss: tensor(0.0614)\n",
      "11221 Traning Loss: tensor(0.0617)\n",
      "11222 Traning Loss: tensor(0.0598)\n",
      "11223 Traning Loss: tensor(0.0600)\n",
      "11224 Traning Loss: tensor(0.0618)\n",
      "11225 Traning Loss: tensor(0.0608)\n",
      "11226 Traning Loss: tensor(0.0595)\n",
      "11227 Traning Loss: tensor(0.0618)\n",
      "11228 Traning Loss: tensor(0.0609)\n",
      "11229 Traning Loss: tensor(0.0612)\n",
      "11230 Traning Loss: tensor(0.0603)\n",
      "11231 Traning Loss: tensor(0.0601)\n",
      "11232 Traning Loss: tensor(0.0606)\n",
      "11233 Traning Loss: tensor(0.0611)\n",
      "11234 Traning Loss: tensor(0.0606)\n",
      "11235 Traning Loss: tensor(0.0620)\n",
      "11236 Traning Loss: tensor(0.0600)\n",
      "11237 Traning Loss: tensor(0.0600)\n",
      "11238 Traning Loss: tensor(0.0607)\n",
      "11239 Traning Loss: tensor(0.0608)\n",
      "11240 Traning Loss: tensor(0.0598)\n",
      "11241 Traning Loss: tensor(0.0607)\n",
      "11242 Traning Loss: tensor(0.0612)\n",
      "11243 Traning Loss: tensor(0.0602)\n",
      "11244 Traning Loss: tensor(0.0607)\n",
      "11245 Traning Loss: tensor(0.0609)\n",
      "11246 Traning Loss: tensor(0.0606)\n",
      "11247 Traning Loss: tensor(0.0596)\n",
      "11248 Traning Loss: tensor(0.0605)\n",
      "11249 Traning Loss: tensor(0.0604)\n",
      "11250 Traning Loss: tensor(0.0602)\n",
      "11251 Traning Loss: tensor(0.0603)\n",
      "11252 Traning Loss: tensor(0.0605)\n",
      "11253 Traning Loss: tensor(0.0614)\n",
      "11254 Traning Loss: tensor(0.0618)\n",
      "11255 Traning Loss: tensor(0.0600)\n",
      "11256 Traning Loss: tensor(0.0604)\n",
      "11257 Traning Loss: tensor(0.0609)\n",
      "11258 Traning Loss: tensor(0.0608)\n",
      "11259 Traning Loss: tensor(0.0612)\n",
      "11260 Traning Loss: tensor(0.0600)\n",
      "11261 Traning Loss: tensor(0.0606)\n",
      "11262 Traning Loss: tensor(0.0603)\n",
      "11263 Traning Loss: tensor(0.0604)\n",
      "11264 Traning Loss: tensor(0.0604)\n",
      "11265 Traning Loss: tensor(0.0596)\n",
      "11266 Traning Loss: tensor(0.0601)\n",
      "11267 Traning Loss: tensor(0.0602)\n",
      "11268 Traning Loss: tensor(0.0598)\n",
      "11269 Traning Loss: tensor(0.0606)\n",
      "11270 Traning Loss: tensor(0.0609)\n",
      "11271 Traning Loss: tensor(0.0609)\n",
      "11272 Traning Loss: tensor(0.0601)\n",
      "11273 Traning Loss: tensor(0.0604)\n",
      "11274 Traning Loss: tensor(0.0605)\n",
      "11275 Traning Loss: tensor(0.0605)\n",
      "11276 Traning Loss: tensor(0.0618)\n",
      "11277 Traning Loss: tensor(0.0603)\n",
      "11278 Traning Loss: tensor(0.0613)\n",
      "11279 Traning Loss: tensor(0.0599)\n",
      "11280 Traning Loss: tensor(0.0594)\n",
      "11281 Traning Loss: tensor(0.0605)\n",
      "11282 Traning Loss: tensor(0.0610)\n",
      "11283 Traning Loss: tensor(0.0610)\n",
      "11284 Traning Loss: tensor(0.0608)\n",
      "11285 Traning Loss: tensor(0.0609)\n",
      "11286 Traning Loss: tensor(0.0609)\n",
      "11287 Traning Loss: tensor(0.0592)\n",
      "11288 Traning Loss: tensor(0.0597)\n",
      "11289 Traning Loss: tensor(0.0611)\n",
      "11290 Traning Loss: tensor(0.0609)\n",
      "11291 Traning Loss: tensor(0.0597)\n",
      "11292 Traning Loss: tensor(0.0603)\n",
      "11293 Traning Loss: tensor(0.0599)\n",
      "11294 Traning Loss: tensor(0.0598)\n",
      "11295 Traning Loss: tensor(0.0608)\n",
      "11296 Traning Loss: tensor(0.0608)\n",
      "11297 Traning Loss: tensor(0.0601)\n",
      "11298 Traning Loss: tensor(0.0607)\n",
      "11299 Traning Loss: tensor(0.0592)\n",
      "11300 Traning Loss: tensor(0.0603)\n",
      "11301 Traning Loss: tensor(0.0608)\n",
      "11302 Traning Loss: tensor(0.0610)\n",
      "11303 Traning Loss: tensor(0.0595)\n",
      "11304 Traning Loss: tensor(0.0594)\n",
      "11305 Traning Loss: tensor(0.0609)\n",
      "11306 Traning Loss: tensor(0.0600)\n",
      "11307 Traning Loss: tensor(0.0606)\n",
      "11308 Traning Loss: tensor(0.0618)\n",
      "11309 Traning Loss: tensor(0.0608)\n",
      "11310 Traning Loss: tensor(0.0609)\n",
      "11311 Traning Loss: tensor(0.0604)\n",
      "11312 Traning Loss: tensor(0.0597)\n",
      "11313 Traning Loss: tensor(0.0612)\n",
      "11314 Traning Loss: tensor(0.0596)\n",
      "11315 Traning Loss: tensor(0.0600)\n",
      "11316 Traning Loss: tensor(0.0595)\n",
      "11317 Traning Loss: tensor(0.0614)\n",
      "11318 Traning Loss: tensor(0.0605)\n",
      "11319 Traning Loss: tensor(0.0601)\n",
      "11320 Traning Loss: tensor(0.0597)\n",
      "11321 Traning Loss: tensor(0.0609)\n",
      "11322 Traning Loss: tensor(0.0612)\n",
      "11323 Traning Loss: tensor(0.0603)\n",
      "11324 Traning Loss: tensor(0.0600)\n",
      "11325 Traning Loss: tensor(0.0599)\n",
      "11326 Traning Loss: tensor(0.0605)\n",
      "11327 Traning Loss: tensor(0.0601)\n",
      "11328 Traning Loss: tensor(0.0603)\n",
      "11329 Traning Loss: tensor(0.0599)\n",
      "11330 Traning Loss: tensor(0.0604)\n",
      "11331 Traning Loss: tensor(0.0608)\n",
      "11332 Traning Loss: tensor(0.0595)\n",
      "11333 Traning Loss: tensor(0.0598)\n",
      "11334 Traning Loss: tensor(0.0596)\n",
      "11335 Traning Loss: tensor(0.0599)\n",
      "11336 Traning Loss: tensor(0.0598)\n",
      "11337 Traning Loss: tensor(0.0594)\n",
      "11338 Traning Loss: tensor(0.0608)\n",
      "11339 Traning Loss: tensor(0.0592)\n",
      "11340 Traning Loss: tensor(0.0614)\n",
      "11341 Traning Loss: tensor(0.0597)\n",
      "11342 Traning Loss: tensor(0.0605)\n",
      "11343 Traning Loss: tensor(0.0594)\n",
      "11344 Traning Loss: tensor(0.0615)\n",
      "11345 Traning Loss: tensor(0.0614)\n",
      "11346 Traning Loss: tensor(0.0601)\n",
      "11347 Traning Loss: tensor(0.0612)\n",
      "11348 Traning Loss: tensor(0.0597)\n",
      "11349 Traning Loss: tensor(0.0603)\n",
      "11350 Traning Loss: tensor(0.0605)\n",
      "11351 Traning Loss: tensor(0.0605)\n",
      "11352 Traning Loss: tensor(0.0602)\n",
      "11353 Traning Loss: tensor(0.0601)\n",
      "11354 Traning Loss: tensor(0.0601)\n",
      "11355 Traning Loss: tensor(0.0602)\n",
      "11356 Traning Loss: tensor(0.0599)\n",
      "11357 Traning Loss: tensor(0.0590)\n",
      "11358 Traning Loss: tensor(0.0605)\n",
      "11359 Traning Loss: tensor(0.0601)\n",
      "11360 Traning Loss: tensor(0.0599)\n",
      "11361 Traning Loss: tensor(0.0600)\n",
      "11362 Traning Loss: tensor(0.0600)\n",
      "11363 Traning Loss: tensor(0.0606)\n",
      "11364 Traning Loss: tensor(0.0595)\n",
      "11365 Traning Loss: tensor(0.0608)\n",
      "11366 Traning Loss: tensor(0.0611)\n",
      "11367 Traning Loss: tensor(0.0595)\n",
      "11368 Traning Loss: tensor(0.0601)\n",
      "11369 Traning Loss: tensor(0.0600)\n",
      "11370 Traning Loss: tensor(0.0608)\n",
      "11371 Traning Loss: tensor(0.0591)\n",
      "11372 Traning Loss: tensor(0.0600)\n",
      "11373 Traning Loss: tensor(0.0608)\n",
      "11374 Traning Loss: tensor(0.0599)\n",
      "11375 Traning Loss: tensor(0.0605)\n",
      "11376 Traning Loss: tensor(0.0601)\n",
      "11377 Traning Loss: tensor(0.0601)\n",
      "11378 Traning Loss: tensor(0.0600)\n",
      "11379 Traning Loss: tensor(0.0599)\n",
      "11380 Traning Loss: tensor(0.0593)\n",
      "11381 Traning Loss: tensor(0.0600)\n",
      "11382 Traning Loss: tensor(0.0588)\n",
      "11383 Traning Loss: tensor(0.0601)\n",
      "11384 Traning Loss: tensor(0.0588)\n",
      "11385 Traning Loss: tensor(0.0590)\n",
      "11386 Traning Loss: tensor(0.0587)\n",
      "11387 Traning Loss: tensor(0.0601)\n",
      "11388 Traning Loss: tensor(0.0609)\n",
      "11389 Traning Loss: tensor(0.0620)\n",
      "11390 Traning Loss: tensor(0.0603)\n",
      "11391 Traning Loss: tensor(0.0607)\n",
      "11392 Traning Loss: tensor(0.0594)\n",
      "11393 Traning Loss: tensor(0.0612)\n",
      "11394 Traning Loss: tensor(0.0587)\n",
      "11395 Traning Loss: tensor(0.0600)\n",
      "11396 Traning Loss: tensor(0.0596)\n",
      "11397 Traning Loss: tensor(0.0591)\n",
      "11398 Traning Loss: tensor(0.0595)\n",
      "11399 Traning Loss: tensor(0.0602)\n",
      "11400 Traning Loss: tensor(0.0603)\n",
      "11401 Traning Loss: tensor(0.0607)\n",
      "11402 Traning Loss: tensor(0.0597)\n",
      "11403 Traning Loss: tensor(0.0598)\n",
      "11404 Traning Loss: tensor(0.0591)\n",
      "11405 Traning Loss: tensor(0.0603)\n",
      "11406 Traning Loss: tensor(0.0596)\n",
      "11407 Traning Loss: tensor(0.0591)\n",
      "11408 Traning Loss: tensor(0.0600)\n",
      "11409 Traning Loss: tensor(0.0610)\n",
      "11410 Traning Loss: tensor(0.0601)\n",
      "11411 Traning Loss: tensor(0.0596)\n",
      "11412 Traning Loss: tensor(0.0594)\n",
      "11413 Traning Loss: tensor(0.0586)\n",
      "11414 Traning Loss: tensor(0.0599)\n",
      "11415 Traning Loss: tensor(0.0596)\n",
      "11416 Traning Loss: tensor(0.0589)\n",
      "11417 Traning Loss: tensor(0.0599)\n",
      "11418 Traning Loss: tensor(0.0588)\n",
      "11419 Traning Loss: tensor(0.0589)\n",
      "11420 Traning Loss: tensor(0.0596)\n",
      "11421 Traning Loss: tensor(0.0597)\n",
      "11422 Traning Loss: tensor(0.0600)\n",
      "11423 Traning Loss: tensor(0.0599)\n",
      "11424 Traning Loss: tensor(0.0599)\n",
      "11425 Traning Loss: tensor(0.0597)\n",
      "11426 Traning Loss: tensor(0.0599)\n",
      "11427 Traning Loss: tensor(0.0588)\n",
      "11428 Traning Loss: tensor(0.0610)\n",
      "11429 Traning Loss: tensor(0.0594)\n",
      "11430 Traning Loss: tensor(0.0595)\n",
      "11431 Traning Loss: tensor(0.0588)\n",
      "11432 Traning Loss: tensor(0.0604)\n",
      "11433 Traning Loss: tensor(0.0589)\n",
      "11434 Traning Loss: tensor(0.0610)\n",
      "11435 Traning Loss: tensor(0.0588)\n",
      "11436 Traning Loss: tensor(0.0596)\n",
      "11437 Traning Loss: tensor(0.0593)\n",
      "11438 Traning Loss: tensor(0.0598)\n",
      "11439 Traning Loss: tensor(0.0602)\n",
      "11440 Traning Loss: tensor(0.0604)\n",
      "11441 Traning Loss: tensor(0.0601)\n",
      "11442 Traning Loss: tensor(0.0590)\n",
      "11443 Traning Loss: tensor(0.0606)\n",
      "11444 Traning Loss: tensor(0.0592)\n",
      "11445 Traning Loss: tensor(0.0597)\n",
      "11446 Traning Loss: tensor(0.0594)\n",
      "11447 Traning Loss: tensor(0.0585)\n",
      "11448 Traning Loss: tensor(0.0609)\n",
      "11449 Traning Loss: tensor(0.0591)\n",
      "11450 Traning Loss: tensor(0.0594)\n",
      "11451 Traning Loss: tensor(0.0587)\n",
      "11452 Traning Loss: tensor(0.0598)\n",
      "11453 Traning Loss: tensor(0.0578)\n",
      "11454 Traning Loss: tensor(0.0583)\n",
      "11455 Traning Loss: tensor(0.0596)\n",
      "11456 Traning Loss: tensor(0.0602)\n",
      "11457 Traning Loss: tensor(0.0602)\n",
      "11458 Traning Loss: tensor(0.0601)\n",
      "11459 Traning Loss: tensor(0.0600)\n",
      "11460 Traning Loss: tensor(0.0608)\n",
      "11461 Traning Loss: tensor(0.0591)\n",
      "11462 Traning Loss: tensor(0.0594)\n",
      "11463 Traning Loss: tensor(0.0604)\n",
      "11464 Traning Loss: tensor(0.0592)\n",
      "11465 Traning Loss: tensor(0.0597)\n",
      "11466 Traning Loss: tensor(0.0596)\n",
      "11467 Traning Loss: tensor(0.0584)\n",
      "11468 Traning Loss: tensor(0.0584)\n",
      "11469 Traning Loss: tensor(0.0605)\n",
      "11470 Traning Loss: tensor(0.0592)\n",
      "11471 Traning Loss: tensor(0.0598)\n",
      "11472 Traning Loss: tensor(0.0585)\n",
      "11473 Traning Loss: tensor(0.0588)\n",
      "11474 Traning Loss: tensor(0.0591)\n",
      "11475 Traning Loss: tensor(0.0599)\n",
      "11476 Traning Loss: tensor(0.0599)\n",
      "11477 Traning Loss: tensor(0.0586)\n",
      "11478 Traning Loss: tensor(0.0594)\n",
      "11479 Traning Loss: tensor(0.0596)\n",
      "11480 Traning Loss: tensor(0.0583)\n",
      "11481 Traning Loss: tensor(0.0585)\n",
      "11482 Traning Loss: tensor(0.0591)\n",
      "11483 Traning Loss: tensor(0.0598)\n",
      "11484 Traning Loss: tensor(0.0580)\n",
      "11485 Traning Loss: tensor(0.0589)\n",
      "11486 Traning Loss: tensor(0.0591)\n",
      "11487 Traning Loss: tensor(0.0585)\n",
      "11488 Traning Loss: tensor(0.0610)\n",
      "11489 Traning Loss: tensor(0.0598)\n",
      "11490 Traning Loss: tensor(0.0589)\n",
      "11491 Traning Loss: tensor(0.0596)\n",
      "11492 Traning Loss: tensor(0.0587)\n",
      "11493 Traning Loss: tensor(0.0592)\n",
      "11494 Traning Loss: tensor(0.0592)\n",
      "11495 Traning Loss: tensor(0.0601)\n",
      "11496 Traning Loss: tensor(0.0597)\n",
      "11497 Traning Loss: tensor(0.0581)\n",
      "11498 Traning Loss: tensor(0.0591)\n",
      "11499 Traning Loss: tensor(0.0588)\n",
      "11500 Traning Loss: tensor(0.0602)\n",
      "11501 Traning Loss: tensor(0.0593)\n",
      "11502 Traning Loss: tensor(0.0594)\n",
      "11503 Traning Loss: tensor(0.0584)\n",
      "11504 Traning Loss: tensor(0.0589)\n",
      "11505 Traning Loss: tensor(0.0595)\n",
      "11506 Traning Loss: tensor(0.0589)\n",
      "11507 Traning Loss: tensor(0.0594)\n",
      "11508 Traning Loss: tensor(0.0595)\n",
      "11509 Traning Loss: tensor(0.0588)\n",
      "11510 Traning Loss: tensor(0.0594)\n",
      "11511 Traning Loss: tensor(0.0582)\n",
      "11512 Traning Loss: tensor(0.0595)\n",
      "11513 Traning Loss: tensor(0.0586)\n",
      "11514 Traning Loss: tensor(0.0595)\n",
      "11515 Traning Loss: tensor(0.0589)\n",
      "11516 Traning Loss: tensor(0.0596)\n",
      "11517 Traning Loss: tensor(0.0585)\n",
      "11518 Traning Loss: tensor(0.0597)\n",
      "11519 Traning Loss: tensor(0.0589)\n",
      "11520 Traning Loss: tensor(0.0580)\n",
      "11521 Traning Loss: tensor(0.0578)\n",
      "11522 Traning Loss: tensor(0.0578)\n",
      "11523 Traning Loss: tensor(0.0584)\n",
      "11524 Traning Loss: tensor(0.0590)\n",
      "11525 Traning Loss: tensor(0.0592)\n",
      "11526 Traning Loss: tensor(0.0591)\n",
      "11527 Traning Loss: tensor(0.0593)\n",
      "11528 Traning Loss: tensor(0.0591)\n",
      "11529 Traning Loss: tensor(0.0601)\n",
      "11530 Traning Loss: tensor(0.0596)\n",
      "11531 Traning Loss: tensor(0.0601)\n",
      "11532 Traning Loss: tensor(0.0585)\n",
      "11533 Traning Loss: tensor(0.0590)\n",
      "11534 Traning Loss: tensor(0.0594)\n",
      "11535 Traning Loss: tensor(0.0590)\n",
      "11536 Traning Loss: tensor(0.0590)\n",
      "11537 Traning Loss: tensor(0.0590)\n",
      "11538 Traning Loss: tensor(0.0588)\n",
      "11539 Traning Loss: tensor(0.0586)\n",
      "11540 Traning Loss: tensor(0.0594)\n",
      "11541 Traning Loss: tensor(0.0597)\n",
      "11542 Traning Loss: tensor(0.0602)\n",
      "11543 Traning Loss: tensor(0.0579)\n",
      "11544 Traning Loss: tensor(0.0586)\n",
      "11545 Traning Loss: tensor(0.0590)\n",
      "11546 Traning Loss: tensor(0.0588)\n",
      "11547 Traning Loss: tensor(0.0598)\n",
      "11548 Traning Loss: tensor(0.0587)\n",
      "11549 Traning Loss: tensor(0.0597)\n",
      "11550 Traning Loss: tensor(0.0594)\n",
      "11551 Traning Loss: tensor(0.0588)\n",
      "11552 Traning Loss: tensor(0.0583)\n",
      "11553 Traning Loss: tensor(0.0600)\n",
      "11554 Traning Loss: tensor(0.0588)\n",
      "11555 Traning Loss: tensor(0.0581)\n",
      "11556 Traning Loss: tensor(0.0587)\n",
      "11557 Traning Loss: tensor(0.0585)\n",
      "11558 Traning Loss: tensor(0.0581)\n",
      "11559 Traning Loss: tensor(0.0594)\n",
      "11560 Traning Loss: tensor(0.0584)\n",
      "11561 Traning Loss: tensor(0.0591)\n",
      "11562 Traning Loss: tensor(0.0602)\n",
      "11563 Traning Loss: tensor(0.0593)\n",
      "11564 Traning Loss: tensor(0.0592)\n",
      "11565 Traning Loss: tensor(0.0593)\n",
      "11566 Traning Loss: tensor(0.0593)\n",
      "11567 Traning Loss: tensor(0.0587)\n",
      "11568 Traning Loss: tensor(0.0585)\n",
      "11569 Traning Loss: tensor(0.0579)\n",
      "11570 Traning Loss: tensor(0.0582)\n",
      "11571 Traning Loss: tensor(0.0581)\n",
      "11572 Traning Loss: tensor(0.0579)\n",
      "11573 Traning Loss: tensor(0.0585)\n",
      "11574 Traning Loss: tensor(0.0594)\n",
      "11575 Traning Loss: tensor(0.0580)\n",
      "11576 Traning Loss: tensor(0.0590)\n",
      "11577 Traning Loss: tensor(0.0580)\n",
      "11578 Traning Loss: tensor(0.0597)\n",
      "11579 Traning Loss: tensor(0.0594)\n",
      "11580 Traning Loss: tensor(0.0593)\n",
      "11581 Traning Loss: tensor(0.0588)\n",
      "11582 Traning Loss: tensor(0.0600)\n",
      "11583 Traning Loss: tensor(0.0600)\n",
      "11584 Traning Loss: tensor(0.0589)\n",
      "11585 Traning Loss: tensor(0.0587)\n",
      "11586 Traning Loss: tensor(0.0587)\n",
      "11587 Traning Loss: tensor(0.0599)\n",
      "11588 Traning Loss: tensor(0.0592)\n",
      "11589 Traning Loss: tensor(0.0578)\n",
      "11590 Traning Loss: tensor(0.0585)\n",
      "11591 Traning Loss: tensor(0.0593)\n",
      "11592 Traning Loss: tensor(0.0587)\n",
      "11593 Traning Loss: tensor(0.0602)\n",
      "11594 Traning Loss: tensor(0.0599)\n",
      "11595 Traning Loss: tensor(0.0587)\n",
      "11596 Traning Loss: tensor(0.0591)\n",
      "11597 Traning Loss: tensor(0.0582)\n",
      "11598 Traning Loss: tensor(0.0580)\n",
      "11599 Traning Loss: tensor(0.0592)\n",
      "11600 Traning Loss: tensor(0.0588)\n",
      "11601 Traning Loss: tensor(0.0591)\n",
      "11602 Traning Loss: tensor(0.0589)\n",
      "11603 Traning Loss: tensor(0.0584)\n",
      "11604 Traning Loss: tensor(0.0574)\n",
      "11605 Traning Loss: tensor(0.0591)\n",
      "11606 Traning Loss: tensor(0.0579)\n",
      "11607 Traning Loss: tensor(0.0572)\n",
      "11608 Traning Loss: tensor(0.0570)\n",
      "11609 Traning Loss: tensor(0.0588)\n",
      "11610 Traning Loss: tensor(0.0590)\n",
      "11611 Traning Loss: tensor(0.0583)\n",
      "11612 Traning Loss: tensor(0.0573)\n",
      "11613 Traning Loss: tensor(0.0577)\n",
      "11614 Traning Loss: tensor(0.0578)\n",
      "11615 Traning Loss: tensor(0.0594)\n",
      "11616 Traning Loss: tensor(0.0574)\n",
      "11617 Traning Loss: tensor(0.0582)\n",
      "11618 Traning Loss: tensor(0.0585)\n",
      "11619 Traning Loss: tensor(0.0580)\n",
      "11620 Traning Loss: tensor(0.0581)\n",
      "11621 Traning Loss: tensor(0.0583)\n",
      "11622 Traning Loss: tensor(0.0571)\n",
      "11623 Traning Loss: tensor(0.0581)\n",
      "11624 Traning Loss: tensor(0.0585)\n",
      "11625 Traning Loss: tensor(0.0578)\n",
      "11626 Traning Loss: tensor(0.0594)\n",
      "11627 Traning Loss: tensor(0.0584)\n",
      "11628 Traning Loss: tensor(0.0584)\n",
      "11629 Traning Loss: tensor(0.0587)\n",
      "11630 Traning Loss: tensor(0.0575)\n",
      "11631 Traning Loss: tensor(0.0592)\n",
      "11632 Traning Loss: tensor(0.0576)\n",
      "11633 Traning Loss: tensor(0.0571)\n",
      "11634 Traning Loss: tensor(0.0580)\n",
      "11635 Traning Loss: tensor(0.0593)\n",
      "11636 Traning Loss: tensor(0.0584)\n",
      "11637 Traning Loss: tensor(0.0590)\n",
      "11638 Traning Loss: tensor(0.0585)\n",
      "11639 Traning Loss: tensor(0.0573)\n",
      "11640 Traning Loss: tensor(0.0573)\n",
      "11641 Traning Loss: tensor(0.0583)\n",
      "11642 Traning Loss: tensor(0.0585)\n",
      "11643 Traning Loss: tensor(0.0587)\n",
      "11644 Traning Loss: tensor(0.0568)\n",
      "11645 Traning Loss: tensor(0.0590)\n",
      "11646 Traning Loss: tensor(0.0586)\n",
      "11647 Traning Loss: tensor(0.0583)\n",
      "11648 Traning Loss: tensor(0.0578)\n",
      "11649 Traning Loss: tensor(0.0572)\n",
      "11650 Traning Loss: tensor(0.0591)\n",
      "11651 Traning Loss: tensor(0.0583)\n",
      "11652 Traning Loss: tensor(0.0579)\n",
      "11653 Traning Loss: tensor(0.0576)\n",
      "11654 Traning Loss: tensor(0.0573)\n",
      "11655 Traning Loss: tensor(0.0589)\n",
      "11656 Traning Loss: tensor(0.0582)\n",
      "11657 Traning Loss: tensor(0.0581)\n",
      "11658 Traning Loss: tensor(0.0578)\n",
      "11659 Traning Loss: tensor(0.0587)\n",
      "11660 Traning Loss: tensor(0.0593)\n",
      "11661 Traning Loss: tensor(0.0598)\n",
      "11662 Traning Loss: tensor(0.0592)\n",
      "11663 Traning Loss: tensor(0.0596)\n",
      "11664 Traning Loss: tensor(0.0576)\n",
      "11665 Traning Loss: tensor(0.0579)\n",
      "11666 Traning Loss: tensor(0.0582)\n",
      "11667 Traning Loss: tensor(0.0597)\n",
      "11668 Traning Loss: tensor(0.0581)\n",
      "11669 Traning Loss: tensor(0.0584)\n",
      "11670 Traning Loss: tensor(0.0581)\n",
      "11671 Traning Loss: tensor(0.0584)\n",
      "11672 Traning Loss: tensor(0.0581)\n",
      "11673 Traning Loss: tensor(0.0578)\n",
      "11674 Traning Loss: tensor(0.0587)\n",
      "11675 Traning Loss: tensor(0.0585)\n",
      "11676 Traning Loss: tensor(0.0577)\n",
      "11677 Traning Loss: tensor(0.0577)\n",
      "11678 Traning Loss: tensor(0.0581)\n",
      "11679 Traning Loss: tensor(0.0569)\n",
      "11680 Traning Loss: tensor(0.0576)\n",
      "11681 Traning Loss: tensor(0.0580)\n",
      "11682 Traning Loss: tensor(0.0587)\n",
      "11683 Traning Loss: tensor(0.0582)\n",
      "11684 Traning Loss: tensor(0.0583)\n",
      "11685 Traning Loss: tensor(0.0578)\n",
      "11686 Traning Loss: tensor(0.0578)\n",
      "11687 Traning Loss: tensor(0.0580)\n",
      "11688 Traning Loss: tensor(0.0586)\n",
      "11689 Traning Loss: tensor(0.0580)\n",
      "11690 Traning Loss: tensor(0.0587)\n",
      "11691 Traning Loss: tensor(0.0570)\n",
      "11692 Traning Loss: tensor(0.0582)\n",
      "11693 Traning Loss: tensor(0.0574)\n",
      "11694 Traning Loss: tensor(0.0586)\n",
      "11695 Traning Loss: tensor(0.0585)\n",
      "11696 Traning Loss: tensor(0.0595)\n",
      "11697 Traning Loss: tensor(0.0593)\n",
      "11698 Traning Loss: tensor(0.0571)\n",
      "11699 Traning Loss: tensor(0.0590)\n",
      "11700 Traning Loss: tensor(0.0582)\n",
      "11701 Traning Loss: tensor(0.0584)\n",
      "11702 Traning Loss: tensor(0.0578)\n",
      "11703 Traning Loss: tensor(0.0570)\n",
      "11704 Traning Loss: tensor(0.0590)\n",
      "11705 Traning Loss: tensor(0.0578)\n",
      "11706 Traning Loss: tensor(0.0588)\n",
      "11707 Traning Loss: tensor(0.0583)\n",
      "11708 Traning Loss: tensor(0.0581)\n",
      "11709 Traning Loss: tensor(0.0574)\n",
      "11710 Traning Loss: tensor(0.0577)\n",
      "11711 Traning Loss: tensor(0.0584)\n",
      "11712 Traning Loss: tensor(0.0568)\n",
      "11713 Traning Loss: tensor(0.0576)\n",
      "11714 Traning Loss: tensor(0.0576)\n",
      "11715 Traning Loss: tensor(0.0579)\n",
      "11716 Traning Loss: tensor(0.0576)\n",
      "11717 Traning Loss: tensor(0.0574)\n",
      "11718 Traning Loss: tensor(0.0578)\n",
      "11719 Traning Loss: tensor(0.0578)\n",
      "11720 Traning Loss: tensor(0.0582)\n",
      "11721 Traning Loss: tensor(0.0588)\n",
      "11722 Traning Loss: tensor(0.0582)\n",
      "11723 Traning Loss: tensor(0.0586)\n",
      "11724 Traning Loss: tensor(0.0587)\n",
      "11725 Traning Loss: tensor(0.0571)\n",
      "11726 Traning Loss: tensor(0.0574)\n",
      "11727 Traning Loss: tensor(0.0577)\n",
      "11728 Traning Loss: tensor(0.0574)\n",
      "11729 Traning Loss: tensor(0.0577)\n",
      "11730 Traning Loss: tensor(0.0588)\n",
      "11731 Traning Loss: tensor(0.0578)\n",
      "11732 Traning Loss: tensor(0.0575)\n",
      "11733 Traning Loss: tensor(0.0588)\n",
      "11734 Traning Loss: tensor(0.0593)\n",
      "11735 Traning Loss: tensor(0.0571)\n",
      "11736 Traning Loss: tensor(0.0577)\n",
      "11737 Traning Loss: tensor(0.0587)\n",
      "11738 Traning Loss: tensor(0.0569)\n",
      "11739 Traning Loss: tensor(0.0570)\n",
      "11740 Traning Loss: tensor(0.0570)\n",
      "11741 Traning Loss: tensor(0.0568)\n",
      "11742 Traning Loss: tensor(0.0578)\n",
      "11743 Traning Loss: tensor(0.0574)\n",
      "11744 Traning Loss: tensor(0.0578)\n",
      "11745 Traning Loss: tensor(0.0581)\n",
      "11746 Traning Loss: tensor(0.0582)\n",
      "11747 Traning Loss: tensor(0.0575)\n",
      "11748 Traning Loss: tensor(0.0581)\n",
      "11749 Traning Loss: tensor(0.0574)\n",
      "11750 Traning Loss: tensor(0.0595)\n",
      "11751 Traning Loss: tensor(0.0574)\n",
      "11752 Traning Loss: tensor(0.0573)\n",
      "11753 Traning Loss: tensor(0.0571)\n",
      "11754 Traning Loss: tensor(0.0589)\n",
      "11755 Traning Loss: tensor(0.0587)\n",
      "11756 Traning Loss: tensor(0.0574)\n",
      "11757 Traning Loss: tensor(0.0593)\n",
      "11758 Traning Loss: tensor(0.0566)\n",
      "11759 Traning Loss: tensor(0.0574)\n",
      "11760 Traning Loss: tensor(0.0576)\n",
      "11761 Traning Loss: tensor(0.0574)\n",
      "11762 Traning Loss: tensor(0.0585)\n",
      "11763 Traning Loss: tensor(0.0562)\n",
      "11764 Traning Loss: tensor(0.0572)\n",
      "11765 Traning Loss: tensor(0.0567)\n",
      "11766 Traning Loss: tensor(0.0573)\n",
      "11767 Traning Loss: tensor(0.0585)\n",
      "11768 Traning Loss: tensor(0.0582)\n",
      "11769 Traning Loss: tensor(0.0570)\n",
      "11770 Traning Loss: tensor(0.0578)\n",
      "11771 Traning Loss: tensor(0.0566)\n",
      "11772 Traning Loss: tensor(0.0575)\n",
      "11773 Traning Loss: tensor(0.0565)\n",
      "11774 Traning Loss: tensor(0.0564)\n",
      "11775 Traning Loss: tensor(0.0574)\n",
      "11776 Traning Loss: tensor(0.0570)\n",
      "11777 Traning Loss: tensor(0.0583)\n",
      "11778 Traning Loss: tensor(0.0568)\n",
      "11779 Traning Loss: tensor(0.0581)\n",
      "11780 Traning Loss: tensor(0.0575)\n",
      "11781 Traning Loss: tensor(0.0580)\n",
      "11782 Traning Loss: tensor(0.0579)\n",
      "11783 Traning Loss: tensor(0.0580)\n",
      "11784 Traning Loss: tensor(0.0578)\n",
      "11785 Traning Loss: tensor(0.0575)\n",
      "11786 Traning Loss: tensor(0.0578)\n",
      "11787 Traning Loss: tensor(0.0590)\n",
      "11788 Traning Loss: tensor(0.0581)\n",
      "11789 Traning Loss: tensor(0.0578)\n",
      "11790 Traning Loss: tensor(0.0582)\n",
      "11791 Traning Loss: tensor(0.0572)\n",
      "11792 Traning Loss: tensor(0.0577)\n",
      "11793 Traning Loss: tensor(0.0566)\n",
      "11794 Traning Loss: tensor(0.0579)\n",
      "11795 Traning Loss: tensor(0.0577)\n",
      "11796 Traning Loss: tensor(0.0577)\n",
      "11797 Traning Loss: tensor(0.0581)\n",
      "11798 Traning Loss: tensor(0.0593)\n",
      "11799 Traning Loss: tensor(0.0576)\n",
      "11800 Traning Loss: tensor(0.0573)\n",
      "11801 Traning Loss: tensor(0.0579)\n",
      "11802 Traning Loss: tensor(0.0578)\n",
      "11803 Traning Loss: tensor(0.0580)\n",
      "11804 Traning Loss: tensor(0.0573)\n",
      "11805 Traning Loss: tensor(0.0576)\n",
      "11806 Traning Loss: tensor(0.0582)\n",
      "11807 Traning Loss: tensor(0.0578)\n",
      "11808 Traning Loss: tensor(0.0571)\n",
      "11809 Traning Loss: tensor(0.0564)\n",
      "11810 Traning Loss: tensor(0.0565)\n",
      "11811 Traning Loss: tensor(0.0581)\n",
      "11812 Traning Loss: tensor(0.0568)\n",
      "11813 Traning Loss: tensor(0.0581)\n",
      "11814 Traning Loss: tensor(0.0571)\n",
      "11815 Traning Loss: tensor(0.0571)\n",
      "11816 Traning Loss: tensor(0.0581)\n",
      "11817 Traning Loss: tensor(0.0576)\n",
      "11818 Traning Loss: tensor(0.0563)\n",
      "11819 Traning Loss: tensor(0.0580)\n",
      "11820 Traning Loss: tensor(0.0568)\n",
      "11821 Traning Loss: tensor(0.0565)\n",
      "11822 Traning Loss: tensor(0.0573)\n",
      "11823 Traning Loss: tensor(0.0568)\n",
      "11824 Traning Loss: tensor(0.0568)\n",
      "11825 Traning Loss: tensor(0.0573)\n",
      "11826 Traning Loss: tensor(0.0572)\n",
      "11827 Traning Loss: tensor(0.0572)\n",
      "11828 Traning Loss: tensor(0.0553)\n",
      "11829 Traning Loss: tensor(0.0581)\n",
      "11830 Traning Loss: tensor(0.0552)\n",
      "11831 Traning Loss: tensor(0.0576)\n",
      "11832 Traning Loss: tensor(0.0563)\n",
      "11833 Traning Loss: tensor(0.0566)\n",
      "11834 Traning Loss: tensor(0.0570)\n",
      "11835 Traning Loss: tensor(0.0568)\n",
      "11836 Traning Loss: tensor(0.0563)\n",
      "11837 Traning Loss: tensor(0.0585)\n",
      "11838 Traning Loss: tensor(0.0585)\n",
      "11839 Traning Loss: tensor(0.0585)\n",
      "11840 Traning Loss: tensor(0.0563)\n",
      "11841 Traning Loss: tensor(0.0570)\n",
      "11842 Traning Loss: tensor(0.0575)\n",
      "11843 Traning Loss: tensor(0.0569)\n",
      "11844 Traning Loss: tensor(0.0573)\n",
      "11845 Traning Loss: tensor(0.0569)\n",
      "11846 Traning Loss: tensor(0.0576)\n",
      "11847 Traning Loss: tensor(0.0573)\n",
      "11848 Traning Loss: tensor(0.0574)\n",
      "11849 Traning Loss: tensor(0.0579)\n",
      "11850 Traning Loss: tensor(0.0567)\n",
      "11851 Traning Loss: tensor(0.0570)\n",
      "11852 Traning Loss: tensor(0.0565)\n",
      "11853 Traning Loss: tensor(0.0564)\n",
      "11854 Traning Loss: tensor(0.0564)\n",
      "11855 Traning Loss: tensor(0.0560)\n",
      "11856 Traning Loss: tensor(0.0566)\n",
      "11857 Traning Loss: tensor(0.0570)\n",
      "11858 Traning Loss: tensor(0.0576)\n",
      "11859 Traning Loss: tensor(0.0563)\n",
      "11860 Traning Loss: tensor(0.0564)\n",
      "11861 Traning Loss: tensor(0.0572)\n",
      "11862 Traning Loss: tensor(0.0566)\n",
      "11863 Traning Loss: tensor(0.0566)\n",
      "11864 Traning Loss: tensor(0.0560)\n",
      "11865 Traning Loss: tensor(0.0568)\n",
      "11866 Traning Loss: tensor(0.0567)\n",
      "11867 Traning Loss: tensor(0.0570)\n",
      "11868 Traning Loss: tensor(0.0570)\n",
      "11869 Traning Loss: tensor(0.0563)\n",
      "11870 Traning Loss: tensor(0.0569)\n",
      "11871 Traning Loss: tensor(0.0564)\n",
      "11872 Traning Loss: tensor(0.0568)\n",
      "11873 Traning Loss: tensor(0.0574)\n",
      "11874 Traning Loss: tensor(0.0569)\n",
      "11875 Traning Loss: tensor(0.0586)\n",
      "11876 Traning Loss: tensor(0.0565)\n",
      "11877 Traning Loss: tensor(0.0568)\n",
      "11878 Traning Loss: tensor(0.0558)\n",
      "11879 Traning Loss: tensor(0.0570)\n",
      "11880 Traning Loss: tensor(0.0575)\n",
      "11881 Traning Loss: tensor(0.0567)\n",
      "11882 Traning Loss: tensor(0.0565)\n",
      "11883 Traning Loss: tensor(0.0577)\n",
      "11884 Traning Loss: tensor(0.0576)\n",
      "11885 Traning Loss: tensor(0.0570)\n",
      "11886 Traning Loss: tensor(0.0571)\n",
      "11887 Traning Loss: tensor(0.0560)\n",
      "11888 Traning Loss: tensor(0.0565)\n",
      "11889 Traning Loss: tensor(0.0558)\n",
      "11890 Traning Loss: tensor(0.0565)\n",
      "11891 Traning Loss: tensor(0.0578)\n",
      "11892 Traning Loss: tensor(0.0563)\n",
      "11893 Traning Loss: tensor(0.0564)\n",
      "11894 Traning Loss: tensor(0.0575)\n",
      "11895 Traning Loss: tensor(0.0571)\n",
      "11896 Traning Loss: tensor(0.0570)\n",
      "11897 Traning Loss: tensor(0.0579)\n",
      "11898 Traning Loss: tensor(0.0567)\n",
      "11899 Traning Loss: tensor(0.0567)\n",
      "11900 Traning Loss: tensor(0.0565)\n",
      "11901 Traning Loss: tensor(0.0559)\n",
      "11902 Traning Loss: tensor(0.0548)\n",
      "11903 Traning Loss: tensor(0.0565)\n",
      "11904 Traning Loss: tensor(0.0562)\n",
      "11905 Traning Loss: tensor(0.0568)\n",
      "11906 Traning Loss: tensor(0.0554)\n",
      "11907 Traning Loss: tensor(0.0560)\n",
      "11908 Traning Loss: tensor(0.0578)\n",
      "11909 Traning Loss: tensor(0.0560)\n",
      "11910 Traning Loss: tensor(0.0559)\n",
      "11911 Traning Loss: tensor(0.0558)\n",
      "11912 Traning Loss: tensor(0.0558)\n",
      "11913 Traning Loss: tensor(0.0569)\n",
      "11914 Traning Loss: tensor(0.0560)\n",
      "11915 Traning Loss: tensor(0.0557)\n",
      "11916 Traning Loss: tensor(0.0570)\n",
      "11917 Traning Loss: tensor(0.0556)\n",
      "11918 Traning Loss: tensor(0.0562)\n",
      "11919 Traning Loss: tensor(0.0577)\n",
      "11920 Traning Loss: tensor(0.0561)\n",
      "11921 Traning Loss: tensor(0.0564)\n",
      "11922 Traning Loss: tensor(0.0579)\n",
      "11923 Traning Loss: tensor(0.0574)\n",
      "11924 Traning Loss: tensor(0.0569)\n",
      "11925 Traning Loss: tensor(0.0568)\n",
      "11926 Traning Loss: tensor(0.0566)\n",
      "11927 Traning Loss: tensor(0.0570)\n",
      "11928 Traning Loss: tensor(0.0560)\n",
      "11929 Traning Loss: tensor(0.0570)\n",
      "11930 Traning Loss: tensor(0.0558)\n",
      "11931 Traning Loss: tensor(0.0559)\n",
      "11932 Traning Loss: tensor(0.0562)\n",
      "11933 Traning Loss: tensor(0.0558)\n",
      "11934 Traning Loss: tensor(0.0566)\n",
      "11935 Traning Loss: tensor(0.0565)\n",
      "11936 Traning Loss: tensor(0.0574)\n",
      "11937 Traning Loss: tensor(0.0549)\n",
      "11938 Traning Loss: tensor(0.0566)\n",
      "11939 Traning Loss: tensor(0.0571)\n",
      "11940 Traning Loss: tensor(0.0561)\n",
      "11941 Traning Loss: tensor(0.0563)\n",
      "11942 Traning Loss: tensor(0.0567)\n",
      "11943 Traning Loss: tensor(0.0561)\n",
      "11944 Traning Loss: tensor(0.0555)\n",
      "11945 Traning Loss: tensor(0.0566)\n",
      "11946 Traning Loss: tensor(0.0567)\n",
      "11947 Traning Loss: tensor(0.0555)\n",
      "11948 Traning Loss: tensor(0.0564)\n",
      "11949 Traning Loss: tensor(0.0577)\n",
      "11950 Traning Loss: tensor(0.0561)\n",
      "11951 Traning Loss: tensor(0.0561)\n",
      "11952 Traning Loss: tensor(0.0561)\n",
      "11953 Traning Loss: tensor(0.0575)\n",
      "11954 Traning Loss: tensor(0.0555)\n",
      "11955 Traning Loss: tensor(0.0566)\n",
      "11956 Traning Loss: tensor(0.0551)\n",
      "11957 Traning Loss: tensor(0.0564)\n",
      "11958 Traning Loss: tensor(0.0565)\n",
      "11959 Traning Loss: tensor(0.0567)\n",
      "11960 Traning Loss: tensor(0.0572)\n",
      "11961 Traning Loss: tensor(0.0563)\n",
      "11962 Traning Loss: tensor(0.0565)\n",
      "11963 Traning Loss: tensor(0.0548)\n",
      "11964 Traning Loss: tensor(0.0553)\n",
      "11965 Traning Loss: tensor(0.0570)\n",
      "11966 Traning Loss: tensor(0.0562)\n",
      "11967 Traning Loss: tensor(0.0574)\n",
      "11968 Traning Loss: tensor(0.0563)\n",
      "11969 Traning Loss: tensor(0.0554)\n",
      "11970 Traning Loss: tensor(0.0565)\n",
      "11971 Traning Loss: tensor(0.0559)\n",
      "11972 Traning Loss: tensor(0.0559)\n",
      "11973 Traning Loss: tensor(0.0568)\n",
      "11974 Traning Loss: tensor(0.0558)\n",
      "11975 Traning Loss: tensor(0.0566)\n",
      "11976 Traning Loss: tensor(0.0551)\n",
      "11977 Traning Loss: tensor(0.0569)\n",
      "11978 Traning Loss: tensor(0.0551)\n",
      "11979 Traning Loss: tensor(0.0549)\n",
      "11980 Traning Loss: tensor(0.0555)\n",
      "11981 Traning Loss: tensor(0.0556)\n",
      "11982 Traning Loss: tensor(0.0569)\n",
      "11983 Traning Loss: tensor(0.0557)\n",
      "11984 Traning Loss: tensor(0.0554)\n",
      "11985 Traning Loss: tensor(0.0555)\n",
      "11986 Traning Loss: tensor(0.0565)\n",
      "11987 Traning Loss: tensor(0.0568)\n",
      "11988 Traning Loss: tensor(0.0546)\n",
      "11989 Traning Loss: tensor(0.0553)\n",
      "11990 Traning Loss: tensor(0.0556)\n",
      "11991 Traning Loss: tensor(0.0548)\n",
      "11992 Traning Loss: tensor(0.0554)\n",
      "11993 Traning Loss: tensor(0.0565)\n",
      "11994 Traning Loss: tensor(0.0560)\n",
      "11995 Traning Loss: tensor(0.0567)\n",
      "11996 Traning Loss: tensor(0.0555)\n",
      "11997 Traning Loss: tensor(0.0558)\n",
      "11998 Traning Loss: tensor(0.0565)\n",
      "11999 Traning Loss: tensor(0.0559)\n",
      "12000 Traning Loss: tensor(0.0547)\n",
      "12001 Traning Loss: tensor(0.0552)\n",
      "12002 Traning Loss: tensor(0.0546)\n",
      "12003 Traning Loss: tensor(0.0557)\n",
      "12004 Traning Loss: tensor(0.0557)\n",
      "12005 Traning Loss: tensor(0.0568)\n",
      "12006 Traning Loss: tensor(0.0553)\n",
      "12007 Traning Loss: tensor(0.0573)\n",
      "12008 Traning Loss: tensor(0.0557)\n",
      "12009 Traning Loss: tensor(0.0555)\n",
      "12010 Traning Loss: tensor(0.0562)\n",
      "12011 Traning Loss: tensor(0.0549)\n",
      "12012 Traning Loss: tensor(0.0563)\n",
      "12013 Traning Loss: tensor(0.0568)\n",
      "12014 Traning Loss: tensor(0.0562)\n",
      "12015 Traning Loss: tensor(0.0556)\n",
      "12016 Traning Loss: tensor(0.0560)\n",
      "12017 Traning Loss: tensor(0.0566)\n",
      "12018 Traning Loss: tensor(0.0555)\n",
      "12019 Traning Loss: tensor(0.0554)\n",
      "12020 Traning Loss: tensor(0.0565)\n",
      "12021 Traning Loss: tensor(0.0558)\n",
      "12022 Traning Loss: tensor(0.0549)\n",
      "12023 Traning Loss: tensor(0.0542)\n",
      "12024 Traning Loss: tensor(0.0552)\n",
      "12025 Traning Loss: tensor(0.0561)\n",
      "12026 Traning Loss: tensor(0.0558)\n",
      "12027 Traning Loss: tensor(0.0551)\n",
      "12028 Traning Loss: tensor(0.0560)\n",
      "12029 Traning Loss: tensor(0.0550)\n",
      "12030 Traning Loss: tensor(0.0549)\n",
      "12031 Traning Loss: tensor(0.0560)\n",
      "12032 Traning Loss: tensor(0.0563)\n",
      "12033 Traning Loss: tensor(0.0559)\n",
      "12034 Traning Loss: tensor(0.0579)\n",
      "12035 Traning Loss: tensor(0.0551)\n",
      "12036 Traning Loss: tensor(0.0546)\n",
      "12037 Traning Loss: tensor(0.0551)\n",
      "12038 Traning Loss: tensor(0.0561)\n",
      "12039 Traning Loss: tensor(0.0569)\n",
      "12040 Traning Loss: tensor(0.0553)\n",
      "12041 Traning Loss: tensor(0.0551)\n",
      "12042 Traning Loss: tensor(0.0558)\n",
      "12043 Traning Loss: tensor(0.0562)\n",
      "12044 Traning Loss: tensor(0.0556)\n",
      "12045 Traning Loss: tensor(0.0556)\n",
      "12046 Traning Loss: tensor(0.0566)\n",
      "12047 Traning Loss: tensor(0.0553)\n",
      "12048 Traning Loss: tensor(0.0547)\n",
      "12049 Traning Loss: tensor(0.0556)\n",
      "12050 Traning Loss: tensor(0.0564)\n",
      "12051 Traning Loss: tensor(0.0560)\n",
      "12052 Traning Loss: tensor(0.0565)\n",
      "12053 Traning Loss: tensor(0.0556)\n",
      "12054 Traning Loss: tensor(0.0547)\n",
      "12055 Traning Loss: tensor(0.0553)\n",
      "12056 Traning Loss: tensor(0.0552)\n",
      "12057 Traning Loss: tensor(0.0548)\n",
      "12058 Traning Loss: tensor(0.0551)\n",
      "12059 Traning Loss: tensor(0.0560)\n",
      "12060 Traning Loss: tensor(0.0548)\n",
      "12061 Traning Loss: tensor(0.0556)\n",
      "12062 Traning Loss: tensor(0.0569)\n",
      "12063 Traning Loss: tensor(0.0562)\n",
      "12064 Traning Loss: tensor(0.0566)\n",
      "12065 Traning Loss: tensor(0.0565)\n",
      "12066 Traning Loss: tensor(0.0542)\n",
      "12067 Traning Loss: tensor(0.0562)\n",
      "12068 Traning Loss: tensor(0.0545)\n",
      "12069 Traning Loss: tensor(0.0540)\n",
      "12070 Traning Loss: tensor(0.0558)\n",
      "12071 Traning Loss: tensor(0.0547)\n",
      "12072 Traning Loss: tensor(0.0549)\n",
      "12073 Traning Loss: tensor(0.0554)\n",
      "12074 Traning Loss: tensor(0.0550)\n",
      "12075 Traning Loss: tensor(0.0561)\n",
      "12076 Traning Loss: tensor(0.0571)\n",
      "12077 Traning Loss: tensor(0.0540)\n",
      "12078 Traning Loss: tensor(0.0554)\n",
      "12079 Traning Loss: tensor(0.0556)\n",
      "12080 Traning Loss: tensor(0.0546)\n",
      "12081 Traning Loss: tensor(0.0547)\n",
      "12082 Traning Loss: tensor(0.0539)\n",
      "12083 Traning Loss: tensor(0.0542)\n",
      "12084 Traning Loss: tensor(0.0544)\n",
      "12085 Traning Loss: tensor(0.0561)\n",
      "12086 Traning Loss: tensor(0.0546)\n",
      "12087 Traning Loss: tensor(0.0548)\n",
      "12088 Traning Loss: tensor(0.0545)\n",
      "12089 Traning Loss: tensor(0.0548)\n",
      "12090 Traning Loss: tensor(0.0553)\n",
      "12091 Traning Loss: tensor(0.0544)\n",
      "12092 Traning Loss: tensor(0.0556)\n",
      "12093 Traning Loss: tensor(0.0547)\n",
      "12094 Traning Loss: tensor(0.0533)\n",
      "12095 Traning Loss: tensor(0.0551)\n",
      "12096 Traning Loss: tensor(0.0546)\n",
      "12097 Traning Loss: tensor(0.0562)\n",
      "12098 Traning Loss: tensor(0.0541)\n",
      "12099 Traning Loss: tensor(0.0546)\n",
      "12100 Traning Loss: tensor(0.0556)\n",
      "12101 Traning Loss: tensor(0.0556)\n",
      "12102 Traning Loss: tensor(0.0543)\n",
      "12103 Traning Loss: tensor(0.0544)\n",
      "12104 Traning Loss: tensor(0.0547)\n",
      "12105 Traning Loss: tensor(0.0539)\n",
      "12106 Traning Loss: tensor(0.0550)\n",
      "12107 Traning Loss: tensor(0.0555)\n",
      "12108 Traning Loss: tensor(0.0544)\n",
      "12109 Traning Loss: tensor(0.0551)\n",
      "12110 Traning Loss: tensor(0.0558)\n",
      "12111 Traning Loss: tensor(0.0549)\n",
      "12112 Traning Loss: tensor(0.0548)\n",
      "12113 Traning Loss: tensor(0.0552)\n",
      "12114 Traning Loss: tensor(0.0553)\n",
      "12115 Traning Loss: tensor(0.0548)\n",
      "12116 Traning Loss: tensor(0.0558)\n",
      "12117 Traning Loss: tensor(0.0544)\n",
      "12118 Traning Loss: tensor(0.0557)\n",
      "12119 Traning Loss: tensor(0.0538)\n",
      "12120 Traning Loss: tensor(0.0557)\n",
      "12121 Traning Loss: tensor(0.0549)\n",
      "12122 Traning Loss: tensor(0.0548)\n",
      "12123 Traning Loss: tensor(0.0549)\n",
      "12124 Traning Loss: tensor(0.0557)\n",
      "12125 Traning Loss: tensor(0.0535)\n",
      "12126 Traning Loss: tensor(0.0542)\n",
      "12127 Traning Loss: tensor(0.0556)\n",
      "12128 Traning Loss: tensor(0.0545)\n",
      "12129 Traning Loss: tensor(0.0542)\n",
      "12130 Traning Loss: tensor(0.0549)\n",
      "12131 Traning Loss: tensor(0.0547)\n",
      "12132 Traning Loss: tensor(0.0549)\n",
      "12133 Traning Loss: tensor(0.0534)\n",
      "12134 Traning Loss: tensor(0.0546)\n",
      "12135 Traning Loss: tensor(0.0548)\n",
      "12136 Traning Loss: tensor(0.0548)\n",
      "12137 Traning Loss: tensor(0.0544)\n",
      "12138 Traning Loss: tensor(0.0547)\n",
      "12139 Traning Loss: tensor(0.0553)\n",
      "12140 Traning Loss: tensor(0.0551)\n",
      "12141 Traning Loss: tensor(0.0548)\n",
      "12142 Traning Loss: tensor(0.0551)\n",
      "12143 Traning Loss: tensor(0.0545)\n",
      "12144 Traning Loss: tensor(0.0552)\n",
      "12145 Traning Loss: tensor(0.0556)\n",
      "12146 Traning Loss: tensor(0.0547)\n",
      "12147 Traning Loss: tensor(0.0533)\n",
      "12148 Traning Loss: tensor(0.0544)\n",
      "12149 Traning Loss: tensor(0.0542)\n",
      "12150 Traning Loss: tensor(0.0537)\n",
      "12151 Traning Loss: tensor(0.0546)\n",
      "12152 Traning Loss: tensor(0.0536)\n",
      "12153 Traning Loss: tensor(0.0559)\n",
      "12154 Traning Loss: tensor(0.0540)\n",
      "12155 Traning Loss: tensor(0.0544)\n",
      "12156 Traning Loss: tensor(0.0545)\n",
      "12157 Traning Loss: tensor(0.0556)\n",
      "12158 Traning Loss: tensor(0.0537)\n",
      "12159 Traning Loss: tensor(0.0547)\n",
      "12160 Traning Loss: tensor(0.0536)\n",
      "12161 Traning Loss: tensor(0.0539)\n",
      "12162 Traning Loss: tensor(0.0550)\n",
      "12163 Traning Loss: tensor(0.0557)\n",
      "12164 Traning Loss: tensor(0.0543)\n",
      "12165 Traning Loss: tensor(0.0543)\n",
      "12166 Traning Loss: tensor(0.0538)\n",
      "12167 Traning Loss: tensor(0.0539)\n",
      "12168 Traning Loss: tensor(0.0548)\n",
      "12169 Traning Loss: tensor(0.0575)\n",
      "12170 Traning Loss: tensor(0.0544)\n",
      "12171 Traning Loss: tensor(0.0553)\n",
      "12172 Traning Loss: tensor(0.0545)\n",
      "12173 Traning Loss: tensor(0.0542)\n",
      "12174 Traning Loss: tensor(0.0557)\n",
      "12175 Traning Loss: tensor(0.0551)\n",
      "12176 Traning Loss: tensor(0.0552)\n",
      "12177 Traning Loss: tensor(0.0551)\n",
      "12178 Traning Loss: tensor(0.0545)\n",
      "12179 Traning Loss: tensor(0.0538)\n",
      "12180 Traning Loss: tensor(0.0534)\n",
      "12181 Traning Loss: tensor(0.0545)\n",
      "12182 Traning Loss: tensor(0.0555)\n",
      "12183 Traning Loss: tensor(0.0537)\n",
      "12184 Traning Loss: tensor(0.0554)\n",
      "12185 Traning Loss: tensor(0.0554)\n",
      "12186 Traning Loss: tensor(0.0547)\n",
      "12187 Traning Loss: tensor(0.0546)\n",
      "12188 Traning Loss: tensor(0.0538)\n",
      "12189 Traning Loss: tensor(0.0547)\n",
      "12190 Traning Loss: tensor(0.0549)\n",
      "12191 Traning Loss: tensor(0.0545)\n",
      "12192 Traning Loss: tensor(0.0539)\n",
      "12193 Traning Loss: tensor(0.0547)\n",
      "12194 Traning Loss: tensor(0.0539)\n",
      "12195 Traning Loss: tensor(0.0533)\n",
      "12196 Traning Loss: tensor(0.0536)\n",
      "12197 Traning Loss: tensor(0.0550)\n",
      "12198 Traning Loss: tensor(0.0542)\n",
      "12199 Traning Loss: tensor(0.0539)\n",
      "12200 Traning Loss: tensor(0.0541)\n",
      "12201 Traning Loss: tensor(0.0539)\n",
      "12202 Traning Loss: tensor(0.0539)\n",
      "12203 Traning Loss: tensor(0.0541)\n",
      "12204 Traning Loss: tensor(0.0540)\n",
      "12205 Traning Loss: tensor(0.0531)\n",
      "12206 Traning Loss: tensor(0.0547)\n",
      "12207 Traning Loss: tensor(0.0547)\n",
      "12208 Traning Loss: tensor(0.0538)\n",
      "12209 Traning Loss: tensor(0.0540)\n",
      "12210 Traning Loss: tensor(0.0538)\n",
      "12211 Traning Loss: tensor(0.0532)\n",
      "12212 Traning Loss: tensor(0.0528)\n",
      "12213 Traning Loss: tensor(0.0538)\n",
      "12214 Traning Loss: tensor(0.0542)\n",
      "12215 Traning Loss: tensor(0.0551)\n",
      "12216 Traning Loss: tensor(0.0534)\n",
      "12217 Traning Loss: tensor(0.0532)\n",
      "12218 Traning Loss: tensor(0.0531)\n",
      "12219 Traning Loss: tensor(0.0534)\n",
      "12220 Traning Loss: tensor(0.0543)\n",
      "12221 Traning Loss: tensor(0.0541)\n",
      "12222 Traning Loss: tensor(0.0544)\n",
      "12223 Traning Loss: tensor(0.0546)\n",
      "12224 Traning Loss: tensor(0.0538)\n",
      "12225 Traning Loss: tensor(0.0555)\n",
      "12226 Traning Loss: tensor(0.0539)\n",
      "12227 Traning Loss: tensor(0.0534)\n",
      "12228 Traning Loss: tensor(0.0529)\n",
      "12229 Traning Loss: tensor(0.0533)\n",
      "12230 Traning Loss: tensor(0.0538)\n",
      "12231 Traning Loss: tensor(0.0547)\n",
      "12232 Traning Loss: tensor(0.0528)\n",
      "12233 Traning Loss: tensor(0.0541)\n",
      "12234 Traning Loss: tensor(0.0542)\n",
      "12235 Traning Loss: tensor(0.0548)\n",
      "12236 Traning Loss: tensor(0.0532)\n",
      "12237 Traning Loss: tensor(0.0558)\n",
      "12238 Traning Loss: tensor(0.0526)\n",
      "12239 Traning Loss: tensor(0.0531)\n",
      "12240 Traning Loss: tensor(0.0528)\n",
      "12241 Traning Loss: tensor(0.0537)\n",
      "12242 Traning Loss: tensor(0.0549)\n",
      "12243 Traning Loss: tensor(0.0535)\n",
      "12244 Traning Loss: tensor(0.0535)\n",
      "12245 Traning Loss: tensor(0.0533)\n",
      "12246 Traning Loss: tensor(0.0531)\n",
      "12247 Traning Loss: tensor(0.0531)\n",
      "12248 Traning Loss: tensor(0.0524)\n",
      "12249 Traning Loss: tensor(0.0542)\n",
      "12250 Traning Loss: tensor(0.0525)\n",
      "12251 Traning Loss: tensor(0.0530)\n",
      "12252 Traning Loss: tensor(0.0543)\n",
      "12253 Traning Loss: tensor(0.0531)\n",
      "12254 Traning Loss: tensor(0.0537)\n",
      "12255 Traning Loss: tensor(0.0541)\n",
      "12256 Traning Loss: tensor(0.0540)\n",
      "12257 Traning Loss: tensor(0.0528)\n",
      "12258 Traning Loss: tensor(0.0538)\n",
      "12259 Traning Loss: tensor(0.0539)\n",
      "12260 Traning Loss: tensor(0.0532)\n",
      "12261 Traning Loss: tensor(0.0526)\n",
      "12262 Traning Loss: tensor(0.0529)\n",
      "12263 Traning Loss: tensor(0.0529)\n",
      "12264 Traning Loss: tensor(0.0534)\n",
      "12265 Traning Loss: tensor(0.0527)\n",
      "12266 Traning Loss: tensor(0.0547)\n",
      "12267 Traning Loss: tensor(0.0537)\n",
      "12268 Traning Loss: tensor(0.0549)\n",
      "12269 Traning Loss: tensor(0.0540)\n",
      "12270 Traning Loss: tensor(0.0523)\n",
      "12271 Traning Loss: tensor(0.0532)\n",
      "12272 Traning Loss: tensor(0.0531)\n",
      "12273 Traning Loss: tensor(0.0529)\n",
      "12274 Traning Loss: tensor(0.0524)\n",
      "12275 Traning Loss: tensor(0.0542)\n",
      "12276 Traning Loss: tensor(0.0541)\n",
      "12277 Traning Loss: tensor(0.0530)\n",
      "12278 Traning Loss: tensor(0.0536)\n",
      "12279 Traning Loss: tensor(0.0542)\n",
      "12280 Traning Loss: tensor(0.0546)\n",
      "12281 Traning Loss: tensor(0.0539)\n",
      "12282 Traning Loss: tensor(0.0542)\n",
      "12283 Traning Loss: tensor(0.0534)\n",
      "12284 Traning Loss: tensor(0.0522)\n",
      "12285 Traning Loss: tensor(0.0531)\n",
      "12286 Traning Loss: tensor(0.0522)\n",
      "12287 Traning Loss: tensor(0.0532)\n",
      "12288 Traning Loss: tensor(0.0524)\n",
      "12289 Traning Loss: tensor(0.0532)\n",
      "12290 Traning Loss: tensor(0.0524)\n",
      "12291 Traning Loss: tensor(0.0534)\n",
      "12292 Traning Loss: tensor(0.0554)\n",
      "12293 Traning Loss: tensor(0.0534)\n",
      "12294 Traning Loss: tensor(0.0537)\n",
      "12295 Traning Loss: tensor(0.0528)\n",
      "12296 Traning Loss: tensor(0.0525)\n",
      "12297 Traning Loss: tensor(0.0542)\n",
      "12298 Traning Loss: tensor(0.0528)\n",
      "12299 Traning Loss: tensor(0.0530)\n",
      "12300 Traning Loss: tensor(0.0531)\n",
      "12301 Traning Loss: tensor(0.0537)\n",
      "12302 Traning Loss: tensor(0.0518)\n",
      "12303 Traning Loss: tensor(0.0533)\n",
      "12304 Traning Loss: tensor(0.0536)\n",
      "12305 Traning Loss: tensor(0.0530)\n",
      "12306 Traning Loss: tensor(0.0538)\n",
      "12307 Traning Loss: tensor(0.0537)\n",
      "12308 Traning Loss: tensor(0.0527)\n",
      "12309 Traning Loss: tensor(0.0525)\n",
      "12310 Traning Loss: tensor(0.0530)\n",
      "12311 Traning Loss: tensor(0.0522)\n",
      "12312 Traning Loss: tensor(0.0534)\n",
      "12313 Traning Loss: tensor(0.0535)\n",
      "12314 Traning Loss: tensor(0.0535)\n",
      "12315 Traning Loss: tensor(0.0531)\n",
      "12316 Traning Loss: tensor(0.0529)\n",
      "12317 Traning Loss: tensor(0.0538)\n",
      "12318 Traning Loss: tensor(0.0532)\n",
      "12319 Traning Loss: tensor(0.0526)\n",
      "12320 Traning Loss: tensor(0.0527)\n",
      "12321 Traning Loss: tensor(0.0536)\n",
      "12322 Traning Loss: tensor(0.0526)\n",
      "12323 Traning Loss: tensor(0.0528)\n",
      "12324 Traning Loss: tensor(0.0524)\n",
      "12325 Traning Loss: tensor(0.0530)\n",
      "12326 Traning Loss: tensor(0.0536)\n",
      "12327 Traning Loss: tensor(0.0529)\n",
      "12328 Traning Loss: tensor(0.0529)\n",
      "12329 Traning Loss: tensor(0.0529)\n",
      "12330 Traning Loss: tensor(0.0521)\n",
      "12331 Traning Loss: tensor(0.0525)\n",
      "12332 Traning Loss: tensor(0.0515)\n",
      "12333 Traning Loss: tensor(0.0536)\n",
      "12334 Traning Loss: tensor(0.0535)\n",
      "12335 Traning Loss: tensor(0.0533)\n",
      "12336 Traning Loss: tensor(0.0525)\n",
      "12337 Traning Loss: tensor(0.0534)\n",
      "12338 Traning Loss: tensor(0.0522)\n",
      "12339 Traning Loss: tensor(0.0534)\n",
      "12340 Traning Loss: tensor(0.0518)\n",
      "12341 Traning Loss: tensor(0.0534)\n",
      "12342 Traning Loss: tensor(0.0520)\n",
      "12343 Traning Loss: tensor(0.0537)\n",
      "12344 Traning Loss: tensor(0.0524)\n",
      "12345 Traning Loss: tensor(0.0520)\n",
      "12346 Traning Loss: tensor(0.0523)\n",
      "12347 Traning Loss: tensor(0.0527)\n",
      "12348 Traning Loss: tensor(0.0530)\n",
      "12349 Traning Loss: tensor(0.0534)\n",
      "12350 Traning Loss: tensor(0.0522)\n",
      "12351 Traning Loss: tensor(0.0528)\n",
      "12352 Traning Loss: tensor(0.0517)\n",
      "12353 Traning Loss: tensor(0.0521)\n",
      "12354 Traning Loss: tensor(0.0518)\n",
      "12355 Traning Loss: tensor(0.0523)\n",
      "12356 Traning Loss: tensor(0.0515)\n",
      "12357 Traning Loss: tensor(0.0518)\n",
      "12358 Traning Loss: tensor(0.0540)\n",
      "12359 Traning Loss: tensor(0.0530)\n",
      "12360 Traning Loss: tensor(0.0526)\n",
      "12361 Traning Loss: tensor(0.0539)\n",
      "12362 Traning Loss: tensor(0.0522)\n",
      "12363 Traning Loss: tensor(0.0518)\n",
      "12364 Traning Loss: tensor(0.0522)\n",
      "12365 Traning Loss: tensor(0.0526)\n",
      "12366 Traning Loss: tensor(0.0535)\n",
      "12367 Traning Loss: tensor(0.0524)\n",
      "12368 Traning Loss: tensor(0.0529)\n",
      "12369 Traning Loss: tensor(0.0526)\n",
      "12370 Traning Loss: tensor(0.0535)\n",
      "12371 Traning Loss: tensor(0.0533)\n",
      "12372 Traning Loss: tensor(0.0523)\n",
      "12373 Traning Loss: tensor(0.0530)\n",
      "12374 Traning Loss: tensor(0.0530)\n",
      "12375 Traning Loss: tensor(0.0527)\n",
      "12376 Traning Loss: tensor(0.0526)\n",
      "12377 Traning Loss: tensor(0.0508)\n",
      "12378 Traning Loss: tensor(0.0525)\n",
      "12379 Traning Loss: tensor(0.0517)\n",
      "12380 Traning Loss: tensor(0.0522)\n",
      "12381 Traning Loss: tensor(0.0528)\n",
      "12382 Traning Loss: tensor(0.0524)\n",
      "12383 Traning Loss: tensor(0.0536)\n",
      "12384 Traning Loss: tensor(0.0527)\n",
      "12385 Traning Loss: tensor(0.0534)\n",
      "12386 Traning Loss: tensor(0.0514)\n",
      "12387 Traning Loss: tensor(0.0525)\n",
      "12388 Traning Loss: tensor(0.0529)\n",
      "12389 Traning Loss: tensor(0.0521)\n",
      "12390 Traning Loss: tensor(0.0524)\n",
      "12391 Traning Loss: tensor(0.0515)\n",
      "12392 Traning Loss: tensor(0.0521)\n",
      "12393 Traning Loss: tensor(0.0519)\n",
      "12394 Traning Loss: tensor(0.0533)\n",
      "12395 Traning Loss: tensor(0.0520)\n",
      "12396 Traning Loss: tensor(0.0522)\n",
      "12397 Traning Loss: tensor(0.0519)\n",
      "12398 Traning Loss: tensor(0.0531)\n",
      "12399 Traning Loss: tensor(0.0521)\n",
      "12400 Traning Loss: tensor(0.0529)\n",
      "12401 Traning Loss: tensor(0.0544)\n",
      "12402 Traning Loss: tensor(0.0513)\n",
      "12403 Traning Loss: tensor(0.0515)\n",
      "12404 Traning Loss: tensor(0.0513)\n",
      "12405 Traning Loss: tensor(0.0518)\n",
      "12406 Traning Loss: tensor(0.0523)\n",
      "12407 Traning Loss: tensor(0.0515)\n",
      "12408 Traning Loss: tensor(0.0506)\n",
      "12409 Traning Loss: tensor(0.0518)\n",
      "12410 Traning Loss: tensor(0.0537)\n",
      "12411 Traning Loss: tensor(0.0519)\n",
      "12412 Traning Loss: tensor(0.0522)\n",
      "12413 Traning Loss: tensor(0.0524)\n",
      "12414 Traning Loss: tensor(0.0526)\n",
      "12415 Traning Loss: tensor(0.0515)\n",
      "12416 Traning Loss: tensor(0.0532)\n",
      "12417 Traning Loss: tensor(0.0528)\n",
      "12418 Traning Loss: tensor(0.0523)\n",
      "12419 Traning Loss: tensor(0.0516)\n",
      "12420 Traning Loss: tensor(0.0522)\n",
      "12421 Traning Loss: tensor(0.0522)\n",
      "12422 Traning Loss: tensor(0.0517)\n",
      "12423 Traning Loss: tensor(0.0513)\n",
      "12424 Traning Loss: tensor(0.0515)\n",
      "12425 Traning Loss: tensor(0.0519)\n",
      "12426 Traning Loss: tensor(0.0525)\n",
      "12427 Traning Loss: tensor(0.0515)\n",
      "12428 Traning Loss: tensor(0.0515)\n",
      "12429 Traning Loss: tensor(0.0511)\n",
      "12430 Traning Loss: tensor(0.0525)\n",
      "12431 Traning Loss: tensor(0.0521)\n",
      "12432 Traning Loss: tensor(0.0504)\n",
      "12433 Traning Loss: tensor(0.0518)\n",
      "12434 Traning Loss: tensor(0.0527)\n",
      "12435 Traning Loss: tensor(0.0512)\n",
      "12436 Traning Loss: tensor(0.0515)\n",
      "12437 Traning Loss: tensor(0.0516)\n",
      "12438 Traning Loss: tensor(0.0514)\n",
      "12439 Traning Loss: tensor(0.0513)\n",
      "12440 Traning Loss: tensor(0.0519)\n",
      "12441 Traning Loss: tensor(0.0525)\n",
      "12442 Traning Loss: tensor(0.0516)\n",
      "12443 Traning Loss: tensor(0.0522)\n",
      "12444 Traning Loss: tensor(0.0514)\n",
      "12445 Traning Loss: tensor(0.0524)\n",
      "12446 Traning Loss: tensor(0.0512)\n",
      "12447 Traning Loss: tensor(0.0522)\n",
      "12448 Traning Loss: tensor(0.0524)\n",
      "12449 Traning Loss: tensor(0.0512)\n",
      "12450 Traning Loss: tensor(0.0504)\n",
      "12451 Traning Loss: tensor(0.0521)\n",
      "12452 Traning Loss: tensor(0.0530)\n",
      "12453 Traning Loss: tensor(0.0510)\n",
      "12454 Traning Loss: tensor(0.0521)\n",
      "12455 Traning Loss: tensor(0.0528)\n",
      "12456 Traning Loss: tensor(0.0524)\n",
      "12457 Traning Loss: tensor(0.0528)\n",
      "12458 Traning Loss: tensor(0.0518)\n",
      "12459 Traning Loss: tensor(0.0510)\n",
      "12460 Traning Loss: tensor(0.0512)\n",
      "12461 Traning Loss: tensor(0.0522)\n",
      "12462 Traning Loss: tensor(0.0516)\n",
      "12463 Traning Loss: tensor(0.0517)\n",
      "12464 Traning Loss: tensor(0.0520)\n",
      "12465 Traning Loss: tensor(0.0522)\n",
      "12466 Traning Loss: tensor(0.0523)\n",
      "12467 Traning Loss: tensor(0.0514)\n",
      "12468 Traning Loss: tensor(0.0508)\n",
      "12469 Traning Loss: tensor(0.0526)\n",
      "12470 Traning Loss: tensor(0.0521)\n",
      "12471 Traning Loss: tensor(0.0515)\n",
      "12472 Traning Loss: tensor(0.0522)\n",
      "12473 Traning Loss: tensor(0.0510)\n",
      "12474 Traning Loss: tensor(0.0509)\n",
      "12475 Traning Loss: tensor(0.0514)\n",
      "12476 Traning Loss: tensor(0.0509)\n",
      "12477 Traning Loss: tensor(0.0510)\n",
      "12478 Traning Loss: tensor(0.0512)\n",
      "12479 Traning Loss: tensor(0.0511)\n",
      "12480 Traning Loss: tensor(0.0511)\n",
      "12481 Traning Loss: tensor(0.0511)\n",
      "12482 Traning Loss: tensor(0.0515)\n",
      "12483 Traning Loss: tensor(0.0500)\n",
      "12484 Traning Loss: tensor(0.0517)\n",
      "12485 Traning Loss: tensor(0.0505)\n",
      "12486 Traning Loss: tensor(0.0505)\n",
      "12487 Traning Loss: tensor(0.0502)\n",
      "12488 Traning Loss: tensor(0.0520)\n",
      "12489 Traning Loss: tensor(0.0506)\n",
      "12490 Traning Loss: tensor(0.0513)\n",
      "12491 Traning Loss: tensor(0.0501)\n",
      "12492 Traning Loss: tensor(0.0513)\n",
      "12493 Traning Loss: tensor(0.0527)\n",
      "12494 Traning Loss: tensor(0.0503)\n",
      "12495 Traning Loss: tensor(0.0515)\n",
      "12496 Traning Loss: tensor(0.0509)\n",
      "12497 Traning Loss: tensor(0.0509)\n",
      "12498 Traning Loss: tensor(0.0510)\n",
      "12499 Traning Loss: tensor(0.0508)\n",
      "12500 Traning Loss: tensor(0.0513)\n",
      "12501 Traning Loss: tensor(0.0512)\n",
      "12502 Traning Loss: tensor(0.0522)\n",
      "12503 Traning Loss: tensor(0.0504)\n",
      "12504 Traning Loss: tensor(0.0521)\n",
      "12505 Traning Loss: tensor(0.0513)\n",
      "12506 Traning Loss: tensor(0.0510)\n",
      "12507 Traning Loss: tensor(0.0516)\n",
      "12508 Traning Loss: tensor(0.0499)\n",
      "12509 Traning Loss: tensor(0.0512)\n",
      "12510 Traning Loss: tensor(0.0519)\n",
      "12511 Traning Loss: tensor(0.0512)\n",
      "12512 Traning Loss: tensor(0.0512)\n",
      "12513 Traning Loss: tensor(0.0499)\n",
      "12514 Traning Loss: tensor(0.0506)\n",
      "12515 Traning Loss: tensor(0.0516)\n",
      "12516 Traning Loss: tensor(0.0509)\n",
      "12517 Traning Loss: tensor(0.0512)\n",
      "12518 Traning Loss: tensor(0.0508)\n",
      "12519 Traning Loss: tensor(0.0515)\n",
      "12520 Traning Loss: tensor(0.0508)\n",
      "12521 Traning Loss: tensor(0.0510)\n",
      "12522 Traning Loss: tensor(0.0507)\n",
      "12523 Traning Loss: tensor(0.0502)\n",
      "12524 Traning Loss: tensor(0.0509)\n",
      "12525 Traning Loss: tensor(0.0515)\n",
      "12526 Traning Loss: tensor(0.0510)\n",
      "12527 Traning Loss: tensor(0.0506)\n",
      "12528 Traning Loss: tensor(0.0502)\n",
      "12529 Traning Loss: tensor(0.0509)\n",
      "12530 Traning Loss: tensor(0.0510)\n",
      "12531 Traning Loss: tensor(0.0508)\n",
      "12532 Traning Loss: tensor(0.0511)\n",
      "12533 Traning Loss: tensor(0.0522)\n",
      "12534 Traning Loss: tensor(0.0510)\n",
      "12535 Traning Loss: tensor(0.0505)\n",
      "12536 Traning Loss: tensor(0.0505)\n",
      "12537 Traning Loss: tensor(0.0511)\n",
      "12538 Traning Loss: tensor(0.0512)\n",
      "12539 Traning Loss: tensor(0.0504)\n",
      "12540 Traning Loss: tensor(0.0500)\n",
      "12541 Traning Loss: tensor(0.0510)\n",
      "12542 Traning Loss: tensor(0.0507)\n",
      "12543 Traning Loss: tensor(0.0501)\n",
      "12544 Traning Loss: tensor(0.0521)\n",
      "12545 Traning Loss: tensor(0.0523)\n",
      "12546 Traning Loss: tensor(0.0518)\n",
      "12547 Traning Loss: tensor(0.0506)\n",
      "12548 Traning Loss: tensor(0.0517)\n",
      "12549 Traning Loss: tensor(0.0503)\n",
      "12550 Traning Loss: tensor(0.0510)\n",
      "12551 Traning Loss: tensor(0.0505)\n",
      "12552 Traning Loss: tensor(0.0495)\n",
      "12553 Traning Loss: tensor(0.0509)\n",
      "12554 Traning Loss: tensor(0.0503)\n",
      "12555 Traning Loss: tensor(0.0512)\n",
      "12556 Traning Loss: tensor(0.0514)\n",
      "12557 Traning Loss: tensor(0.0516)\n",
      "12558 Traning Loss: tensor(0.0496)\n",
      "12559 Traning Loss: tensor(0.0507)\n",
      "12560 Traning Loss: tensor(0.0512)\n",
      "12561 Traning Loss: tensor(0.0499)\n",
      "12562 Traning Loss: tensor(0.0506)\n",
      "12563 Traning Loss: tensor(0.0491)\n",
      "12564 Traning Loss: tensor(0.0502)\n",
      "12565 Traning Loss: tensor(0.0498)\n",
      "12566 Traning Loss: tensor(0.0506)\n",
      "12567 Traning Loss: tensor(0.0505)\n",
      "12568 Traning Loss: tensor(0.0507)\n",
      "12569 Traning Loss: tensor(0.0509)\n",
      "12570 Traning Loss: tensor(0.0509)\n",
      "12571 Traning Loss: tensor(0.0505)\n",
      "12572 Traning Loss: tensor(0.0494)\n",
      "12573 Traning Loss: tensor(0.0515)\n",
      "12574 Traning Loss: tensor(0.0512)\n",
      "12575 Traning Loss: tensor(0.0499)\n",
      "12576 Traning Loss: tensor(0.0520)\n",
      "12577 Traning Loss: tensor(0.0497)\n",
      "12578 Traning Loss: tensor(0.0492)\n",
      "12579 Traning Loss: tensor(0.0504)\n",
      "12580 Traning Loss: tensor(0.0512)\n",
      "12581 Traning Loss: tensor(0.0500)\n",
      "12582 Traning Loss: tensor(0.0497)\n",
      "12583 Traning Loss: tensor(0.0504)\n",
      "12584 Traning Loss: tensor(0.0508)\n",
      "12585 Traning Loss: tensor(0.0498)\n",
      "12586 Traning Loss: tensor(0.0496)\n",
      "12587 Traning Loss: tensor(0.0503)\n",
      "12588 Traning Loss: tensor(0.0498)\n",
      "12589 Traning Loss: tensor(0.0500)\n",
      "12590 Traning Loss: tensor(0.0500)\n",
      "12591 Traning Loss: tensor(0.0498)\n",
      "12592 Traning Loss: tensor(0.0497)\n",
      "12593 Traning Loss: tensor(0.0486)\n",
      "12594 Traning Loss: tensor(0.0506)\n",
      "12595 Traning Loss: tensor(0.0495)\n",
      "12596 Traning Loss: tensor(0.0496)\n",
      "12597 Traning Loss: tensor(0.0520)\n",
      "12598 Traning Loss: tensor(0.0504)\n",
      "12599 Traning Loss: tensor(0.0499)\n",
      "12600 Traning Loss: tensor(0.0507)\n",
      "12601 Traning Loss: tensor(0.0501)\n",
      "12602 Traning Loss: tensor(0.0504)\n",
      "12603 Traning Loss: tensor(0.0501)\n",
      "12604 Traning Loss: tensor(0.0499)\n",
      "12605 Traning Loss: tensor(0.0500)\n",
      "12606 Traning Loss: tensor(0.0491)\n",
      "12607 Traning Loss: tensor(0.0500)\n",
      "12608 Traning Loss: tensor(0.0497)\n",
      "12609 Traning Loss: tensor(0.0504)\n",
      "12610 Traning Loss: tensor(0.0496)\n",
      "12611 Traning Loss: tensor(0.0497)\n",
      "12612 Traning Loss: tensor(0.0496)\n",
      "12613 Traning Loss: tensor(0.0506)\n",
      "12614 Traning Loss: tensor(0.0498)\n",
      "12615 Traning Loss: tensor(0.0509)\n",
      "12616 Traning Loss: tensor(0.0498)\n",
      "12617 Traning Loss: tensor(0.0502)\n",
      "12618 Traning Loss: tensor(0.0490)\n",
      "12619 Traning Loss: tensor(0.0503)\n",
      "12620 Traning Loss: tensor(0.0488)\n",
      "12621 Traning Loss: tensor(0.0495)\n",
      "12622 Traning Loss: tensor(0.0487)\n",
      "12623 Traning Loss: tensor(0.0492)\n",
      "12624 Traning Loss: tensor(0.0497)\n",
      "12625 Traning Loss: tensor(0.0500)\n",
      "12626 Traning Loss: tensor(0.0488)\n",
      "12627 Traning Loss: tensor(0.0503)\n",
      "12628 Traning Loss: tensor(0.0497)\n",
      "12629 Traning Loss: tensor(0.0497)\n",
      "12630 Traning Loss: tensor(0.0496)\n",
      "12631 Traning Loss: tensor(0.0501)\n",
      "12632 Traning Loss: tensor(0.0496)\n",
      "12633 Traning Loss: tensor(0.0494)\n",
      "12634 Traning Loss: tensor(0.0489)\n",
      "12635 Traning Loss: tensor(0.0502)\n",
      "12636 Traning Loss: tensor(0.0483)\n",
      "12637 Traning Loss: tensor(0.0493)\n",
      "12638 Traning Loss: tensor(0.0492)\n",
      "12639 Traning Loss: tensor(0.0489)\n",
      "12640 Traning Loss: tensor(0.0490)\n",
      "12641 Traning Loss: tensor(0.0485)\n",
      "12642 Traning Loss: tensor(0.0496)\n",
      "12643 Traning Loss: tensor(0.0500)\n",
      "12644 Traning Loss: tensor(0.0487)\n",
      "12645 Traning Loss: tensor(0.0490)\n",
      "12646 Traning Loss: tensor(0.0506)\n",
      "12647 Traning Loss: tensor(0.0487)\n",
      "12648 Traning Loss: tensor(0.0481)\n",
      "12649 Traning Loss: tensor(0.0497)\n",
      "12650 Traning Loss: tensor(0.0500)\n",
      "12651 Traning Loss: tensor(0.0493)\n",
      "12652 Traning Loss: tensor(0.0478)\n",
      "12653 Traning Loss: tensor(0.0504)\n",
      "12654 Traning Loss: tensor(0.0492)\n",
      "12655 Traning Loss: tensor(0.0494)\n",
      "12656 Traning Loss: tensor(0.0493)\n",
      "12657 Traning Loss: tensor(0.0505)\n",
      "12658 Traning Loss: tensor(0.0499)\n",
      "12659 Traning Loss: tensor(0.0500)\n",
      "12660 Traning Loss: tensor(0.0500)\n",
      "12661 Traning Loss: tensor(0.0499)\n",
      "12662 Traning Loss: tensor(0.0497)\n",
      "12663 Traning Loss: tensor(0.0488)\n",
      "12664 Traning Loss: tensor(0.0490)\n",
      "12665 Traning Loss: tensor(0.0488)\n",
      "12666 Traning Loss: tensor(0.0491)\n",
      "12667 Traning Loss: tensor(0.0505)\n",
      "12668 Traning Loss: tensor(0.0484)\n",
      "12669 Traning Loss: tensor(0.0498)\n",
      "12670 Traning Loss: tensor(0.0494)\n",
      "12671 Traning Loss: tensor(0.0489)\n",
      "12672 Traning Loss: tensor(0.0495)\n",
      "12673 Traning Loss: tensor(0.0492)\n",
      "12674 Traning Loss: tensor(0.0501)\n",
      "12675 Traning Loss: tensor(0.0500)\n",
      "12676 Traning Loss: tensor(0.0490)\n",
      "12677 Traning Loss: tensor(0.0487)\n",
      "12678 Traning Loss: tensor(0.0487)\n",
      "12679 Traning Loss: tensor(0.0491)\n",
      "12680 Traning Loss: tensor(0.0492)\n",
      "12681 Traning Loss: tensor(0.0485)\n",
      "12682 Traning Loss: tensor(0.0493)\n",
      "12683 Traning Loss: tensor(0.0490)\n",
      "12684 Traning Loss: tensor(0.0500)\n",
      "12685 Traning Loss: tensor(0.0486)\n",
      "12686 Traning Loss: tensor(0.0495)\n",
      "12687 Traning Loss: tensor(0.0489)\n",
      "12688 Traning Loss: tensor(0.0478)\n",
      "12689 Traning Loss: tensor(0.0491)\n",
      "12690 Traning Loss: tensor(0.0498)\n",
      "12691 Traning Loss: tensor(0.0499)\n",
      "12692 Traning Loss: tensor(0.0493)\n",
      "12693 Traning Loss: tensor(0.0493)\n",
      "12694 Traning Loss: tensor(0.0489)\n",
      "12695 Traning Loss: tensor(0.0490)\n",
      "12696 Traning Loss: tensor(0.0488)\n",
      "12697 Traning Loss: tensor(0.0500)\n",
      "12698 Traning Loss: tensor(0.0487)\n",
      "12699 Traning Loss: tensor(0.0486)\n",
      "12700 Traning Loss: tensor(0.0488)\n",
      "12701 Traning Loss: tensor(0.0487)\n",
      "12702 Traning Loss: tensor(0.0492)\n",
      "12703 Traning Loss: tensor(0.0481)\n",
      "12704 Traning Loss: tensor(0.0491)\n",
      "12705 Traning Loss: tensor(0.0493)\n",
      "12706 Traning Loss: tensor(0.0493)\n",
      "12707 Traning Loss: tensor(0.0485)\n",
      "12708 Traning Loss: tensor(0.0485)\n",
      "12709 Traning Loss: tensor(0.0493)\n",
      "12710 Traning Loss: tensor(0.0488)\n",
      "12711 Traning Loss: tensor(0.0479)\n",
      "12712 Traning Loss: tensor(0.0479)\n",
      "12713 Traning Loss: tensor(0.0490)\n",
      "12714 Traning Loss: tensor(0.0478)\n",
      "12715 Traning Loss: tensor(0.0477)\n",
      "12716 Traning Loss: tensor(0.0482)\n",
      "12717 Traning Loss: tensor(0.0492)\n",
      "12718 Traning Loss: tensor(0.0482)\n",
      "12719 Traning Loss: tensor(0.0482)\n",
      "12720 Traning Loss: tensor(0.0484)\n",
      "12721 Traning Loss: tensor(0.0484)\n",
      "12722 Traning Loss: tensor(0.0490)\n",
      "12723 Traning Loss: tensor(0.0474)\n",
      "12724 Traning Loss: tensor(0.0481)\n",
      "12725 Traning Loss: tensor(0.0481)\n",
      "12726 Traning Loss: tensor(0.0486)\n",
      "12727 Traning Loss: tensor(0.0489)\n",
      "12728 Traning Loss: tensor(0.0486)\n",
      "12729 Traning Loss: tensor(0.0481)\n",
      "12730 Traning Loss: tensor(0.0492)\n",
      "12731 Traning Loss: tensor(0.0480)\n",
      "12732 Traning Loss: tensor(0.0488)\n",
      "12733 Traning Loss: tensor(0.0484)\n",
      "12734 Traning Loss: tensor(0.0487)\n",
      "12735 Traning Loss: tensor(0.0489)\n",
      "12736 Traning Loss: tensor(0.0484)\n",
      "12737 Traning Loss: tensor(0.0481)\n",
      "12738 Traning Loss: tensor(0.0480)\n",
      "12739 Traning Loss: tensor(0.0477)\n",
      "12740 Traning Loss: tensor(0.0479)\n",
      "12741 Traning Loss: tensor(0.0467)\n",
      "12742 Traning Loss: tensor(0.0490)\n",
      "12743 Traning Loss: tensor(0.0488)\n",
      "12744 Traning Loss: tensor(0.0486)\n",
      "12745 Traning Loss: tensor(0.0478)\n",
      "12746 Traning Loss: tensor(0.0471)\n",
      "12747 Traning Loss: tensor(0.0479)\n",
      "12748 Traning Loss: tensor(0.0483)\n",
      "12749 Traning Loss: tensor(0.0485)\n",
      "12750 Traning Loss: tensor(0.0475)\n",
      "12751 Traning Loss: tensor(0.0480)\n",
      "12752 Traning Loss: tensor(0.0489)\n",
      "12753 Traning Loss: tensor(0.0474)\n",
      "12754 Traning Loss: tensor(0.0479)\n",
      "12755 Traning Loss: tensor(0.0496)\n",
      "12756 Traning Loss: tensor(0.0481)\n",
      "12757 Traning Loss: tensor(0.0474)\n",
      "12758 Traning Loss: tensor(0.0490)\n",
      "12759 Traning Loss: tensor(0.0486)\n",
      "12760 Traning Loss: tensor(0.0485)\n",
      "12761 Traning Loss: tensor(0.0463)\n",
      "12762 Traning Loss: tensor(0.0479)\n",
      "12763 Traning Loss: tensor(0.0477)\n",
      "12764 Traning Loss: tensor(0.0480)\n",
      "12765 Traning Loss: tensor(0.0480)\n",
      "12766 Traning Loss: tensor(0.0484)\n",
      "12767 Traning Loss: tensor(0.0479)\n",
      "12768 Traning Loss: tensor(0.0480)\n",
      "12769 Traning Loss: tensor(0.0473)\n",
      "12770 Traning Loss: tensor(0.0486)\n",
      "12771 Traning Loss: tensor(0.0485)\n",
      "12772 Traning Loss: tensor(0.0477)\n",
      "12773 Traning Loss: tensor(0.0470)\n",
      "12774 Traning Loss: tensor(0.0478)\n",
      "12775 Traning Loss: tensor(0.0481)\n",
      "12776 Traning Loss: tensor(0.0484)\n",
      "12777 Traning Loss: tensor(0.0488)\n",
      "12778 Traning Loss: tensor(0.0471)\n",
      "12779 Traning Loss: tensor(0.0476)\n",
      "12780 Traning Loss: tensor(0.0475)\n",
      "12781 Traning Loss: tensor(0.0472)\n",
      "12782 Traning Loss: tensor(0.0471)\n",
      "12783 Traning Loss: tensor(0.0489)\n",
      "12784 Traning Loss: tensor(0.0484)\n",
      "12785 Traning Loss: tensor(0.0498)\n",
      "12786 Traning Loss: tensor(0.0471)\n",
      "12787 Traning Loss: tensor(0.0463)\n",
      "12788 Traning Loss: tensor(0.0472)\n",
      "12789 Traning Loss: tensor(0.0474)\n",
      "12790 Traning Loss: tensor(0.0487)\n",
      "12791 Traning Loss: tensor(0.0474)\n",
      "12792 Traning Loss: tensor(0.0482)\n",
      "12793 Traning Loss: tensor(0.0465)\n",
      "12794 Traning Loss: tensor(0.0487)\n",
      "12795 Traning Loss: tensor(0.0483)\n",
      "12796 Traning Loss: tensor(0.0482)\n",
      "12797 Traning Loss: tensor(0.0479)\n",
      "12798 Traning Loss: tensor(0.0466)\n",
      "12799 Traning Loss: tensor(0.0484)\n",
      "12800 Traning Loss: tensor(0.0472)\n",
      "12801 Traning Loss: tensor(0.0478)\n",
      "12802 Traning Loss: tensor(0.0474)\n",
      "12803 Traning Loss: tensor(0.0479)\n",
      "12804 Traning Loss: tensor(0.0473)\n",
      "12805 Traning Loss: tensor(0.0475)\n",
      "12806 Traning Loss: tensor(0.0474)\n",
      "12807 Traning Loss: tensor(0.0482)\n",
      "12808 Traning Loss: tensor(0.0475)\n",
      "12809 Traning Loss: tensor(0.0479)\n",
      "12810 Traning Loss: tensor(0.0483)\n",
      "12811 Traning Loss: tensor(0.0472)\n",
      "12812 Traning Loss: tensor(0.0486)\n",
      "12813 Traning Loss: tensor(0.0468)\n",
      "12814 Traning Loss: tensor(0.0477)\n",
      "12815 Traning Loss: tensor(0.0471)\n",
      "12816 Traning Loss: tensor(0.0470)\n",
      "12817 Traning Loss: tensor(0.0465)\n",
      "12818 Traning Loss: tensor(0.0478)\n",
      "12819 Traning Loss: tensor(0.0482)\n",
      "12820 Traning Loss: tensor(0.0480)\n",
      "12821 Traning Loss: tensor(0.0462)\n",
      "12822 Traning Loss: tensor(0.0465)\n",
      "12823 Traning Loss: tensor(0.0465)\n",
      "12824 Traning Loss: tensor(0.0473)\n",
      "12825 Traning Loss: tensor(0.0469)\n",
      "12826 Traning Loss: tensor(0.0474)\n",
      "12827 Traning Loss: tensor(0.0469)\n",
      "12828 Traning Loss: tensor(0.0476)\n",
      "12829 Traning Loss: tensor(0.0468)\n",
      "12830 Traning Loss: tensor(0.0469)\n",
      "12831 Traning Loss: tensor(0.0482)\n",
      "12832 Traning Loss: tensor(0.0457)\n",
      "12833 Traning Loss: tensor(0.0472)\n",
      "12834 Traning Loss: tensor(0.0479)\n",
      "12835 Traning Loss: tensor(0.0475)\n",
      "12836 Traning Loss: tensor(0.0473)\n",
      "12837 Traning Loss: tensor(0.0499)\n",
      "12838 Traning Loss: tensor(0.0468)\n",
      "12839 Traning Loss: tensor(0.0475)\n",
      "12840 Traning Loss: tensor(0.0478)\n",
      "12841 Traning Loss: tensor(0.0473)\n",
      "12842 Traning Loss: tensor(0.0462)\n",
      "12843 Traning Loss: tensor(0.0486)\n",
      "12844 Traning Loss: tensor(0.0489)\n",
      "12845 Traning Loss: tensor(0.0481)\n",
      "12846 Traning Loss: tensor(0.0462)\n",
      "12847 Traning Loss: tensor(0.0475)\n",
      "12848 Traning Loss: tensor(0.0463)\n",
      "12849 Traning Loss: tensor(0.0459)\n",
      "12850 Traning Loss: tensor(0.0452)\n",
      "12851 Traning Loss: tensor(0.0475)\n",
      "12852 Traning Loss: tensor(0.0488)\n",
      "12853 Traning Loss: tensor(0.0464)\n",
      "12854 Traning Loss: tensor(0.0475)\n",
      "12855 Traning Loss: tensor(0.0479)\n",
      "12856 Traning Loss: tensor(0.0460)\n",
      "12857 Traning Loss: tensor(0.0459)\n",
      "12858 Traning Loss: tensor(0.0467)\n",
      "12859 Traning Loss: tensor(0.0461)\n",
      "12860 Traning Loss: tensor(0.0476)\n",
      "12861 Traning Loss: tensor(0.0457)\n",
      "12862 Traning Loss: tensor(0.0473)\n",
      "12863 Traning Loss: tensor(0.0466)\n",
      "12864 Traning Loss: tensor(0.0457)\n",
      "12865 Traning Loss: tensor(0.0474)\n",
      "12866 Traning Loss: tensor(0.0463)\n",
      "12867 Traning Loss: tensor(0.0468)\n",
      "12868 Traning Loss: tensor(0.0460)\n",
      "12869 Traning Loss: tensor(0.0460)\n",
      "12870 Traning Loss: tensor(0.0469)\n",
      "12871 Traning Loss: tensor(0.0457)\n",
      "12872 Traning Loss: tensor(0.0466)\n",
      "12873 Traning Loss: tensor(0.0470)\n",
      "12874 Traning Loss: tensor(0.0478)\n",
      "12875 Traning Loss: tensor(0.0447)\n",
      "12876 Traning Loss: tensor(0.0461)\n",
      "12877 Traning Loss: tensor(0.0492)\n",
      "12878 Traning Loss: tensor(0.0472)\n",
      "12879 Traning Loss: tensor(0.0460)\n",
      "12880 Traning Loss: tensor(0.0461)\n",
      "12881 Traning Loss: tensor(0.0476)\n",
      "12882 Traning Loss: tensor(0.0475)\n",
      "12883 Traning Loss: tensor(0.0472)\n",
      "12884 Traning Loss: tensor(0.0472)\n",
      "12885 Traning Loss: tensor(0.0464)\n",
      "12886 Traning Loss: tensor(0.0463)\n",
      "12887 Traning Loss: tensor(0.0453)\n",
      "12888 Traning Loss: tensor(0.0471)\n",
      "12889 Traning Loss: tensor(0.0454)\n",
      "12890 Traning Loss: tensor(0.0460)\n",
      "12891 Traning Loss: tensor(0.0463)\n",
      "12892 Traning Loss: tensor(0.0457)\n",
      "12893 Traning Loss: tensor(0.0476)\n",
      "12894 Traning Loss: tensor(0.0462)\n",
      "12895 Traning Loss: tensor(0.0464)\n",
      "12896 Traning Loss: tensor(0.0466)\n",
      "12897 Traning Loss: tensor(0.0455)\n",
      "12898 Traning Loss: tensor(0.0462)\n",
      "12899 Traning Loss: tensor(0.0474)\n",
      "12900 Traning Loss: tensor(0.0458)\n",
      "12901 Traning Loss: tensor(0.0459)\n",
      "12902 Traning Loss: tensor(0.0459)\n",
      "12903 Traning Loss: tensor(0.0464)\n",
      "12904 Traning Loss: tensor(0.0470)\n",
      "12905 Traning Loss: tensor(0.0455)\n",
      "12906 Traning Loss: tensor(0.0453)\n",
      "12907 Traning Loss: tensor(0.0469)\n",
      "12908 Traning Loss: tensor(0.0445)\n",
      "12909 Traning Loss: tensor(0.0455)\n",
      "12910 Traning Loss: tensor(0.0462)\n",
      "12911 Traning Loss: tensor(0.0458)\n",
      "12912 Traning Loss: tensor(0.0464)\n",
      "12913 Traning Loss: tensor(0.0454)\n",
      "12914 Traning Loss: tensor(0.0461)\n",
      "12915 Traning Loss: tensor(0.0453)\n",
      "12916 Traning Loss: tensor(0.0451)\n",
      "12917 Traning Loss: tensor(0.0440)\n",
      "12918 Traning Loss: tensor(0.0454)\n",
      "12919 Traning Loss: tensor(0.0460)\n",
      "12920 Traning Loss: tensor(0.0458)\n",
      "12921 Traning Loss: tensor(0.0457)\n",
      "12922 Traning Loss: tensor(0.0449)\n",
      "12923 Traning Loss: tensor(0.0460)\n",
      "12924 Traning Loss: tensor(0.0451)\n",
      "12925 Traning Loss: tensor(0.0458)\n",
      "12926 Traning Loss: tensor(0.0453)\n",
      "12927 Traning Loss: tensor(0.0456)\n",
      "12928 Traning Loss: tensor(0.0454)\n",
      "12929 Traning Loss: tensor(0.0457)\n",
      "12930 Traning Loss: tensor(0.0453)\n",
      "12931 Traning Loss: tensor(0.0454)\n",
      "12932 Traning Loss: tensor(0.0439)\n",
      "12933 Traning Loss: tensor(0.0449)\n",
      "12934 Traning Loss: tensor(0.0457)\n",
      "12935 Traning Loss: tensor(0.0452)\n",
      "12936 Traning Loss: tensor(0.0460)\n",
      "12937 Traning Loss: tensor(0.0446)\n",
      "12938 Traning Loss: tensor(0.0467)\n",
      "12939 Traning Loss: tensor(0.0460)\n",
      "12940 Traning Loss: tensor(0.0450)\n",
      "12941 Traning Loss: tensor(0.0463)\n",
      "12942 Traning Loss: tensor(0.0475)\n",
      "12943 Traning Loss: tensor(0.0456)\n",
      "12944 Traning Loss: tensor(0.0457)\n",
      "12945 Traning Loss: tensor(0.0454)\n",
      "12946 Traning Loss: tensor(0.0464)\n",
      "12947 Traning Loss: tensor(0.0454)\n",
      "12948 Traning Loss: tensor(0.0454)\n",
      "12949 Traning Loss: tensor(0.0463)\n",
      "12950 Traning Loss: tensor(0.0476)\n",
      "12951 Traning Loss: tensor(0.0455)\n",
      "12952 Traning Loss: tensor(0.0464)\n",
      "12953 Traning Loss: tensor(0.0462)\n",
      "12954 Traning Loss: tensor(0.0456)\n",
      "12955 Traning Loss: tensor(0.0447)\n",
      "12956 Traning Loss: tensor(0.0456)\n",
      "12957 Traning Loss: tensor(0.0473)\n",
      "12958 Traning Loss: tensor(0.0458)\n",
      "12959 Traning Loss: tensor(0.0458)\n",
      "12960 Traning Loss: tensor(0.0448)\n",
      "12961 Traning Loss: tensor(0.0454)\n",
      "12962 Traning Loss: tensor(0.0446)\n",
      "12963 Traning Loss: tensor(0.0464)\n",
      "12964 Traning Loss: tensor(0.0453)\n",
      "12965 Traning Loss: tensor(0.0447)\n",
      "12966 Traning Loss: tensor(0.0462)\n",
      "12967 Traning Loss: tensor(0.0453)\n",
      "12968 Traning Loss: tensor(0.0447)\n",
      "12969 Traning Loss: tensor(0.0451)\n",
      "12970 Traning Loss: tensor(0.0457)\n",
      "12971 Traning Loss: tensor(0.0453)\n",
      "12972 Traning Loss: tensor(0.0454)\n",
      "12973 Traning Loss: tensor(0.0465)\n",
      "12974 Traning Loss: tensor(0.0459)\n",
      "12975 Traning Loss: tensor(0.0449)\n",
      "12976 Traning Loss: tensor(0.0458)\n",
      "12977 Traning Loss: tensor(0.0466)\n",
      "12978 Traning Loss: tensor(0.0453)\n",
      "12979 Traning Loss: tensor(0.0446)\n",
      "12980 Traning Loss: tensor(0.0448)\n",
      "12981 Traning Loss: tensor(0.0455)\n",
      "12982 Traning Loss: tensor(0.0449)\n",
      "12983 Traning Loss: tensor(0.0451)\n",
      "12984 Traning Loss: tensor(0.0452)\n",
      "12985 Traning Loss: tensor(0.0448)\n",
      "12986 Traning Loss: tensor(0.0439)\n",
      "12987 Traning Loss: tensor(0.0457)\n",
      "12988 Traning Loss: tensor(0.0445)\n",
      "12989 Traning Loss: tensor(0.0439)\n",
      "12990 Traning Loss: tensor(0.0457)\n",
      "12991 Traning Loss: tensor(0.0453)\n",
      "12992 Traning Loss: tensor(0.0450)\n",
      "12993 Traning Loss: tensor(0.0453)\n",
      "12994 Traning Loss: tensor(0.0449)\n",
      "12995 Traning Loss: tensor(0.0447)\n",
      "12996 Traning Loss: tensor(0.0447)\n",
      "12997 Traning Loss: tensor(0.0457)\n",
      "12998 Traning Loss: tensor(0.0447)\n",
      "12999 Traning Loss: tensor(0.0447)\n",
      "13000 Traning Loss: tensor(0.0439)\n",
      "13001 Traning Loss: tensor(0.0443)\n",
      "13002 Traning Loss: tensor(0.0438)\n",
      "13003 Traning Loss: tensor(0.0437)\n",
      "13004 Traning Loss: tensor(0.0439)\n",
      "13005 Traning Loss: tensor(0.0447)\n",
      "13006 Traning Loss: tensor(0.0441)\n",
      "13007 Traning Loss: tensor(0.0440)\n",
      "13008 Traning Loss: tensor(0.0449)\n",
      "13009 Traning Loss: tensor(0.0434)\n",
      "13010 Traning Loss: tensor(0.0439)\n",
      "13011 Traning Loss: tensor(0.0445)\n",
      "13012 Traning Loss: tensor(0.0464)\n",
      "13013 Traning Loss: tensor(0.0448)\n",
      "13014 Traning Loss: tensor(0.0438)\n",
      "13015 Traning Loss: tensor(0.0446)\n",
      "13016 Traning Loss: tensor(0.0448)\n",
      "13017 Traning Loss: tensor(0.0440)\n",
      "13018 Traning Loss: tensor(0.0440)\n",
      "13019 Traning Loss: tensor(0.0446)\n",
      "13020 Traning Loss: tensor(0.0454)\n",
      "13021 Traning Loss: tensor(0.0433)\n",
      "13022 Traning Loss: tensor(0.0438)\n",
      "13023 Traning Loss: tensor(0.0435)\n",
      "13024 Traning Loss: tensor(0.0447)\n",
      "13025 Traning Loss: tensor(0.0451)\n",
      "13026 Traning Loss: tensor(0.0457)\n",
      "13027 Traning Loss: tensor(0.0449)\n",
      "13028 Traning Loss: tensor(0.0441)\n",
      "13029 Traning Loss: tensor(0.0429)\n",
      "13030 Traning Loss: tensor(0.0443)\n",
      "13031 Traning Loss: tensor(0.0454)\n",
      "13032 Traning Loss: tensor(0.0444)\n",
      "13033 Traning Loss: tensor(0.0451)\n",
      "13034 Traning Loss: tensor(0.0458)\n",
      "13035 Traning Loss: tensor(0.0432)\n",
      "13036 Traning Loss: tensor(0.0443)\n",
      "13037 Traning Loss: tensor(0.0448)\n",
      "13038 Traning Loss: tensor(0.0433)\n",
      "13039 Traning Loss: tensor(0.0442)\n",
      "13040 Traning Loss: tensor(0.0440)\n",
      "13041 Traning Loss: tensor(0.0445)\n",
      "13042 Traning Loss: tensor(0.0433)\n",
      "13043 Traning Loss: tensor(0.0434)\n",
      "13044 Traning Loss: tensor(0.0431)\n",
      "13045 Traning Loss: tensor(0.0442)\n",
      "13046 Traning Loss: tensor(0.0447)\n",
      "13047 Traning Loss: tensor(0.0442)\n",
      "13048 Traning Loss: tensor(0.0436)\n",
      "13049 Traning Loss: tensor(0.0437)\n",
      "13050 Traning Loss: tensor(0.0448)\n",
      "13051 Traning Loss: tensor(0.0434)\n",
      "13052 Traning Loss: tensor(0.0456)\n",
      "13053 Traning Loss: tensor(0.0435)\n",
      "13054 Traning Loss: tensor(0.0444)\n",
      "13055 Traning Loss: tensor(0.0439)\n",
      "13056 Traning Loss: tensor(0.0439)\n",
      "13057 Traning Loss: tensor(0.0425)\n",
      "13058 Traning Loss: tensor(0.0435)\n",
      "13059 Traning Loss: tensor(0.0436)\n",
      "13060 Traning Loss: tensor(0.0421)\n",
      "13061 Traning Loss: tensor(0.0425)\n",
      "13062 Traning Loss: tensor(0.0436)\n",
      "13063 Traning Loss: tensor(0.0442)\n",
      "13064 Traning Loss: tensor(0.0436)\n",
      "13065 Traning Loss: tensor(0.0444)\n",
      "13066 Traning Loss: tensor(0.0437)\n",
      "13067 Traning Loss: tensor(0.0428)\n",
      "13068 Traning Loss: tensor(0.0439)\n",
      "13069 Traning Loss: tensor(0.0437)\n",
      "13070 Traning Loss: tensor(0.0448)\n",
      "13071 Traning Loss: tensor(0.0434)\n",
      "13072 Traning Loss: tensor(0.0437)\n",
      "13073 Traning Loss: tensor(0.0431)\n",
      "13074 Traning Loss: tensor(0.0442)\n",
      "13075 Traning Loss: tensor(0.0433)\n",
      "13076 Traning Loss: tensor(0.0445)\n",
      "13077 Traning Loss: tensor(0.0440)\n",
      "13078 Traning Loss: tensor(0.0449)\n",
      "13079 Traning Loss: tensor(0.0442)\n",
      "13080 Traning Loss: tensor(0.0444)\n",
      "13081 Traning Loss: tensor(0.0438)\n",
      "13082 Traning Loss: tensor(0.0433)\n",
      "13083 Traning Loss: tensor(0.0439)\n",
      "13084 Traning Loss: tensor(0.0439)\n",
      "13085 Traning Loss: tensor(0.0439)\n",
      "13086 Traning Loss: tensor(0.0433)\n",
      "13087 Traning Loss: tensor(0.0429)\n",
      "13088 Traning Loss: tensor(0.0427)\n",
      "13089 Traning Loss: tensor(0.0435)\n",
      "13090 Traning Loss: tensor(0.0421)\n",
      "13091 Traning Loss: tensor(0.0442)\n",
      "13092 Traning Loss: tensor(0.0439)\n",
      "13093 Traning Loss: tensor(0.0435)\n",
      "13094 Traning Loss: tensor(0.0431)\n",
      "13095 Traning Loss: tensor(0.0433)\n",
      "13096 Traning Loss: tensor(0.0442)\n",
      "13097 Traning Loss: tensor(0.0430)\n",
      "13098 Traning Loss: tensor(0.0436)\n",
      "13099 Traning Loss: tensor(0.0435)\n",
      "13100 Traning Loss: tensor(0.0425)\n",
      "13101 Traning Loss: tensor(0.0426)\n",
      "13102 Traning Loss: tensor(0.0434)\n",
      "13103 Traning Loss: tensor(0.0442)\n",
      "13104 Traning Loss: tensor(0.0443)\n",
      "13105 Traning Loss: tensor(0.0437)\n",
      "13106 Traning Loss: tensor(0.0436)\n",
      "13107 Traning Loss: tensor(0.0417)\n",
      "13108 Traning Loss: tensor(0.0455)\n",
      "13109 Traning Loss: tensor(0.0428)\n",
      "13110 Traning Loss: tensor(0.0436)\n",
      "13111 Traning Loss: tensor(0.0447)\n",
      "13112 Traning Loss: tensor(0.0435)\n",
      "13113 Traning Loss: tensor(0.0434)\n",
      "13114 Traning Loss: tensor(0.0447)\n",
      "13115 Traning Loss: tensor(0.0433)\n",
      "13116 Traning Loss: tensor(0.0435)\n",
      "13117 Traning Loss: tensor(0.0422)\n",
      "13118 Traning Loss: tensor(0.0441)\n",
      "13119 Traning Loss: tensor(0.0428)\n",
      "13120 Traning Loss: tensor(0.0431)\n",
      "13121 Traning Loss: tensor(0.0429)\n",
      "13122 Traning Loss: tensor(0.0435)\n",
      "13123 Traning Loss: tensor(0.0428)\n",
      "13124 Traning Loss: tensor(0.0423)\n",
      "13125 Traning Loss: tensor(0.0421)\n",
      "13126 Traning Loss: tensor(0.0427)\n",
      "13127 Traning Loss: tensor(0.0438)\n",
      "13128 Traning Loss: tensor(0.0437)\n",
      "13129 Traning Loss: tensor(0.0447)\n",
      "13130 Traning Loss: tensor(0.0442)\n",
      "13131 Traning Loss: tensor(0.0424)\n",
      "13132 Traning Loss: tensor(0.0438)\n",
      "13133 Traning Loss: tensor(0.0452)\n",
      "13134 Traning Loss: tensor(0.0439)\n",
      "13135 Traning Loss: tensor(0.0431)\n",
      "13136 Traning Loss: tensor(0.0437)\n",
      "13137 Traning Loss: tensor(0.0441)\n",
      "13138 Traning Loss: tensor(0.0431)\n",
      "13139 Traning Loss: tensor(0.0439)\n",
      "13140 Traning Loss: tensor(0.0437)\n",
      "13141 Traning Loss: tensor(0.0429)\n",
      "13142 Traning Loss: tensor(0.0427)\n",
      "13143 Traning Loss: tensor(0.0423)\n",
      "13144 Traning Loss: tensor(0.0430)\n",
      "13145 Traning Loss: tensor(0.0426)\n",
      "13146 Traning Loss: tensor(0.0420)\n",
      "13147 Traning Loss: tensor(0.0425)\n",
      "13148 Traning Loss: tensor(0.0428)\n",
      "13149 Traning Loss: tensor(0.0422)\n",
      "13150 Traning Loss: tensor(0.0421)\n",
      "13151 Traning Loss: tensor(0.0435)\n",
      "13152 Traning Loss: tensor(0.0433)\n",
      "13153 Traning Loss: tensor(0.0421)\n",
      "13154 Traning Loss: tensor(0.0422)\n",
      "13155 Traning Loss: tensor(0.0437)\n",
      "13156 Traning Loss: tensor(0.0437)\n",
      "13157 Traning Loss: tensor(0.0427)\n",
      "13158 Traning Loss: tensor(0.0425)\n",
      "13159 Traning Loss: tensor(0.0426)\n",
      "13160 Traning Loss: tensor(0.0422)\n",
      "13161 Traning Loss: tensor(0.0414)\n",
      "13162 Traning Loss: tensor(0.0422)\n",
      "13163 Traning Loss: tensor(0.0442)\n",
      "13164 Traning Loss: tensor(0.0410)\n",
      "13165 Traning Loss: tensor(0.0421)\n",
      "13166 Traning Loss: tensor(0.0423)\n",
      "13167 Traning Loss: tensor(0.0414)\n",
      "13168 Traning Loss: tensor(0.0424)\n",
      "13169 Traning Loss: tensor(0.0414)\n",
      "13170 Traning Loss: tensor(0.0423)\n",
      "13171 Traning Loss: tensor(0.0424)\n",
      "13172 Traning Loss: tensor(0.0421)\n",
      "13173 Traning Loss: tensor(0.0422)\n",
      "13174 Traning Loss: tensor(0.0434)\n",
      "13175 Traning Loss: tensor(0.0420)\n",
      "13176 Traning Loss: tensor(0.0421)\n",
      "13177 Traning Loss: tensor(0.0418)\n",
      "13178 Traning Loss: tensor(0.0425)\n",
      "13179 Traning Loss: tensor(0.0416)\n",
      "13180 Traning Loss: tensor(0.0405)\n",
      "13181 Traning Loss: tensor(0.0432)\n",
      "13182 Traning Loss: tensor(0.0429)\n",
      "13183 Traning Loss: tensor(0.0422)\n",
      "13184 Traning Loss: tensor(0.0427)\n",
      "13185 Traning Loss: tensor(0.0416)\n",
      "13186 Traning Loss: tensor(0.0423)\n",
      "13187 Traning Loss: tensor(0.0407)\n",
      "13188 Traning Loss: tensor(0.0408)\n",
      "13189 Traning Loss: tensor(0.0424)\n",
      "13190 Traning Loss: tensor(0.0425)\n",
      "13191 Traning Loss: tensor(0.0419)\n",
      "13192 Traning Loss: tensor(0.0414)\n",
      "13193 Traning Loss: tensor(0.0413)\n",
      "13194 Traning Loss: tensor(0.0424)\n",
      "13195 Traning Loss: tensor(0.0418)\n",
      "13196 Traning Loss: tensor(0.0415)\n",
      "13197 Traning Loss: tensor(0.0422)\n",
      "13198 Traning Loss: tensor(0.0427)\n",
      "13199 Traning Loss: tensor(0.0432)\n",
      "13200 Traning Loss: tensor(0.0420)\n",
      "13201 Traning Loss: tensor(0.0414)\n",
      "13202 Traning Loss: tensor(0.0419)\n",
      "13203 Traning Loss: tensor(0.0422)\n",
      "13204 Traning Loss: tensor(0.0416)\n",
      "13205 Traning Loss: tensor(0.0422)\n",
      "13206 Traning Loss: tensor(0.0423)\n",
      "13207 Traning Loss: tensor(0.0413)\n",
      "13208 Traning Loss: tensor(0.0426)\n",
      "13209 Traning Loss: tensor(0.0419)\n",
      "13210 Traning Loss: tensor(0.0433)\n",
      "13211 Traning Loss: tensor(0.0420)\n",
      "13212 Traning Loss: tensor(0.0406)\n",
      "13213 Traning Loss: tensor(0.0420)\n",
      "13214 Traning Loss: tensor(0.0412)\n",
      "13215 Traning Loss: tensor(0.0427)\n",
      "13216 Traning Loss: tensor(0.0418)\n",
      "13217 Traning Loss: tensor(0.0413)\n",
      "13218 Traning Loss: tensor(0.0422)\n",
      "13219 Traning Loss: tensor(0.0429)\n",
      "13220 Traning Loss: tensor(0.0434)\n",
      "13221 Traning Loss: tensor(0.0417)\n",
      "13222 Traning Loss: tensor(0.0416)\n",
      "13223 Traning Loss: tensor(0.0419)\n",
      "13224 Traning Loss: tensor(0.0420)\n",
      "13225 Traning Loss: tensor(0.0414)\n",
      "13226 Traning Loss: tensor(0.0422)\n",
      "13227 Traning Loss: tensor(0.0421)\n",
      "13228 Traning Loss: tensor(0.0428)\n",
      "13229 Traning Loss: tensor(0.0416)\n",
      "13230 Traning Loss: tensor(0.0422)\n",
      "13231 Traning Loss: tensor(0.0414)\n",
      "13232 Traning Loss: tensor(0.0419)\n",
      "13233 Traning Loss: tensor(0.0420)\n",
      "13234 Traning Loss: tensor(0.0418)\n",
      "13235 Traning Loss: tensor(0.0423)\n",
      "13236 Traning Loss: tensor(0.0428)\n",
      "13237 Traning Loss: tensor(0.0410)\n",
      "13238 Traning Loss: tensor(0.0417)\n",
      "13239 Traning Loss: tensor(0.0408)\n",
      "13240 Traning Loss: tensor(0.0413)\n",
      "13241 Traning Loss: tensor(0.0411)\n",
      "13242 Traning Loss: tensor(0.0426)\n",
      "13243 Traning Loss: tensor(0.0419)\n",
      "13244 Traning Loss: tensor(0.0422)\n",
      "13245 Traning Loss: tensor(0.0423)\n",
      "13246 Traning Loss: tensor(0.0415)\n",
      "13247 Traning Loss: tensor(0.0413)\n",
      "13248 Traning Loss: tensor(0.0418)\n",
      "13249 Traning Loss: tensor(0.0410)\n",
      "13250 Traning Loss: tensor(0.0417)\n",
      "13251 Traning Loss: tensor(0.0405)\n",
      "13252 Traning Loss: tensor(0.0414)\n",
      "13253 Traning Loss: tensor(0.0411)\n",
      "13254 Traning Loss: tensor(0.0416)\n",
      "13255 Traning Loss: tensor(0.0408)\n",
      "13256 Traning Loss: tensor(0.0421)\n",
      "13257 Traning Loss: tensor(0.0412)\n",
      "13258 Traning Loss: tensor(0.0410)\n",
      "13259 Traning Loss: tensor(0.0418)\n",
      "13260 Traning Loss: tensor(0.0408)\n",
      "13261 Traning Loss: tensor(0.0428)\n",
      "13262 Traning Loss: tensor(0.0403)\n",
      "13263 Traning Loss: tensor(0.0414)\n",
      "13264 Traning Loss: tensor(0.0419)\n",
      "13265 Traning Loss: tensor(0.0409)\n",
      "13266 Traning Loss: tensor(0.0401)\n",
      "13267 Traning Loss: tensor(0.0418)\n",
      "13268 Traning Loss: tensor(0.0412)\n",
      "13269 Traning Loss: tensor(0.0421)\n",
      "13270 Traning Loss: tensor(0.0407)\n",
      "13271 Traning Loss: tensor(0.0398)\n",
      "13272 Traning Loss: tensor(0.0410)\n",
      "13273 Traning Loss: tensor(0.0414)\n",
      "13274 Traning Loss: tensor(0.0411)\n",
      "13275 Traning Loss: tensor(0.0405)\n",
      "13276 Traning Loss: tensor(0.0415)\n",
      "13277 Traning Loss: tensor(0.0415)\n",
      "13278 Traning Loss: tensor(0.0426)\n",
      "13279 Traning Loss: tensor(0.0416)\n",
      "13280 Traning Loss: tensor(0.0428)\n",
      "13281 Traning Loss: tensor(0.0423)\n",
      "13282 Traning Loss: tensor(0.0413)\n",
      "13283 Traning Loss: tensor(0.0410)\n",
      "13284 Traning Loss: tensor(0.0422)\n",
      "13285 Traning Loss: tensor(0.0401)\n",
      "13286 Traning Loss: tensor(0.0409)\n",
      "13287 Traning Loss: tensor(0.0430)\n",
      "13288 Traning Loss: tensor(0.0417)\n",
      "13289 Traning Loss: tensor(0.0408)\n",
      "13290 Traning Loss: tensor(0.0409)\n",
      "13291 Traning Loss: tensor(0.0420)\n",
      "13292 Traning Loss: tensor(0.0420)\n",
      "13293 Traning Loss: tensor(0.0404)\n",
      "13294 Traning Loss: tensor(0.0421)\n",
      "13295 Traning Loss: tensor(0.0424)\n",
      "13296 Traning Loss: tensor(0.0411)\n",
      "13297 Traning Loss: tensor(0.0415)\n",
      "13298 Traning Loss: tensor(0.0431)\n",
      "13299 Traning Loss: tensor(0.0416)\n",
      "13300 Traning Loss: tensor(0.0404)\n",
      "13301 Traning Loss: tensor(0.0410)\n",
      "13302 Traning Loss: tensor(0.0424)\n",
      "13303 Traning Loss: tensor(0.0405)\n",
      "13304 Traning Loss: tensor(0.0401)\n",
      "13305 Traning Loss: tensor(0.0418)\n",
      "13306 Traning Loss: tensor(0.0401)\n",
      "13307 Traning Loss: tensor(0.0415)\n",
      "13308 Traning Loss: tensor(0.0401)\n",
      "13309 Traning Loss: tensor(0.0420)\n",
      "13310 Traning Loss: tensor(0.0406)\n",
      "13311 Traning Loss: tensor(0.0422)\n",
      "13312 Traning Loss: tensor(0.0403)\n",
      "13313 Traning Loss: tensor(0.0401)\n",
      "13314 Traning Loss: tensor(0.0394)\n",
      "13315 Traning Loss: tensor(0.0403)\n",
      "13316 Traning Loss: tensor(0.0423)\n",
      "13317 Traning Loss: tensor(0.0407)\n",
      "13318 Traning Loss: tensor(0.0407)\n",
      "13319 Traning Loss: tensor(0.0419)\n",
      "13320 Traning Loss: tensor(0.0412)\n",
      "13321 Traning Loss: tensor(0.0418)\n",
      "13322 Traning Loss: tensor(0.0407)\n",
      "13323 Traning Loss: tensor(0.0396)\n",
      "13324 Traning Loss: tensor(0.0404)\n",
      "13325 Traning Loss: tensor(0.0412)\n",
      "13326 Traning Loss: tensor(0.0411)\n",
      "13327 Traning Loss: tensor(0.0403)\n",
      "13328 Traning Loss: tensor(0.0413)\n",
      "13329 Traning Loss: tensor(0.0408)\n",
      "13330 Traning Loss: tensor(0.0400)\n",
      "13331 Traning Loss: tensor(0.0410)\n",
      "13332 Traning Loss: tensor(0.0402)\n",
      "13333 Traning Loss: tensor(0.0407)\n",
      "13334 Traning Loss: tensor(0.0403)\n",
      "13335 Traning Loss: tensor(0.0429)\n",
      "13336 Traning Loss: tensor(0.0414)\n",
      "13337 Traning Loss: tensor(0.0412)\n",
      "13338 Traning Loss: tensor(0.0397)\n",
      "13339 Traning Loss: tensor(0.0417)\n",
      "13340 Traning Loss: tensor(0.0406)\n",
      "13341 Traning Loss: tensor(0.0395)\n",
      "13342 Traning Loss: tensor(0.0397)\n",
      "13343 Traning Loss: tensor(0.0396)\n",
      "13344 Traning Loss: tensor(0.0393)\n",
      "13345 Traning Loss: tensor(0.0397)\n",
      "13346 Traning Loss: tensor(0.0395)\n",
      "13347 Traning Loss: tensor(0.0408)\n",
      "13348 Traning Loss: tensor(0.0402)\n",
      "13349 Traning Loss: tensor(0.0409)\n",
      "13350 Traning Loss: tensor(0.0406)\n",
      "13351 Traning Loss: tensor(0.0399)\n",
      "13352 Traning Loss: tensor(0.0392)\n",
      "13353 Traning Loss: tensor(0.0401)\n",
      "13354 Traning Loss: tensor(0.0398)\n",
      "13355 Traning Loss: tensor(0.0422)\n",
      "13356 Traning Loss: tensor(0.0420)\n",
      "13357 Traning Loss: tensor(0.0400)\n",
      "13358 Traning Loss: tensor(0.0403)\n",
      "13359 Traning Loss: tensor(0.0407)\n",
      "13360 Traning Loss: tensor(0.0382)\n",
      "13361 Traning Loss: tensor(0.0401)\n",
      "13362 Traning Loss: tensor(0.0410)\n",
      "13363 Traning Loss: tensor(0.0398)\n",
      "13364 Traning Loss: tensor(0.0396)\n",
      "13365 Traning Loss: tensor(0.0399)\n",
      "13366 Traning Loss: tensor(0.0416)\n",
      "13367 Traning Loss: tensor(0.0406)\n",
      "13368 Traning Loss: tensor(0.0399)\n",
      "13369 Traning Loss: tensor(0.0427)\n",
      "13370 Traning Loss: tensor(0.0401)\n",
      "13371 Traning Loss: tensor(0.0412)\n",
      "13372 Traning Loss: tensor(0.0398)\n",
      "13373 Traning Loss: tensor(0.0405)\n",
      "13374 Traning Loss: tensor(0.0396)\n",
      "13375 Traning Loss: tensor(0.0403)\n",
      "13376 Traning Loss: tensor(0.0399)\n",
      "13377 Traning Loss: tensor(0.0410)\n",
      "13378 Traning Loss: tensor(0.0401)\n",
      "13379 Traning Loss: tensor(0.0414)\n",
      "13380 Traning Loss: tensor(0.0415)\n",
      "13381 Traning Loss: tensor(0.0405)\n",
      "13382 Traning Loss: tensor(0.0389)\n",
      "13383 Traning Loss: tensor(0.0401)\n",
      "13384 Traning Loss: tensor(0.0403)\n",
      "13385 Traning Loss: tensor(0.0402)\n",
      "13386 Traning Loss: tensor(0.0395)\n",
      "13387 Traning Loss: tensor(0.0404)\n",
      "13388 Traning Loss: tensor(0.0400)\n",
      "13389 Traning Loss: tensor(0.0411)\n",
      "13390 Traning Loss: tensor(0.0400)\n",
      "13391 Traning Loss: tensor(0.0424)\n",
      "13392 Traning Loss: tensor(0.0399)\n",
      "13393 Traning Loss: tensor(0.0412)\n",
      "13394 Traning Loss: tensor(0.0392)\n",
      "13395 Traning Loss: tensor(0.0392)\n",
      "13396 Traning Loss: tensor(0.0406)\n",
      "13397 Traning Loss: tensor(0.0411)\n",
      "13398 Traning Loss: tensor(0.0401)\n",
      "13399 Traning Loss: tensor(0.0390)\n",
      "13400 Traning Loss: tensor(0.0387)\n",
      "13401 Traning Loss: tensor(0.0403)\n",
      "13402 Traning Loss: tensor(0.0400)\n",
      "13403 Traning Loss: tensor(0.0404)\n",
      "13404 Traning Loss: tensor(0.0402)\n",
      "13405 Traning Loss: tensor(0.0400)\n",
      "13406 Traning Loss: tensor(0.0392)\n",
      "13407 Traning Loss: tensor(0.0396)\n",
      "13408 Traning Loss: tensor(0.0414)\n",
      "13409 Traning Loss: tensor(0.0396)\n",
      "13410 Traning Loss: tensor(0.0382)\n",
      "13411 Traning Loss: tensor(0.0400)\n",
      "13412 Traning Loss: tensor(0.0397)\n",
      "13413 Traning Loss: tensor(0.0396)\n",
      "13414 Traning Loss: tensor(0.0410)\n",
      "13415 Traning Loss: tensor(0.0395)\n",
      "13416 Traning Loss: tensor(0.0410)\n",
      "13417 Traning Loss: tensor(0.0387)\n",
      "13418 Traning Loss: tensor(0.0401)\n",
      "13419 Traning Loss: tensor(0.0394)\n",
      "13420 Traning Loss: tensor(0.0402)\n",
      "13421 Traning Loss: tensor(0.0388)\n",
      "13422 Traning Loss: tensor(0.0397)\n",
      "13423 Traning Loss: tensor(0.0396)\n",
      "13424 Traning Loss: tensor(0.0383)\n",
      "13425 Traning Loss: tensor(0.0390)\n",
      "13426 Traning Loss: tensor(0.0397)\n",
      "13427 Traning Loss: tensor(0.0405)\n",
      "13428 Traning Loss: tensor(0.0394)\n",
      "13429 Traning Loss: tensor(0.0384)\n",
      "13430 Traning Loss: tensor(0.0400)\n",
      "13431 Traning Loss: tensor(0.0388)\n",
      "13432 Traning Loss: tensor(0.0397)\n",
      "13433 Traning Loss: tensor(0.0391)\n",
      "13434 Traning Loss: tensor(0.0396)\n",
      "13435 Traning Loss: tensor(0.0403)\n",
      "13436 Traning Loss: tensor(0.0411)\n",
      "13437 Traning Loss: tensor(0.0386)\n",
      "13438 Traning Loss: tensor(0.0389)\n",
      "13439 Traning Loss: tensor(0.0390)\n",
      "13440 Traning Loss: tensor(0.0386)\n",
      "13441 Traning Loss: tensor(0.0399)\n",
      "13442 Traning Loss: tensor(0.0388)\n",
      "13443 Traning Loss: tensor(0.0403)\n",
      "13444 Traning Loss: tensor(0.0384)\n",
      "13445 Traning Loss: tensor(0.0400)\n",
      "13446 Traning Loss: tensor(0.0388)\n",
      "13447 Traning Loss: tensor(0.0403)\n",
      "13448 Traning Loss: tensor(0.0382)\n",
      "13449 Traning Loss: tensor(0.0407)\n",
      "13450 Traning Loss: tensor(0.0388)\n",
      "13451 Traning Loss: tensor(0.0388)\n",
      "13452 Traning Loss: tensor(0.0416)\n",
      "13453 Traning Loss: tensor(0.0407)\n",
      "13454 Traning Loss: tensor(0.0388)\n",
      "13455 Traning Loss: tensor(0.0399)\n",
      "13456 Traning Loss: tensor(0.0402)\n",
      "13457 Traning Loss: tensor(0.0380)\n",
      "13458 Traning Loss: tensor(0.0390)\n",
      "13459 Traning Loss: tensor(0.0395)\n",
      "13460 Traning Loss: tensor(0.0397)\n",
      "13461 Traning Loss: tensor(0.0394)\n",
      "13462 Traning Loss: tensor(0.0391)\n",
      "13463 Traning Loss: tensor(0.0402)\n",
      "13464 Traning Loss: tensor(0.0411)\n",
      "13465 Traning Loss: tensor(0.0385)\n",
      "13466 Traning Loss: tensor(0.0386)\n",
      "13467 Traning Loss: tensor(0.0393)\n",
      "13468 Traning Loss: tensor(0.0404)\n",
      "13469 Traning Loss: tensor(0.0390)\n",
      "13470 Traning Loss: tensor(0.0386)\n",
      "13471 Traning Loss: tensor(0.0405)\n",
      "13472 Traning Loss: tensor(0.0403)\n",
      "13473 Traning Loss: tensor(0.0389)\n",
      "13474 Traning Loss: tensor(0.0405)\n",
      "13475 Traning Loss: tensor(0.0428)\n",
      "13476 Traning Loss: tensor(0.0398)\n",
      "13477 Traning Loss: tensor(0.0395)\n",
      "13478 Traning Loss: tensor(0.0398)\n",
      "13479 Traning Loss: tensor(0.0402)\n",
      "13480 Traning Loss: tensor(0.0388)\n",
      "13481 Traning Loss: tensor(0.0390)\n",
      "13482 Traning Loss: tensor(0.0394)\n",
      "13483 Traning Loss: tensor(0.0386)\n",
      "13484 Traning Loss: tensor(0.0393)\n",
      "13485 Traning Loss: tensor(0.0394)\n",
      "13486 Traning Loss: tensor(0.0387)\n",
      "13487 Traning Loss: tensor(0.0396)\n",
      "13488 Traning Loss: tensor(0.0392)\n",
      "13489 Traning Loss: tensor(0.0385)\n",
      "13490 Traning Loss: tensor(0.0385)\n",
      "13491 Traning Loss: tensor(0.0397)\n",
      "13492 Traning Loss: tensor(0.0397)\n",
      "13493 Traning Loss: tensor(0.0397)\n",
      "13494 Traning Loss: tensor(0.0390)\n",
      "13495 Traning Loss: tensor(0.0385)\n",
      "13496 Traning Loss: tensor(0.0397)\n",
      "13497 Traning Loss: tensor(0.0380)\n",
      "13498 Traning Loss: tensor(0.0379)\n",
      "13499 Traning Loss: tensor(0.0408)\n",
      "13500 Traning Loss: tensor(0.0378)\n",
      "13501 Traning Loss: tensor(0.0390)\n",
      "13502 Traning Loss: tensor(0.0384)\n",
      "13503 Traning Loss: tensor(0.0395)\n",
      "13504 Traning Loss: tensor(0.0384)\n",
      "13505 Traning Loss: tensor(0.0392)\n",
      "13506 Traning Loss: tensor(0.0397)\n",
      "13507 Traning Loss: tensor(0.0397)\n",
      "13508 Traning Loss: tensor(0.0381)\n",
      "13509 Traning Loss: tensor(0.0377)\n",
      "13510 Traning Loss: tensor(0.0379)\n",
      "13511 Traning Loss: tensor(0.0372)\n",
      "13512 Traning Loss: tensor(0.0390)\n",
      "13513 Traning Loss: tensor(0.0407)\n",
      "13514 Traning Loss: tensor(0.0394)\n",
      "13515 Traning Loss: tensor(0.0388)\n",
      "13516 Traning Loss: tensor(0.0390)\n",
      "13517 Traning Loss: tensor(0.0393)\n",
      "13518 Traning Loss: tensor(0.0387)\n",
      "13519 Traning Loss: tensor(0.0395)\n",
      "13520 Traning Loss: tensor(0.0395)\n",
      "13521 Traning Loss: tensor(0.0393)\n",
      "13522 Traning Loss: tensor(0.0387)\n",
      "13523 Traning Loss: tensor(0.0393)\n",
      "13524 Traning Loss: tensor(0.0410)\n",
      "13525 Traning Loss: tensor(0.0391)\n",
      "13526 Traning Loss: tensor(0.0389)\n",
      "13527 Traning Loss: tensor(0.0387)\n",
      "13528 Traning Loss: tensor(0.0397)\n",
      "13529 Traning Loss: tensor(0.0381)\n",
      "13530 Traning Loss: tensor(0.0383)\n",
      "13531 Traning Loss: tensor(0.0380)\n",
      "13532 Traning Loss: tensor(0.0379)\n",
      "13533 Traning Loss: tensor(0.0380)\n",
      "13534 Traning Loss: tensor(0.0394)\n",
      "13535 Traning Loss: tensor(0.0381)\n",
      "13536 Traning Loss: tensor(0.0379)\n",
      "13537 Traning Loss: tensor(0.0402)\n",
      "13538 Traning Loss: tensor(0.0394)\n",
      "13539 Traning Loss: tensor(0.0388)\n",
      "13540 Traning Loss: tensor(0.0391)\n",
      "13541 Traning Loss: tensor(0.0395)\n",
      "13542 Traning Loss: tensor(0.0382)\n",
      "13543 Traning Loss: tensor(0.0391)\n",
      "13544 Traning Loss: tensor(0.0401)\n",
      "13545 Traning Loss: tensor(0.0395)\n",
      "13546 Traning Loss: tensor(0.0390)\n",
      "13547 Traning Loss: tensor(0.0380)\n",
      "13548 Traning Loss: tensor(0.0387)\n",
      "13549 Traning Loss: tensor(0.0375)\n",
      "13550 Traning Loss: tensor(0.0371)\n",
      "13551 Traning Loss: tensor(0.0390)\n",
      "13552 Traning Loss: tensor(0.0377)\n",
      "13553 Traning Loss: tensor(0.0384)\n",
      "13554 Traning Loss: tensor(0.0388)\n",
      "13555 Traning Loss: tensor(0.0393)\n",
      "13556 Traning Loss: tensor(0.0381)\n",
      "13557 Traning Loss: tensor(0.0394)\n",
      "13558 Traning Loss: tensor(0.0380)\n",
      "13559 Traning Loss: tensor(0.0385)\n",
      "13560 Traning Loss: tensor(0.0391)\n",
      "13561 Traning Loss: tensor(0.0371)\n",
      "13562 Traning Loss: tensor(0.0389)\n",
      "13563 Traning Loss: tensor(0.0385)\n",
      "13564 Traning Loss: tensor(0.0383)\n",
      "13565 Traning Loss: tensor(0.0386)\n",
      "13566 Traning Loss: tensor(0.0380)\n",
      "13567 Traning Loss: tensor(0.0382)\n",
      "13568 Traning Loss: tensor(0.0369)\n",
      "13569 Traning Loss: tensor(0.0377)\n",
      "13570 Traning Loss: tensor(0.0379)\n",
      "13571 Traning Loss: tensor(0.0377)\n",
      "13572 Traning Loss: tensor(0.0379)\n",
      "13573 Traning Loss: tensor(0.0386)\n",
      "13574 Traning Loss: tensor(0.0379)\n",
      "13575 Traning Loss: tensor(0.0392)\n",
      "13576 Traning Loss: tensor(0.0374)\n",
      "13577 Traning Loss: tensor(0.0381)\n",
      "13578 Traning Loss: tensor(0.0386)\n",
      "13579 Traning Loss: tensor(0.0386)\n",
      "13580 Traning Loss: tensor(0.0398)\n",
      "13581 Traning Loss: tensor(0.0383)\n",
      "13582 Traning Loss: tensor(0.0393)\n",
      "13583 Traning Loss: tensor(0.0377)\n",
      "13584 Traning Loss: tensor(0.0385)\n",
      "13585 Traning Loss: tensor(0.0379)\n",
      "13586 Traning Loss: tensor(0.0399)\n",
      "13587 Traning Loss: tensor(0.0392)\n",
      "13588 Traning Loss: tensor(0.0376)\n",
      "13589 Traning Loss: tensor(0.0389)\n",
      "13590 Traning Loss: tensor(0.0390)\n",
      "13591 Traning Loss: tensor(0.0380)\n",
      "13592 Traning Loss: tensor(0.0369)\n",
      "13593 Traning Loss: tensor(0.0380)\n",
      "13594 Traning Loss: tensor(0.0391)\n",
      "13595 Traning Loss: tensor(0.0378)\n",
      "13596 Traning Loss: tensor(0.0383)\n",
      "13597 Traning Loss: tensor(0.0390)\n",
      "13598 Traning Loss: tensor(0.0388)\n",
      "13599 Traning Loss: tensor(0.0412)\n",
      "13600 Traning Loss: tensor(0.0387)\n",
      "13601 Traning Loss: tensor(0.0386)\n",
      "13602 Traning Loss: tensor(0.0385)\n",
      "13603 Traning Loss: tensor(0.0380)\n",
      "13604 Traning Loss: tensor(0.0387)\n",
      "13605 Traning Loss: tensor(0.0372)\n",
      "13606 Traning Loss: tensor(0.0385)\n",
      "13607 Traning Loss: tensor(0.0374)\n",
      "13608 Traning Loss: tensor(0.0385)\n",
      "13609 Traning Loss: tensor(0.0375)\n",
      "13610 Traning Loss: tensor(0.0403)\n",
      "13611 Traning Loss: tensor(0.0386)\n",
      "13612 Traning Loss: tensor(0.0381)\n",
      "13613 Traning Loss: tensor(0.0379)\n",
      "13614 Traning Loss: tensor(0.0384)\n",
      "13615 Traning Loss: tensor(0.0381)\n",
      "13616 Traning Loss: tensor(0.0385)\n",
      "13617 Traning Loss: tensor(0.0386)\n",
      "13618 Traning Loss: tensor(0.0378)\n",
      "13619 Traning Loss: tensor(0.0393)\n",
      "13620 Traning Loss: tensor(0.0376)\n",
      "13621 Traning Loss: tensor(0.0375)\n",
      "13622 Traning Loss: tensor(0.0393)\n",
      "13623 Traning Loss: tensor(0.0377)\n",
      "13624 Traning Loss: tensor(0.0372)\n",
      "13625 Traning Loss: tensor(0.0370)\n",
      "13626 Traning Loss: tensor(0.0378)\n",
      "13627 Traning Loss: tensor(0.0381)\n",
      "13628 Traning Loss: tensor(0.0387)\n",
      "13629 Traning Loss: tensor(0.0379)\n",
      "13630 Traning Loss: tensor(0.0394)\n",
      "13631 Traning Loss: tensor(0.0377)\n",
      "13632 Traning Loss: tensor(0.0371)\n",
      "13633 Traning Loss: tensor(0.0375)\n",
      "13634 Traning Loss: tensor(0.0373)\n",
      "13635 Traning Loss: tensor(0.0381)\n",
      "13636 Traning Loss: tensor(0.0394)\n",
      "13637 Traning Loss: tensor(0.0380)\n",
      "13638 Traning Loss: tensor(0.0382)\n",
      "13639 Traning Loss: tensor(0.0381)\n",
      "13640 Traning Loss: tensor(0.0387)\n",
      "13641 Traning Loss: tensor(0.0379)\n",
      "13642 Traning Loss: tensor(0.0367)\n",
      "13643 Traning Loss: tensor(0.0376)\n",
      "13644 Traning Loss: tensor(0.0377)\n",
      "13645 Traning Loss: tensor(0.0371)\n",
      "13646 Traning Loss: tensor(0.0374)\n",
      "13647 Traning Loss: tensor(0.0383)\n",
      "13648 Traning Loss: tensor(0.0379)\n",
      "13649 Traning Loss: tensor(0.0371)\n",
      "13650 Traning Loss: tensor(0.0369)\n",
      "13651 Traning Loss: tensor(0.0379)\n",
      "13652 Traning Loss: tensor(0.0387)\n",
      "13653 Traning Loss: tensor(0.0377)\n",
      "13654 Traning Loss: tensor(0.0373)\n",
      "13655 Traning Loss: tensor(0.0382)\n",
      "13656 Traning Loss: tensor(0.0379)\n",
      "13657 Traning Loss: tensor(0.0396)\n",
      "13658 Traning Loss: tensor(0.0369)\n",
      "13659 Traning Loss: tensor(0.0379)\n",
      "13660 Traning Loss: tensor(0.0382)\n",
      "13661 Traning Loss: tensor(0.0407)\n",
      "13662 Traning Loss: tensor(0.0383)\n",
      "13663 Traning Loss: tensor(0.0382)\n",
      "13664 Traning Loss: tensor(0.0382)\n",
      "13665 Traning Loss: tensor(0.0384)\n",
      "13666 Traning Loss: tensor(0.0390)\n",
      "13667 Traning Loss: tensor(0.0372)\n",
      "13668 Traning Loss: tensor(0.0378)\n",
      "13669 Traning Loss: tensor(0.0378)\n",
      "13670 Traning Loss: tensor(0.0356)\n",
      "13671 Traning Loss: tensor(0.0368)\n",
      "13672 Traning Loss: tensor(0.0389)\n",
      "13673 Traning Loss: tensor(0.0380)\n",
      "13674 Traning Loss: tensor(0.0395)\n",
      "13675 Traning Loss: tensor(0.0361)\n",
      "13676 Traning Loss: tensor(0.0374)\n",
      "13677 Traning Loss: tensor(0.0375)\n",
      "13678 Traning Loss: tensor(0.0363)\n",
      "13679 Traning Loss: tensor(0.0377)\n",
      "13680 Traning Loss: tensor(0.0374)\n",
      "13681 Traning Loss: tensor(0.0394)\n",
      "13682 Traning Loss: tensor(0.0393)\n",
      "13683 Traning Loss: tensor(0.0368)\n",
      "13684 Traning Loss: tensor(0.0374)\n",
      "13685 Traning Loss: tensor(0.0375)\n",
      "13686 Traning Loss: tensor(0.0369)\n",
      "13687 Traning Loss: tensor(0.0394)\n",
      "13688 Traning Loss: tensor(0.0382)\n",
      "13689 Traning Loss: tensor(0.0375)\n",
      "13690 Traning Loss: tensor(0.0372)\n",
      "13691 Traning Loss: tensor(0.0362)\n",
      "13692 Traning Loss: tensor(0.0372)\n",
      "13693 Traning Loss: tensor(0.0371)\n",
      "13694 Traning Loss: tensor(0.0369)\n",
      "13695 Traning Loss: tensor(0.0371)\n",
      "13696 Traning Loss: tensor(0.0383)\n",
      "13697 Traning Loss: tensor(0.0374)\n",
      "13698 Traning Loss: tensor(0.0376)\n",
      "13699 Traning Loss: tensor(0.0370)\n",
      "13700 Traning Loss: tensor(0.0373)\n",
      "13701 Traning Loss: tensor(0.0374)\n",
      "13702 Traning Loss: tensor(0.0376)\n",
      "13703 Traning Loss: tensor(0.0376)\n",
      "13704 Traning Loss: tensor(0.0359)\n",
      "13705 Traning Loss: tensor(0.0376)\n",
      "13706 Traning Loss: tensor(0.0382)\n",
      "13707 Traning Loss: tensor(0.0390)\n",
      "13708 Traning Loss: tensor(0.0373)\n",
      "13709 Traning Loss: tensor(0.0381)\n",
      "13710 Traning Loss: tensor(0.0381)\n",
      "13711 Traning Loss: tensor(0.0383)\n",
      "13712 Traning Loss: tensor(0.0387)\n",
      "13713 Traning Loss: tensor(0.0379)\n",
      "13714 Traning Loss: tensor(0.0384)\n",
      "13715 Traning Loss: tensor(0.0379)\n",
      "13716 Traning Loss: tensor(0.0384)\n",
      "13717 Traning Loss: tensor(0.0380)\n",
      "13718 Traning Loss: tensor(0.0403)\n",
      "13719 Traning Loss: tensor(0.0385)\n",
      "13720 Traning Loss: tensor(0.0370)\n",
      "13721 Traning Loss: tensor(0.0365)\n",
      "13722 Traning Loss: tensor(0.0373)\n",
      "13723 Traning Loss: tensor(0.0361)\n",
      "13724 Traning Loss: tensor(0.0366)\n",
      "13725 Traning Loss: tensor(0.0361)\n",
      "13726 Traning Loss: tensor(0.0372)\n",
      "13727 Traning Loss: tensor(0.0382)\n",
      "13728 Traning Loss: tensor(0.0376)\n",
      "13729 Traning Loss: tensor(0.0366)\n",
      "13730 Traning Loss: tensor(0.0368)\n",
      "13731 Traning Loss: tensor(0.0355)\n",
      "13732 Traning Loss: tensor(0.0374)\n",
      "13733 Traning Loss: tensor(0.0368)\n",
      "13734 Traning Loss: tensor(0.0374)\n",
      "13735 Traning Loss: tensor(0.0369)\n",
      "13736 Traning Loss: tensor(0.0365)\n",
      "13737 Traning Loss: tensor(0.0372)\n",
      "13738 Traning Loss: tensor(0.0378)\n",
      "13739 Traning Loss: tensor(0.0370)\n",
      "13740 Traning Loss: tensor(0.0380)\n",
      "13741 Traning Loss: tensor(0.0363)\n",
      "13742 Traning Loss: tensor(0.0366)\n",
      "13743 Traning Loss: tensor(0.0366)\n",
      "13744 Traning Loss: tensor(0.0379)\n",
      "13745 Traning Loss: tensor(0.0369)\n",
      "13746 Traning Loss: tensor(0.0364)\n",
      "13747 Traning Loss: tensor(0.0382)\n",
      "13748 Traning Loss: tensor(0.0372)\n",
      "13749 Traning Loss: tensor(0.0385)\n",
      "13750 Traning Loss: tensor(0.0377)\n",
      "13751 Traning Loss: tensor(0.0369)\n",
      "13752 Traning Loss: tensor(0.0377)\n",
      "13753 Traning Loss: tensor(0.0385)\n",
      "13754 Traning Loss: tensor(0.0386)\n",
      "13755 Traning Loss: tensor(0.0383)\n",
      "13756 Traning Loss: tensor(0.0385)\n",
      "13757 Traning Loss: tensor(0.0363)\n",
      "13758 Traning Loss: tensor(0.0374)\n",
      "13759 Traning Loss: tensor(0.0380)\n",
      "13760 Traning Loss: tensor(0.0370)\n",
      "13761 Traning Loss: tensor(0.0366)\n",
      "13762 Traning Loss: tensor(0.0361)\n",
      "13763 Traning Loss: tensor(0.0375)\n",
      "13764 Traning Loss: tensor(0.0360)\n",
      "13765 Traning Loss: tensor(0.0366)\n",
      "13766 Traning Loss: tensor(0.0371)\n",
      "13767 Traning Loss: tensor(0.0388)\n",
      "13768 Traning Loss: tensor(0.0380)\n",
      "13769 Traning Loss: tensor(0.0381)\n",
      "13770 Traning Loss: tensor(0.0381)\n",
      "13771 Traning Loss: tensor(0.0364)\n",
      "13772 Traning Loss: tensor(0.0387)\n",
      "13773 Traning Loss: tensor(0.0359)\n",
      "13774 Traning Loss: tensor(0.0372)\n",
      "13775 Traning Loss: tensor(0.0367)\n",
      "13776 Traning Loss: tensor(0.0373)\n",
      "13777 Traning Loss: tensor(0.0375)\n",
      "13778 Traning Loss: tensor(0.0373)\n",
      "13779 Traning Loss: tensor(0.0374)\n",
      "13780 Traning Loss: tensor(0.0375)\n",
      "13781 Traning Loss: tensor(0.0373)\n",
      "13782 Traning Loss: tensor(0.0381)\n",
      "13783 Traning Loss: tensor(0.0365)\n",
      "13784 Traning Loss: tensor(0.0366)\n",
      "13785 Traning Loss: tensor(0.0389)\n",
      "13786 Traning Loss: tensor(0.0374)\n",
      "13787 Traning Loss: tensor(0.0383)\n",
      "13788 Traning Loss: tensor(0.0375)\n",
      "13789 Traning Loss: tensor(0.0367)\n",
      "13790 Traning Loss: tensor(0.0379)\n",
      "13791 Traning Loss: tensor(0.0367)\n",
      "13792 Traning Loss: tensor(0.0363)\n",
      "13793 Traning Loss: tensor(0.0403)\n",
      "13794 Traning Loss: tensor(0.0377)\n",
      "13795 Traning Loss: tensor(0.0358)\n",
      "13796 Traning Loss: tensor(0.0372)\n",
      "13797 Traning Loss: tensor(0.0376)\n",
      "13798 Traning Loss: tensor(0.0374)\n",
      "13799 Traning Loss: tensor(0.0389)\n",
      "13800 Traning Loss: tensor(0.0380)\n",
      "13801 Traning Loss: tensor(0.0358)\n",
      "13802 Traning Loss: tensor(0.0367)\n",
      "13803 Traning Loss: tensor(0.0377)\n",
      "13804 Traning Loss: tensor(0.0372)\n",
      "13805 Traning Loss: tensor(0.0387)\n",
      "13806 Traning Loss: tensor(0.0368)\n",
      "13807 Traning Loss: tensor(0.0365)\n",
      "13808 Traning Loss: tensor(0.0409)\n",
      "13809 Traning Loss: tensor(0.0358)\n",
      "13810 Traning Loss: tensor(0.0358)\n",
      "13811 Traning Loss: tensor(0.0387)\n",
      "13812 Traning Loss: tensor(0.0363)\n",
      "13813 Traning Loss: tensor(0.0354)\n",
      "13814 Traning Loss: tensor(0.0377)\n",
      "13815 Traning Loss: tensor(0.0377)\n",
      "13816 Traning Loss: tensor(0.0367)\n",
      "13817 Traning Loss: tensor(0.0365)\n",
      "13818 Traning Loss: tensor(0.0378)\n",
      "13819 Traning Loss: tensor(0.0384)\n",
      "13820 Traning Loss: tensor(0.0365)\n",
      "13821 Traning Loss: tensor(0.0360)\n",
      "13822 Traning Loss: tensor(0.0383)\n",
      "13823 Traning Loss: tensor(0.0373)\n",
      "13824 Traning Loss: tensor(0.0362)\n",
      "13825 Traning Loss: tensor(0.0372)\n",
      "13826 Traning Loss: tensor(0.0388)\n",
      "13827 Traning Loss: tensor(0.0374)\n",
      "13828 Traning Loss: tensor(0.0370)\n",
      "13829 Traning Loss: tensor(0.0392)\n",
      "13830 Traning Loss: tensor(0.0379)\n",
      "13831 Traning Loss: tensor(0.0361)\n",
      "13832 Traning Loss: tensor(0.0365)\n",
      "13833 Traning Loss: tensor(0.0365)\n",
      "13834 Traning Loss: tensor(0.0377)\n",
      "13835 Traning Loss: tensor(0.0376)\n",
      "13836 Traning Loss: tensor(0.0361)\n",
      "13837 Traning Loss: tensor(0.0379)\n",
      "13838 Traning Loss: tensor(0.0355)\n",
      "13839 Traning Loss: tensor(0.0370)\n",
      "13840 Traning Loss: tensor(0.0364)\n",
      "13841 Traning Loss: tensor(0.0378)\n",
      "13842 Traning Loss: tensor(0.0371)\n",
      "13843 Traning Loss: tensor(0.0369)\n",
      "13844 Traning Loss: tensor(0.0381)\n",
      "13845 Traning Loss: tensor(0.0371)\n",
      "13846 Traning Loss: tensor(0.0374)\n",
      "13847 Traning Loss: tensor(0.0378)\n",
      "13848 Traning Loss: tensor(0.0363)\n",
      "13849 Traning Loss: tensor(0.0366)\n",
      "13850 Traning Loss: tensor(0.0376)\n",
      "13851 Traning Loss: tensor(0.0376)\n",
      "13852 Traning Loss: tensor(0.0369)\n",
      "13853 Traning Loss: tensor(0.0374)\n",
      "13854 Traning Loss: tensor(0.0359)\n",
      "13855 Traning Loss: tensor(0.0363)\n",
      "13856 Traning Loss: tensor(0.0365)\n",
      "13857 Traning Loss: tensor(0.0365)\n",
      "13858 Traning Loss: tensor(0.0388)\n",
      "13859 Traning Loss: tensor(0.0365)\n",
      "13860 Traning Loss: tensor(0.0375)\n",
      "13861 Traning Loss: tensor(0.0366)\n",
      "13862 Traning Loss: tensor(0.0372)\n",
      "13863 Traning Loss: tensor(0.0358)\n",
      "13864 Traning Loss: tensor(0.0361)\n",
      "13865 Traning Loss: tensor(0.0350)\n",
      "13866 Traning Loss: tensor(0.0368)\n",
      "13867 Traning Loss: tensor(0.0371)\n",
      "13868 Traning Loss: tensor(0.0362)\n",
      "13869 Traning Loss: tensor(0.0375)\n",
      "13870 Traning Loss: tensor(0.0360)\n",
      "13871 Traning Loss: tensor(0.0358)\n",
      "13872 Traning Loss: tensor(0.0360)\n",
      "13873 Traning Loss: tensor(0.0376)\n",
      "13874 Traning Loss: tensor(0.0371)\n",
      "13875 Traning Loss: tensor(0.0362)\n",
      "13876 Traning Loss: tensor(0.0353)\n",
      "13877 Traning Loss: tensor(0.0375)\n",
      "13878 Traning Loss: tensor(0.0360)\n",
      "13879 Traning Loss: tensor(0.0358)\n",
      "13880 Traning Loss: tensor(0.0353)\n",
      "13881 Traning Loss: tensor(0.0368)\n",
      "13882 Traning Loss: tensor(0.0364)\n",
      "13883 Traning Loss: tensor(0.0357)\n",
      "13884 Traning Loss: tensor(0.0360)\n",
      "13885 Traning Loss: tensor(0.0365)\n",
      "13886 Traning Loss: tensor(0.0362)\n",
      "13887 Traning Loss: tensor(0.0357)\n",
      "13888 Traning Loss: tensor(0.0357)\n",
      "13889 Traning Loss: tensor(0.0359)\n",
      "13890 Traning Loss: tensor(0.0374)\n",
      "13891 Traning Loss: tensor(0.0355)\n",
      "13892 Traning Loss: tensor(0.0371)\n",
      "13893 Traning Loss: tensor(0.0367)\n",
      "13894 Traning Loss: tensor(0.0375)\n",
      "13895 Traning Loss: tensor(0.0377)\n",
      "13896 Traning Loss: tensor(0.0359)\n",
      "13897 Traning Loss: tensor(0.0352)\n",
      "13898 Traning Loss: tensor(0.0372)\n",
      "13899 Traning Loss: tensor(0.0365)\n",
      "13900 Traning Loss: tensor(0.0357)\n",
      "13901 Traning Loss: tensor(0.0350)\n",
      "13902 Traning Loss: tensor(0.0356)\n",
      "13903 Traning Loss: tensor(0.0345)\n",
      "13904 Traning Loss: tensor(0.0362)\n",
      "13905 Traning Loss: tensor(0.0375)\n",
      "13906 Traning Loss: tensor(0.0357)\n",
      "13907 Traning Loss: tensor(0.0361)\n",
      "13908 Traning Loss: tensor(0.0377)\n",
      "13909 Traning Loss: tensor(0.0352)\n",
      "13910 Traning Loss: tensor(0.0363)\n",
      "13911 Traning Loss: tensor(0.0378)\n",
      "13912 Traning Loss: tensor(0.0369)\n",
      "13913 Traning Loss: tensor(0.0356)\n",
      "13914 Traning Loss: tensor(0.0369)\n",
      "13915 Traning Loss: tensor(0.0354)\n",
      "13916 Traning Loss: tensor(0.0359)\n",
      "13917 Traning Loss: tensor(0.0356)\n",
      "13918 Traning Loss: tensor(0.0347)\n",
      "13919 Traning Loss: tensor(0.0358)\n",
      "13920 Traning Loss: tensor(0.0370)\n",
      "13921 Traning Loss: tensor(0.0359)\n",
      "13922 Traning Loss: tensor(0.0353)\n",
      "13923 Traning Loss: tensor(0.0362)\n",
      "13924 Traning Loss: tensor(0.0379)\n",
      "13925 Traning Loss: tensor(0.0359)\n",
      "13926 Traning Loss: tensor(0.0364)\n",
      "13927 Traning Loss: tensor(0.0367)\n",
      "13928 Traning Loss: tensor(0.0358)\n",
      "13929 Traning Loss: tensor(0.0363)\n",
      "13930 Traning Loss: tensor(0.0356)\n",
      "13931 Traning Loss: tensor(0.0366)\n",
      "13932 Traning Loss: tensor(0.0379)\n",
      "13933 Traning Loss: tensor(0.0357)\n",
      "13934 Traning Loss: tensor(0.0362)\n",
      "13935 Traning Loss: tensor(0.0370)\n",
      "13936 Traning Loss: tensor(0.0363)\n",
      "13937 Traning Loss: tensor(0.0356)\n",
      "13938 Traning Loss: tensor(0.0355)\n",
      "13939 Traning Loss: tensor(0.0377)\n",
      "13940 Traning Loss: tensor(0.0369)\n",
      "13941 Traning Loss: tensor(0.0373)\n",
      "13942 Traning Loss: tensor(0.0369)\n",
      "13943 Traning Loss: tensor(0.0364)\n",
      "13944 Traning Loss: tensor(0.0347)\n",
      "13945 Traning Loss: tensor(0.0367)\n",
      "13946 Traning Loss: tensor(0.0349)\n",
      "13947 Traning Loss: tensor(0.0357)\n",
      "13948 Traning Loss: tensor(0.0357)\n",
      "13949 Traning Loss: tensor(0.0365)\n",
      "13950 Traning Loss: tensor(0.0346)\n",
      "13951 Traning Loss: tensor(0.0352)\n",
      "13952 Traning Loss: tensor(0.0384)\n",
      "13953 Traning Loss: tensor(0.0357)\n",
      "13954 Traning Loss: tensor(0.0361)\n",
      "13955 Traning Loss: tensor(0.0353)\n",
      "13956 Traning Loss: tensor(0.0354)\n",
      "13957 Traning Loss: tensor(0.0347)\n",
      "13958 Traning Loss: tensor(0.0369)\n",
      "13959 Traning Loss: tensor(0.0368)\n",
      "13960 Traning Loss: tensor(0.0357)\n",
      "13961 Traning Loss: tensor(0.0347)\n",
      "13962 Traning Loss: tensor(0.0367)\n",
      "13963 Traning Loss: tensor(0.0345)\n",
      "13964 Traning Loss: tensor(0.0366)\n",
      "13965 Traning Loss: tensor(0.0393)\n",
      "13966 Traning Loss: tensor(0.0350)\n",
      "13967 Traning Loss: tensor(0.0372)\n",
      "13968 Traning Loss: tensor(0.0374)\n",
      "13969 Traning Loss: tensor(0.0354)\n",
      "13970 Traning Loss: tensor(0.0345)\n",
      "13971 Traning Loss: tensor(0.0368)\n",
      "13972 Traning Loss: tensor(0.0362)\n",
      "13973 Traning Loss: tensor(0.0338)\n",
      "13974 Traning Loss: tensor(0.0368)\n",
      "13975 Traning Loss: tensor(0.0367)\n",
      "13976 Traning Loss: tensor(0.0341)\n",
      "13977 Traning Loss: tensor(0.0357)\n",
      "13978 Traning Loss: tensor(0.0366)\n",
      "13979 Traning Loss: tensor(0.0367)\n",
      "13980 Traning Loss: tensor(0.0382)\n",
      "13981 Traning Loss: tensor(0.0357)\n",
      "13982 Traning Loss: tensor(0.0387)\n",
      "13983 Traning Loss: tensor(0.0354)\n",
      "13984 Traning Loss: tensor(0.0364)\n",
      "13985 Traning Loss: tensor(0.0377)\n",
      "13986 Traning Loss: tensor(0.0363)\n",
      "13987 Traning Loss: tensor(0.0374)\n",
      "13988 Traning Loss: tensor(0.0345)\n",
      "13989 Traning Loss: tensor(0.0379)\n",
      "13990 Traning Loss: tensor(0.0362)\n",
      "13991 Traning Loss: tensor(0.0355)\n",
      "13992 Traning Loss: tensor(0.0349)\n",
      "13993 Traning Loss: tensor(0.0361)\n",
      "13994 Traning Loss: tensor(0.0357)\n",
      "13995 Traning Loss: tensor(0.0372)\n",
      "13996 Traning Loss: tensor(0.0361)\n",
      "13997 Traning Loss: tensor(0.0349)\n",
      "13998 Traning Loss: tensor(0.0358)\n",
      "13999 Traning Loss: tensor(0.0361)\n",
      "14000 Traning Loss: tensor(0.0360)\n",
      "14001 Traning Loss: tensor(0.0354)\n",
      "14002 Traning Loss: tensor(0.0377)\n",
      "14003 Traning Loss: tensor(0.0362)\n",
      "14004 Traning Loss: tensor(0.0371)\n",
      "14005 Traning Loss: tensor(0.0343)\n",
      "14006 Traning Loss: tensor(0.0378)\n",
      "14007 Traning Loss: tensor(0.0357)\n",
      "14008 Traning Loss: tensor(0.0349)\n",
      "14009 Traning Loss: tensor(0.0362)\n",
      "14010 Traning Loss: tensor(0.0383)\n",
      "14011 Traning Loss: tensor(0.0373)\n",
      "14012 Traning Loss: tensor(0.0372)\n",
      "14013 Traning Loss: tensor(0.0352)\n",
      "14014 Traning Loss: tensor(0.0349)\n",
      "14015 Traning Loss: tensor(0.0359)\n",
      "14016 Traning Loss: tensor(0.0359)\n",
      "14017 Traning Loss: tensor(0.0361)\n",
      "14018 Traning Loss: tensor(0.0357)\n",
      "14019 Traning Loss: tensor(0.0353)\n",
      "14020 Traning Loss: tensor(0.0362)\n",
      "14021 Traning Loss: tensor(0.0372)\n",
      "14022 Traning Loss: tensor(0.0361)\n",
      "14023 Traning Loss: tensor(0.0342)\n",
      "14024 Traning Loss: tensor(0.0350)\n",
      "14025 Traning Loss: tensor(0.0384)\n",
      "14026 Traning Loss: tensor(0.0362)\n",
      "14027 Traning Loss: tensor(0.0353)\n",
      "14028 Traning Loss: tensor(0.0342)\n",
      "14029 Traning Loss: tensor(0.0349)\n",
      "14030 Traning Loss: tensor(0.0352)\n",
      "14031 Traning Loss: tensor(0.0360)\n",
      "14032 Traning Loss: tensor(0.0358)\n",
      "14033 Traning Loss: tensor(0.0346)\n",
      "14034 Traning Loss: tensor(0.0355)\n",
      "14035 Traning Loss: tensor(0.0348)\n",
      "14036 Traning Loss: tensor(0.0351)\n",
      "14037 Traning Loss: tensor(0.0354)\n",
      "14038 Traning Loss: tensor(0.0360)\n",
      "14039 Traning Loss: tensor(0.0355)\n",
      "14040 Traning Loss: tensor(0.0356)\n",
      "14041 Traning Loss: tensor(0.0361)\n",
      "14042 Traning Loss: tensor(0.0355)\n",
      "14043 Traning Loss: tensor(0.0346)\n",
      "14044 Traning Loss: tensor(0.0351)\n",
      "14045 Traning Loss: tensor(0.0360)\n",
      "14046 Traning Loss: tensor(0.0365)\n",
      "14047 Traning Loss: tensor(0.0359)\n",
      "14048 Traning Loss: tensor(0.0349)\n",
      "14049 Traning Loss: tensor(0.0367)\n",
      "14050 Traning Loss: tensor(0.0365)\n",
      "14051 Traning Loss: tensor(0.0365)\n",
      "14052 Traning Loss: tensor(0.0369)\n",
      "14053 Traning Loss: tensor(0.0359)\n",
      "14054 Traning Loss: tensor(0.0379)\n",
      "14055 Traning Loss: tensor(0.0362)\n",
      "14056 Traning Loss: tensor(0.0361)\n",
      "14057 Traning Loss: tensor(0.0366)\n",
      "14058 Traning Loss: tensor(0.0358)\n",
      "14059 Traning Loss: tensor(0.0370)\n",
      "14060 Traning Loss: tensor(0.0365)\n",
      "14061 Traning Loss: tensor(0.0353)\n",
      "14062 Traning Loss: tensor(0.0346)\n",
      "14063 Traning Loss: tensor(0.0353)\n",
      "14064 Traning Loss: tensor(0.0353)\n",
      "14065 Traning Loss: tensor(0.0360)\n",
      "14066 Traning Loss: tensor(0.0362)\n",
      "14067 Traning Loss: tensor(0.0352)\n",
      "14068 Traning Loss: tensor(0.0361)\n",
      "14069 Traning Loss: tensor(0.0362)\n",
      "14070 Traning Loss: tensor(0.0361)\n",
      "14071 Traning Loss: tensor(0.0350)\n",
      "14072 Traning Loss: tensor(0.0345)\n",
      "14073 Traning Loss: tensor(0.0363)\n",
      "14074 Traning Loss: tensor(0.0359)\n",
      "14075 Traning Loss: tensor(0.0361)\n",
      "14076 Traning Loss: tensor(0.0355)\n",
      "14077 Traning Loss: tensor(0.0350)\n",
      "14078 Traning Loss: tensor(0.0382)\n",
      "14079 Traning Loss: tensor(0.0355)\n",
      "14080 Traning Loss: tensor(0.0369)\n",
      "14081 Traning Loss: tensor(0.0352)\n",
      "14082 Traning Loss: tensor(0.0356)\n",
      "14083 Traning Loss: tensor(0.0345)\n",
      "14084 Traning Loss: tensor(0.0346)\n",
      "14085 Traning Loss: tensor(0.0360)\n",
      "14086 Traning Loss: tensor(0.0354)\n",
      "14087 Traning Loss: tensor(0.0380)\n",
      "14088 Traning Loss: tensor(0.0348)\n",
      "14089 Traning Loss: tensor(0.0353)\n",
      "14090 Traning Loss: tensor(0.0356)\n",
      "14091 Traning Loss: tensor(0.0345)\n",
      "14092 Traning Loss: tensor(0.0349)\n",
      "14093 Traning Loss: tensor(0.0360)\n",
      "14094 Traning Loss: tensor(0.0360)\n",
      "14095 Traning Loss: tensor(0.0371)\n",
      "14096 Traning Loss: tensor(0.0373)\n",
      "14097 Traning Loss: tensor(0.0354)\n",
      "14098 Traning Loss: tensor(0.0360)\n",
      "14099 Traning Loss: tensor(0.0363)\n",
      "14100 Traning Loss: tensor(0.0361)\n",
      "14101 Traning Loss: tensor(0.0376)\n",
      "14102 Traning Loss: tensor(0.0355)\n",
      "14103 Traning Loss: tensor(0.0345)\n",
      "14104 Traning Loss: tensor(0.0345)\n",
      "14105 Traning Loss: tensor(0.0369)\n",
      "14106 Traning Loss: tensor(0.0354)\n",
      "14107 Traning Loss: tensor(0.0349)\n",
      "14108 Traning Loss: tensor(0.0364)\n",
      "14109 Traning Loss: tensor(0.0372)\n",
      "14110 Traning Loss: tensor(0.0337)\n",
      "14111 Traning Loss: tensor(0.0357)\n",
      "14112 Traning Loss: tensor(0.0358)\n",
      "14113 Traning Loss: tensor(0.0354)\n",
      "14114 Traning Loss: tensor(0.0382)\n",
      "14115 Traning Loss: tensor(0.0364)\n",
      "14116 Traning Loss: tensor(0.0362)\n",
      "14117 Traning Loss: tensor(0.0357)\n",
      "14118 Traning Loss: tensor(0.0352)\n",
      "14119 Traning Loss: tensor(0.0361)\n",
      "14120 Traning Loss: tensor(0.0352)\n",
      "14121 Traning Loss: tensor(0.0353)\n",
      "14122 Traning Loss: tensor(0.0355)\n",
      "14123 Traning Loss: tensor(0.0368)\n",
      "14124 Traning Loss: tensor(0.0358)\n",
      "14125 Traning Loss: tensor(0.0351)\n",
      "14126 Traning Loss: tensor(0.0357)\n",
      "14127 Traning Loss: tensor(0.0359)\n",
      "14128 Traning Loss: tensor(0.0346)\n",
      "14129 Traning Loss: tensor(0.0357)\n",
      "14130 Traning Loss: tensor(0.0345)\n",
      "14131 Traning Loss: tensor(0.0354)\n",
      "14132 Traning Loss: tensor(0.0345)\n",
      "14133 Traning Loss: tensor(0.0366)\n",
      "14134 Traning Loss: tensor(0.0361)\n",
      "14135 Traning Loss: tensor(0.0351)\n",
      "14136 Traning Loss: tensor(0.0351)\n",
      "14137 Traning Loss: tensor(0.0381)\n",
      "14138 Traning Loss: tensor(0.0347)\n",
      "14139 Traning Loss: tensor(0.0346)\n",
      "14140 Traning Loss: tensor(0.0358)\n",
      "14141 Traning Loss: tensor(0.0358)\n",
      "14142 Traning Loss: tensor(0.0347)\n",
      "14143 Traning Loss: tensor(0.0347)\n",
      "14144 Traning Loss: tensor(0.0341)\n",
      "14145 Traning Loss: tensor(0.0366)\n",
      "14146 Traning Loss: tensor(0.0383)\n",
      "14147 Traning Loss: tensor(0.0346)\n",
      "14148 Traning Loss: tensor(0.0387)\n",
      "14149 Traning Loss: tensor(0.0359)\n",
      "14150 Traning Loss: tensor(0.0356)\n",
      "14151 Traning Loss: tensor(0.0353)\n",
      "14152 Traning Loss: tensor(0.0355)\n",
      "14153 Traning Loss: tensor(0.0361)\n",
      "14154 Traning Loss: tensor(0.0345)\n",
      "14155 Traning Loss: tensor(0.0358)\n",
      "14156 Traning Loss: tensor(0.0367)\n",
      "14157 Traning Loss: tensor(0.0362)\n",
      "14158 Traning Loss: tensor(0.0337)\n",
      "14159 Traning Loss: tensor(0.0369)\n",
      "14160 Traning Loss: tensor(0.0347)\n",
      "14161 Traning Loss: tensor(0.0345)\n",
      "14162 Traning Loss: tensor(0.0369)\n",
      "14163 Traning Loss: tensor(0.0369)\n",
      "14164 Traning Loss: tensor(0.0365)\n",
      "14165 Traning Loss: tensor(0.0351)\n",
      "14166 Traning Loss: tensor(0.0352)\n",
      "14167 Traning Loss: tensor(0.0368)\n",
      "14168 Traning Loss: tensor(0.0391)\n",
      "14169 Traning Loss: tensor(0.0341)\n",
      "14170 Traning Loss: tensor(0.0359)\n",
      "14171 Traning Loss: tensor(0.0359)\n",
      "14172 Traning Loss: tensor(0.0343)\n",
      "14173 Traning Loss: tensor(0.0371)\n",
      "14174 Traning Loss: tensor(0.0354)\n",
      "14175 Traning Loss: tensor(0.0358)\n",
      "14176 Traning Loss: tensor(0.0342)\n",
      "14177 Traning Loss: tensor(0.0364)\n",
      "14178 Traning Loss: tensor(0.0351)\n",
      "14179 Traning Loss: tensor(0.0355)\n",
      "14180 Traning Loss: tensor(0.0365)\n",
      "14181 Traning Loss: tensor(0.0353)\n",
      "14182 Traning Loss: tensor(0.0355)\n",
      "14183 Traning Loss: tensor(0.0356)\n",
      "14184 Traning Loss: tensor(0.0358)\n",
      "14185 Traning Loss: tensor(0.0363)\n",
      "14186 Traning Loss: tensor(0.0363)\n",
      "14187 Traning Loss: tensor(0.0366)\n",
      "14188 Traning Loss: tensor(0.0350)\n",
      "14189 Traning Loss: tensor(0.0341)\n",
      "14190 Traning Loss: tensor(0.0349)\n",
      "14191 Traning Loss: tensor(0.0354)\n",
      "14192 Traning Loss: tensor(0.0335)\n",
      "14193 Traning Loss: tensor(0.0364)\n",
      "14194 Traning Loss: tensor(0.0365)\n",
      "14195 Traning Loss: tensor(0.0341)\n",
      "14196 Traning Loss: tensor(0.0355)\n",
      "14197 Traning Loss: tensor(0.0355)\n",
      "14198 Traning Loss: tensor(0.0353)\n",
      "14199 Traning Loss: tensor(0.0379)\n",
      "14200 Traning Loss: tensor(0.0352)\n",
      "14201 Traning Loss: tensor(0.0365)\n",
      "14202 Traning Loss: tensor(0.0355)\n",
      "14203 Traning Loss: tensor(0.0370)\n",
      "14204 Traning Loss: tensor(0.0358)\n",
      "14205 Traning Loss: tensor(0.0373)\n",
      "14206 Traning Loss: tensor(0.0349)\n",
      "14207 Traning Loss: tensor(0.0367)\n",
      "14208 Traning Loss: tensor(0.0350)\n",
      "14209 Traning Loss: tensor(0.0350)\n",
      "14210 Traning Loss: tensor(0.0350)\n",
      "14211 Traning Loss: tensor(0.0371)\n",
      "14212 Traning Loss: tensor(0.0351)\n",
      "14213 Traning Loss: tensor(0.0381)\n",
      "14214 Traning Loss: tensor(0.0367)\n",
      "14215 Traning Loss: tensor(0.0354)\n",
      "14216 Traning Loss: tensor(0.0370)\n",
      "14217 Traning Loss: tensor(0.0350)\n",
      "14218 Traning Loss: tensor(0.0362)\n",
      "14219 Traning Loss: tensor(0.0357)\n",
      "14220 Traning Loss: tensor(0.0344)\n",
      "14221 Traning Loss: tensor(0.0388)\n",
      "14222 Traning Loss: tensor(0.0365)\n",
      "14223 Traning Loss: tensor(0.0362)\n",
      "14224 Traning Loss: tensor(0.0382)\n",
      "14225 Traning Loss: tensor(0.0360)\n",
      "14226 Traning Loss: tensor(0.0348)\n",
      "14227 Traning Loss: tensor(0.0360)\n",
      "14228 Traning Loss: tensor(0.0366)\n",
      "14229 Traning Loss: tensor(0.0346)\n",
      "14230 Traning Loss: tensor(0.0358)\n",
      "14231 Traning Loss: tensor(0.0360)\n",
      "14232 Traning Loss: tensor(0.0361)\n",
      "14233 Traning Loss: tensor(0.0342)\n",
      "14234 Traning Loss: tensor(0.0343)\n",
      "14235 Traning Loss: tensor(0.0345)\n",
      "14236 Traning Loss: tensor(0.0348)\n",
      "14237 Traning Loss: tensor(0.0350)\n",
      "14238 Traning Loss: tensor(0.0354)\n",
      "14239 Traning Loss: tensor(0.0344)\n",
      "14240 Traning Loss: tensor(0.0343)\n",
      "14241 Traning Loss: tensor(0.0361)\n",
      "14242 Traning Loss: tensor(0.0357)\n",
      "14243 Traning Loss: tensor(0.0347)\n",
      "14244 Traning Loss: tensor(0.0347)\n",
      "14245 Traning Loss: tensor(0.0346)\n",
      "14246 Traning Loss: tensor(0.0360)\n",
      "14247 Traning Loss: tensor(0.0355)\n",
      "14248 Traning Loss: tensor(0.0353)\n",
      "14249 Traning Loss: tensor(0.0352)\n",
      "14250 Traning Loss: tensor(0.0354)\n",
      "14251 Traning Loss: tensor(0.0360)\n",
      "14252 Traning Loss: tensor(0.0338)\n",
      "14253 Traning Loss: tensor(0.0348)\n",
      "14254 Traning Loss: tensor(0.0341)\n",
      "14255 Traning Loss: tensor(0.0363)\n",
      "14256 Traning Loss: tensor(0.0345)\n",
      "14257 Traning Loss: tensor(0.0357)\n",
      "14258 Traning Loss: tensor(0.0365)\n",
      "14259 Traning Loss: tensor(0.0343)\n",
      "14260 Traning Loss: tensor(0.0350)\n",
      "14261 Traning Loss: tensor(0.0344)\n",
      "14262 Traning Loss: tensor(0.0347)\n",
      "14263 Traning Loss: tensor(0.0358)\n",
      "14264 Traning Loss: tensor(0.0356)\n",
      "14265 Traning Loss: tensor(0.0350)\n",
      "14266 Traning Loss: tensor(0.0344)\n",
      "14267 Traning Loss: tensor(0.0364)\n",
      "14268 Traning Loss: tensor(0.0341)\n",
      "14269 Traning Loss: tensor(0.0358)\n",
      "14270 Traning Loss: tensor(0.0340)\n",
      "14271 Traning Loss: tensor(0.0351)\n",
      "14272 Traning Loss: tensor(0.0346)\n",
      "14273 Traning Loss: tensor(0.0352)\n",
      "14274 Traning Loss: tensor(0.0350)\n",
      "14275 Traning Loss: tensor(0.0355)\n",
      "14276 Traning Loss: tensor(0.0353)\n",
      "14277 Traning Loss: tensor(0.0389)\n",
      "14278 Traning Loss: tensor(0.0346)\n",
      "14279 Traning Loss: tensor(0.0374)\n",
      "14280 Traning Loss: tensor(0.0366)\n",
      "14281 Traning Loss: tensor(0.0350)\n",
      "14282 Traning Loss: tensor(0.0378)\n",
      "14283 Traning Loss: tensor(0.0348)\n",
      "14284 Traning Loss: tensor(0.0358)\n",
      "14285 Traning Loss: tensor(0.0364)\n",
      "14286 Traning Loss: tensor(0.0388)\n",
      "14287 Traning Loss: tensor(0.0356)\n",
      "14288 Traning Loss: tensor(0.0356)\n",
      "14289 Traning Loss: tensor(0.0354)\n",
      "14290 Traning Loss: tensor(0.0359)\n",
      "14291 Traning Loss: tensor(0.0351)\n",
      "14292 Traning Loss: tensor(0.0362)\n",
      "14293 Traning Loss: tensor(0.0365)\n",
      "14294 Traning Loss: tensor(0.0364)\n",
      "14295 Traning Loss: tensor(0.0351)\n",
      "14296 Traning Loss: tensor(0.0335)\n",
      "14297 Traning Loss: tensor(0.0353)\n",
      "14298 Traning Loss: tensor(0.0353)\n",
      "14299 Traning Loss: tensor(0.0357)\n",
      "14300 Traning Loss: tensor(0.0356)\n",
      "14301 Traning Loss: tensor(0.0344)\n",
      "14302 Traning Loss: tensor(0.0353)\n",
      "14303 Traning Loss: tensor(0.0356)\n",
      "14304 Traning Loss: tensor(0.0382)\n",
      "14305 Traning Loss: tensor(0.0343)\n",
      "14306 Traning Loss: tensor(0.0354)\n",
      "14307 Traning Loss: tensor(0.0339)\n",
      "14308 Traning Loss: tensor(0.0351)\n",
      "14309 Traning Loss: tensor(0.0345)\n",
      "14310 Traning Loss: tensor(0.0343)\n",
      "14311 Traning Loss: tensor(0.0343)\n",
      "14312 Traning Loss: tensor(0.0359)\n",
      "14313 Traning Loss: tensor(0.0355)\n",
      "14314 Traning Loss: tensor(0.0371)\n",
      "14315 Traning Loss: tensor(0.0346)\n",
      "14316 Traning Loss: tensor(0.0358)\n",
      "14317 Traning Loss: tensor(0.0359)\n",
      "14318 Traning Loss: tensor(0.0345)\n",
      "14319 Traning Loss: tensor(0.0362)\n",
      "14320 Traning Loss: tensor(0.0357)\n",
      "14321 Traning Loss: tensor(0.0352)\n",
      "14322 Traning Loss: tensor(0.0338)\n",
      "14323 Traning Loss: tensor(0.0345)\n",
      "14324 Traning Loss: tensor(0.0366)\n",
      "14325 Traning Loss: tensor(0.0347)\n",
      "14326 Traning Loss: tensor(0.0368)\n",
      "14327 Traning Loss: tensor(0.0366)\n",
      "14328 Traning Loss: tensor(0.0356)\n",
      "14329 Traning Loss: tensor(0.0357)\n",
      "14330 Traning Loss: tensor(0.0369)\n",
      "14331 Traning Loss: tensor(0.0336)\n",
      "14332 Traning Loss: tensor(0.0352)\n",
      "14333 Traning Loss: tensor(0.0352)\n",
      "14334 Traning Loss: tensor(0.0369)\n",
      "14335 Traning Loss: tensor(0.0353)\n",
      "14336 Traning Loss: tensor(0.0351)\n",
      "14337 Traning Loss: tensor(0.0372)\n",
      "14338 Traning Loss: tensor(0.0345)\n",
      "14339 Traning Loss: tensor(0.0346)\n",
      "14340 Traning Loss: tensor(0.0344)\n",
      "14341 Traning Loss: tensor(0.0359)\n",
      "14342 Traning Loss: tensor(0.0335)\n",
      "14343 Traning Loss: tensor(0.0328)\n",
      "14344 Traning Loss: tensor(0.0338)\n",
      "14345 Traning Loss: tensor(0.0340)\n",
      "14346 Traning Loss: tensor(0.0364)\n",
      "14347 Traning Loss: tensor(0.0357)\n",
      "14348 Traning Loss: tensor(0.0344)\n",
      "14349 Traning Loss: tensor(0.0365)\n",
      "14350 Traning Loss: tensor(0.0350)\n",
      "14351 Traning Loss: tensor(0.0340)\n",
      "14352 Traning Loss: tensor(0.0339)\n",
      "14353 Traning Loss: tensor(0.0353)\n",
      "14354 Traning Loss: tensor(0.0389)\n",
      "14355 Traning Loss: tensor(0.0335)\n",
      "14356 Traning Loss: tensor(0.0363)\n",
      "14357 Traning Loss: tensor(0.0360)\n",
      "14358 Traning Loss: tensor(0.0355)\n",
      "14359 Traning Loss: tensor(0.0346)\n",
      "14360 Traning Loss: tensor(0.0343)\n",
      "14361 Traning Loss: tensor(0.0363)\n",
      "14362 Traning Loss: tensor(0.0352)\n",
      "14363 Traning Loss: tensor(0.0369)\n",
      "14364 Traning Loss: tensor(0.0358)\n",
      "14365 Traning Loss: tensor(0.0349)\n",
      "14366 Traning Loss: tensor(0.0351)\n",
      "14367 Traning Loss: tensor(0.0355)\n",
      "14368 Traning Loss: tensor(0.0366)\n",
      "14369 Traning Loss: tensor(0.0370)\n",
      "14370 Traning Loss: tensor(0.0348)\n",
      "14371 Traning Loss: tensor(0.0339)\n",
      "14372 Traning Loss: tensor(0.0342)\n",
      "14373 Traning Loss: tensor(0.0363)\n",
      "14374 Traning Loss: tensor(0.0337)\n",
      "14375 Traning Loss: tensor(0.0348)\n",
      "14376 Traning Loss: tensor(0.0345)\n",
      "14377 Traning Loss: tensor(0.0358)\n",
      "14378 Traning Loss: tensor(0.0359)\n",
      "14379 Traning Loss: tensor(0.0365)\n",
      "14380 Traning Loss: tensor(0.0373)\n",
      "14381 Traning Loss: tensor(0.0359)\n",
      "14382 Traning Loss: tensor(0.0373)\n",
      "14383 Traning Loss: tensor(0.0353)\n",
      "14384 Traning Loss: tensor(0.0368)\n",
      "14385 Traning Loss: tensor(0.0349)\n",
      "14386 Traning Loss: tensor(0.0368)\n",
      "14387 Traning Loss: tensor(0.0368)\n",
      "14388 Traning Loss: tensor(0.0350)\n",
      "14389 Traning Loss: tensor(0.0359)\n",
      "14390 Traning Loss: tensor(0.0339)\n",
      "14391 Traning Loss: tensor(0.0339)\n",
      "14392 Traning Loss: tensor(0.0366)\n",
      "14393 Traning Loss: tensor(0.0353)\n",
      "14394 Traning Loss: tensor(0.0352)\n",
      "14395 Traning Loss: tensor(0.0347)\n",
      "14396 Traning Loss: tensor(0.0358)\n",
      "14397 Traning Loss: tensor(0.0354)\n",
      "14398 Traning Loss: tensor(0.0359)\n",
      "14399 Traning Loss: tensor(0.0332)\n",
      "14400 Traning Loss: tensor(0.0373)\n",
      "14401 Traning Loss: tensor(0.0341)\n",
      "14402 Traning Loss: tensor(0.0356)\n",
      "14403 Traning Loss: tensor(0.0348)\n",
      "14404 Traning Loss: tensor(0.0361)\n",
      "14405 Traning Loss: tensor(0.0343)\n",
      "14406 Traning Loss: tensor(0.0359)\n",
      "14407 Traning Loss: tensor(0.0369)\n",
      "14408 Traning Loss: tensor(0.0344)\n",
      "14409 Traning Loss: tensor(0.0340)\n",
      "14410 Traning Loss: tensor(0.0365)\n",
      "14411 Traning Loss: tensor(0.0369)\n",
      "14412 Traning Loss: tensor(0.0340)\n",
      "14413 Traning Loss: tensor(0.0346)\n",
      "14414 Traning Loss: tensor(0.0349)\n",
      "14415 Traning Loss: tensor(0.0357)\n",
      "14416 Traning Loss: tensor(0.0347)\n",
      "14417 Traning Loss: tensor(0.0338)\n",
      "14418 Traning Loss: tensor(0.0355)\n",
      "14419 Traning Loss: tensor(0.0360)\n",
      "14420 Traning Loss: tensor(0.0339)\n",
      "14421 Traning Loss: tensor(0.0348)\n",
      "14422 Traning Loss: tensor(0.0344)\n",
      "14423 Traning Loss: tensor(0.0350)\n",
      "14424 Traning Loss: tensor(0.0340)\n",
      "14425 Traning Loss: tensor(0.0343)\n",
      "14426 Traning Loss: tensor(0.0355)\n",
      "14427 Traning Loss: tensor(0.0355)\n",
      "14428 Traning Loss: tensor(0.0338)\n",
      "14429 Traning Loss: tensor(0.0348)\n",
      "14430 Traning Loss: tensor(0.0354)\n",
      "14431 Traning Loss: tensor(0.0344)\n",
      "14432 Traning Loss: tensor(0.0330)\n",
      "14433 Traning Loss: tensor(0.0345)\n",
      "14434 Traning Loss: tensor(0.0364)\n",
      "14435 Traning Loss: tensor(0.0359)\n",
      "14436 Traning Loss: tensor(0.0328)\n",
      "14437 Traning Loss: tensor(0.0338)\n",
      "14438 Traning Loss: tensor(0.0352)\n",
      "14439 Traning Loss: tensor(0.0345)\n",
      "14440 Traning Loss: tensor(0.0354)\n",
      "14441 Traning Loss: tensor(0.0343)\n",
      "14442 Traning Loss: tensor(0.0348)\n",
      "14443 Traning Loss: tensor(0.0349)\n",
      "14444 Traning Loss: tensor(0.0346)\n",
      "14445 Traning Loss: tensor(0.0340)\n",
      "14446 Traning Loss: tensor(0.0336)\n",
      "14447 Traning Loss: tensor(0.0341)\n",
      "14448 Traning Loss: tensor(0.0350)\n",
      "14449 Traning Loss: tensor(0.0341)\n",
      "14450 Traning Loss: tensor(0.0357)\n",
      "14451 Traning Loss: tensor(0.0336)\n",
      "14452 Traning Loss: tensor(0.0346)\n",
      "14453 Traning Loss: tensor(0.0343)\n",
      "14454 Traning Loss: tensor(0.0366)\n",
      "14455 Traning Loss: tensor(0.0362)\n",
      "14456 Traning Loss: tensor(0.0356)\n",
      "14457 Traning Loss: tensor(0.0354)\n",
      "14458 Traning Loss: tensor(0.0364)\n",
      "14459 Traning Loss: tensor(0.0339)\n",
      "14460 Traning Loss: tensor(0.0341)\n",
      "14461 Traning Loss: tensor(0.0379)\n",
      "14462 Traning Loss: tensor(0.0342)\n",
      "14463 Traning Loss: tensor(0.0353)\n",
      "14464 Traning Loss: tensor(0.0340)\n",
      "14465 Traning Loss: tensor(0.0341)\n",
      "14466 Traning Loss: tensor(0.0347)\n",
      "14467 Traning Loss: tensor(0.0341)\n",
      "14468 Traning Loss: tensor(0.0348)\n",
      "14469 Traning Loss: tensor(0.0341)\n",
      "14470 Traning Loss: tensor(0.0340)\n",
      "14471 Traning Loss: tensor(0.0354)\n",
      "14472 Traning Loss: tensor(0.0358)\n",
      "14473 Traning Loss: tensor(0.0361)\n",
      "14474 Traning Loss: tensor(0.0351)\n",
      "14475 Traning Loss: tensor(0.0356)\n",
      "14476 Traning Loss: tensor(0.0342)\n",
      "14477 Traning Loss: tensor(0.0345)\n",
      "14478 Traning Loss: tensor(0.0344)\n",
      "14479 Traning Loss: tensor(0.0347)\n",
      "14480 Traning Loss: tensor(0.0360)\n",
      "14481 Traning Loss: tensor(0.0344)\n",
      "14482 Traning Loss: tensor(0.0354)\n",
      "14483 Traning Loss: tensor(0.0337)\n",
      "14484 Traning Loss: tensor(0.0336)\n",
      "14485 Traning Loss: tensor(0.0365)\n",
      "14486 Traning Loss: tensor(0.0344)\n",
      "14487 Traning Loss: tensor(0.0341)\n",
      "14488 Traning Loss: tensor(0.0342)\n",
      "14489 Traning Loss: tensor(0.0348)\n",
      "14490 Traning Loss: tensor(0.0358)\n",
      "14491 Traning Loss: tensor(0.0329)\n",
      "14492 Traning Loss: tensor(0.0360)\n",
      "14493 Traning Loss: tensor(0.0348)\n",
      "14494 Traning Loss: tensor(0.0333)\n",
      "14495 Traning Loss: tensor(0.0330)\n",
      "14496 Traning Loss: tensor(0.0344)\n",
      "14497 Traning Loss: tensor(0.0327)\n",
      "14498 Traning Loss: tensor(0.0351)\n",
      "14499 Traning Loss: tensor(0.0331)\n",
      "14500 Traning Loss: tensor(0.0342)\n",
      "14501 Traning Loss: tensor(0.0329)\n",
      "14502 Traning Loss: tensor(0.0369)\n",
      "14503 Traning Loss: tensor(0.0348)\n",
      "14504 Traning Loss: tensor(0.0347)\n",
      "14505 Traning Loss: tensor(0.0346)\n",
      "14506 Traning Loss: tensor(0.0355)\n",
      "14507 Traning Loss: tensor(0.0354)\n",
      "14508 Traning Loss: tensor(0.0343)\n",
      "14509 Traning Loss: tensor(0.0355)\n",
      "14510 Traning Loss: tensor(0.0354)\n",
      "14511 Traning Loss: tensor(0.0333)\n",
      "14512 Traning Loss: tensor(0.0351)\n",
      "14513 Traning Loss: tensor(0.0335)\n",
      "14514 Traning Loss: tensor(0.0361)\n",
      "14515 Traning Loss: tensor(0.0336)\n",
      "14516 Traning Loss: tensor(0.0336)\n",
      "14517 Traning Loss: tensor(0.0335)\n",
      "14518 Traning Loss: tensor(0.0346)\n",
      "14519 Traning Loss: tensor(0.0356)\n",
      "14520 Traning Loss: tensor(0.0350)\n",
      "14521 Traning Loss: tensor(0.0345)\n",
      "14522 Traning Loss: tensor(0.0363)\n",
      "14523 Traning Loss: tensor(0.0336)\n",
      "14524 Traning Loss: tensor(0.0357)\n",
      "14525 Traning Loss: tensor(0.0347)\n",
      "14526 Traning Loss: tensor(0.0358)\n",
      "14527 Traning Loss: tensor(0.0338)\n",
      "14528 Traning Loss: tensor(0.0343)\n",
      "14529 Traning Loss: tensor(0.0339)\n",
      "14530 Traning Loss: tensor(0.0358)\n",
      "14531 Traning Loss: tensor(0.0372)\n",
      "14532 Traning Loss: tensor(0.0354)\n",
      "14533 Traning Loss: tensor(0.0359)\n",
      "14534 Traning Loss: tensor(0.0349)\n",
      "14535 Traning Loss: tensor(0.0344)\n",
      "14536 Traning Loss: tensor(0.0325)\n",
      "14537 Traning Loss: tensor(0.0336)\n",
      "14538 Traning Loss: tensor(0.0342)\n",
      "14539 Traning Loss: tensor(0.0344)\n",
      "14540 Traning Loss: tensor(0.0339)\n",
      "14541 Traning Loss: tensor(0.0345)\n",
      "14542 Traning Loss: tensor(0.0351)\n",
      "14543 Traning Loss: tensor(0.0343)\n",
      "14544 Traning Loss: tensor(0.0332)\n",
      "14545 Traning Loss: tensor(0.0349)\n",
      "14546 Traning Loss: tensor(0.0358)\n",
      "14547 Traning Loss: tensor(0.0365)\n",
      "14548 Traning Loss: tensor(0.0337)\n",
      "14549 Traning Loss: tensor(0.0350)\n",
      "14550 Traning Loss: tensor(0.0352)\n",
      "14551 Traning Loss: tensor(0.0338)\n",
      "14552 Traning Loss: tensor(0.0348)\n",
      "14553 Traning Loss: tensor(0.0341)\n",
      "14554 Traning Loss: tensor(0.0334)\n",
      "14555 Traning Loss: tensor(0.0347)\n",
      "14556 Traning Loss: tensor(0.0351)\n",
      "14557 Traning Loss: tensor(0.0342)\n",
      "14558 Traning Loss: tensor(0.0346)\n",
      "14559 Traning Loss: tensor(0.0328)\n",
      "14560 Traning Loss: tensor(0.0328)\n",
      "14561 Traning Loss: tensor(0.0347)\n",
      "14562 Traning Loss: tensor(0.0333)\n",
      "14563 Traning Loss: tensor(0.0359)\n",
      "14564 Traning Loss: tensor(0.0332)\n",
      "14565 Traning Loss: tensor(0.0346)\n",
      "14566 Traning Loss: tensor(0.0349)\n",
      "14567 Traning Loss: tensor(0.0348)\n",
      "14568 Traning Loss: tensor(0.0363)\n",
      "14569 Traning Loss: tensor(0.0339)\n",
      "14570 Traning Loss: tensor(0.0357)\n",
      "14571 Traning Loss: tensor(0.0353)\n",
      "14572 Traning Loss: tensor(0.0340)\n",
      "14573 Traning Loss: tensor(0.0350)\n",
      "14574 Traning Loss: tensor(0.0324)\n",
      "14575 Traning Loss: tensor(0.0342)\n",
      "14576 Traning Loss: tensor(0.0338)\n",
      "14577 Traning Loss: tensor(0.0333)\n",
      "14578 Traning Loss: tensor(0.0337)\n",
      "14579 Traning Loss: tensor(0.0349)\n",
      "14580 Traning Loss: tensor(0.0354)\n",
      "14581 Traning Loss: tensor(0.0338)\n",
      "14582 Traning Loss: tensor(0.0337)\n",
      "14583 Traning Loss: tensor(0.0352)\n",
      "14584 Traning Loss: tensor(0.0353)\n",
      "14585 Traning Loss: tensor(0.0349)\n",
      "14586 Traning Loss: tensor(0.0339)\n",
      "14587 Traning Loss: tensor(0.0351)\n",
      "14588 Traning Loss: tensor(0.0346)\n",
      "14589 Traning Loss: tensor(0.0337)\n",
      "14590 Traning Loss: tensor(0.0335)\n",
      "14591 Traning Loss: tensor(0.0354)\n",
      "14592 Traning Loss: tensor(0.0332)\n",
      "14593 Traning Loss: tensor(0.0347)\n",
      "14594 Traning Loss: tensor(0.0345)\n",
      "14595 Traning Loss: tensor(0.0338)\n",
      "14596 Traning Loss: tensor(0.0334)\n",
      "14597 Traning Loss: tensor(0.0346)\n",
      "14598 Traning Loss: tensor(0.0363)\n",
      "14599 Traning Loss: tensor(0.0337)\n",
      "14600 Traning Loss: tensor(0.0347)\n",
      "14601 Traning Loss: tensor(0.0367)\n",
      "14602 Traning Loss: tensor(0.0341)\n",
      "14603 Traning Loss: tensor(0.0335)\n",
      "14604 Traning Loss: tensor(0.0342)\n",
      "14605 Traning Loss: tensor(0.0336)\n",
      "14606 Traning Loss: tensor(0.0343)\n",
      "14607 Traning Loss: tensor(0.0353)\n",
      "14608 Traning Loss: tensor(0.0345)\n",
      "14609 Traning Loss: tensor(0.0343)\n",
      "14610 Traning Loss: tensor(0.0346)\n",
      "14611 Traning Loss: tensor(0.0349)\n",
      "14612 Traning Loss: tensor(0.0348)\n",
      "14613 Traning Loss: tensor(0.0340)\n",
      "14614 Traning Loss: tensor(0.0325)\n",
      "14615 Traning Loss: tensor(0.0357)\n",
      "14616 Traning Loss: tensor(0.0338)\n",
      "14617 Traning Loss: tensor(0.0347)\n",
      "14618 Traning Loss: tensor(0.0328)\n",
      "14619 Traning Loss: tensor(0.0352)\n",
      "14620 Traning Loss: tensor(0.0345)\n",
      "14621 Traning Loss: tensor(0.0339)\n",
      "14622 Traning Loss: tensor(0.0332)\n",
      "14623 Traning Loss: tensor(0.0332)\n",
      "14624 Traning Loss: tensor(0.0350)\n",
      "14625 Traning Loss: tensor(0.0346)\n",
      "14626 Traning Loss: tensor(0.0341)\n",
      "14627 Traning Loss: tensor(0.0337)\n",
      "14628 Traning Loss: tensor(0.0372)\n",
      "14629 Traning Loss: tensor(0.0369)\n",
      "14630 Traning Loss: tensor(0.0344)\n",
      "14631 Traning Loss: tensor(0.0350)\n",
      "14632 Traning Loss: tensor(0.0354)\n",
      "14633 Traning Loss: tensor(0.0346)\n",
      "14634 Traning Loss: tensor(0.0361)\n",
      "14635 Traning Loss: tensor(0.0339)\n",
      "14636 Traning Loss: tensor(0.0369)\n",
      "14637 Traning Loss: tensor(0.0346)\n",
      "14638 Traning Loss: tensor(0.0347)\n",
      "14639 Traning Loss: tensor(0.0370)\n",
      "14640 Traning Loss: tensor(0.0362)\n",
      "14641 Traning Loss: tensor(0.0385)\n",
      "14642 Traning Loss: tensor(0.0343)\n",
      "14643 Traning Loss: tensor(0.0332)\n",
      "14644 Traning Loss: tensor(0.0353)\n",
      "14645 Traning Loss: tensor(0.0355)\n",
      "14646 Traning Loss: tensor(0.0355)\n",
      "14647 Traning Loss: tensor(0.0329)\n",
      "14648 Traning Loss: tensor(0.0346)\n",
      "14649 Traning Loss: tensor(0.0352)\n",
      "14650 Traning Loss: tensor(0.0357)\n",
      "14651 Traning Loss: tensor(0.0345)\n",
      "14652 Traning Loss: tensor(0.0366)\n",
      "14653 Traning Loss: tensor(0.0341)\n",
      "14654 Traning Loss: tensor(0.0354)\n",
      "14655 Traning Loss: tensor(0.0342)\n",
      "14656 Traning Loss: tensor(0.0347)\n",
      "14657 Traning Loss: tensor(0.0352)\n",
      "14658 Traning Loss: tensor(0.0365)\n",
      "14659 Traning Loss: tensor(0.0350)\n",
      "14660 Traning Loss: tensor(0.0342)\n",
      "14661 Traning Loss: tensor(0.0326)\n",
      "14662 Traning Loss: tensor(0.0354)\n",
      "14663 Traning Loss: tensor(0.0333)\n",
      "14664 Traning Loss: tensor(0.0351)\n",
      "14665 Traning Loss: tensor(0.0334)\n",
      "14666 Traning Loss: tensor(0.0339)\n",
      "14667 Traning Loss: tensor(0.0333)\n",
      "14668 Traning Loss: tensor(0.0342)\n",
      "14669 Traning Loss: tensor(0.0347)\n",
      "14670 Traning Loss: tensor(0.0327)\n",
      "14671 Traning Loss: tensor(0.0347)\n",
      "14672 Traning Loss: tensor(0.0360)\n",
      "14673 Traning Loss: tensor(0.0339)\n",
      "14674 Traning Loss: tensor(0.0358)\n",
      "14675 Traning Loss: tensor(0.0344)\n",
      "14676 Traning Loss: tensor(0.0362)\n",
      "14677 Traning Loss: tensor(0.0358)\n",
      "14678 Traning Loss: tensor(0.0353)\n",
      "14679 Traning Loss: tensor(0.0329)\n",
      "14680 Traning Loss: tensor(0.0336)\n",
      "14681 Traning Loss: tensor(0.0353)\n",
      "14682 Traning Loss: tensor(0.0345)\n",
      "14683 Traning Loss: tensor(0.0343)\n",
      "14684 Traning Loss: tensor(0.0343)\n",
      "14685 Traning Loss: tensor(0.0347)\n",
      "14686 Traning Loss: tensor(0.0366)\n",
      "14687 Traning Loss: tensor(0.0340)\n",
      "14688 Traning Loss: tensor(0.0345)\n",
      "14689 Traning Loss: tensor(0.0357)\n",
      "14690 Traning Loss: tensor(0.0359)\n",
      "14691 Traning Loss: tensor(0.0340)\n",
      "14692 Traning Loss: tensor(0.0357)\n",
      "14693 Traning Loss: tensor(0.0343)\n",
      "14694 Traning Loss: tensor(0.0339)\n",
      "14695 Traning Loss: tensor(0.0336)\n",
      "14696 Traning Loss: tensor(0.0351)\n",
      "14697 Traning Loss: tensor(0.0351)\n",
      "14698 Traning Loss: tensor(0.0343)\n",
      "14699 Traning Loss: tensor(0.0345)\n",
      "14700 Traning Loss: tensor(0.0328)\n",
      "14701 Traning Loss: tensor(0.0337)\n",
      "14702 Traning Loss: tensor(0.0340)\n",
      "14703 Traning Loss: tensor(0.0341)\n",
      "14704 Traning Loss: tensor(0.0332)\n",
      "14705 Traning Loss: tensor(0.0349)\n",
      "14706 Traning Loss: tensor(0.0342)\n",
      "14707 Traning Loss: tensor(0.0350)\n",
      "14708 Traning Loss: tensor(0.0345)\n",
      "14709 Traning Loss: tensor(0.0350)\n",
      "14710 Traning Loss: tensor(0.0354)\n",
      "14711 Traning Loss: tensor(0.0364)\n",
      "14712 Traning Loss: tensor(0.0328)\n",
      "14713 Traning Loss: tensor(0.0342)\n",
      "14714 Traning Loss: tensor(0.0353)\n",
      "14715 Traning Loss: tensor(0.0336)\n",
      "14716 Traning Loss: tensor(0.0329)\n",
      "14717 Traning Loss: tensor(0.0359)\n",
      "14718 Traning Loss: tensor(0.0353)\n",
      "14719 Traning Loss: tensor(0.0352)\n",
      "14720 Traning Loss: tensor(0.0347)\n",
      "14721 Traning Loss: tensor(0.0364)\n",
      "14722 Traning Loss: tensor(0.0346)\n",
      "14723 Traning Loss: tensor(0.0341)\n",
      "14724 Traning Loss: tensor(0.0369)\n",
      "14725 Traning Loss: tensor(0.0340)\n",
      "14726 Traning Loss: tensor(0.0331)\n",
      "14727 Traning Loss: tensor(0.0342)\n",
      "14728 Traning Loss: tensor(0.0352)\n",
      "14729 Traning Loss: tensor(0.0343)\n",
      "14730 Traning Loss: tensor(0.0339)\n",
      "14731 Traning Loss: tensor(0.0366)\n",
      "14732 Traning Loss: tensor(0.0357)\n",
      "14733 Traning Loss: tensor(0.0363)\n",
      "14734 Traning Loss: tensor(0.0364)\n",
      "14735 Traning Loss: tensor(0.0335)\n",
      "14736 Traning Loss: tensor(0.0334)\n",
      "14737 Traning Loss: tensor(0.0357)\n",
      "14738 Traning Loss: tensor(0.0348)\n",
      "14739 Traning Loss: tensor(0.0330)\n",
      "14740 Traning Loss: tensor(0.0343)\n",
      "14741 Traning Loss: tensor(0.0381)\n",
      "14742 Traning Loss: tensor(0.0332)\n",
      "14743 Traning Loss: tensor(0.0333)\n",
      "14744 Traning Loss: tensor(0.0345)\n",
      "14745 Traning Loss: tensor(0.0364)\n",
      "14746 Traning Loss: tensor(0.0341)\n",
      "14747 Traning Loss: tensor(0.0351)\n",
      "14748 Traning Loss: tensor(0.0334)\n",
      "14749 Traning Loss: tensor(0.0341)\n",
      "14750 Traning Loss: tensor(0.0323)\n",
      "14751 Traning Loss: tensor(0.0354)\n",
      "14752 Traning Loss: tensor(0.0345)\n",
      "14753 Traning Loss: tensor(0.0337)\n",
      "14754 Traning Loss: tensor(0.0345)\n",
      "14755 Traning Loss: tensor(0.0334)\n",
      "14756 Traning Loss: tensor(0.0350)\n",
      "14757 Traning Loss: tensor(0.0357)\n",
      "14758 Traning Loss: tensor(0.0350)\n",
      "14759 Traning Loss: tensor(0.0333)\n",
      "14760 Traning Loss: tensor(0.0332)\n",
      "14761 Traning Loss: tensor(0.0325)\n",
      "14762 Traning Loss: tensor(0.0347)\n",
      "14763 Traning Loss: tensor(0.0345)\n",
      "14764 Traning Loss: tensor(0.0334)\n",
      "14765 Traning Loss: tensor(0.0337)\n",
      "14766 Traning Loss: tensor(0.0385)\n",
      "14767 Traning Loss: tensor(0.0350)\n",
      "14768 Traning Loss: tensor(0.0356)\n",
      "14769 Traning Loss: tensor(0.0352)\n",
      "14770 Traning Loss: tensor(0.0353)\n",
      "14771 Traning Loss: tensor(0.0349)\n",
      "14772 Traning Loss: tensor(0.0347)\n",
      "14773 Traning Loss: tensor(0.0341)\n",
      "14774 Traning Loss: tensor(0.0351)\n",
      "14775 Traning Loss: tensor(0.0343)\n",
      "14776 Traning Loss: tensor(0.0363)\n",
      "14777 Traning Loss: tensor(0.0359)\n",
      "14778 Traning Loss: tensor(0.0351)\n",
      "14779 Traning Loss: tensor(0.0340)\n",
      "14780 Traning Loss: tensor(0.0350)\n",
      "14781 Traning Loss: tensor(0.0333)\n",
      "14782 Traning Loss: tensor(0.0352)\n",
      "14783 Traning Loss: tensor(0.0337)\n",
      "14784 Traning Loss: tensor(0.0354)\n",
      "14785 Traning Loss: tensor(0.0351)\n",
      "14786 Traning Loss: tensor(0.0328)\n",
      "14787 Traning Loss: tensor(0.0336)\n",
      "14788 Traning Loss: tensor(0.0359)\n",
      "14789 Traning Loss: tensor(0.0338)\n",
      "14790 Traning Loss: tensor(0.0333)\n",
      "14791 Traning Loss: tensor(0.0354)\n",
      "14792 Traning Loss: tensor(0.0324)\n",
      "14793 Traning Loss: tensor(0.0334)\n",
      "14794 Traning Loss: tensor(0.0339)\n",
      "14795 Traning Loss: tensor(0.0339)\n",
      "14796 Traning Loss: tensor(0.0343)\n",
      "14797 Traning Loss: tensor(0.0326)\n",
      "14798 Traning Loss: tensor(0.0346)\n",
      "14799 Traning Loss: tensor(0.0347)\n",
      "14800 Traning Loss: tensor(0.0360)\n",
      "14801 Traning Loss: tensor(0.0357)\n",
      "14802 Traning Loss: tensor(0.0336)\n",
      "14803 Traning Loss: tensor(0.0330)\n",
      "14804 Traning Loss: tensor(0.0346)\n",
      "14805 Traning Loss: tensor(0.0325)\n",
      "14806 Traning Loss: tensor(0.0331)\n",
      "14807 Traning Loss: tensor(0.0338)\n",
      "14808 Traning Loss: tensor(0.0350)\n",
      "14809 Traning Loss: tensor(0.0340)\n",
      "14810 Traning Loss: tensor(0.0331)\n",
      "14811 Traning Loss: tensor(0.0322)\n",
      "14812 Traning Loss: tensor(0.0362)\n",
      "14813 Traning Loss: tensor(0.0342)\n",
      "14814 Traning Loss: tensor(0.0332)\n",
      "14815 Traning Loss: tensor(0.0347)\n",
      "14816 Traning Loss: tensor(0.0348)\n",
      "14817 Traning Loss: tensor(0.0350)\n",
      "14818 Traning Loss: tensor(0.0341)\n",
      "14819 Traning Loss: tensor(0.0353)\n",
      "14820 Traning Loss: tensor(0.0320)\n",
      "14821 Traning Loss: tensor(0.0353)\n",
      "14822 Traning Loss: tensor(0.0328)\n",
      "14823 Traning Loss: tensor(0.0340)\n",
      "14824 Traning Loss: tensor(0.0346)\n",
      "14825 Traning Loss: tensor(0.0344)\n",
      "14826 Traning Loss: tensor(0.0345)\n",
      "14827 Traning Loss: tensor(0.0347)\n",
      "14828 Traning Loss: tensor(0.0333)\n",
      "14829 Traning Loss: tensor(0.0337)\n",
      "14830 Traning Loss: tensor(0.0347)\n",
      "14831 Traning Loss: tensor(0.0333)\n",
      "14832 Traning Loss: tensor(0.0348)\n",
      "14833 Traning Loss: tensor(0.0325)\n",
      "14834 Traning Loss: tensor(0.0331)\n",
      "14835 Traning Loss: tensor(0.0331)\n",
      "14836 Traning Loss: tensor(0.0341)\n",
      "14837 Traning Loss: tensor(0.0363)\n",
      "14838 Traning Loss: tensor(0.0346)\n",
      "14839 Traning Loss: tensor(0.0335)\n",
      "14840 Traning Loss: tensor(0.0350)\n",
      "14841 Traning Loss: tensor(0.0330)\n",
      "14842 Traning Loss: tensor(0.0340)\n",
      "14843 Traning Loss: tensor(0.0347)\n",
      "14844 Traning Loss: tensor(0.0321)\n",
      "14845 Traning Loss: tensor(0.0339)\n",
      "14846 Traning Loss: tensor(0.0344)\n",
      "14847 Traning Loss: tensor(0.0333)\n",
      "14848 Traning Loss: tensor(0.0349)\n",
      "14849 Traning Loss: tensor(0.0354)\n",
      "14850 Traning Loss: tensor(0.0341)\n",
      "14851 Traning Loss: tensor(0.0339)\n",
      "14852 Traning Loss: tensor(0.0340)\n",
      "14853 Traning Loss: tensor(0.0345)\n",
      "14854 Traning Loss: tensor(0.0331)\n",
      "14855 Traning Loss: tensor(0.0345)\n",
      "14856 Traning Loss: tensor(0.0342)\n",
      "14857 Traning Loss: tensor(0.0323)\n",
      "14858 Traning Loss: tensor(0.0345)\n",
      "14859 Traning Loss: tensor(0.0342)\n",
      "14860 Traning Loss: tensor(0.0371)\n",
      "14861 Traning Loss: tensor(0.0330)\n",
      "14862 Traning Loss: tensor(0.0350)\n",
      "14863 Traning Loss: tensor(0.0359)\n",
      "14864 Traning Loss: tensor(0.0354)\n",
      "14865 Traning Loss: tensor(0.0346)\n",
      "14866 Traning Loss: tensor(0.0350)\n",
      "14867 Traning Loss: tensor(0.0352)\n",
      "14868 Traning Loss: tensor(0.0345)\n",
      "14869 Traning Loss: tensor(0.0341)\n",
      "14870 Traning Loss: tensor(0.0350)\n",
      "14871 Traning Loss: tensor(0.0364)\n",
      "14872 Traning Loss: tensor(0.0337)\n",
      "14873 Traning Loss: tensor(0.0350)\n",
      "14874 Traning Loss: tensor(0.0340)\n",
      "14875 Traning Loss: tensor(0.0359)\n",
      "14876 Traning Loss: tensor(0.0356)\n",
      "14877 Traning Loss: tensor(0.0362)\n",
      "14878 Traning Loss: tensor(0.0349)\n",
      "14879 Traning Loss: tensor(0.0342)\n",
      "14880 Traning Loss: tensor(0.0341)\n",
      "14881 Traning Loss: tensor(0.0350)\n",
      "14882 Traning Loss: tensor(0.0348)\n",
      "14883 Traning Loss: tensor(0.0353)\n",
      "14884 Traning Loss: tensor(0.0337)\n",
      "14885 Traning Loss: tensor(0.0351)\n",
      "14886 Traning Loss: tensor(0.0373)\n",
      "14887 Traning Loss: tensor(0.0321)\n",
      "14888 Traning Loss: tensor(0.0348)\n",
      "14889 Traning Loss: tensor(0.0361)\n",
      "14890 Traning Loss: tensor(0.0352)\n",
      "14891 Traning Loss: tensor(0.0334)\n",
      "14892 Traning Loss: tensor(0.0333)\n",
      "14893 Traning Loss: tensor(0.0355)\n",
      "14894 Traning Loss: tensor(0.0334)\n",
      "14895 Traning Loss: tensor(0.0335)\n",
      "14896 Traning Loss: tensor(0.0371)\n",
      "14897 Traning Loss: tensor(0.0350)\n",
      "14898 Traning Loss: tensor(0.0338)\n",
      "14899 Traning Loss: tensor(0.0341)\n",
      "14900 Traning Loss: tensor(0.0325)\n",
      "14901 Traning Loss: tensor(0.0343)\n",
      "14902 Traning Loss: tensor(0.0331)\n",
      "14903 Traning Loss: tensor(0.0332)\n",
      "14904 Traning Loss: tensor(0.0348)\n",
      "14905 Traning Loss: tensor(0.0349)\n",
      "14906 Traning Loss: tensor(0.0326)\n",
      "14907 Traning Loss: tensor(0.0345)\n",
      "14908 Traning Loss: tensor(0.0325)\n",
      "14909 Traning Loss: tensor(0.0336)\n",
      "14910 Traning Loss: tensor(0.0345)\n",
      "14911 Traning Loss: tensor(0.0333)\n",
      "14912 Traning Loss: tensor(0.0338)\n",
      "14913 Traning Loss: tensor(0.0352)\n",
      "14914 Traning Loss: tensor(0.0360)\n",
      "14915 Traning Loss: tensor(0.0338)\n",
      "14916 Traning Loss: tensor(0.0330)\n",
      "14917 Traning Loss: tensor(0.0346)\n",
      "14918 Traning Loss: tensor(0.0335)\n",
      "14919 Traning Loss: tensor(0.0350)\n",
      "14920 Traning Loss: tensor(0.0352)\n",
      "14921 Traning Loss: tensor(0.0352)\n",
      "14922 Traning Loss: tensor(0.0348)\n",
      "14923 Traning Loss: tensor(0.0365)\n",
      "14924 Traning Loss: tensor(0.0338)\n",
      "14925 Traning Loss: tensor(0.0352)\n",
      "14926 Traning Loss: tensor(0.0371)\n",
      "14927 Traning Loss: tensor(0.0349)\n",
      "14928 Traning Loss: tensor(0.0348)\n",
      "14929 Traning Loss: tensor(0.0341)\n",
      "14930 Traning Loss: tensor(0.0343)\n",
      "14931 Traning Loss: tensor(0.0342)\n",
      "14932 Traning Loss: tensor(0.0333)\n",
      "14933 Traning Loss: tensor(0.0333)\n",
      "14934 Traning Loss: tensor(0.0348)\n",
      "14935 Traning Loss: tensor(0.0337)\n",
      "14936 Traning Loss: tensor(0.0334)\n",
      "14937 Traning Loss: tensor(0.0320)\n",
      "14938 Traning Loss: tensor(0.0319)\n",
      "14939 Traning Loss: tensor(0.0340)\n",
      "14940 Traning Loss: tensor(0.0352)\n",
      "14941 Traning Loss: tensor(0.0337)\n",
      "14942 Traning Loss: tensor(0.0345)\n",
      "14943 Traning Loss: tensor(0.0336)\n",
      "14944 Traning Loss: tensor(0.0321)\n",
      "14945 Traning Loss: tensor(0.0324)\n",
      "14946 Traning Loss: tensor(0.0334)\n",
      "14947 Traning Loss: tensor(0.0333)\n",
      "14948 Traning Loss: tensor(0.0354)\n",
      "14949 Traning Loss: tensor(0.0323)\n",
      "14950 Traning Loss: tensor(0.0353)\n",
      "14951 Traning Loss: tensor(0.0340)\n",
      "14952 Traning Loss: tensor(0.0348)\n",
      "14953 Traning Loss: tensor(0.0331)\n",
      "14954 Traning Loss: tensor(0.0341)\n",
      "14955 Traning Loss: tensor(0.0326)\n",
      "14956 Traning Loss: tensor(0.0346)\n",
      "14957 Traning Loss: tensor(0.0340)\n",
      "14958 Traning Loss: tensor(0.0357)\n",
      "14959 Traning Loss: tensor(0.0362)\n",
      "14960 Traning Loss: tensor(0.0349)\n",
      "14961 Traning Loss: tensor(0.0344)\n",
      "14962 Traning Loss: tensor(0.0349)\n",
      "14963 Traning Loss: tensor(0.0332)\n",
      "14964 Traning Loss: tensor(0.0334)\n",
      "14965 Traning Loss: tensor(0.0345)\n",
      "14966 Traning Loss: tensor(0.0345)\n",
      "14967 Traning Loss: tensor(0.0342)\n",
      "14968 Traning Loss: tensor(0.0352)\n",
      "14969 Traning Loss: tensor(0.0331)\n",
      "14970 Traning Loss: tensor(0.0332)\n",
      "14971 Traning Loss: tensor(0.0340)\n",
      "14972 Traning Loss: tensor(0.0325)\n",
      "14973 Traning Loss: tensor(0.0328)\n",
      "14974 Traning Loss: tensor(0.0355)\n",
      "14975 Traning Loss: tensor(0.0366)\n",
      "14976 Traning Loss: tensor(0.0330)\n",
      "14977 Traning Loss: tensor(0.0336)\n",
      "14978 Traning Loss: tensor(0.0348)\n",
      "14979 Traning Loss: tensor(0.0338)\n",
      "14980 Traning Loss: tensor(0.0326)\n",
      "14981 Traning Loss: tensor(0.0333)\n",
      "14982 Traning Loss: tensor(0.0333)\n",
      "14983 Traning Loss: tensor(0.0339)\n",
      "14984 Traning Loss: tensor(0.0359)\n",
      "14985 Traning Loss: tensor(0.0344)\n",
      "14986 Traning Loss: tensor(0.0330)\n",
      "14987 Traning Loss: tensor(0.0352)\n",
      "14988 Traning Loss: tensor(0.0337)\n",
      "14989 Traning Loss: tensor(0.0354)\n",
      "14990 Traning Loss: tensor(0.0342)\n",
      "14991 Traning Loss: tensor(0.0332)\n",
      "14992 Traning Loss: tensor(0.0352)\n",
      "14993 Traning Loss: tensor(0.0337)\n",
      "14994 Traning Loss: tensor(0.0329)\n",
      "14995 Traning Loss: tensor(0.0346)\n",
      "14996 Traning Loss: tensor(0.0332)\n",
      "14997 Traning Loss: tensor(0.0346)\n",
      "14998 Traning Loss: tensor(0.0319)\n",
      "14999 Traning Loss: tensor(0.0341)\n",
      "15000 Traning Loss: tensor(0.0342)\n",
      "15001 Traning Loss: tensor(0.0356)\n",
      "15002 Traning Loss: tensor(0.0334)\n",
      "15003 Traning Loss: tensor(0.0331)\n",
      "15004 Traning Loss: tensor(0.0332)\n",
      "15005 Traning Loss: tensor(0.0326)\n",
      "15006 Traning Loss: tensor(0.0334)\n",
      "15007 Traning Loss: tensor(0.0331)\n",
      "15008 Traning Loss: tensor(0.0322)\n",
      "15009 Traning Loss: tensor(0.0342)\n",
      "15010 Traning Loss: tensor(0.0346)\n",
      "15011 Traning Loss: tensor(0.0330)\n",
      "15012 Traning Loss: tensor(0.0354)\n",
      "15013 Traning Loss: tensor(0.0332)\n",
      "15014 Traning Loss: tensor(0.0341)\n",
      "15015 Traning Loss: tensor(0.0334)\n",
      "15016 Traning Loss: tensor(0.0326)\n",
      "15017 Traning Loss: tensor(0.0343)\n",
      "15018 Traning Loss: tensor(0.0334)\n",
      "15019 Traning Loss: tensor(0.0336)\n",
      "15020 Traning Loss: tensor(0.0353)\n",
      "15021 Traning Loss: tensor(0.0351)\n",
      "15022 Traning Loss: tensor(0.0329)\n",
      "15023 Traning Loss: tensor(0.0332)\n",
      "15024 Traning Loss: tensor(0.0341)\n",
      "15025 Traning Loss: tensor(0.0352)\n",
      "15026 Traning Loss: tensor(0.0329)\n",
      "15027 Traning Loss: tensor(0.0342)\n",
      "15028 Traning Loss: tensor(0.0376)\n",
      "15029 Traning Loss: tensor(0.0340)\n",
      "15030 Traning Loss: tensor(0.0323)\n",
      "15031 Traning Loss: tensor(0.0324)\n",
      "15032 Traning Loss: tensor(0.0340)\n",
      "15033 Traning Loss: tensor(0.0348)\n",
      "15034 Traning Loss: tensor(0.0326)\n",
      "15035 Traning Loss: tensor(0.0316)\n",
      "15036 Traning Loss: tensor(0.0333)\n",
      "15037 Traning Loss: tensor(0.0333)\n",
      "15038 Traning Loss: tensor(0.0327)\n",
      "15039 Traning Loss: tensor(0.0341)\n",
      "15040 Traning Loss: tensor(0.0347)\n",
      "15041 Traning Loss: tensor(0.0328)\n",
      "15042 Traning Loss: tensor(0.0344)\n",
      "15043 Traning Loss: tensor(0.0335)\n",
      "15044 Traning Loss: tensor(0.0346)\n",
      "15045 Traning Loss: tensor(0.0328)\n",
      "15046 Traning Loss: tensor(0.0343)\n",
      "15047 Traning Loss: tensor(0.0329)\n",
      "15048 Traning Loss: tensor(0.0340)\n",
      "15049 Traning Loss: tensor(0.0355)\n",
      "15050 Traning Loss: tensor(0.0333)\n",
      "15051 Traning Loss: tensor(0.0328)\n",
      "15052 Traning Loss: tensor(0.0338)\n",
      "15053 Traning Loss: tensor(0.0338)\n",
      "15054 Traning Loss: tensor(0.0336)\n",
      "15055 Traning Loss: tensor(0.0336)\n",
      "15056 Traning Loss: tensor(0.0332)\n",
      "15057 Traning Loss: tensor(0.0332)\n",
      "15058 Traning Loss: tensor(0.0327)\n",
      "15059 Traning Loss: tensor(0.0349)\n",
      "15060 Traning Loss: tensor(0.0332)\n",
      "15061 Traning Loss: tensor(0.0334)\n",
      "15062 Traning Loss: tensor(0.0348)\n",
      "15063 Traning Loss: tensor(0.0325)\n",
      "15064 Traning Loss: tensor(0.0334)\n",
      "15065 Traning Loss: tensor(0.0333)\n",
      "15066 Traning Loss: tensor(0.0344)\n",
      "15067 Traning Loss: tensor(0.0333)\n",
      "15068 Traning Loss: tensor(0.0338)\n",
      "15069 Traning Loss: tensor(0.0352)\n",
      "15070 Traning Loss: tensor(0.0332)\n",
      "15071 Traning Loss: tensor(0.0348)\n",
      "15072 Traning Loss: tensor(0.0329)\n",
      "15073 Traning Loss: tensor(0.0340)\n",
      "15074 Traning Loss: tensor(0.0338)\n",
      "15075 Traning Loss: tensor(0.0345)\n",
      "15076 Traning Loss: tensor(0.0340)\n",
      "15077 Traning Loss: tensor(0.0365)\n",
      "15078 Traning Loss: tensor(0.0356)\n",
      "15079 Traning Loss: tensor(0.0329)\n",
      "15080 Traning Loss: tensor(0.0332)\n",
      "15081 Traning Loss: tensor(0.0331)\n",
      "15082 Traning Loss: tensor(0.0342)\n",
      "15083 Traning Loss: tensor(0.0350)\n",
      "15084 Traning Loss: tensor(0.0331)\n",
      "15085 Traning Loss: tensor(0.0334)\n",
      "15086 Traning Loss: tensor(0.0327)\n",
      "15087 Traning Loss: tensor(0.0349)\n",
      "15088 Traning Loss: tensor(0.0328)\n",
      "15089 Traning Loss: tensor(0.0326)\n",
      "15090 Traning Loss: tensor(0.0334)\n",
      "15091 Traning Loss: tensor(0.0332)\n",
      "15092 Traning Loss: tensor(0.0316)\n",
      "15093 Traning Loss: tensor(0.0326)\n",
      "15094 Traning Loss: tensor(0.0341)\n",
      "15095 Traning Loss: tensor(0.0345)\n",
      "15096 Traning Loss: tensor(0.0341)\n",
      "15097 Traning Loss: tensor(0.0324)\n",
      "15098 Traning Loss: tensor(0.0339)\n",
      "15099 Traning Loss: tensor(0.0334)\n",
      "15100 Traning Loss: tensor(0.0342)\n",
      "15101 Traning Loss: tensor(0.0337)\n",
      "15102 Traning Loss: tensor(0.0343)\n",
      "15103 Traning Loss: tensor(0.0334)\n",
      "15104 Traning Loss: tensor(0.0347)\n",
      "15105 Traning Loss: tensor(0.0344)\n",
      "15106 Traning Loss: tensor(0.0342)\n",
      "15107 Traning Loss: tensor(0.0338)\n",
      "15108 Traning Loss: tensor(0.0345)\n",
      "15109 Traning Loss: tensor(0.0358)\n",
      "15110 Traning Loss: tensor(0.0352)\n",
      "15111 Traning Loss: tensor(0.0362)\n",
      "15112 Traning Loss: tensor(0.0327)\n",
      "15113 Traning Loss: tensor(0.0346)\n",
      "15114 Traning Loss: tensor(0.0335)\n",
      "15115 Traning Loss: tensor(0.0341)\n",
      "15116 Traning Loss: tensor(0.0337)\n",
      "15117 Traning Loss: tensor(0.0340)\n",
      "15118 Traning Loss: tensor(0.0369)\n",
      "15119 Traning Loss: tensor(0.0351)\n",
      "15120 Traning Loss: tensor(0.0381)\n",
      "15121 Traning Loss: tensor(0.0341)\n",
      "15122 Traning Loss: tensor(0.0362)\n",
      "15123 Traning Loss: tensor(0.0334)\n",
      "15124 Traning Loss: tensor(0.0334)\n",
      "15125 Traning Loss: tensor(0.0366)\n",
      "15126 Traning Loss: tensor(0.0336)\n",
      "15127 Traning Loss: tensor(0.0340)\n",
      "15128 Traning Loss: tensor(0.0370)\n",
      "15129 Traning Loss: tensor(0.0332)\n",
      "15130 Traning Loss: tensor(0.0337)\n",
      "15131 Traning Loss: tensor(0.0347)\n",
      "15132 Traning Loss: tensor(0.0336)\n",
      "15133 Traning Loss: tensor(0.0342)\n",
      "15134 Traning Loss: tensor(0.0336)\n",
      "15135 Traning Loss: tensor(0.0329)\n",
      "15136 Traning Loss: tensor(0.0357)\n",
      "15137 Traning Loss: tensor(0.0345)\n",
      "15138 Traning Loss: tensor(0.0341)\n",
      "15139 Traning Loss: tensor(0.0358)\n",
      "15140 Traning Loss: tensor(0.0350)\n",
      "15141 Traning Loss: tensor(0.0337)\n",
      "15142 Traning Loss: tensor(0.0333)\n",
      "15143 Traning Loss: tensor(0.0349)\n",
      "15144 Traning Loss: tensor(0.0332)\n",
      "15145 Traning Loss: tensor(0.0338)\n",
      "15146 Traning Loss: tensor(0.0341)\n",
      "15147 Traning Loss: tensor(0.0353)\n",
      "15148 Traning Loss: tensor(0.0342)\n",
      "15149 Traning Loss: tensor(0.0325)\n",
      "15150 Traning Loss: tensor(0.0328)\n",
      "15151 Traning Loss: tensor(0.0319)\n",
      "15152 Traning Loss: tensor(0.0333)\n",
      "15153 Traning Loss: tensor(0.0335)\n",
      "15154 Traning Loss: tensor(0.0338)\n",
      "15155 Traning Loss: tensor(0.0345)\n",
      "15156 Traning Loss: tensor(0.0338)\n",
      "15157 Traning Loss: tensor(0.0341)\n",
      "15158 Traning Loss: tensor(0.0339)\n",
      "15159 Traning Loss: tensor(0.0354)\n",
      "15160 Traning Loss: tensor(0.0328)\n",
      "15161 Traning Loss: tensor(0.0333)\n",
      "15162 Traning Loss: tensor(0.0336)\n",
      "15163 Traning Loss: tensor(0.0338)\n",
      "15164 Traning Loss: tensor(0.0327)\n",
      "15165 Traning Loss: tensor(0.0340)\n",
      "15166 Traning Loss: tensor(0.0315)\n",
      "15167 Traning Loss: tensor(0.0333)\n",
      "15168 Traning Loss: tensor(0.0349)\n",
      "15169 Traning Loss: tensor(0.0336)\n",
      "15170 Traning Loss: tensor(0.0325)\n",
      "15171 Traning Loss: tensor(0.0325)\n",
      "15172 Traning Loss: tensor(0.0324)\n",
      "15173 Traning Loss: tensor(0.0358)\n",
      "15174 Traning Loss: tensor(0.0330)\n",
      "15175 Traning Loss: tensor(0.0333)\n",
      "15176 Traning Loss: tensor(0.0359)\n",
      "15177 Traning Loss: tensor(0.0333)\n",
      "15178 Traning Loss: tensor(0.0346)\n",
      "15179 Traning Loss: tensor(0.0327)\n",
      "15180 Traning Loss: tensor(0.0353)\n",
      "15181 Traning Loss: tensor(0.0339)\n",
      "15182 Traning Loss: tensor(0.0361)\n",
      "15183 Traning Loss: tensor(0.0327)\n",
      "15184 Traning Loss: tensor(0.0366)\n",
      "15185 Traning Loss: tensor(0.0321)\n",
      "15186 Traning Loss: tensor(0.0339)\n",
      "15187 Traning Loss: tensor(0.0343)\n",
      "15188 Traning Loss: tensor(0.0336)\n",
      "15189 Traning Loss: tensor(0.0348)\n",
      "15190 Traning Loss: tensor(0.0361)\n",
      "15191 Traning Loss: tensor(0.0322)\n",
      "15192 Traning Loss: tensor(0.0357)\n",
      "15193 Traning Loss: tensor(0.0334)\n",
      "15194 Traning Loss: tensor(0.0318)\n",
      "15195 Traning Loss: tensor(0.0343)\n",
      "15196 Traning Loss: tensor(0.0337)\n",
      "15197 Traning Loss: tensor(0.0358)\n",
      "15198 Traning Loss: tensor(0.0350)\n",
      "15199 Traning Loss: tensor(0.0351)\n",
      "15200 Traning Loss: tensor(0.0312)\n",
      "15201 Traning Loss: tensor(0.0335)\n",
      "15202 Traning Loss: tensor(0.0332)\n",
      "15203 Traning Loss: tensor(0.0333)\n",
      "15204 Traning Loss: tensor(0.0343)\n",
      "15205 Traning Loss: tensor(0.0311)\n",
      "15206 Traning Loss: tensor(0.0336)\n",
      "15207 Traning Loss: tensor(0.0359)\n",
      "15208 Traning Loss: tensor(0.0370)\n",
      "15209 Traning Loss: tensor(0.0330)\n",
      "15210 Traning Loss: tensor(0.0349)\n",
      "15211 Traning Loss: tensor(0.0338)\n",
      "15212 Traning Loss: tensor(0.0347)\n",
      "15213 Traning Loss: tensor(0.0342)\n",
      "15214 Traning Loss: tensor(0.0337)\n",
      "15215 Traning Loss: tensor(0.0327)\n",
      "15216 Traning Loss: tensor(0.0338)\n",
      "15217 Traning Loss: tensor(0.0335)\n",
      "15218 Traning Loss: tensor(0.0334)\n",
      "15219 Traning Loss: tensor(0.0333)\n",
      "15220 Traning Loss: tensor(0.0342)\n",
      "15221 Traning Loss: tensor(0.0337)\n",
      "15222 Traning Loss: tensor(0.0342)\n",
      "15223 Traning Loss: tensor(0.0325)\n",
      "15224 Traning Loss: tensor(0.0354)\n",
      "15225 Traning Loss: tensor(0.0363)\n",
      "15226 Traning Loss: tensor(0.0354)\n",
      "15227 Traning Loss: tensor(0.0343)\n",
      "15228 Traning Loss: tensor(0.0351)\n",
      "15229 Traning Loss: tensor(0.0354)\n",
      "15230 Traning Loss: tensor(0.0335)\n",
      "15231 Traning Loss: tensor(0.0354)\n",
      "15232 Traning Loss: tensor(0.0337)\n",
      "15233 Traning Loss: tensor(0.0352)\n",
      "15234 Traning Loss: tensor(0.0357)\n",
      "15235 Traning Loss: tensor(0.0361)\n",
      "15236 Traning Loss: tensor(0.0368)\n",
      "15237 Traning Loss: tensor(0.0342)\n",
      "15238 Traning Loss: tensor(0.0340)\n",
      "15239 Traning Loss: tensor(0.0344)\n",
      "15240 Traning Loss: tensor(0.0331)\n",
      "15241 Traning Loss: tensor(0.0361)\n",
      "15242 Traning Loss: tensor(0.0329)\n",
      "15243 Traning Loss: tensor(0.0343)\n",
      "15244 Traning Loss: tensor(0.0338)\n",
      "15245 Traning Loss: tensor(0.0334)\n",
      "15246 Traning Loss: tensor(0.0346)\n",
      "15247 Traning Loss: tensor(0.0357)\n",
      "15248 Traning Loss: tensor(0.0335)\n",
      "15249 Traning Loss: tensor(0.0349)\n",
      "15250 Traning Loss: tensor(0.0369)\n",
      "15251 Traning Loss: tensor(0.0323)\n",
      "15252 Traning Loss: tensor(0.0336)\n",
      "15253 Traning Loss: tensor(0.0349)\n",
      "15254 Traning Loss: tensor(0.0323)\n",
      "15255 Traning Loss: tensor(0.0345)\n",
      "15256 Traning Loss: tensor(0.0334)\n",
      "15257 Traning Loss: tensor(0.0356)\n",
      "15258 Traning Loss: tensor(0.0326)\n",
      "15259 Traning Loss: tensor(0.0336)\n",
      "15260 Traning Loss: tensor(0.0354)\n",
      "15261 Traning Loss: tensor(0.0330)\n",
      "15262 Traning Loss: tensor(0.0341)\n",
      "15263 Traning Loss: tensor(0.0336)\n",
      "15264 Traning Loss: tensor(0.0325)\n",
      "15265 Traning Loss: tensor(0.0317)\n",
      "15266 Traning Loss: tensor(0.0315)\n",
      "15267 Traning Loss: tensor(0.0339)\n",
      "15268 Traning Loss: tensor(0.0331)\n",
      "15269 Traning Loss: tensor(0.0319)\n",
      "15270 Traning Loss: tensor(0.0337)\n",
      "15271 Traning Loss: tensor(0.0337)\n",
      "15272 Traning Loss: tensor(0.0341)\n",
      "15273 Traning Loss: tensor(0.0344)\n",
      "15274 Traning Loss: tensor(0.0357)\n",
      "15275 Traning Loss: tensor(0.0347)\n",
      "15276 Traning Loss: tensor(0.0325)\n",
      "15277 Traning Loss: tensor(0.0328)\n",
      "15278 Traning Loss: tensor(0.0348)\n",
      "15279 Traning Loss: tensor(0.0333)\n",
      "15280 Traning Loss: tensor(0.0333)\n",
      "15281 Traning Loss: tensor(0.0323)\n",
      "15282 Traning Loss: tensor(0.0314)\n",
      "15283 Traning Loss: tensor(0.0328)\n",
      "15284 Traning Loss: tensor(0.0322)\n",
      "15285 Traning Loss: tensor(0.0337)\n",
      "15286 Traning Loss: tensor(0.0341)\n",
      "15287 Traning Loss: tensor(0.0333)\n",
      "15288 Traning Loss: tensor(0.0336)\n",
      "15289 Traning Loss: tensor(0.0334)\n",
      "15290 Traning Loss: tensor(0.0383)\n",
      "15291 Traning Loss: tensor(0.0328)\n",
      "15292 Traning Loss: tensor(0.0321)\n",
      "15293 Traning Loss: tensor(0.0347)\n",
      "15294 Traning Loss: tensor(0.0331)\n",
      "15295 Traning Loss: tensor(0.0320)\n",
      "15296 Traning Loss: tensor(0.0330)\n",
      "15297 Traning Loss: tensor(0.0335)\n",
      "15298 Traning Loss: tensor(0.0322)\n",
      "15299 Traning Loss: tensor(0.0343)\n",
      "15300 Traning Loss: tensor(0.0336)\n",
      "15301 Traning Loss: tensor(0.0332)\n",
      "15302 Traning Loss: tensor(0.0328)\n",
      "15303 Traning Loss: tensor(0.0340)\n",
      "15304 Traning Loss: tensor(0.0343)\n",
      "15305 Traning Loss: tensor(0.0351)\n",
      "15306 Traning Loss: tensor(0.0344)\n",
      "15307 Traning Loss: tensor(0.0344)\n",
      "15308 Traning Loss: tensor(0.0319)\n",
      "15309 Traning Loss: tensor(0.0339)\n",
      "15310 Traning Loss: tensor(0.0325)\n",
      "15311 Traning Loss: tensor(0.0319)\n",
      "15312 Traning Loss: tensor(0.0332)\n",
      "15313 Traning Loss: tensor(0.0321)\n",
      "15314 Traning Loss: tensor(0.0339)\n",
      "15315 Traning Loss: tensor(0.0333)\n",
      "15316 Traning Loss: tensor(0.0343)\n",
      "15317 Traning Loss: tensor(0.0331)\n",
      "15318 Traning Loss: tensor(0.0317)\n",
      "15319 Traning Loss: tensor(0.0344)\n",
      "15320 Traning Loss: tensor(0.0330)\n",
      "15321 Traning Loss: tensor(0.0324)\n",
      "15322 Traning Loss: tensor(0.0319)\n",
      "15323 Traning Loss: tensor(0.0333)\n",
      "15324 Traning Loss: tensor(0.0339)\n",
      "15325 Traning Loss: tensor(0.0318)\n",
      "15326 Traning Loss: tensor(0.0343)\n",
      "15327 Traning Loss: tensor(0.0354)\n",
      "15328 Traning Loss: tensor(0.0322)\n",
      "15329 Traning Loss: tensor(0.0330)\n",
      "15330 Traning Loss: tensor(0.0321)\n",
      "15331 Traning Loss: tensor(0.0320)\n",
      "15332 Traning Loss: tensor(0.0322)\n",
      "15333 Traning Loss: tensor(0.0331)\n",
      "15334 Traning Loss: tensor(0.0331)\n",
      "15335 Traning Loss: tensor(0.0317)\n",
      "15336 Traning Loss: tensor(0.0335)\n",
      "15337 Traning Loss: tensor(0.0305)\n",
      "15338 Traning Loss: tensor(0.0328)\n",
      "15339 Traning Loss: tensor(0.0334)\n",
      "15340 Traning Loss: tensor(0.0320)\n",
      "15341 Traning Loss: tensor(0.0319)\n",
      "15342 Traning Loss: tensor(0.0324)\n",
      "15343 Traning Loss: tensor(0.0344)\n",
      "15344 Traning Loss: tensor(0.0335)\n",
      "15345 Traning Loss: tensor(0.0339)\n",
      "15346 Traning Loss: tensor(0.0324)\n",
      "15347 Traning Loss: tensor(0.0346)\n",
      "15348 Traning Loss: tensor(0.0347)\n",
      "15349 Traning Loss: tensor(0.0354)\n",
      "15350 Traning Loss: tensor(0.0353)\n",
      "15351 Traning Loss: tensor(0.0350)\n",
      "15352 Traning Loss: tensor(0.0343)\n",
      "15353 Traning Loss: tensor(0.0328)\n",
      "15354 Traning Loss: tensor(0.0328)\n",
      "15355 Traning Loss: tensor(0.0337)\n",
      "15356 Traning Loss: tensor(0.0347)\n",
      "15357 Traning Loss: tensor(0.0334)\n",
      "15358 Traning Loss: tensor(0.0330)\n",
      "15359 Traning Loss: tensor(0.0354)\n",
      "15360 Traning Loss: tensor(0.0337)\n",
      "15361 Traning Loss: tensor(0.0327)\n",
      "15362 Traning Loss: tensor(0.0351)\n",
      "15363 Traning Loss: tensor(0.0344)\n",
      "15364 Traning Loss: tensor(0.0327)\n",
      "15365 Traning Loss: tensor(0.0322)\n",
      "15366 Traning Loss: tensor(0.0329)\n",
      "15367 Traning Loss: tensor(0.0333)\n",
      "15368 Traning Loss: tensor(0.0349)\n",
      "15369 Traning Loss: tensor(0.0349)\n",
      "15370 Traning Loss: tensor(0.0335)\n",
      "15371 Traning Loss: tensor(0.0315)\n",
      "15372 Traning Loss: tensor(0.0334)\n",
      "15373 Traning Loss: tensor(0.0343)\n",
      "15374 Traning Loss: tensor(0.0340)\n",
      "15375 Traning Loss: tensor(0.0311)\n",
      "15376 Traning Loss: tensor(0.0333)\n",
      "15377 Traning Loss: tensor(0.0356)\n",
      "15378 Traning Loss: tensor(0.0337)\n",
      "15379 Traning Loss: tensor(0.0332)\n",
      "15380 Traning Loss: tensor(0.0326)\n",
      "15381 Traning Loss: tensor(0.0335)\n",
      "15382 Traning Loss: tensor(0.0346)\n",
      "15383 Traning Loss: tensor(0.0324)\n",
      "15384 Traning Loss: tensor(0.0336)\n",
      "15385 Traning Loss: tensor(0.0339)\n",
      "15386 Traning Loss: tensor(0.0347)\n",
      "15387 Traning Loss: tensor(0.0358)\n",
      "15388 Traning Loss: tensor(0.0339)\n",
      "15389 Traning Loss: tensor(0.0342)\n",
      "15390 Traning Loss: tensor(0.0336)\n",
      "15391 Traning Loss: tensor(0.0381)\n",
      "15392 Traning Loss: tensor(0.0353)\n",
      "15393 Traning Loss: tensor(0.0353)\n",
      "15394 Traning Loss: tensor(0.0351)\n",
      "15395 Traning Loss: tensor(0.0339)\n",
      "15396 Traning Loss: tensor(0.0327)\n",
      "15397 Traning Loss: tensor(0.0351)\n",
      "15398 Traning Loss: tensor(0.0362)\n",
      "15399 Traning Loss: tensor(0.0332)\n",
      "15400 Traning Loss: tensor(0.0337)\n",
      "15401 Traning Loss: tensor(0.0325)\n",
      "15402 Traning Loss: tensor(0.0349)\n",
      "15403 Traning Loss: tensor(0.0330)\n",
      "15404 Traning Loss: tensor(0.0342)\n",
      "15405 Traning Loss: tensor(0.0363)\n",
      "15406 Traning Loss: tensor(0.0364)\n",
      "15407 Traning Loss: tensor(0.0336)\n",
      "15408 Traning Loss: tensor(0.0349)\n",
      "15409 Traning Loss: tensor(0.0323)\n",
      "15410 Traning Loss: tensor(0.0328)\n",
      "15411 Traning Loss: tensor(0.0329)\n",
      "15412 Traning Loss: tensor(0.0329)\n",
      "15413 Traning Loss: tensor(0.0349)\n",
      "15414 Traning Loss: tensor(0.0322)\n",
      "15415 Traning Loss: tensor(0.0329)\n",
      "15416 Traning Loss: tensor(0.0348)\n",
      "15417 Traning Loss: tensor(0.0349)\n",
      "15418 Traning Loss: tensor(0.0331)\n",
      "15419 Traning Loss: tensor(0.0333)\n",
      "15420 Traning Loss: tensor(0.0323)\n",
      "15421 Traning Loss: tensor(0.0337)\n",
      "15422 Traning Loss: tensor(0.0356)\n",
      "15423 Traning Loss: tensor(0.0344)\n",
      "15424 Traning Loss: tensor(0.0316)\n",
      "15425 Traning Loss: tensor(0.0332)\n",
      "15426 Traning Loss: tensor(0.0336)\n",
      "15427 Traning Loss: tensor(0.0324)\n",
      "15428 Traning Loss: tensor(0.0329)\n",
      "15429 Traning Loss: tensor(0.0333)\n",
      "15430 Traning Loss: tensor(0.0332)\n",
      "15431 Traning Loss: tensor(0.0338)\n",
      "15432 Traning Loss: tensor(0.0319)\n",
      "15433 Traning Loss: tensor(0.0332)\n",
      "15434 Traning Loss: tensor(0.0346)\n",
      "15435 Traning Loss: tensor(0.0333)\n",
      "15436 Traning Loss: tensor(0.0322)\n",
      "15437 Traning Loss: tensor(0.0322)\n",
      "15438 Traning Loss: tensor(0.0316)\n",
      "15439 Traning Loss: tensor(0.0357)\n",
      "15440 Traning Loss: tensor(0.0356)\n",
      "15441 Traning Loss: tensor(0.0331)\n",
      "15442 Traning Loss: tensor(0.0330)\n",
      "15443 Traning Loss: tensor(0.0337)\n",
      "15444 Traning Loss: tensor(0.0362)\n",
      "15445 Traning Loss: tensor(0.0331)\n",
      "15446 Traning Loss: tensor(0.0341)\n",
      "15447 Traning Loss: tensor(0.0352)\n",
      "15448 Traning Loss: tensor(0.0324)\n",
      "15449 Traning Loss: tensor(0.0327)\n",
      "15450 Traning Loss: tensor(0.0325)\n",
      "15451 Traning Loss: tensor(0.0352)\n",
      "15452 Traning Loss: tensor(0.0314)\n",
      "15453 Traning Loss: tensor(0.0318)\n",
      "15454 Traning Loss: tensor(0.0336)\n",
      "15455 Traning Loss: tensor(0.0321)\n",
      "15456 Traning Loss: tensor(0.0325)\n",
      "15457 Traning Loss: tensor(0.0345)\n",
      "15458 Traning Loss: tensor(0.0343)\n",
      "15459 Traning Loss: tensor(0.0346)\n",
      "15460 Traning Loss: tensor(0.0353)\n",
      "15461 Traning Loss: tensor(0.0318)\n",
      "15462 Traning Loss: tensor(0.0351)\n",
      "15463 Traning Loss: tensor(0.0320)\n",
      "15464 Traning Loss: tensor(0.0341)\n",
      "15465 Traning Loss: tensor(0.0347)\n",
      "15466 Traning Loss: tensor(0.0327)\n",
      "15467 Traning Loss: tensor(0.0338)\n",
      "15468 Traning Loss: tensor(0.0367)\n",
      "15469 Traning Loss: tensor(0.0338)\n",
      "15470 Traning Loss: tensor(0.0350)\n",
      "15471 Traning Loss: tensor(0.0338)\n",
      "15472 Traning Loss: tensor(0.0345)\n",
      "15473 Traning Loss: tensor(0.0326)\n",
      "15474 Traning Loss: tensor(0.0346)\n",
      "15475 Traning Loss: tensor(0.0334)\n",
      "15476 Traning Loss: tensor(0.0321)\n",
      "15477 Traning Loss: tensor(0.0375)\n",
      "15478 Traning Loss: tensor(0.0334)\n",
      "15479 Traning Loss: tensor(0.0349)\n",
      "15480 Traning Loss: tensor(0.0335)\n",
      "15481 Traning Loss: tensor(0.0341)\n",
      "15482 Traning Loss: tensor(0.0327)\n",
      "15483 Traning Loss: tensor(0.0306)\n",
      "15484 Traning Loss: tensor(0.0328)\n",
      "15485 Traning Loss: tensor(0.0330)\n",
      "15486 Traning Loss: tensor(0.0332)\n",
      "15487 Traning Loss: tensor(0.0336)\n",
      "15488 Traning Loss: tensor(0.0348)\n",
      "15489 Traning Loss: tensor(0.0346)\n",
      "15490 Traning Loss: tensor(0.0333)\n",
      "15491 Traning Loss: tensor(0.0313)\n",
      "15492 Traning Loss: tensor(0.0331)\n",
      "15493 Traning Loss: tensor(0.0331)\n",
      "15494 Traning Loss: tensor(0.0330)\n",
      "15495 Traning Loss: tensor(0.0352)\n",
      "15496 Traning Loss: tensor(0.0324)\n",
      "15497 Traning Loss: tensor(0.0344)\n",
      "15498 Traning Loss: tensor(0.0316)\n",
      "15499 Traning Loss: tensor(0.0338)\n",
      "15500 Traning Loss: tensor(0.0327)\n",
      "15501 Traning Loss: tensor(0.0324)\n",
      "15502 Traning Loss: tensor(0.0336)\n",
      "15503 Traning Loss: tensor(0.0323)\n",
      "15504 Traning Loss: tensor(0.0340)\n",
      "15505 Traning Loss: tensor(0.0340)\n",
      "15506 Traning Loss: tensor(0.0331)\n",
      "15507 Traning Loss: tensor(0.0317)\n",
      "15508 Traning Loss: tensor(0.0324)\n",
      "15509 Traning Loss: tensor(0.0345)\n",
      "15510 Traning Loss: tensor(0.0325)\n",
      "15511 Traning Loss: tensor(0.0341)\n",
      "15512 Traning Loss: tensor(0.0329)\n",
      "15513 Traning Loss: tensor(0.0334)\n",
      "15514 Traning Loss: tensor(0.0327)\n",
      "15515 Traning Loss: tensor(0.0325)\n",
      "15516 Traning Loss: tensor(0.0358)\n",
      "15517 Traning Loss: tensor(0.0334)\n",
      "15518 Traning Loss: tensor(0.0322)\n",
      "15519 Traning Loss: tensor(0.0326)\n",
      "15520 Traning Loss: tensor(0.0332)\n",
      "15521 Traning Loss: tensor(0.0357)\n",
      "15522 Traning Loss: tensor(0.0326)\n",
      "15523 Traning Loss: tensor(0.0325)\n",
      "15524 Traning Loss: tensor(0.0315)\n",
      "15525 Traning Loss: tensor(0.0335)\n",
      "15526 Traning Loss: tensor(0.0321)\n",
      "15527 Traning Loss: tensor(0.0314)\n",
      "15528 Traning Loss: tensor(0.0322)\n",
      "15529 Traning Loss: tensor(0.0327)\n",
      "15530 Traning Loss: tensor(0.0326)\n",
      "15531 Traning Loss: tensor(0.0327)\n",
      "15532 Traning Loss: tensor(0.0326)\n",
      "15533 Traning Loss: tensor(0.0349)\n",
      "15534 Traning Loss: tensor(0.0346)\n",
      "15535 Traning Loss: tensor(0.0337)\n",
      "15536 Traning Loss: tensor(0.0368)\n",
      "15537 Traning Loss: tensor(0.0342)\n",
      "15538 Traning Loss: tensor(0.0347)\n",
      "15539 Traning Loss: tensor(0.0348)\n",
      "15540 Traning Loss: tensor(0.0327)\n",
      "15541 Traning Loss: tensor(0.0312)\n",
      "15542 Traning Loss: tensor(0.0329)\n",
      "15543 Traning Loss: tensor(0.0320)\n",
      "15544 Traning Loss: tensor(0.0321)\n",
      "15545 Traning Loss: tensor(0.0329)\n",
      "15546 Traning Loss: tensor(0.0332)\n",
      "15547 Traning Loss: tensor(0.0316)\n",
      "15548 Traning Loss: tensor(0.0345)\n",
      "15549 Traning Loss: tensor(0.0346)\n",
      "15550 Traning Loss: tensor(0.0343)\n",
      "15551 Traning Loss: tensor(0.0336)\n",
      "15552 Traning Loss: tensor(0.0334)\n",
      "15553 Traning Loss: tensor(0.0334)\n",
      "15554 Traning Loss: tensor(0.0332)\n",
      "15555 Traning Loss: tensor(0.0320)\n",
      "15556 Traning Loss: tensor(0.0329)\n",
      "15557 Traning Loss: tensor(0.0329)\n",
      "15558 Traning Loss: tensor(0.0332)\n",
      "15559 Traning Loss: tensor(0.0329)\n",
      "15560 Traning Loss: tensor(0.0331)\n",
      "15561 Traning Loss: tensor(0.0339)\n",
      "15562 Traning Loss: tensor(0.0333)\n",
      "15563 Traning Loss: tensor(0.0344)\n",
      "15564 Traning Loss: tensor(0.0334)\n",
      "15565 Traning Loss: tensor(0.0328)\n",
      "15566 Traning Loss: tensor(0.0327)\n",
      "15567 Traning Loss: tensor(0.0353)\n",
      "15568 Traning Loss: tensor(0.0339)\n",
      "15569 Traning Loss: tensor(0.0352)\n",
      "15570 Traning Loss: tensor(0.0325)\n",
      "15571 Traning Loss: tensor(0.0322)\n",
      "15572 Traning Loss: tensor(0.0353)\n",
      "15573 Traning Loss: tensor(0.0350)\n",
      "15574 Traning Loss: tensor(0.0318)\n",
      "15575 Traning Loss: tensor(0.0310)\n",
      "15576 Traning Loss: tensor(0.0332)\n",
      "15577 Traning Loss: tensor(0.0346)\n",
      "15578 Traning Loss: tensor(0.0319)\n",
      "15579 Traning Loss: tensor(0.0334)\n",
      "15580 Traning Loss: tensor(0.0351)\n",
      "15581 Traning Loss: tensor(0.0339)\n",
      "15582 Traning Loss: tensor(0.0329)\n",
      "15583 Traning Loss: tensor(0.0324)\n",
      "15584 Traning Loss: tensor(0.0335)\n",
      "15585 Traning Loss: tensor(0.0342)\n",
      "15586 Traning Loss: tensor(0.0332)\n",
      "15587 Traning Loss: tensor(0.0338)\n",
      "15588 Traning Loss: tensor(0.0339)\n",
      "15589 Traning Loss: tensor(0.0329)\n",
      "15590 Traning Loss: tensor(0.0327)\n",
      "15591 Traning Loss: tensor(0.0341)\n",
      "15592 Traning Loss: tensor(0.0326)\n",
      "15593 Traning Loss: tensor(0.0343)\n",
      "15594 Traning Loss: tensor(0.0340)\n",
      "15595 Traning Loss: tensor(0.0323)\n",
      "15596 Traning Loss: tensor(0.0304)\n",
      "15597 Traning Loss: tensor(0.0324)\n",
      "15598 Traning Loss: tensor(0.0336)\n",
      "15599 Traning Loss: tensor(0.0327)\n",
      "15600 Traning Loss: tensor(0.0306)\n",
      "15601 Traning Loss: tensor(0.0318)\n",
      "15602 Traning Loss: tensor(0.0321)\n",
      "15603 Traning Loss: tensor(0.0343)\n",
      "15604 Traning Loss: tensor(0.0333)\n",
      "15605 Traning Loss: tensor(0.0324)\n",
      "15606 Traning Loss: tensor(0.0322)\n",
      "15607 Traning Loss: tensor(0.0326)\n",
      "15608 Traning Loss: tensor(0.0329)\n",
      "15609 Traning Loss: tensor(0.0334)\n",
      "15610 Traning Loss: tensor(0.0325)\n",
      "15611 Traning Loss: tensor(0.0340)\n",
      "15612 Traning Loss: tensor(0.0324)\n",
      "15613 Traning Loss: tensor(0.0329)\n",
      "15614 Traning Loss: tensor(0.0335)\n",
      "15615 Traning Loss: tensor(0.0339)\n",
      "15616 Traning Loss: tensor(0.0346)\n",
      "15617 Traning Loss: tensor(0.0312)\n",
      "15618 Traning Loss: tensor(0.0321)\n",
      "15619 Traning Loss: tensor(0.0350)\n",
      "15620 Traning Loss: tensor(0.0336)\n",
      "15621 Traning Loss: tensor(0.0317)\n",
      "15622 Traning Loss: tensor(0.0330)\n",
      "15623 Traning Loss: tensor(0.0343)\n",
      "15624 Traning Loss: tensor(0.0350)\n",
      "15625 Traning Loss: tensor(0.0341)\n",
      "15626 Traning Loss: tensor(0.0320)\n",
      "15627 Traning Loss: tensor(0.0319)\n",
      "15628 Traning Loss: tensor(0.0320)\n",
      "15629 Traning Loss: tensor(0.0335)\n",
      "15630 Traning Loss: tensor(0.0323)\n",
      "15631 Traning Loss: tensor(0.0338)\n",
      "15632 Traning Loss: tensor(0.0327)\n",
      "15633 Traning Loss: tensor(0.0351)\n",
      "15634 Traning Loss: tensor(0.0328)\n",
      "15635 Traning Loss: tensor(0.0329)\n",
      "15636 Traning Loss: tensor(0.0339)\n",
      "15637 Traning Loss: tensor(0.0340)\n",
      "15638 Traning Loss: tensor(0.0337)\n",
      "15639 Traning Loss: tensor(0.0322)\n",
      "15640 Traning Loss: tensor(0.0340)\n",
      "15641 Traning Loss: tensor(0.0323)\n",
      "15642 Traning Loss: tensor(0.0340)\n",
      "15643 Traning Loss: tensor(0.0330)\n",
      "15644 Traning Loss: tensor(0.0338)\n",
      "15645 Traning Loss: tensor(0.0328)\n",
      "15646 Traning Loss: tensor(0.0342)\n",
      "15647 Traning Loss: tensor(0.0326)\n",
      "15648 Traning Loss: tensor(0.0338)\n",
      "15649 Traning Loss: tensor(0.0332)\n",
      "15650 Traning Loss: tensor(0.0324)\n",
      "15651 Traning Loss: tensor(0.0312)\n",
      "15652 Traning Loss: tensor(0.0326)\n",
      "15653 Traning Loss: tensor(0.0332)\n",
      "15654 Traning Loss: tensor(0.0336)\n",
      "15655 Traning Loss: tensor(0.0338)\n",
      "15656 Traning Loss: tensor(0.0327)\n",
      "15657 Traning Loss: tensor(0.0325)\n",
      "15658 Traning Loss: tensor(0.0335)\n",
      "15659 Traning Loss: tensor(0.0337)\n",
      "15660 Traning Loss: tensor(0.0332)\n",
      "15661 Traning Loss: tensor(0.0328)\n",
      "15662 Traning Loss: tensor(0.0311)\n",
      "15663 Traning Loss: tensor(0.0337)\n",
      "15664 Traning Loss: tensor(0.0337)\n",
      "15665 Traning Loss: tensor(0.0329)\n",
      "15666 Traning Loss: tensor(0.0316)\n",
      "15667 Traning Loss: tensor(0.0329)\n",
      "15668 Traning Loss: tensor(0.0337)\n",
      "15669 Traning Loss: tensor(0.0334)\n",
      "15670 Traning Loss: tensor(0.0330)\n",
      "15671 Traning Loss: tensor(0.0356)\n",
      "15672 Traning Loss: tensor(0.0347)\n",
      "15673 Traning Loss: tensor(0.0321)\n",
      "15674 Traning Loss: tensor(0.0339)\n",
      "15675 Traning Loss: tensor(0.0318)\n",
      "15676 Traning Loss: tensor(0.0337)\n",
      "15677 Traning Loss: tensor(0.0323)\n",
      "15678 Traning Loss: tensor(0.0325)\n",
      "15679 Traning Loss: tensor(0.0335)\n",
      "15680 Traning Loss: tensor(0.0348)\n",
      "15681 Traning Loss: tensor(0.0339)\n",
      "15682 Traning Loss: tensor(0.0346)\n",
      "15683 Traning Loss: tensor(0.0356)\n",
      "15684 Traning Loss: tensor(0.0338)\n",
      "15685 Traning Loss: tensor(0.0343)\n",
      "15686 Traning Loss: tensor(0.0364)\n",
      "15687 Traning Loss: tensor(0.0324)\n",
      "15688 Traning Loss: tensor(0.0328)\n",
      "15689 Traning Loss: tensor(0.0322)\n",
      "15690 Traning Loss: tensor(0.0335)\n",
      "15691 Traning Loss: tensor(0.0337)\n",
      "15692 Traning Loss: tensor(0.0339)\n",
      "15693 Traning Loss: tensor(0.0326)\n",
      "15694 Traning Loss: tensor(0.0328)\n",
      "15695 Traning Loss: tensor(0.0344)\n",
      "15696 Traning Loss: tensor(0.0327)\n",
      "15697 Traning Loss: tensor(0.0331)\n",
      "15698 Traning Loss: tensor(0.0336)\n",
      "15699 Traning Loss: tensor(0.0339)\n",
      "15700 Traning Loss: tensor(0.0339)\n",
      "15701 Traning Loss: tensor(0.0319)\n",
      "15702 Traning Loss: tensor(0.0339)\n",
      "15703 Traning Loss: tensor(0.0320)\n",
      "15704 Traning Loss: tensor(0.0314)\n",
      "15705 Traning Loss: tensor(0.0322)\n",
      "15706 Traning Loss: tensor(0.0336)\n",
      "15707 Traning Loss: tensor(0.0313)\n",
      "15708 Traning Loss: tensor(0.0336)\n",
      "15709 Traning Loss: tensor(0.0321)\n",
      "15710 Traning Loss: tensor(0.0321)\n",
      "15711 Traning Loss: tensor(0.0320)\n",
      "15712 Traning Loss: tensor(0.0316)\n",
      "15713 Traning Loss: tensor(0.0322)\n",
      "15714 Traning Loss: tensor(0.0326)\n",
      "15715 Traning Loss: tensor(0.0342)\n",
      "15716 Traning Loss: tensor(0.0314)\n",
      "15717 Traning Loss: tensor(0.0324)\n",
      "15718 Traning Loss: tensor(0.0327)\n",
      "15719 Traning Loss: tensor(0.0342)\n",
      "15720 Traning Loss: tensor(0.0331)\n",
      "15721 Traning Loss: tensor(0.0338)\n",
      "15722 Traning Loss: tensor(0.0335)\n",
      "15723 Traning Loss: tensor(0.0317)\n",
      "15724 Traning Loss: tensor(0.0338)\n",
      "15725 Traning Loss: tensor(0.0322)\n",
      "15726 Traning Loss: tensor(0.0334)\n",
      "15727 Traning Loss: tensor(0.0326)\n",
      "15728 Traning Loss: tensor(0.0342)\n",
      "15729 Traning Loss: tensor(0.0325)\n",
      "15730 Traning Loss: tensor(0.0337)\n",
      "15731 Traning Loss: tensor(0.0329)\n",
      "15732 Traning Loss: tensor(0.0320)\n",
      "15733 Traning Loss: tensor(0.0346)\n",
      "15734 Traning Loss: tensor(0.0322)\n",
      "15735 Traning Loss: tensor(0.0339)\n",
      "15736 Traning Loss: tensor(0.0332)\n",
      "15737 Traning Loss: tensor(0.0328)\n",
      "15738 Traning Loss: tensor(0.0321)\n",
      "15739 Traning Loss: tensor(0.0320)\n",
      "15740 Traning Loss: tensor(0.0342)\n",
      "15741 Traning Loss: tensor(0.0328)\n",
      "15742 Traning Loss: tensor(0.0346)\n",
      "15743 Traning Loss: tensor(0.0341)\n",
      "15744 Traning Loss: tensor(0.0348)\n",
      "15745 Traning Loss: tensor(0.0340)\n",
      "15746 Traning Loss: tensor(0.0330)\n",
      "15747 Traning Loss: tensor(0.0331)\n",
      "15748 Traning Loss: tensor(0.0341)\n",
      "15749 Traning Loss: tensor(0.0329)\n",
      "15750 Traning Loss: tensor(0.0313)\n",
      "15751 Traning Loss: tensor(0.0335)\n",
      "15752 Traning Loss: tensor(0.0333)\n",
      "15753 Traning Loss: tensor(0.0334)\n",
      "15754 Traning Loss: tensor(0.0330)\n",
      "15755 Traning Loss: tensor(0.0326)\n",
      "15756 Traning Loss: tensor(0.0318)\n",
      "15757 Traning Loss: tensor(0.0333)\n",
      "15758 Traning Loss: tensor(0.0337)\n",
      "15759 Traning Loss: tensor(0.0329)\n",
      "15760 Traning Loss: tensor(0.0336)\n",
      "15761 Traning Loss: tensor(0.0340)\n",
      "15762 Traning Loss: tensor(0.0337)\n",
      "15763 Traning Loss: tensor(0.0337)\n",
      "15764 Traning Loss: tensor(0.0330)\n",
      "15765 Traning Loss: tensor(0.0323)\n",
      "15766 Traning Loss: tensor(0.0337)\n",
      "15767 Traning Loss: tensor(0.0319)\n",
      "15768 Traning Loss: tensor(0.0329)\n",
      "15769 Traning Loss: tensor(0.0332)\n",
      "15770 Traning Loss: tensor(0.0328)\n",
      "15771 Traning Loss: tensor(0.0333)\n",
      "15772 Traning Loss: tensor(0.0328)\n",
      "15773 Traning Loss: tensor(0.0328)\n",
      "15774 Traning Loss: tensor(0.0361)\n",
      "15775 Traning Loss: tensor(0.0338)\n",
      "15776 Traning Loss: tensor(0.0312)\n",
      "15777 Traning Loss: tensor(0.0321)\n",
      "15778 Traning Loss: tensor(0.0327)\n",
      "15779 Traning Loss: tensor(0.0317)\n",
      "15780 Traning Loss: tensor(0.0324)\n",
      "15781 Traning Loss: tensor(0.0337)\n",
      "15782 Traning Loss: tensor(0.0345)\n",
      "15783 Traning Loss: tensor(0.0310)\n",
      "15784 Traning Loss: tensor(0.0329)\n",
      "15785 Traning Loss: tensor(0.0312)\n",
      "15786 Traning Loss: tensor(0.0322)\n",
      "15787 Traning Loss: tensor(0.0363)\n",
      "15788 Traning Loss: tensor(0.0324)\n",
      "15789 Traning Loss: tensor(0.0333)\n",
      "15790 Traning Loss: tensor(0.0324)\n",
      "15791 Traning Loss: tensor(0.0339)\n",
      "15792 Traning Loss: tensor(0.0320)\n",
      "15793 Traning Loss: tensor(0.0318)\n",
      "15794 Traning Loss: tensor(0.0326)\n",
      "15795 Traning Loss: tensor(0.0311)\n",
      "15796 Traning Loss: tensor(0.0327)\n",
      "15797 Traning Loss: tensor(0.0325)\n",
      "15798 Traning Loss: tensor(0.0314)\n",
      "15799 Traning Loss: tensor(0.0317)\n",
      "15800 Traning Loss: tensor(0.0327)\n",
      "15801 Traning Loss: tensor(0.0313)\n",
      "15802 Traning Loss: tensor(0.0323)\n",
      "15803 Traning Loss: tensor(0.0319)\n",
      "15804 Traning Loss: tensor(0.0348)\n",
      "15805 Traning Loss: tensor(0.0333)\n",
      "15806 Traning Loss: tensor(0.0312)\n",
      "15807 Traning Loss: tensor(0.0335)\n",
      "15808 Traning Loss: tensor(0.0331)\n",
      "15809 Traning Loss: tensor(0.0318)\n",
      "15810 Traning Loss: tensor(0.0339)\n",
      "15811 Traning Loss: tensor(0.0316)\n",
      "15812 Traning Loss: tensor(0.0338)\n",
      "15813 Traning Loss: tensor(0.0320)\n",
      "15814 Traning Loss: tensor(0.0330)\n",
      "15815 Traning Loss: tensor(0.0315)\n",
      "15816 Traning Loss: tensor(0.0312)\n",
      "15817 Traning Loss: tensor(0.0334)\n",
      "15818 Traning Loss: tensor(0.0319)\n",
      "15819 Traning Loss: tensor(0.0342)\n",
      "15820 Traning Loss: tensor(0.0329)\n",
      "15821 Traning Loss: tensor(0.0329)\n",
      "15822 Traning Loss: tensor(0.0346)\n",
      "15823 Traning Loss: tensor(0.0351)\n",
      "15824 Traning Loss: tensor(0.0333)\n",
      "15825 Traning Loss: tensor(0.0325)\n",
      "15826 Traning Loss: tensor(0.0315)\n",
      "15827 Traning Loss: tensor(0.0320)\n",
      "15828 Traning Loss: tensor(0.0324)\n",
      "15829 Traning Loss: tensor(0.0327)\n",
      "15830 Traning Loss: tensor(0.0336)\n",
      "15831 Traning Loss: tensor(0.0339)\n",
      "15832 Traning Loss: tensor(0.0321)\n",
      "15833 Traning Loss: tensor(0.0335)\n",
      "15834 Traning Loss: tensor(0.0301)\n",
      "15835 Traning Loss: tensor(0.0339)\n",
      "15836 Traning Loss: tensor(0.0315)\n",
      "15837 Traning Loss: tensor(0.0349)\n",
      "15838 Traning Loss: tensor(0.0332)\n",
      "15839 Traning Loss: tensor(0.0332)\n",
      "15840 Traning Loss: tensor(0.0346)\n",
      "15841 Traning Loss: tensor(0.0316)\n",
      "15842 Traning Loss: tensor(0.0326)\n",
      "15843 Traning Loss: tensor(0.0324)\n",
      "15844 Traning Loss: tensor(0.0323)\n",
      "15845 Traning Loss: tensor(0.0320)\n",
      "15846 Traning Loss: tensor(0.0339)\n",
      "15847 Traning Loss: tensor(0.0316)\n",
      "15848 Traning Loss: tensor(0.0333)\n",
      "15849 Traning Loss: tensor(0.0316)\n",
      "15850 Traning Loss: tensor(0.0336)\n",
      "15851 Traning Loss: tensor(0.0343)\n",
      "15852 Traning Loss: tensor(0.0337)\n",
      "15853 Traning Loss: tensor(0.0322)\n",
      "15854 Traning Loss: tensor(0.0326)\n",
      "15855 Traning Loss: tensor(0.0339)\n",
      "15856 Traning Loss: tensor(0.0339)\n",
      "15857 Traning Loss: tensor(0.0321)\n",
      "15858 Traning Loss: tensor(0.0336)\n",
      "15859 Traning Loss: tensor(0.0322)\n",
      "15860 Traning Loss: tensor(0.0329)\n",
      "15861 Traning Loss: tensor(0.0339)\n",
      "15862 Traning Loss: tensor(0.0323)\n",
      "15863 Traning Loss: tensor(0.0331)\n",
      "15864 Traning Loss: tensor(0.0330)\n",
      "15865 Traning Loss: tensor(0.0350)\n",
      "15866 Traning Loss: tensor(0.0329)\n",
      "15867 Traning Loss: tensor(0.0323)\n",
      "15868 Traning Loss: tensor(0.0346)\n",
      "15869 Traning Loss: tensor(0.0356)\n",
      "15870 Traning Loss: tensor(0.0325)\n",
      "15871 Traning Loss: tensor(0.0315)\n",
      "15872 Traning Loss: tensor(0.0331)\n",
      "15873 Traning Loss: tensor(0.0326)\n",
      "15874 Traning Loss: tensor(0.0319)\n",
      "15875 Traning Loss: tensor(0.0315)\n",
      "15876 Traning Loss: tensor(0.0313)\n",
      "15877 Traning Loss: tensor(0.0306)\n",
      "15878 Traning Loss: tensor(0.0325)\n",
      "15879 Traning Loss: tensor(0.0322)\n",
      "15880 Traning Loss: tensor(0.0335)\n",
      "15881 Traning Loss: tensor(0.0326)\n",
      "15882 Traning Loss: tensor(0.0328)\n",
      "15883 Traning Loss: tensor(0.0310)\n",
      "15884 Traning Loss: tensor(0.0321)\n",
      "15885 Traning Loss: tensor(0.0309)\n",
      "15886 Traning Loss: tensor(0.0323)\n",
      "15887 Traning Loss: tensor(0.0331)\n",
      "15888 Traning Loss: tensor(0.0333)\n",
      "15889 Traning Loss: tensor(0.0322)\n",
      "15890 Traning Loss: tensor(0.0355)\n",
      "15891 Traning Loss: tensor(0.0348)\n",
      "15892 Traning Loss: tensor(0.0320)\n",
      "15893 Traning Loss: tensor(0.0319)\n",
      "15894 Traning Loss: tensor(0.0316)\n",
      "15895 Traning Loss: tensor(0.0341)\n",
      "15896 Traning Loss: tensor(0.0323)\n",
      "15897 Traning Loss: tensor(0.0349)\n",
      "15898 Traning Loss: tensor(0.0321)\n",
      "15899 Traning Loss: tensor(0.0335)\n",
      "15900 Traning Loss: tensor(0.0328)\n",
      "15901 Traning Loss: tensor(0.0348)\n",
      "15902 Traning Loss: tensor(0.0339)\n",
      "15903 Traning Loss: tensor(0.0336)\n",
      "15904 Traning Loss: tensor(0.0330)\n",
      "15905 Traning Loss: tensor(0.0339)\n",
      "15906 Traning Loss: tensor(0.0306)\n",
      "15907 Traning Loss: tensor(0.0340)\n",
      "15908 Traning Loss: tensor(0.0317)\n",
      "15909 Traning Loss: tensor(0.0323)\n",
      "15910 Traning Loss: tensor(0.0337)\n",
      "15911 Traning Loss: tensor(0.0329)\n",
      "15912 Traning Loss: tensor(0.0355)\n",
      "15913 Traning Loss: tensor(0.0316)\n",
      "15914 Traning Loss: tensor(0.0337)\n",
      "15915 Traning Loss: tensor(0.0317)\n",
      "15916 Traning Loss: tensor(0.0316)\n",
      "15917 Traning Loss: tensor(0.0323)\n",
      "15918 Traning Loss: tensor(0.0336)\n",
      "15919 Traning Loss: tensor(0.0319)\n",
      "15920 Traning Loss: tensor(0.0314)\n",
      "15921 Traning Loss: tensor(0.0315)\n",
      "15922 Traning Loss: tensor(0.0322)\n",
      "15923 Traning Loss: tensor(0.0325)\n",
      "15924 Traning Loss: tensor(0.0317)\n",
      "15925 Traning Loss: tensor(0.0325)\n",
      "15926 Traning Loss: tensor(0.0322)\n",
      "15927 Traning Loss: tensor(0.0311)\n",
      "15928 Traning Loss: tensor(0.0363)\n",
      "15929 Traning Loss: tensor(0.0320)\n",
      "15930 Traning Loss: tensor(0.0325)\n",
      "15931 Traning Loss: tensor(0.0335)\n",
      "15932 Traning Loss: tensor(0.0353)\n",
      "15933 Traning Loss: tensor(0.0330)\n",
      "15934 Traning Loss: tensor(0.0331)\n",
      "15935 Traning Loss: tensor(0.0327)\n",
      "15936 Traning Loss: tensor(0.0372)\n",
      "15937 Traning Loss: tensor(0.0314)\n",
      "15938 Traning Loss: tensor(0.0339)\n",
      "15939 Traning Loss: tensor(0.0317)\n",
      "15940 Traning Loss: tensor(0.0335)\n",
      "15941 Traning Loss: tensor(0.0333)\n",
      "15942 Traning Loss: tensor(0.0331)\n",
      "15943 Traning Loss: tensor(0.0340)\n",
      "15944 Traning Loss: tensor(0.0347)\n",
      "15945 Traning Loss: tensor(0.0326)\n",
      "15946 Traning Loss: tensor(0.0333)\n",
      "15947 Traning Loss: tensor(0.0336)\n",
      "15948 Traning Loss: tensor(0.0329)\n",
      "15949 Traning Loss: tensor(0.0325)\n",
      "15950 Traning Loss: tensor(0.0377)\n",
      "15951 Traning Loss: tensor(0.0331)\n",
      "15952 Traning Loss: tensor(0.0365)\n",
      "15953 Traning Loss: tensor(0.0334)\n",
      "15954 Traning Loss: tensor(0.0339)\n",
      "15955 Traning Loss: tensor(0.0336)\n",
      "15956 Traning Loss: tensor(0.0338)\n",
      "15957 Traning Loss: tensor(0.0328)\n",
      "15958 Traning Loss: tensor(0.0334)\n",
      "15959 Traning Loss: tensor(0.0343)\n",
      "15960 Traning Loss: tensor(0.0340)\n",
      "15961 Traning Loss: tensor(0.0335)\n",
      "15962 Traning Loss: tensor(0.0332)\n",
      "15963 Traning Loss: tensor(0.0327)\n",
      "15964 Traning Loss: tensor(0.0325)\n",
      "15965 Traning Loss: tensor(0.0331)\n",
      "15966 Traning Loss: tensor(0.0332)\n",
      "15967 Traning Loss: tensor(0.0322)\n",
      "15968 Traning Loss: tensor(0.0331)\n",
      "15969 Traning Loss: tensor(0.0362)\n",
      "15970 Traning Loss: tensor(0.0321)\n",
      "15971 Traning Loss: tensor(0.0335)\n",
      "15972 Traning Loss: tensor(0.0318)\n",
      "15973 Traning Loss: tensor(0.0365)\n",
      "15974 Traning Loss: tensor(0.0321)\n",
      "15975 Traning Loss: tensor(0.0315)\n",
      "15976 Traning Loss: tensor(0.0341)\n",
      "15977 Traning Loss: tensor(0.0330)\n",
      "15978 Traning Loss: tensor(0.0316)\n",
      "15979 Traning Loss: tensor(0.0340)\n",
      "15980 Traning Loss: tensor(0.0317)\n",
      "15981 Traning Loss: tensor(0.0347)\n",
      "15982 Traning Loss: tensor(0.0332)\n",
      "15983 Traning Loss: tensor(0.0324)\n",
      "15984 Traning Loss: tensor(0.0358)\n",
      "15985 Traning Loss: tensor(0.0332)\n",
      "15986 Traning Loss: tensor(0.0334)\n",
      "15987 Traning Loss: tensor(0.0338)\n",
      "15988 Traning Loss: tensor(0.0356)\n",
      "15989 Traning Loss: tensor(0.0330)\n",
      "15990 Traning Loss: tensor(0.0351)\n",
      "15991 Traning Loss: tensor(0.0336)\n",
      "15992 Traning Loss: tensor(0.0326)\n",
      "15993 Traning Loss: tensor(0.0330)\n",
      "15994 Traning Loss: tensor(0.0356)\n",
      "15995 Traning Loss: tensor(0.0340)\n",
      "15996 Traning Loss: tensor(0.0327)\n",
      "15997 Traning Loss: tensor(0.0335)\n",
      "15998 Traning Loss: tensor(0.0325)\n",
      "15999 Traning Loss: tensor(0.0326)\n",
      "16000 Traning Loss: tensor(0.0320)\n",
      "16001 Traning Loss: tensor(0.0323)\n",
      "16002 Traning Loss: tensor(0.0320)\n",
      "16003 Traning Loss: tensor(0.0321)\n",
      "16004 Traning Loss: tensor(0.0322)\n",
      "16005 Traning Loss: tensor(0.0336)\n",
      "16006 Traning Loss: tensor(0.0330)\n",
      "16007 Traning Loss: tensor(0.0316)\n",
      "16008 Traning Loss: tensor(0.0325)\n",
      "16009 Traning Loss: tensor(0.0342)\n",
      "16010 Traning Loss: tensor(0.0323)\n",
      "16011 Traning Loss: tensor(0.0306)\n",
      "16012 Traning Loss: tensor(0.0320)\n",
      "16013 Traning Loss: tensor(0.0310)\n",
      "16014 Traning Loss: tensor(0.0315)\n",
      "16015 Traning Loss: tensor(0.0308)\n",
      "16016 Traning Loss: tensor(0.0310)\n",
      "16017 Traning Loss: tensor(0.0337)\n",
      "16018 Traning Loss: tensor(0.0328)\n",
      "16019 Traning Loss: tensor(0.0331)\n",
      "16020 Traning Loss: tensor(0.0326)\n",
      "16021 Traning Loss: tensor(0.0335)\n",
      "16022 Traning Loss: tensor(0.0312)\n",
      "16023 Traning Loss: tensor(0.0349)\n",
      "16024 Traning Loss: tensor(0.0322)\n",
      "16025 Traning Loss: tensor(0.0359)\n",
      "16026 Traning Loss: tensor(0.0333)\n",
      "16027 Traning Loss: tensor(0.0335)\n",
      "16028 Traning Loss: tensor(0.0327)\n",
      "16029 Traning Loss: tensor(0.0341)\n",
      "16030 Traning Loss: tensor(0.0334)\n",
      "16031 Traning Loss: tensor(0.0321)\n",
      "16032 Traning Loss: tensor(0.0314)\n",
      "16033 Traning Loss: tensor(0.0320)\n",
      "16034 Traning Loss: tensor(0.0332)\n",
      "16035 Traning Loss: tensor(0.0340)\n",
      "16036 Traning Loss: tensor(0.0335)\n",
      "16037 Traning Loss: tensor(0.0321)\n",
      "16038 Traning Loss: tensor(0.0328)\n",
      "16039 Traning Loss: tensor(0.0334)\n",
      "16040 Traning Loss: tensor(0.0356)\n",
      "16041 Traning Loss: tensor(0.0305)\n",
      "16042 Traning Loss: tensor(0.0304)\n",
      "16043 Traning Loss: tensor(0.0316)\n",
      "16044 Traning Loss: tensor(0.0339)\n",
      "16045 Traning Loss: tensor(0.0336)\n",
      "16046 Traning Loss: tensor(0.0324)\n",
      "16047 Traning Loss: tensor(0.0332)\n",
      "16048 Traning Loss: tensor(0.0341)\n",
      "16049 Traning Loss: tensor(0.0329)\n",
      "16050 Traning Loss: tensor(0.0328)\n",
      "16051 Traning Loss: tensor(0.0347)\n",
      "16052 Traning Loss: tensor(0.0314)\n",
      "16053 Traning Loss: tensor(0.0313)\n",
      "16054 Traning Loss: tensor(0.0323)\n",
      "16055 Traning Loss: tensor(0.0348)\n",
      "16056 Traning Loss: tensor(0.0317)\n",
      "16057 Traning Loss: tensor(0.0342)\n",
      "16058 Traning Loss: tensor(0.0318)\n",
      "16059 Traning Loss: tensor(0.0339)\n",
      "16060 Traning Loss: tensor(0.0351)\n",
      "16061 Traning Loss: tensor(0.0333)\n",
      "16062 Traning Loss: tensor(0.0341)\n",
      "16063 Traning Loss: tensor(0.0357)\n",
      "16064 Traning Loss: tensor(0.0304)\n",
      "16065 Traning Loss: tensor(0.0327)\n",
      "16066 Traning Loss: tensor(0.0317)\n",
      "16067 Traning Loss: tensor(0.0323)\n",
      "16068 Traning Loss: tensor(0.0315)\n",
      "16069 Traning Loss: tensor(0.0322)\n",
      "16070 Traning Loss: tensor(0.0323)\n",
      "16071 Traning Loss: tensor(0.0326)\n",
      "16072 Traning Loss: tensor(0.0341)\n",
      "16073 Traning Loss: tensor(0.0355)\n",
      "16074 Traning Loss: tensor(0.0322)\n",
      "16075 Traning Loss: tensor(0.0335)\n",
      "16076 Traning Loss: tensor(0.0318)\n",
      "16077 Traning Loss: tensor(0.0351)\n",
      "16078 Traning Loss: tensor(0.0353)\n",
      "16079 Traning Loss: tensor(0.0332)\n",
      "16080 Traning Loss: tensor(0.0340)\n",
      "16081 Traning Loss: tensor(0.0337)\n",
      "16082 Traning Loss: tensor(0.0347)\n",
      "16083 Traning Loss: tensor(0.0334)\n",
      "16084 Traning Loss: tensor(0.0336)\n",
      "16085 Traning Loss: tensor(0.0327)\n",
      "16086 Traning Loss: tensor(0.0339)\n",
      "16087 Traning Loss: tensor(0.0336)\n",
      "16088 Traning Loss: tensor(0.0341)\n",
      "16089 Traning Loss: tensor(0.0347)\n",
      "16090 Traning Loss: tensor(0.0354)\n",
      "16091 Traning Loss: tensor(0.0314)\n",
      "16092 Traning Loss: tensor(0.0360)\n",
      "16093 Traning Loss: tensor(0.0350)\n",
      "16094 Traning Loss: tensor(0.0349)\n",
      "16095 Traning Loss: tensor(0.0323)\n",
      "16096 Traning Loss: tensor(0.0316)\n",
      "16097 Traning Loss: tensor(0.0317)\n",
      "16098 Traning Loss: tensor(0.0334)\n",
      "16099 Traning Loss: tensor(0.0342)\n",
      "16100 Traning Loss: tensor(0.0331)\n",
      "16101 Traning Loss: tensor(0.0319)\n",
      "16102 Traning Loss: tensor(0.0321)\n",
      "16103 Traning Loss: tensor(0.0328)\n",
      "16104 Traning Loss: tensor(0.0319)\n",
      "16105 Traning Loss: tensor(0.0317)\n",
      "16106 Traning Loss: tensor(0.0316)\n",
      "16107 Traning Loss: tensor(0.0335)\n",
      "16108 Traning Loss: tensor(0.0320)\n",
      "16109 Traning Loss: tensor(0.0316)\n",
      "16110 Traning Loss: tensor(0.0332)\n",
      "16111 Traning Loss: tensor(0.0335)\n",
      "16112 Traning Loss: tensor(0.0342)\n",
      "16113 Traning Loss: tensor(0.0324)\n",
      "16114 Traning Loss: tensor(0.0326)\n",
      "16115 Traning Loss: tensor(0.0325)\n",
      "16116 Traning Loss: tensor(0.0314)\n",
      "16117 Traning Loss: tensor(0.0341)\n",
      "16118 Traning Loss: tensor(0.0312)\n",
      "16119 Traning Loss: tensor(0.0340)\n",
      "16120 Traning Loss: tensor(0.0316)\n",
      "16121 Traning Loss: tensor(0.0344)\n",
      "16122 Traning Loss: tensor(0.0330)\n",
      "16123 Traning Loss: tensor(0.0331)\n",
      "16124 Traning Loss: tensor(0.0324)\n",
      "16125 Traning Loss: tensor(0.0349)\n",
      "16126 Traning Loss: tensor(0.0328)\n",
      "16127 Traning Loss: tensor(0.0347)\n",
      "16128 Traning Loss: tensor(0.0324)\n",
      "16129 Traning Loss: tensor(0.0308)\n",
      "16130 Traning Loss: tensor(0.0319)\n",
      "16131 Traning Loss: tensor(0.0322)\n",
      "16132 Traning Loss: tensor(0.0315)\n",
      "16133 Traning Loss: tensor(0.0310)\n",
      "16134 Traning Loss: tensor(0.0311)\n",
      "16135 Traning Loss: tensor(0.0369)\n",
      "16136 Traning Loss: tensor(0.0330)\n",
      "16137 Traning Loss: tensor(0.0324)\n",
      "16138 Traning Loss: tensor(0.0317)\n",
      "16139 Traning Loss: tensor(0.0321)\n",
      "16140 Traning Loss: tensor(0.0316)\n",
      "16141 Traning Loss: tensor(0.0312)\n",
      "16142 Traning Loss: tensor(0.0310)\n",
      "16143 Traning Loss: tensor(0.0331)\n",
      "16144 Traning Loss: tensor(0.0320)\n",
      "16145 Traning Loss: tensor(0.0318)\n",
      "16146 Traning Loss: tensor(0.0334)\n",
      "16147 Traning Loss: tensor(0.0319)\n",
      "16148 Traning Loss: tensor(0.0330)\n",
      "16149 Traning Loss: tensor(0.0334)\n",
      "16150 Traning Loss: tensor(0.0327)\n",
      "16151 Traning Loss: tensor(0.0337)\n",
      "16152 Traning Loss: tensor(0.0321)\n",
      "16153 Traning Loss: tensor(0.0326)\n",
      "16154 Traning Loss: tensor(0.0302)\n",
      "16155 Traning Loss: tensor(0.0330)\n",
      "16156 Traning Loss: tensor(0.0337)\n",
      "16157 Traning Loss: tensor(0.0337)\n",
      "16158 Traning Loss: tensor(0.0340)\n",
      "16159 Traning Loss: tensor(0.0320)\n",
      "16160 Traning Loss: tensor(0.0327)\n",
      "16161 Traning Loss: tensor(0.0317)\n",
      "16162 Traning Loss: tensor(0.0333)\n",
      "16163 Traning Loss: tensor(0.0328)\n",
      "16164 Traning Loss: tensor(0.0333)\n",
      "16165 Traning Loss: tensor(0.0321)\n",
      "16166 Traning Loss: tensor(0.0312)\n",
      "16167 Traning Loss: tensor(0.0343)\n",
      "16168 Traning Loss: tensor(0.0323)\n",
      "16169 Traning Loss: tensor(0.0338)\n",
      "16170 Traning Loss: tensor(0.0330)\n",
      "16171 Traning Loss: tensor(0.0315)\n",
      "16172 Traning Loss: tensor(0.0306)\n",
      "16173 Traning Loss: tensor(0.0331)\n",
      "16174 Traning Loss: tensor(0.0325)\n",
      "16175 Traning Loss: tensor(0.0347)\n",
      "16176 Traning Loss: tensor(0.0329)\n",
      "16177 Traning Loss: tensor(0.0324)\n",
      "16178 Traning Loss: tensor(0.0343)\n",
      "16179 Traning Loss: tensor(0.0313)\n",
      "16180 Traning Loss: tensor(0.0328)\n",
      "16181 Traning Loss: tensor(0.0319)\n",
      "16182 Traning Loss: tensor(0.0333)\n",
      "16183 Traning Loss: tensor(0.0326)\n",
      "16184 Traning Loss: tensor(0.0353)\n",
      "16185 Traning Loss: tensor(0.0322)\n",
      "16186 Traning Loss: tensor(0.0332)\n",
      "16187 Traning Loss: tensor(0.0318)\n",
      "16188 Traning Loss: tensor(0.0330)\n",
      "16189 Traning Loss: tensor(0.0322)\n",
      "16190 Traning Loss: tensor(0.0321)\n",
      "16191 Traning Loss: tensor(0.0312)\n",
      "16192 Traning Loss: tensor(0.0332)\n",
      "16193 Traning Loss: tensor(0.0315)\n",
      "16194 Traning Loss: tensor(0.0336)\n",
      "16195 Traning Loss: tensor(0.0335)\n",
      "16196 Traning Loss: tensor(0.0343)\n",
      "16197 Traning Loss: tensor(0.0323)\n",
      "16198 Traning Loss: tensor(0.0327)\n",
      "16199 Traning Loss: tensor(0.0345)\n",
      "16200 Traning Loss: tensor(0.0322)\n",
      "16201 Traning Loss: tensor(0.0338)\n",
      "16202 Traning Loss: tensor(0.0359)\n",
      "16203 Traning Loss: tensor(0.0316)\n",
      "16204 Traning Loss: tensor(0.0334)\n",
      "16205 Traning Loss: tensor(0.0331)\n",
      "16206 Traning Loss: tensor(0.0341)\n",
      "16207 Traning Loss: tensor(0.0328)\n",
      "16208 Traning Loss: tensor(0.0326)\n",
      "16209 Traning Loss: tensor(0.0339)\n",
      "16210 Traning Loss: tensor(0.0314)\n",
      "16211 Traning Loss: tensor(0.0317)\n",
      "16212 Traning Loss: tensor(0.0356)\n",
      "16213 Traning Loss: tensor(0.0349)\n",
      "16214 Traning Loss: tensor(0.0329)\n",
      "16215 Traning Loss: tensor(0.0350)\n",
      "16216 Traning Loss: tensor(0.0338)\n",
      "16217 Traning Loss: tensor(0.0328)\n",
      "16218 Traning Loss: tensor(0.0321)\n",
      "16219 Traning Loss: tensor(0.0308)\n",
      "16220 Traning Loss: tensor(0.0332)\n",
      "16221 Traning Loss: tensor(0.0305)\n",
      "16222 Traning Loss: tensor(0.0332)\n",
      "16223 Traning Loss: tensor(0.0338)\n",
      "16224 Traning Loss: tensor(0.0301)\n",
      "16225 Traning Loss: tensor(0.0334)\n",
      "16226 Traning Loss: tensor(0.0320)\n",
      "16227 Traning Loss: tensor(0.0319)\n",
      "16228 Traning Loss: tensor(0.0310)\n",
      "16229 Traning Loss: tensor(0.0328)\n",
      "16230 Traning Loss: tensor(0.0321)\n",
      "16231 Traning Loss: tensor(0.0326)\n",
      "16232 Traning Loss: tensor(0.0338)\n",
      "16233 Traning Loss: tensor(0.0293)\n",
      "16234 Traning Loss: tensor(0.0324)\n",
      "16235 Traning Loss: tensor(0.0334)\n",
      "16236 Traning Loss: tensor(0.0306)\n",
      "16237 Traning Loss: tensor(0.0330)\n",
      "16238 Traning Loss: tensor(0.0316)\n",
      "16239 Traning Loss: tensor(0.0322)\n",
      "16240 Traning Loss: tensor(0.0318)\n",
      "16241 Traning Loss: tensor(0.0331)\n",
      "16242 Traning Loss: tensor(0.0312)\n",
      "16243 Traning Loss: tensor(0.0317)\n",
      "16244 Traning Loss: tensor(0.0327)\n",
      "16245 Traning Loss: tensor(0.0313)\n",
      "16246 Traning Loss: tensor(0.0300)\n",
      "16247 Traning Loss: tensor(0.0306)\n",
      "16248 Traning Loss: tensor(0.0323)\n",
      "16249 Traning Loss: tensor(0.0325)\n",
      "16250 Traning Loss: tensor(0.0338)\n",
      "16251 Traning Loss: tensor(0.0328)\n",
      "16252 Traning Loss: tensor(0.0343)\n",
      "16253 Traning Loss: tensor(0.0315)\n",
      "16254 Traning Loss: tensor(0.0305)\n",
      "16255 Traning Loss: tensor(0.0302)\n",
      "16256 Traning Loss: tensor(0.0329)\n",
      "16257 Traning Loss: tensor(0.0309)\n",
      "16258 Traning Loss: tensor(0.0329)\n",
      "16259 Traning Loss: tensor(0.0351)\n",
      "16260 Traning Loss: tensor(0.0324)\n",
      "16261 Traning Loss: tensor(0.0328)\n",
      "16262 Traning Loss: tensor(0.0335)\n",
      "16263 Traning Loss: tensor(0.0327)\n",
      "16264 Traning Loss: tensor(0.0318)\n",
      "16265 Traning Loss: tensor(0.0320)\n",
      "16266 Traning Loss: tensor(0.0348)\n",
      "16267 Traning Loss: tensor(0.0315)\n",
      "16268 Traning Loss: tensor(0.0333)\n",
      "16269 Traning Loss: tensor(0.0324)\n",
      "16270 Traning Loss: tensor(0.0347)\n",
      "16271 Traning Loss: tensor(0.0324)\n",
      "16272 Traning Loss: tensor(0.0314)\n",
      "16273 Traning Loss: tensor(0.0316)\n",
      "16274 Traning Loss: tensor(0.0319)\n",
      "16275 Traning Loss: tensor(0.0315)\n",
      "16276 Traning Loss: tensor(0.0335)\n",
      "16277 Traning Loss: tensor(0.0316)\n",
      "16278 Traning Loss: tensor(0.0315)\n",
      "16279 Traning Loss: tensor(0.0308)\n",
      "16280 Traning Loss: tensor(0.0330)\n",
      "16281 Traning Loss: tensor(0.0308)\n",
      "16282 Traning Loss: tensor(0.0334)\n",
      "16283 Traning Loss: tensor(0.0319)\n",
      "16284 Traning Loss: tensor(0.0306)\n",
      "16285 Traning Loss: tensor(0.0307)\n",
      "16286 Traning Loss: tensor(0.0339)\n",
      "16287 Traning Loss: tensor(0.0330)\n",
      "16288 Traning Loss: tensor(0.0314)\n",
      "16289 Traning Loss: tensor(0.0342)\n",
      "16290 Traning Loss: tensor(0.0318)\n",
      "16291 Traning Loss: tensor(0.0322)\n",
      "16292 Traning Loss: tensor(0.0328)\n",
      "16293 Traning Loss: tensor(0.0315)\n",
      "16294 Traning Loss: tensor(0.0317)\n",
      "16295 Traning Loss: tensor(0.0331)\n",
      "16296 Traning Loss: tensor(0.0331)\n",
      "16297 Traning Loss: tensor(0.0348)\n",
      "16298 Traning Loss: tensor(0.0321)\n",
      "16299 Traning Loss: tensor(0.0320)\n",
      "16300 Traning Loss: tensor(0.0302)\n",
      "16301 Traning Loss: tensor(0.0318)\n",
      "16302 Traning Loss: tensor(0.0308)\n",
      "16303 Traning Loss: tensor(0.0330)\n",
      "16304 Traning Loss: tensor(0.0327)\n",
      "16305 Traning Loss: tensor(0.0311)\n",
      "16306 Traning Loss: tensor(0.0330)\n",
      "16307 Traning Loss: tensor(0.0310)\n",
      "16308 Traning Loss: tensor(0.0335)\n",
      "16309 Traning Loss: tensor(0.0326)\n",
      "16310 Traning Loss: tensor(0.0331)\n",
      "16311 Traning Loss: tensor(0.0334)\n",
      "16312 Traning Loss: tensor(0.0332)\n",
      "16313 Traning Loss: tensor(0.0335)\n",
      "16314 Traning Loss: tensor(0.0329)\n",
      "16315 Traning Loss: tensor(0.0356)\n",
      "16316 Traning Loss: tensor(0.0316)\n",
      "16317 Traning Loss: tensor(0.0338)\n",
      "16318 Traning Loss: tensor(0.0332)\n",
      "16319 Traning Loss: tensor(0.0337)\n",
      "16320 Traning Loss: tensor(0.0315)\n",
      "16321 Traning Loss: tensor(0.0320)\n",
      "16322 Traning Loss: tensor(0.0337)\n",
      "16323 Traning Loss: tensor(0.0337)\n",
      "16324 Traning Loss: tensor(0.0326)\n",
      "16325 Traning Loss: tensor(0.0329)\n",
      "16326 Traning Loss: tensor(0.0307)\n",
      "16327 Traning Loss: tensor(0.0347)\n",
      "16328 Traning Loss: tensor(0.0335)\n",
      "16329 Traning Loss: tensor(0.0333)\n",
      "16330 Traning Loss: tensor(0.0341)\n",
      "16331 Traning Loss: tensor(0.0328)\n",
      "16332 Traning Loss: tensor(0.0316)\n",
      "16333 Traning Loss: tensor(0.0319)\n",
      "16334 Traning Loss: tensor(0.0332)\n",
      "16335 Traning Loss: tensor(0.0327)\n",
      "16336 Traning Loss: tensor(0.0322)\n",
      "16337 Traning Loss: tensor(0.0343)\n",
      "16338 Traning Loss: tensor(0.0324)\n",
      "16339 Traning Loss: tensor(0.0330)\n",
      "16340 Traning Loss: tensor(0.0315)\n",
      "16341 Traning Loss: tensor(0.0335)\n",
      "16342 Traning Loss: tensor(0.0354)\n",
      "16343 Traning Loss: tensor(0.0332)\n",
      "16344 Traning Loss: tensor(0.0327)\n",
      "16345 Traning Loss: tensor(0.0326)\n",
      "16346 Traning Loss: tensor(0.0338)\n",
      "16347 Traning Loss: tensor(0.0318)\n",
      "16348 Traning Loss: tensor(0.0337)\n",
      "16349 Traning Loss: tensor(0.0325)\n",
      "16350 Traning Loss: tensor(0.0345)\n",
      "16351 Traning Loss: tensor(0.0306)\n",
      "16352 Traning Loss: tensor(0.0307)\n",
      "16353 Traning Loss: tensor(0.0323)\n",
      "16354 Traning Loss: tensor(0.0318)\n",
      "16355 Traning Loss: tensor(0.0315)\n",
      "16356 Traning Loss: tensor(0.0311)\n",
      "16357 Traning Loss: tensor(0.0324)\n",
      "16358 Traning Loss: tensor(0.0319)\n",
      "16359 Traning Loss: tensor(0.0327)\n",
      "16360 Traning Loss: tensor(0.0315)\n",
      "16361 Traning Loss: tensor(0.0321)\n",
      "16362 Traning Loss: tensor(0.0310)\n",
      "16363 Traning Loss: tensor(0.0300)\n",
      "16364 Traning Loss: tensor(0.0336)\n",
      "16365 Traning Loss: tensor(0.0319)\n",
      "16366 Traning Loss: tensor(0.0325)\n",
      "16367 Traning Loss: tensor(0.0312)\n",
      "16368 Traning Loss: tensor(0.0313)\n",
      "16369 Traning Loss: tensor(0.0329)\n",
      "16370 Traning Loss: tensor(0.0313)\n",
      "16371 Traning Loss: tensor(0.0321)\n",
      "16372 Traning Loss: tensor(0.0323)\n",
      "16373 Traning Loss: tensor(0.0323)\n",
      "16374 Traning Loss: tensor(0.0324)\n",
      "16375 Traning Loss: tensor(0.0316)\n",
      "16376 Traning Loss: tensor(0.0319)\n",
      "16377 Traning Loss: tensor(0.0325)\n",
      "16378 Traning Loss: tensor(0.0313)\n",
      "16379 Traning Loss: tensor(0.0309)\n",
      "16380 Traning Loss: tensor(0.0334)\n",
      "16381 Traning Loss: tensor(0.0324)\n",
      "16382 Traning Loss: tensor(0.0311)\n",
      "16383 Traning Loss: tensor(0.0328)\n",
      "16384 Traning Loss: tensor(0.0319)\n",
      "16385 Traning Loss: tensor(0.0312)\n",
      "16386 Traning Loss: tensor(0.0319)\n",
      "16387 Traning Loss: tensor(0.0316)\n",
      "16388 Traning Loss: tensor(0.0313)\n",
      "16389 Traning Loss: tensor(0.0314)\n",
      "16390 Traning Loss: tensor(0.0310)\n",
      "16391 Traning Loss: tensor(0.0316)\n",
      "16392 Traning Loss: tensor(0.0320)\n",
      "16393 Traning Loss: tensor(0.0304)\n",
      "16394 Traning Loss: tensor(0.0311)\n",
      "16395 Traning Loss: tensor(0.0325)\n",
      "16396 Traning Loss: tensor(0.0319)\n",
      "16397 Traning Loss: tensor(0.0331)\n",
      "16398 Traning Loss: tensor(0.0345)\n",
      "16399 Traning Loss: tensor(0.0341)\n",
      "16400 Traning Loss: tensor(0.0311)\n",
      "16401 Traning Loss: tensor(0.0316)\n",
      "16402 Traning Loss: tensor(0.0307)\n",
      "16403 Traning Loss: tensor(0.0326)\n",
      "16404 Traning Loss: tensor(0.0318)\n",
      "16405 Traning Loss: tensor(0.0310)\n",
      "16406 Traning Loss: tensor(0.0325)\n",
      "16407 Traning Loss: tensor(0.0319)\n",
      "16408 Traning Loss: tensor(0.0316)\n",
      "16409 Traning Loss: tensor(0.0339)\n",
      "16410 Traning Loss: tensor(0.0307)\n",
      "16411 Traning Loss: tensor(0.0329)\n",
      "16412 Traning Loss: tensor(0.0347)\n",
      "16413 Traning Loss: tensor(0.0317)\n",
      "16414 Traning Loss: tensor(0.0337)\n",
      "16415 Traning Loss: tensor(0.0331)\n",
      "16416 Traning Loss: tensor(0.0342)\n",
      "16417 Traning Loss: tensor(0.0331)\n",
      "16418 Traning Loss: tensor(0.0329)\n",
      "16419 Traning Loss: tensor(0.0321)\n",
      "16420 Traning Loss: tensor(0.0337)\n",
      "16421 Traning Loss: tensor(0.0344)\n",
      "16422 Traning Loss: tensor(0.0326)\n",
      "16423 Traning Loss: tensor(0.0317)\n",
      "16424 Traning Loss: tensor(0.0326)\n",
      "16425 Traning Loss: tensor(0.0330)\n",
      "16426 Traning Loss: tensor(0.0304)\n",
      "16427 Traning Loss: tensor(0.0329)\n",
      "16428 Traning Loss: tensor(0.0324)\n",
      "16429 Traning Loss: tensor(0.0312)\n",
      "16430 Traning Loss: tensor(0.0328)\n",
      "16431 Traning Loss: tensor(0.0334)\n",
      "16432 Traning Loss: tensor(0.0329)\n",
      "16433 Traning Loss: tensor(0.0336)\n",
      "16434 Traning Loss: tensor(0.0318)\n",
      "16435 Traning Loss: tensor(0.0316)\n",
      "16436 Traning Loss: tensor(0.0350)\n",
      "16437 Traning Loss: tensor(0.0329)\n",
      "16438 Traning Loss: tensor(0.0328)\n",
      "16439 Traning Loss: tensor(0.0328)\n",
      "16440 Traning Loss: tensor(0.0312)\n",
      "16441 Traning Loss: tensor(0.0309)\n",
      "16442 Traning Loss: tensor(0.0331)\n",
      "16443 Traning Loss: tensor(0.0346)\n",
      "16444 Traning Loss: tensor(0.0321)\n",
      "16445 Traning Loss: tensor(0.0317)\n",
      "16446 Traning Loss: tensor(0.0324)\n",
      "16447 Traning Loss: tensor(0.0327)\n",
      "16448 Traning Loss: tensor(0.0330)\n",
      "16449 Traning Loss: tensor(0.0328)\n",
      "16450 Traning Loss: tensor(0.0324)\n",
      "16451 Traning Loss: tensor(0.0358)\n",
      "16452 Traning Loss: tensor(0.0318)\n",
      "16453 Traning Loss: tensor(0.0330)\n",
      "16454 Traning Loss: tensor(0.0328)\n",
      "16455 Traning Loss: tensor(0.0328)\n",
      "16456 Traning Loss: tensor(0.0308)\n",
      "16457 Traning Loss: tensor(0.0314)\n",
      "16458 Traning Loss: tensor(0.0334)\n",
      "16459 Traning Loss: tensor(0.0308)\n",
      "16460 Traning Loss: tensor(0.0325)\n",
      "16461 Traning Loss: tensor(0.0307)\n",
      "16462 Traning Loss: tensor(0.0307)\n",
      "16463 Traning Loss: tensor(0.0310)\n",
      "16464 Traning Loss: tensor(0.0317)\n",
      "16465 Traning Loss: tensor(0.0325)\n",
      "16466 Traning Loss: tensor(0.0341)\n",
      "16467 Traning Loss: tensor(0.0330)\n",
      "16468 Traning Loss: tensor(0.0308)\n",
      "16469 Traning Loss: tensor(0.0329)\n",
      "16470 Traning Loss: tensor(0.0334)\n",
      "16471 Traning Loss: tensor(0.0339)\n",
      "16472 Traning Loss: tensor(0.0318)\n",
      "16473 Traning Loss: tensor(0.0311)\n",
      "16474 Traning Loss: tensor(0.0318)\n",
      "16475 Traning Loss: tensor(0.0318)\n",
      "16476 Traning Loss: tensor(0.0316)\n",
      "16477 Traning Loss: tensor(0.0320)\n",
      "16478 Traning Loss: tensor(0.0318)\n",
      "16479 Traning Loss: tensor(0.0329)\n",
      "16480 Traning Loss: tensor(0.0323)\n",
      "16481 Traning Loss: tensor(0.0345)\n",
      "16482 Traning Loss: tensor(0.0339)\n",
      "16483 Traning Loss: tensor(0.0338)\n",
      "16484 Traning Loss: tensor(0.0314)\n",
      "16485 Traning Loss: tensor(0.0312)\n",
      "16486 Traning Loss: tensor(0.0311)\n",
      "16487 Traning Loss: tensor(0.0323)\n",
      "16488 Traning Loss: tensor(0.0321)\n",
      "16489 Traning Loss: tensor(0.0322)\n",
      "16490 Traning Loss: tensor(0.0297)\n",
      "16491 Traning Loss: tensor(0.0327)\n",
      "16492 Traning Loss: tensor(0.0310)\n",
      "16493 Traning Loss: tensor(0.0312)\n",
      "16494 Traning Loss: tensor(0.0334)\n",
      "16495 Traning Loss: tensor(0.0290)\n",
      "16496 Traning Loss: tensor(0.0316)\n",
      "16497 Traning Loss: tensor(0.0316)\n",
      "16498 Traning Loss: tensor(0.0317)\n",
      "16499 Traning Loss: tensor(0.0314)\n",
      "16500 Traning Loss: tensor(0.0309)\n",
      "16501 Traning Loss: tensor(0.0322)\n",
      "16502 Traning Loss: tensor(0.0326)\n",
      "16503 Traning Loss: tensor(0.0333)\n",
      "16504 Traning Loss: tensor(0.0326)\n",
      "16505 Traning Loss: tensor(0.0327)\n",
      "16506 Traning Loss: tensor(0.0316)\n",
      "16507 Traning Loss: tensor(0.0313)\n",
      "16508 Traning Loss: tensor(0.0313)\n",
      "16509 Traning Loss: tensor(0.0333)\n",
      "16510 Traning Loss: tensor(0.0327)\n",
      "16511 Traning Loss: tensor(0.0324)\n",
      "16512 Traning Loss: tensor(0.0318)\n",
      "16513 Traning Loss: tensor(0.0297)\n",
      "16514 Traning Loss: tensor(0.0328)\n",
      "16515 Traning Loss: tensor(0.0313)\n",
      "16516 Traning Loss: tensor(0.0327)\n",
      "16517 Traning Loss: tensor(0.0307)\n",
      "16518 Traning Loss: tensor(0.0311)\n",
      "16519 Traning Loss: tensor(0.0305)\n",
      "16520 Traning Loss: tensor(0.0329)\n",
      "16521 Traning Loss: tensor(0.0312)\n",
      "16522 Traning Loss: tensor(0.0317)\n",
      "16523 Traning Loss: tensor(0.0319)\n",
      "16524 Traning Loss: tensor(0.0325)\n",
      "16525 Traning Loss: tensor(0.0321)\n",
      "16526 Traning Loss: tensor(0.0328)\n",
      "16527 Traning Loss: tensor(0.0311)\n",
      "16528 Traning Loss: tensor(0.0345)\n",
      "16529 Traning Loss: tensor(0.0314)\n",
      "16530 Traning Loss: tensor(0.0329)\n",
      "16531 Traning Loss: tensor(0.0336)\n",
      "16532 Traning Loss: tensor(0.0320)\n",
      "16533 Traning Loss: tensor(0.0323)\n",
      "16534 Traning Loss: tensor(0.0316)\n",
      "16535 Traning Loss: tensor(0.0309)\n",
      "16536 Traning Loss: tensor(0.0329)\n",
      "16537 Traning Loss: tensor(0.0326)\n",
      "16538 Traning Loss: tensor(0.0314)\n",
      "16539 Traning Loss: tensor(0.0326)\n",
      "16540 Traning Loss: tensor(0.0306)\n",
      "16541 Traning Loss: tensor(0.0311)\n",
      "16542 Traning Loss: tensor(0.0338)\n",
      "16543 Traning Loss: tensor(0.0305)\n",
      "16544 Traning Loss: tensor(0.0339)\n",
      "16545 Traning Loss: tensor(0.0319)\n",
      "16546 Traning Loss: tensor(0.0341)\n",
      "16547 Traning Loss: tensor(0.0324)\n",
      "16548 Traning Loss: tensor(0.0331)\n",
      "16549 Traning Loss: tensor(0.0336)\n",
      "16550 Traning Loss: tensor(0.0328)\n",
      "16551 Traning Loss: tensor(0.0330)\n",
      "16552 Traning Loss: tensor(0.0311)\n",
      "16553 Traning Loss: tensor(0.0323)\n",
      "16554 Traning Loss: tensor(0.0322)\n",
      "16555 Traning Loss: tensor(0.0329)\n",
      "16556 Traning Loss: tensor(0.0327)\n",
      "16557 Traning Loss: tensor(0.0346)\n",
      "16558 Traning Loss: tensor(0.0318)\n",
      "16559 Traning Loss: tensor(0.0319)\n",
      "16560 Traning Loss: tensor(0.0319)\n",
      "16561 Traning Loss: tensor(0.0309)\n",
      "16562 Traning Loss: tensor(0.0313)\n",
      "16563 Traning Loss: tensor(0.0309)\n",
      "16564 Traning Loss: tensor(0.0324)\n",
      "16565 Traning Loss: tensor(0.0315)\n",
      "16566 Traning Loss: tensor(0.0322)\n",
      "16567 Traning Loss: tensor(0.0322)\n",
      "16568 Traning Loss: tensor(0.0310)\n",
      "16569 Traning Loss: tensor(0.0322)\n",
      "16570 Traning Loss: tensor(0.0324)\n",
      "16571 Traning Loss: tensor(0.0324)\n",
      "16572 Traning Loss: tensor(0.0317)\n",
      "16573 Traning Loss: tensor(0.0319)\n",
      "16574 Traning Loss: tensor(0.0315)\n",
      "16575 Traning Loss: tensor(0.0314)\n",
      "16576 Traning Loss: tensor(0.0327)\n",
      "16577 Traning Loss: tensor(0.0312)\n",
      "16578 Traning Loss: tensor(0.0315)\n",
      "16579 Traning Loss: tensor(0.0321)\n",
      "16580 Traning Loss: tensor(0.0313)\n",
      "16581 Traning Loss: tensor(0.0319)\n",
      "16582 Traning Loss: tensor(0.0313)\n",
      "16583 Traning Loss: tensor(0.0315)\n",
      "16584 Traning Loss: tensor(0.0335)\n",
      "16585 Traning Loss: tensor(0.0309)\n",
      "16586 Traning Loss: tensor(0.0297)\n",
      "16587 Traning Loss: tensor(0.0321)\n",
      "16588 Traning Loss: tensor(0.0314)\n",
      "16589 Traning Loss: tensor(0.0316)\n",
      "16590 Traning Loss: tensor(0.0320)\n",
      "16591 Traning Loss: tensor(0.0329)\n",
      "16592 Traning Loss: tensor(0.0304)\n",
      "16593 Traning Loss: tensor(0.0316)\n",
      "16594 Traning Loss: tensor(0.0309)\n",
      "16595 Traning Loss: tensor(0.0306)\n",
      "16596 Traning Loss: tensor(0.0320)\n",
      "16597 Traning Loss: tensor(0.0325)\n",
      "16598 Traning Loss: tensor(0.0323)\n",
      "16599 Traning Loss: tensor(0.0346)\n",
      "16600 Traning Loss: tensor(0.0319)\n",
      "16601 Traning Loss: tensor(0.0320)\n",
      "16602 Traning Loss: tensor(0.0326)\n",
      "16603 Traning Loss: tensor(0.0306)\n",
      "16604 Traning Loss: tensor(0.0306)\n",
      "16605 Traning Loss: tensor(0.0347)\n",
      "16606 Traning Loss: tensor(0.0333)\n",
      "16607 Traning Loss: tensor(0.0359)\n",
      "16608 Traning Loss: tensor(0.0305)\n",
      "16609 Traning Loss: tensor(0.0351)\n",
      "16610 Traning Loss: tensor(0.0314)\n",
      "16611 Traning Loss: tensor(0.0334)\n",
      "16612 Traning Loss: tensor(0.0333)\n",
      "16613 Traning Loss: tensor(0.0318)\n",
      "16614 Traning Loss: tensor(0.0337)\n",
      "16615 Traning Loss: tensor(0.0309)\n",
      "16616 Traning Loss: tensor(0.0327)\n",
      "16617 Traning Loss: tensor(0.0318)\n",
      "16618 Traning Loss: tensor(0.0344)\n",
      "16619 Traning Loss: tensor(0.0316)\n",
      "16620 Traning Loss: tensor(0.0331)\n",
      "16621 Traning Loss: tensor(0.0315)\n",
      "16622 Traning Loss: tensor(0.0318)\n",
      "16623 Traning Loss: tensor(0.0309)\n",
      "16624 Traning Loss: tensor(0.0340)\n",
      "16625 Traning Loss: tensor(0.0318)\n",
      "16626 Traning Loss: tensor(0.0312)\n",
      "16627 Traning Loss: tensor(0.0341)\n",
      "16628 Traning Loss: tensor(0.0327)\n",
      "16629 Traning Loss: tensor(0.0342)\n",
      "16630 Traning Loss: tensor(0.0326)\n",
      "16631 Traning Loss: tensor(0.0346)\n",
      "16632 Traning Loss: tensor(0.0323)\n",
      "16633 Traning Loss: tensor(0.0324)\n",
      "16634 Traning Loss: tensor(0.0310)\n",
      "16635 Traning Loss: tensor(0.0330)\n",
      "16636 Traning Loss: tensor(0.0312)\n",
      "16637 Traning Loss: tensor(0.0321)\n",
      "16638 Traning Loss: tensor(0.0319)\n",
      "16639 Traning Loss: tensor(0.0307)\n",
      "16640 Traning Loss: tensor(0.0315)\n",
      "16641 Traning Loss: tensor(0.0325)\n",
      "16642 Traning Loss: tensor(0.0318)\n",
      "16643 Traning Loss: tensor(0.0310)\n",
      "16644 Traning Loss: tensor(0.0323)\n",
      "16645 Traning Loss: tensor(0.0313)\n",
      "16646 Traning Loss: tensor(0.0328)\n",
      "16647 Traning Loss: tensor(0.0314)\n",
      "16648 Traning Loss: tensor(0.0301)\n",
      "16649 Traning Loss: tensor(0.0302)\n",
      "16650 Traning Loss: tensor(0.0337)\n",
      "16651 Traning Loss: tensor(0.0333)\n",
      "16652 Traning Loss: tensor(0.0339)\n",
      "16653 Traning Loss: tensor(0.0329)\n",
      "16654 Traning Loss: tensor(0.0323)\n",
      "16655 Traning Loss: tensor(0.0336)\n",
      "16656 Traning Loss: tensor(0.0317)\n",
      "16657 Traning Loss: tensor(0.0314)\n",
      "16658 Traning Loss: tensor(0.0342)\n",
      "16659 Traning Loss: tensor(0.0334)\n",
      "16660 Traning Loss: tensor(0.0320)\n",
      "16661 Traning Loss: tensor(0.0316)\n",
      "16662 Traning Loss: tensor(0.0314)\n",
      "16663 Traning Loss: tensor(0.0329)\n",
      "16664 Traning Loss: tensor(0.0326)\n",
      "16665 Traning Loss: tensor(0.0321)\n",
      "16666 Traning Loss: tensor(0.0314)\n",
      "16667 Traning Loss: tensor(0.0328)\n",
      "16668 Traning Loss: tensor(0.0319)\n",
      "16669 Traning Loss: tensor(0.0335)\n",
      "16670 Traning Loss: tensor(0.0323)\n",
      "16671 Traning Loss: tensor(0.0339)\n",
      "16672 Traning Loss: tensor(0.0311)\n",
      "16673 Traning Loss: tensor(0.0301)\n",
      "16674 Traning Loss: tensor(0.0322)\n",
      "16675 Traning Loss: tensor(0.0309)\n",
      "16676 Traning Loss: tensor(0.0331)\n",
      "16677 Traning Loss: tensor(0.0316)\n",
      "16678 Traning Loss: tensor(0.0337)\n",
      "16679 Traning Loss: tensor(0.0329)\n",
      "16680 Traning Loss: tensor(0.0337)\n",
      "16681 Traning Loss: tensor(0.0319)\n",
      "16682 Traning Loss: tensor(0.0346)\n",
      "16683 Traning Loss: tensor(0.0319)\n",
      "16684 Traning Loss: tensor(0.0316)\n",
      "16685 Traning Loss: tensor(0.0311)\n",
      "16686 Traning Loss: tensor(0.0309)\n",
      "16687 Traning Loss: tensor(0.0324)\n",
      "16688 Traning Loss: tensor(0.0329)\n",
      "16689 Traning Loss: tensor(0.0324)\n",
      "16690 Traning Loss: tensor(0.0316)\n",
      "16691 Traning Loss: tensor(0.0324)\n",
      "16692 Traning Loss: tensor(0.0337)\n",
      "16693 Traning Loss: tensor(0.0310)\n",
      "16694 Traning Loss: tensor(0.0318)\n",
      "16695 Traning Loss: tensor(0.0312)\n",
      "16696 Traning Loss: tensor(0.0335)\n",
      "16697 Traning Loss: tensor(0.0336)\n",
      "16698 Traning Loss: tensor(0.0314)\n",
      "16699 Traning Loss: tensor(0.0327)\n",
      "16700 Traning Loss: tensor(0.0332)\n",
      "16701 Traning Loss: tensor(0.0315)\n",
      "16702 Traning Loss: tensor(0.0320)\n",
      "16703 Traning Loss: tensor(0.0316)\n",
      "16704 Traning Loss: tensor(0.0327)\n",
      "16705 Traning Loss: tensor(0.0321)\n",
      "16706 Traning Loss: tensor(0.0313)\n",
      "16707 Traning Loss: tensor(0.0319)\n",
      "16708 Traning Loss: tensor(0.0327)\n",
      "16709 Traning Loss: tensor(0.0329)\n",
      "16710 Traning Loss: tensor(0.0306)\n",
      "16711 Traning Loss: tensor(0.0327)\n",
      "16712 Traning Loss: tensor(0.0305)\n",
      "16713 Traning Loss: tensor(0.0307)\n",
      "16714 Traning Loss: tensor(0.0308)\n",
      "16715 Traning Loss: tensor(0.0334)\n",
      "16716 Traning Loss: tensor(0.0320)\n",
      "16717 Traning Loss: tensor(0.0334)\n",
      "16718 Traning Loss: tensor(0.0308)\n",
      "16719 Traning Loss: tensor(0.0318)\n",
      "16720 Traning Loss: tensor(0.0315)\n",
      "16721 Traning Loss: tensor(0.0313)\n",
      "16722 Traning Loss: tensor(0.0299)\n",
      "16723 Traning Loss: tensor(0.0312)\n",
      "16724 Traning Loss: tensor(0.0319)\n",
      "16725 Traning Loss: tensor(0.0311)\n",
      "16726 Traning Loss: tensor(0.0321)\n",
      "16727 Traning Loss: tensor(0.0310)\n",
      "16728 Traning Loss: tensor(0.0331)\n",
      "16729 Traning Loss: tensor(0.0320)\n",
      "16730 Traning Loss: tensor(0.0300)\n",
      "16731 Traning Loss: tensor(0.0326)\n",
      "16732 Traning Loss: tensor(0.0329)\n",
      "16733 Traning Loss: tensor(0.0321)\n",
      "16734 Traning Loss: tensor(0.0328)\n",
      "16735 Traning Loss: tensor(0.0318)\n",
      "16736 Traning Loss: tensor(0.0333)\n",
      "16737 Traning Loss: tensor(0.0314)\n",
      "16738 Traning Loss: tensor(0.0300)\n",
      "16739 Traning Loss: tensor(0.0312)\n",
      "16740 Traning Loss: tensor(0.0320)\n",
      "16741 Traning Loss: tensor(0.0313)\n",
      "16742 Traning Loss: tensor(0.0296)\n",
      "16743 Traning Loss: tensor(0.0328)\n",
      "16744 Traning Loss: tensor(0.0316)\n",
      "16745 Traning Loss: tensor(0.0340)\n",
      "16746 Traning Loss: tensor(0.0325)\n",
      "16747 Traning Loss: tensor(0.0310)\n",
      "16748 Traning Loss: tensor(0.0307)\n",
      "16749 Traning Loss: tensor(0.0308)\n",
      "16750 Traning Loss: tensor(0.0324)\n",
      "16751 Traning Loss: tensor(0.0319)\n",
      "16752 Traning Loss: tensor(0.0327)\n",
      "16753 Traning Loss: tensor(0.0316)\n",
      "16754 Traning Loss: tensor(0.0326)\n",
      "16755 Traning Loss: tensor(0.0316)\n",
      "16756 Traning Loss: tensor(0.0313)\n",
      "16757 Traning Loss: tensor(0.0337)\n",
      "16758 Traning Loss: tensor(0.0307)\n",
      "16759 Traning Loss: tensor(0.0314)\n",
      "16760 Traning Loss: tensor(0.0309)\n",
      "16761 Traning Loss: tensor(0.0312)\n",
      "16762 Traning Loss: tensor(0.0307)\n",
      "16763 Traning Loss: tensor(0.0323)\n",
      "16764 Traning Loss: tensor(0.0320)\n",
      "16765 Traning Loss: tensor(0.0307)\n",
      "16766 Traning Loss: tensor(0.0335)\n",
      "16767 Traning Loss: tensor(0.0318)\n",
      "16768 Traning Loss: tensor(0.0321)\n",
      "16769 Traning Loss: tensor(0.0317)\n",
      "16770 Traning Loss: tensor(0.0322)\n",
      "16771 Traning Loss: tensor(0.0318)\n",
      "16772 Traning Loss: tensor(0.0349)\n",
      "16773 Traning Loss: tensor(0.0347)\n",
      "16774 Traning Loss: tensor(0.0313)\n",
      "16775 Traning Loss: tensor(0.0317)\n",
      "16776 Traning Loss: tensor(0.0331)\n",
      "16777 Traning Loss: tensor(0.0327)\n",
      "16778 Traning Loss: tensor(0.0316)\n",
      "16779 Traning Loss: tensor(0.0326)\n",
      "16780 Traning Loss: tensor(0.0350)\n",
      "16781 Traning Loss: tensor(0.0320)\n",
      "16782 Traning Loss: tensor(0.0325)\n",
      "16783 Traning Loss: tensor(0.0325)\n",
      "16784 Traning Loss: tensor(0.0317)\n",
      "16785 Traning Loss: tensor(0.0339)\n",
      "16786 Traning Loss: tensor(0.0327)\n",
      "16787 Traning Loss: tensor(0.0311)\n",
      "16788 Traning Loss: tensor(0.0318)\n",
      "16789 Traning Loss: tensor(0.0326)\n",
      "16790 Traning Loss: tensor(0.0321)\n",
      "16791 Traning Loss: tensor(0.0320)\n",
      "16792 Traning Loss: tensor(0.0329)\n",
      "16793 Traning Loss: tensor(0.0336)\n",
      "16794 Traning Loss: tensor(0.0338)\n",
      "16795 Traning Loss: tensor(0.0330)\n",
      "16796 Traning Loss: tensor(0.0324)\n",
      "16797 Traning Loss: tensor(0.0317)\n",
      "16798 Traning Loss: tensor(0.0306)\n",
      "16799 Traning Loss: tensor(0.0299)\n",
      "16800 Traning Loss: tensor(0.0318)\n",
      "16801 Traning Loss: tensor(0.0337)\n",
      "16802 Traning Loss: tensor(0.0314)\n",
      "16803 Traning Loss: tensor(0.0339)\n",
      "16804 Traning Loss: tensor(0.0322)\n",
      "16805 Traning Loss: tensor(0.0332)\n",
      "16806 Traning Loss: tensor(0.0318)\n",
      "16807 Traning Loss: tensor(0.0293)\n",
      "16808 Traning Loss: tensor(0.0306)\n",
      "16809 Traning Loss: tensor(0.0309)\n",
      "16810 Traning Loss: tensor(0.0335)\n",
      "16811 Traning Loss: tensor(0.0331)\n",
      "16812 Traning Loss: tensor(0.0321)\n",
      "16813 Traning Loss: tensor(0.0327)\n",
      "16814 Traning Loss: tensor(0.0314)\n",
      "16815 Traning Loss: tensor(0.0318)\n",
      "16816 Traning Loss: tensor(0.0302)\n",
      "16817 Traning Loss: tensor(0.0316)\n",
      "16818 Traning Loss: tensor(0.0344)\n",
      "16819 Traning Loss: tensor(0.0352)\n",
      "16820 Traning Loss: tensor(0.0304)\n",
      "16821 Traning Loss: tensor(0.0325)\n",
      "16822 Traning Loss: tensor(0.0310)\n",
      "16823 Traning Loss: tensor(0.0329)\n",
      "16824 Traning Loss: tensor(0.0308)\n",
      "16825 Traning Loss: tensor(0.0331)\n",
      "16826 Traning Loss: tensor(0.0319)\n",
      "16827 Traning Loss: tensor(0.0314)\n",
      "16828 Traning Loss: tensor(0.0315)\n",
      "16829 Traning Loss: tensor(0.0321)\n",
      "16830 Traning Loss: tensor(0.0334)\n",
      "16831 Traning Loss: tensor(0.0306)\n",
      "16832 Traning Loss: tensor(0.0325)\n",
      "16833 Traning Loss: tensor(0.0323)\n",
      "16834 Traning Loss: tensor(0.0338)\n",
      "16835 Traning Loss: tensor(0.0311)\n",
      "16836 Traning Loss: tensor(0.0331)\n",
      "16837 Traning Loss: tensor(0.0326)\n",
      "16838 Traning Loss: tensor(0.0326)\n",
      "16839 Traning Loss: tensor(0.0328)\n",
      "16840 Traning Loss: tensor(0.0350)\n",
      "16841 Traning Loss: tensor(0.0311)\n",
      "16842 Traning Loss: tensor(0.0319)\n",
      "16843 Traning Loss: tensor(0.0329)\n",
      "16844 Traning Loss: tensor(0.0330)\n",
      "16845 Traning Loss: tensor(0.0314)\n",
      "16846 Traning Loss: tensor(0.0330)\n",
      "16847 Traning Loss: tensor(0.0327)\n",
      "16848 Traning Loss: tensor(0.0319)\n",
      "16849 Traning Loss: tensor(0.0308)\n",
      "16850 Traning Loss: tensor(0.0331)\n",
      "16851 Traning Loss: tensor(0.0336)\n",
      "16852 Traning Loss: tensor(0.0331)\n",
      "16853 Traning Loss: tensor(0.0308)\n",
      "16854 Traning Loss: tensor(0.0309)\n",
      "16855 Traning Loss: tensor(0.0316)\n",
      "16856 Traning Loss: tensor(0.0318)\n",
      "16857 Traning Loss: tensor(0.0311)\n",
      "16858 Traning Loss: tensor(0.0324)\n",
      "16859 Traning Loss: tensor(0.0306)\n",
      "16860 Traning Loss: tensor(0.0312)\n",
      "16861 Traning Loss: tensor(0.0314)\n",
      "16862 Traning Loss: tensor(0.0313)\n",
      "16863 Traning Loss: tensor(0.0315)\n",
      "16864 Traning Loss: tensor(0.0317)\n",
      "16865 Traning Loss: tensor(0.0338)\n",
      "16866 Traning Loss: tensor(0.0302)\n",
      "16867 Traning Loss: tensor(0.0334)\n",
      "16868 Traning Loss: tensor(0.0322)\n",
      "16869 Traning Loss: tensor(0.0304)\n",
      "16870 Traning Loss: tensor(0.0314)\n",
      "16871 Traning Loss: tensor(0.0317)\n",
      "16872 Traning Loss: tensor(0.0328)\n",
      "16873 Traning Loss: tensor(0.0333)\n",
      "16874 Traning Loss: tensor(0.0314)\n",
      "16875 Traning Loss: tensor(0.0330)\n",
      "16876 Traning Loss: tensor(0.0315)\n",
      "16877 Traning Loss: tensor(0.0306)\n",
      "16878 Traning Loss: tensor(0.0340)\n",
      "16879 Traning Loss: tensor(0.0317)\n",
      "16880 Traning Loss: tensor(0.0334)\n",
      "16881 Traning Loss: tensor(0.0320)\n",
      "16882 Traning Loss: tensor(0.0321)\n",
      "16883 Traning Loss: tensor(0.0325)\n",
      "16884 Traning Loss: tensor(0.0325)\n",
      "16885 Traning Loss: tensor(0.0309)\n",
      "16886 Traning Loss: tensor(0.0307)\n",
      "16887 Traning Loss: tensor(0.0313)\n",
      "16888 Traning Loss: tensor(0.0306)\n",
      "16889 Traning Loss: tensor(0.0330)\n",
      "16890 Traning Loss: tensor(0.0301)\n",
      "16891 Traning Loss: tensor(0.0328)\n",
      "16892 Traning Loss: tensor(0.0321)\n",
      "16893 Traning Loss: tensor(0.0337)\n",
      "16894 Traning Loss: tensor(0.0323)\n",
      "16895 Traning Loss: tensor(0.0341)\n",
      "16896 Traning Loss: tensor(0.0313)\n",
      "16897 Traning Loss: tensor(0.0325)\n",
      "16898 Traning Loss: tensor(0.0335)\n",
      "16899 Traning Loss: tensor(0.0320)\n",
      "16900 Traning Loss: tensor(0.0322)\n",
      "16901 Traning Loss: tensor(0.0311)\n",
      "16902 Traning Loss: tensor(0.0346)\n",
      "16903 Traning Loss: tensor(0.0329)\n",
      "16904 Traning Loss: tensor(0.0331)\n",
      "16905 Traning Loss: tensor(0.0316)\n",
      "16906 Traning Loss: tensor(0.0360)\n",
      "16907 Traning Loss: tensor(0.0357)\n",
      "16908 Traning Loss: tensor(0.0347)\n",
      "16909 Traning Loss: tensor(0.0341)\n",
      "16910 Traning Loss: tensor(0.0326)\n",
      "16911 Traning Loss: tensor(0.0321)\n",
      "16912 Traning Loss: tensor(0.0314)\n",
      "16913 Traning Loss: tensor(0.0310)\n",
      "16914 Traning Loss: tensor(0.0330)\n",
      "16915 Traning Loss: tensor(0.0311)\n",
      "16916 Traning Loss: tensor(0.0322)\n",
      "16917 Traning Loss: tensor(0.0322)\n",
      "16918 Traning Loss: tensor(0.0313)\n",
      "16919 Traning Loss: tensor(0.0327)\n",
      "16920 Traning Loss: tensor(0.0329)\n",
      "16921 Traning Loss: tensor(0.0335)\n",
      "16922 Traning Loss: tensor(0.0335)\n",
      "16923 Traning Loss: tensor(0.0318)\n",
      "16924 Traning Loss: tensor(0.0301)\n",
      "16925 Traning Loss: tensor(0.0314)\n",
      "16926 Traning Loss: tensor(0.0340)\n",
      "16927 Traning Loss: tensor(0.0319)\n",
      "16928 Traning Loss: tensor(0.0322)\n",
      "16929 Traning Loss: tensor(0.0340)\n",
      "16930 Traning Loss: tensor(0.0312)\n",
      "16931 Traning Loss: tensor(0.0316)\n",
      "16932 Traning Loss: tensor(0.0310)\n",
      "16933 Traning Loss: tensor(0.0327)\n",
      "16934 Traning Loss: tensor(0.0328)\n",
      "16935 Traning Loss: tensor(0.0325)\n",
      "16936 Traning Loss: tensor(0.0322)\n",
      "16937 Traning Loss: tensor(0.0325)\n",
      "16938 Traning Loss: tensor(0.0319)\n",
      "16939 Traning Loss: tensor(0.0312)\n",
      "16940 Traning Loss: tensor(0.0326)\n",
      "16941 Traning Loss: tensor(0.0309)\n",
      "16942 Traning Loss: tensor(0.0318)\n",
      "16943 Traning Loss: tensor(0.0313)\n",
      "16944 Traning Loss: tensor(0.0309)\n",
      "16945 Traning Loss: tensor(0.0330)\n",
      "16946 Traning Loss: tensor(0.0309)\n",
      "16947 Traning Loss: tensor(0.0321)\n",
      "16948 Traning Loss: tensor(0.0311)\n",
      "16949 Traning Loss: tensor(0.0325)\n",
      "16950 Traning Loss: tensor(0.0314)\n",
      "16951 Traning Loss: tensor(0.0314)\n",
      "16952 Traning Loss: tensor(0.0302)\n",
      "16953 Traning Loss: tensor(0.0324)\n",
      "16954 Traning Loss: tensor(0.0311)\n",
      "16955 Traning Loss: tensor(0.0308)\n",
      "16956 Traning Loss: tensor(0.0331)\n",
      "16957 Traning Loss: tensor(0.0313)\n",
      "16958 Traning Loss: tensor(0.0311)\n",
      "16959 Traning Loss: tensor(0.0329)\n",
      "16960 Traning Loss: tensor(0.0327)\n",
      "16961 Traning Loss: tensor(0.0326)\n",
      "16962 Traning Loss: tensor(0.0323)\n",
      "16963 Traning Loss: tensor(0.0324)\n",
      "16964 Traning Loss: tensor(0.0337)\n",
      "16965 Traning Loss: tensor(0.0331)\n",
      "16966 Traning Loss: tensor(0.0332)\n",
      "16967 Traning Loss: tensor(0.0316)\n",
      "16968 Traning Loss: tensor(0.0323)\n",
      "16969 Traning Loss: tensor(0.0322)\n",
      "16970 Traning Loss: tensor(0.0297)\n",
      "16971 Traning Loss: tensor(0.0326)\n",
      "16972 Traning Loss: tensor(0.0320)\n",
      "16973 Traning Loss: tensor(0.0373)\n",
      "16974 Traning Loss: tensor(0.0306)\n",
      "16975 Traning Loss: tensor(0.0302)\n",
      "16976 Traning Loss: tensor(0.0338)\n",
      "16977 Traning Loss: tensor(0.0327)\n",
      "16978 Traning Loss: tensor(0.0315)\n",
      "16979 Traning Loss: tensor(0.0346)\n",
      "16980 Traning Loss: tensor(0.0313)\n",
      "16981 Traning Loss: tensor(0.0328)\n",
      "16982 Traning Loss: tensor(0.0329)\n",
      "16983 Traning Loss: tensor(0.0324)\n",
      "16984 Traning Loss: tensor(0.0315)\n",
      "16985 Traning Loss: tensor(0.0318)\n",
      "16986 Traning Loss: tensor(0.0318)\n",
      "16987 Traning Loss: tensor(0.0316)\n",
      "16988 Traning Loss: tensor(0.0325)\n",
      "16989 Traning Loss: tensor(0.0313)\n",
      "16990 Traning Loss: tensor(0.0304)\n",
      "16991 Traning Loss: tensor(0.0332)\n",
      "16992 Traning Loss: tensor(0.0322)\n",
      "16993 Traning Loss: tensor(0.0309)\n",
      "16994 Traning Loss: tensor(0.0321)\n",
      "16995 Traning Loss: tensor(0.0313)\n",
      "16996 Traning Loss: tensor(0.0312)\n",
      "16997 Traning Loss: tensor(0.0312)\n",
      "16998 Traning Loss: tensor(0.0321)\n",
      "16999 Traning Loss: tensor(0.0315)\n",
      "17000 Traning Loss: tensor(0.0318)\n",
      "17001 Traning Loss: tensor(0.0320)\n",
      "17002 Traning Loss: tensor(0.0303)\n",
      "17003 Traning Loss: tensor(0.0325)\n",
      "17004 Traning Loss: tensor(0.0305)\n",
      "17005 Traning Loss: tensor(0.0304)\n",
      "17006 Traning Loss: tensor(0.0312)\n",
      "17007 Traning Loss: tensor(0.0326)\n",
      "17008 Traning Loss: tensor(0.0321)\n",
      "17009 Traning Loss: tensor(0.0330)\n",
      "17010 Traning Loss: tensor(0.0309)\n",
      "17011 Traning Loss: tensor(0.0315)\n",
      "17012 Traning Loss: tensor(0.0327)\n",
      "17013 Traning Loss: tensor(0.0320)\n",
      "17014 Traning Loss: tensor(0.0352)\n",
      "17015 Traning Loss: tensor(0.0298)\n",
      "17016 Traning Loss: tensor(0.0310)\n",
      "17017 Traning Loss: tensor(0.0325)\n",
      "17018 Traning Loss: tensor(0.0315)\n",
      "17019 Traning Loss: tensor(0.0330)\n",
      "17020 Traning Loss: tensor(0.0346)\n",
      "17021 Traning Loss: tensor(0.0321)\n",
      "17022 Traning Loss: tensor(0.0319)\n",
      "17023 Traning Loss: tensor(0.0304)\n",
      "17024 Traning Loss: tensor(0.0316)\n",
      "17025 Traning Loss: tensor(0.0336)\n",
      "17026 Traning Loss: tensor(0.0311)\n",
      "17027 Traning Loss: tensor(0.0315)\n",
      "17028 Traning Loss: tensor(0.0310)\n",
      "17029 Traning Loss: tensor(0.0314)\n",
      "17030 Traning Loss: tensor(0.0316)\n",
      "17031 Traning Loss: tensor(0.0328)\n",
      "17032 Traning Loss: tensor(0.0315)\n",
      "17033 Traning Loss: tensor(0.0318)\n",
      "17034 Traning Loss: tensor(0.0319)\n",
      "17035 Traning Loss: tensor(0.0305)\n",
      "17036 Traning Loss: tensor(0.0296)\n",
      "17037 Traning Loss: tensor(0.0311)\n",
      "17038 Traning Loss: tensor(0.0313)\n",
      "17039 Traning Loss: tensor(0.0302)\n",
      "17040 Traning Loss: tensor(0.0299)\n",
      "17041 Traning Loss: tensor(0.0312)\n",
      "17042 Traning Loss: tensor(0.0305)\n",
      "17043 Traning Loss: tensor(0.0324)\n",
      "17044 Traning Loss: tensor(0.0328)\n",
      "17045 Traning Loss: tensor(0.0321)\n",
      "17046 Traning Loss: tensor(0.0325)\n",
      "17047 Traning Loss: tensor(0.0298)\n",
      "17048 Traning Loss: tensor(0.0328)\n",
      "17049 Traning Loss: tensor(0.0308)\n",
      "17050 Traning Loss: tensor(0.0313)\n",
      "17051 Traning Loss: tensor(0.0311)\n",
      "17052 Traning Loss: tensor(0.0310)\n",
      "17053 Traning Loss: tensor(0.0320)\n",
      "17054 Traning Loss: tensor(0.0307)\n",
      "17055 Traning Loss: tensor(0.0327)\n",
      "17056 Traning Loss: tensor(0.0320)\n",
      "17057 Traning Loss: tensor(0.0322)\n",
      "17058 Traning Loss: tensor(0.0325)\n",
      "17059 Traning Loss: tensor(0.0319)\n",
      "17060 Traning Loss: tensor(0.0314)\n",
      "17061 Traning Loss: tensor(0.0336)\n",
      "17062 Traning Loss: tensor(0.0317)\n",
      "17063 Traning Loss: tensor(0.0330)\n",
      "17064 Traning Loss: tensor(0.0320)\n",
      "17065 Traning Loss: tensor(0.0331)\n",
      "17066 Traning Loss: tensor(0.0326)\n",
      "17067 Traning Loss: tensor(0.0320)\n",
      "17068 Traning Loss: tensor(0.0330)\n",
      "17069 Traning Loss: tensor(0.0322)\n",
      "17070 Traning Loss: tensor(0.0349)\n",
      "17071 Traning Loss: tensor(0.0343)\n",
      "17072 Traning Loss: tensor(0.0318)\n",
      "17073 Traning Loss: tensor(0.0324)\n",
      "17074 Traning Loss: tensor(0.0329)\n",
      "17075 Traning Loss: tensor(0.0324)\n",
      "17076 Traning Loss: tensor(0.0322)\n",
      "17077 Traning Loss: tensor(0.0309)\n",
      "17078 Traning Loss: tensor(0.0336)\n",
      "17079 Traning Loss: tensor(0.0332)\n",
      "17080 Traning Loss: tensor(0.0321)\n",
      "17081 Traning Loss: tensor(0.0332)\n",
      "17082 Traning Loss: tensor(0.0328)\n",
      "17083 Traning Loss: tensor(0.0318)\n",
      "17084 Traning Loss: tensor(0.0332)\n",
      "17085 Traning Loss: tensor(0.0331)\n",
      "17086 Traning Loss: tensor(0.0314)\n",
      "17087 Traning Loss: tensor(0.0321)\n",
      "17088 Traning Loss: tensor(0.0324)\n",
      "17089 Traning Loss: tensor(0.0312)\n",
      "17090 Traning Loss: tensor(0.0330)\n",
      "17091 Traning Loss: tensor(0.0330)\n",
      "17092 Traning Loss: tensor(0.0305)\n",
      "17093 Traning Loss: tensor(0.0321)\n",
      "17094 Traning Loss: tensor(0.0321)\n",
      "17095 Traning Loss: tensor(0.0333)\n",
      "17096 Traning Loss: tensor(0.0335)\n",
      "17097 Traning Loss: tensor(0.0337)\n",
      "17098 Traning Loss: tensor(0.0307)\n",
      "17099 Traning Loss: tensor(0.0311)\n",
      "17100 Traning Loss: tensor(0.0308)\n",
      "17101 Traning Loss: tensor(0.0310)\n",
      "17102 Traning Loss: tensor(0.0316)\n",
      "17103 Traning Loss: tensor(0.0305)\n",
      "17104 Traning Loss: tensor(0.0344)\n",
      "17105 Traning Loss: tensor(0.0312)\n",
      "17106 Traning Loss: tensor(0.0320)\n",
      "17107 Traning Loss: tensor(0.0333)\n",
      "17108 Traning Loss: tensor(0.0334)\n",
      "17109 Traning Loss: tensor(0.0324)\n",
      "17110 Traning Loss: tensor(0.0336)\n",
      "17111 Traning Loss: tensor(0.0310)\n",
      "17112 Traning Loss: tensor(0.0305)\n",
      "17113 Traning Loss: tensor(0.0341)\n",
      "17114 Traning Loss: tensor(0.0320)\n",
      "17115 Traning Loss: tensor(0.0318)\n",
      "17116 Traning Loss: tensor(0.0325)\n",
      "17117 Traning Loss: tensor(0.0308)\n",
      "17118 Traning Loss: tensor(0.0326)\n",
      "17119 Traning Loss: tensor(0.0322)\n",
      "17120 Traning Loss: tensor(0.0324)\n",
      "17121 Traning Loss: tensor(0.0297)\n",
      "17122 Traning Loss: tensor(0.0315)\n",
      "17123 Traning Loss: tensor(0.0331)\n",
      "17124 Traning Loss: tensor(0.0335)\n",
      "17125 Traning Loss: tensor(0.0316)\n",
      "17126 Traning Loss: tensor(0.0312)\n",
      "17127 Traning Loss: tensor(0.0309)\n",
      "17128 Traning Loss: tensor(0.0308)\n",
      "17129 Traning Loss: tensor(0.0324)\n",
      "17130 Traning Loss: tensor(0.0319)\n",
      "17131 Traning Loss: tensor(0.0309)\n",
      "17132 Traning Loss: tensor(0.0308)\n",
      "17133 Traning Loss: tensor(0.0305)\n",
      "17134 Traning Loss: tensor(0.0303)\n",
      "17135 Traning Loss: tensor(0.0312)\n",
      "17136 Traning Loss: tensor(0.0304)\n",
      "17137 Traning Loss: tensor(0.0305)\n",
      "17138 Traning Loss: tensor(0.0308)\n",
      "17139 Traning Loss: tensor(0.0323)\n",
      "17140 Traning Loss: tensor(0.0313)\n",
      "17141 Traning Loss: tensor(0.0315)\n",
      "17142 Traning Loss: tensor(0.0308)\n",
      "17143 Traning Loss: tensor(0.0300)\n",
      "17144 Traning Loss: tensor(0.0318)\n",
      "17145 Traning Loss: tensor(0.0312)\n",
      "17146 Traning Loss: tensor(0.0320)\n",
      "17147 Traning Loss: tensor(0.0311)\n",
      "17148 Traning Loss: tensor(0.0309)\n",
      "17149 Traning Loss: tensor(0.0311)\n",
      "17150 Traning Loss: tensor(0.0314)\n",
      "17151 Traning Loss: tensor(0.0315)\n",
      "17152 Traning Loss: tensor(0.0326)\n",
      "17153 Traning Loss: tensor(0.0332)\n",
      "17154 Traning Loss: tensor(0.0333)\n",
      "17155 Traning Loss: tensor(0.0313)\n",
      "17156 Traning Loss: tensor(0.0307)\n",
      "17157 Traning Loss: tensor(0.0310)\n",
      "17158 Traning Loss: tensor(0.0326)\n",
      "17159 Traning Loss: tensor(0.0311)\n",
      "17160 Traning Loss: tensor(0.0310)\n",
      "17161 Traning Loss: tensor(0.0321)\n",
      "17162 Traning Loss: tensor(0.0327)\n",
      "17163 Traning Loss: tensor(0.0314)\n",
      "17164 Traning Loss: tensor(0.0304)\n",
      "17165 Traning Loss: tensor(0.0313)\n",
      "17166 Traning Loss: tensor(0.0339)\n",
      "17167 Traning Loss: tensor(0.0329)\n",
      "17168 Traning Loss: tensor(0.0311)\n",
      "17169 Traning Loss: tensor(0.0313)\n",
      "17170 Traning Loss: tensor(0.0318)\n",
      "17171 Traning Loss: tensor(0.0313)\n",
      "17172 Traning Loss: tensor(0.0302)\n",
      "17173 Traning Loss: tensor(0.0323)\n",
      "17174 Traning Loss: tensor(0.0328)\n",
      "17175 Traning Loss: tensor(0.0324)\n",
      "17176 Traning Loss: tensor(0.0298)\n",
      "17177 Traning Loss: tensor(0.0306)\n",
      "17178 Traning Loss: tensor(0.0319)\n",
      "17179 Traning Loss: tensor(0.0311)\n",
      "17180 Traning Loss: tensor(0.0319)\n",
      "17181 Traning Loss: tensor(0.0319)\n",
      "17182 Traning Loss: tensor(0.0314)\n",
      "17183 Traning Loss: tensor(0.0315)\n",
      "17184 Traning Loss: tensor(0.0311)\n",
      "17185 Traning Loss: tensor(0.0300)\n",
      "17186 Traning Loss: tensor(0.0314)\n",
      "17187 Traning Loss: tensor(0.0312)\n",
      "17188 Traning Loss: tensor(0.0319)\n",
      "17189 Traning Loss: tensor(0.0329)\n",
      "17190 Traning Loss: tensor(0.0302)\n",
      "17191 Traning Loss: tensor(0.0302)\n",
      "17192 Traning Loss: tensor(0.0282)\n",
      "17193 Traning Loss: tensor(0.0323)\n",
      "17194 Traning Loss: tensor(0.0309)\n",
      "17195 Traning Loss: tensor(0.0333)\n",
      "17196 Traning Loss: tensor(0.0319)\n",
      "17197 Traning Loss: tensor(0.0304)\n",
      "17198 Traning Loss: tensor(0.0303)\n",
      "17199 Traning Loss: tensor(0.0314)\n",
      "17200 Traning Loss: tensor(0.0322)\n",
      "17201 Traning Loss: tensor(0.0309)\n",
      "17202 Traning Loss: tensor(0.0303)\n",
      "17203 Traning Loss: tensor(0.0332)\n",
      "17204 Traning Loss: tensor(0.0311)\n",
      "17205 Traning Loss: tensor(0.0307)\n",
      "17206 Traning Loss: tensor(0.0325)\n",
      "17207 Traning Loss: tensor(0.0322)\n",
      "17208 Traning Loss: tensor(0.0314)\n",
      "17209 Traning Loss: tensor(0.0303)\n",
      "17210 Traning Loss: tensor(0.0314)\n",
      "17211 Traning Loss: tensor(0.0306)\n",
      "17212 Traning Loss: tensor(0.0319)\n",
      "17213 Traning Loss: tensor(0.0320)\n",
      "17214 Traning Loss: tensor(0.0315)\n",
      "17215 Traning Loss: tensor(0.0313)\n",
      "17216 Traning Loss: tensor(0.0328)\n",
      "17217 Traning Loss: tensor(0.0313)\n",
      "17218 Traning Loss: tensor(0.0307)\n",
      "17219 Traning Loss: tensor(0.0320)\n",
      "17220 Traning Loss: tensor(0.0323)\n",
      "17221 Traning Loss: tensor(0.0339)\n",
      "17222 Traning Loss: tensor(0.0329)\n",
      "17223 Traning Loss: tensor(0.0326)\n",
      "17224 Traning Loss: tensor(0.0336)\n",
      "17225 Traning Loss: tensor(0.0322)\n",
      "17226 Traning Loss: tensor(0.0335)\n",
      "17227 Traning Loss: tensor(0.0325)\n",
      "17228 Traning Loss: tensor(0.0341)\n",
      "17229 Traning Loss: tensor(0.0328)\n",
      "17230 Traning Loss: tensor(0.0316)\n",
      "17231 Traning Loss: tensor(0.0312)\n",
      "17232 Traning Loss: tensor(0.0331)\n",
      "17233 Traning Loss: tensor(0.0327)\n",
      "17234 Traning Loss: tensor(0.0323)\n",
      "17235 Traning Loss: tensor(0.0311)\n",
      "17236 Traning Loss: tensor(0.0316)\n",
      "17237 Traning Loss: tensor(0.0336)\n",
      "17238 Traning Loss: tensor(0.0305)\n",
      "17239 Traning Loss: tensor(0.0318)\n",
      "17240 Traning Loss: tensor(0.0328)\n",
      "17241 Traning Loss: tensor(0.0321)\n",
      "17242 Traning Loss: tensor(0.0311)\n",
      "17243 Traning Loss: tensor(0.0305)\n",
      "17244 Traning Loss: tensor(0.0322)\n",
      "17245 Traning Loss: tensor(0.0325)\n",
      "17246 Traning Loss: tensor(0.0329)\n",
      "17247 Traning Loss: tensor(0.0309)\n",
      "17248 Traning Loss: tensor(0.0311)\n",
      "17249 Traning Loss: tensor(0.0329)\n",
      "17250 Traning Loss: tensor(0.0311)\n",
      "17251 Traning Loss: tensor(0.0301)\n",
      "17252 Traning Loss: tensor(0.0309)\n",
      "17253 Traning Loss: tensor(0.0335)\n",
      "17254 Traning Loss: tensor(0.0336)\n",
      "17255 Traning Loss: tensor(0.0322)\n",
      "17256 Traning Loss: tensor(0.0329)\n",
      "17257 Traning Loss: tensor(0.0315)\n",
      "17258 Traning Loss: tensor(0.0317)\n",
      "17259 Traning Loss: tensor(0.0314)\n",
      "17260 Traning Loss: tensor(0.0309)\n",
      "17261 Traning Loss: tensor(0.0315)\n",
      "17262 Traning Loss: tensor(0.0309)\n",
      "17263 Traning Loss: tensor(0.0329)\n",
      "17264 Traning Loss: tensor(0.0312)\n",
      "17265 Traning Loss: tensor(0.0320)\n",
      "17266 Traning Loss: tensor(0.0299)\n",
      "17267 Traning Loss: tensor(0.0318)\n",
      "17268 Traning Loss: tensor(0.0304)\n",
      "17269 Traning Loss: tensor(0.0307)\n",
      "17270 Traning Loss: tensor(0.0310)\n",
      "17271 Traning Loss: tensor(0.0307)\n",
      "17272 Traning Loss: tensor(0.0303)\n",
      "17273 Traning Loss: tensor(0.0316)\n",
      "17274 Traning Loss: tensor(0.0314)\n",
      "17275 Traning Loss: tensor(0.0318)\n",
      "17276 Traning Loss: tensor(0.0324)\n",
      "17277 Traning Loss: tensor(0.0319)\n",
      "17278 Traning Loss: tensor(0.0321)\n",
      "17279 Traning Loss: tensor(0.0315)\n",
      "17280 Traning Loss: tensor(0.0316)\n",
      "17281 Traning Loss: tensor(0.0313)\n",
      "17282 Traning Loss: tensor(0.0325)\n",
      "17283 Traning Loss: tensor(0.0321)\n",
      "17284 Traning Loss: tensor(0.0317)\n",
      "17285 Traning Loss: tensor(0.0312)\n",
      "17286 Traning Loss: tensor(0.0319)\n",
      "17287 Traning Loss: tensor(0.0306)\n",
      "17288 Traning Loss: tensor(0.0312)\n",
      "17289 Traning Loss: tensor(0.0331)\n",
      "17290 Traning Loss: tensor(0.0326)\n",
      "17291 Traning Loss: tensor(0.0320)\n",
      "17292 Traning Loss: tensor(0.0293)\n",
      "17293 Traning Loss: tensor(0.0332)\n",
      "17294 Traning Loss: tensor(0.0334)\n",
      "17295 Traning Loss: tensor(0.0309)\n",
      "17296 Traning Loss: tensor(0.0320)\n",
      "17297 Traning Loss: tensor(0.0303)\n",
      "17298 Traning Loss: tensor(0.0312)\n",
      "17299 Traning Loss: tensor(0.0316)\n",
      "17300 Traning Loss: tensor(0.0311)\n",
      "17301 Traning Loss: tensor(0.0316)\n",
      "17302 Traning Loss: tensor(0.0318)\n",
      "17303 Traning Loss: tensor(0.0328)\n",
      "17304 Traning Loss: tensor(0.0317)\n",
      "17305 Traning Loss: tensor(0.0318)\n",
      "17306 Traning Loss: tensor(0.0310)\n",
      "17307 Traning Loss: tensor(0.0318)\n",
      "17308 Traning Loss: tensor(0.0314)\n",
      "17309 Traning Loss: tensor(0.0317)\n",
      "17310 Traning Loss: tensor(0.0314)\n",
      "17311 Traning Loss: tensor(0.0318)\n",
      "17312 Traning Loss: tensor(0.0323)\n",
      "17313 Traning Loss: tensor(0.0315)\n",
      "17314 Traning Loss: tensor(0.0301)\n",
      "17315 Traning Loss: tensor(0.0317)\n",
      "17316 Traning Loss: tensor(0.0334)\n",
      "17317 Traning Loss: tensor(0.0306)\n",
      "17318 Traning Loss: tensor(0.0296)\n",
      "17319 Traning Loss: tensor(0.0322)\n",
      "17320 Traning Loss: tensor(0.0318)\n",
      "17321 Traning Loss: tensor(0.0304)\n",
      "17322 Traning Loss: tensor(0.0328)\n",
      "17323 Traning Loss: tensor(0.0311)\n",
      "17324 Traning Loss: tensor(0.0299)\n",
      "17325 Traning Loss: tensor(0.0299)\n",
      "17326 Traning Loss: tensor(0.0326)\n",
      "17327 Traning Loss: tensor(0.0320)\n",
      "17328 Traning Loss: tensor(0.0312)\n",
      "17329 Traning Loss: tensor(0.0323)\n",
      "17330 Traning Loss: tensor(0.0313)\n",
      "17331 Traning Loss: tensor(0.0333)\n",
      "17332 Traning Loss: tensor(0.0317)\n",
      "17333 Traning Loss: tensor(0.0301)\n",
      "17334 Traning Loss: tensor(0.0311)\n",
      "17335 Traning Loss: tensor(0.0334)\n",
      "17336 Traning Loss: tensor(0.0313)\n",
      "17337 Traning Loss: tensor(0.0335)\n",
      "17338 Traning Loss: tensor(0.0326)\n",
      "17339 Traning Loss: tensor(0.0296)\n",
      "17340 Traning Loss: tensor(0.0316)\n",
      "17341 Traning Loss: tensor(0.0325)\n",
      "17342 Traning Loss: tensor(0.0301)\n",
      "17343 Traning Loss: tensor(0.0329)\n",
      "17344 Traning Loss: tensor(0.0311)\n",
      "17345 Traning Loss: tensor(0.0338)\n",
      "17346 Traning Loss: tensor(0.0311)\n",
      "17347 Traning Loss: tensor(0.0324)\n",
      "17348 Traning Loss: tensor(0.0299)\n",
      "17349 Traning Loss: tensor(0.0319)\n",
      "17350 Traning Loss: tensor(0.0317)\n",
      "17351 Traning Loss: tensor(0.0311)\n",
      "17352 Traning Loss: tensor(0.0315)\n",
      "17353 Traning Loss: tensor(0.0311)\n",
      "17354 Traning Loss: tensor(0.0315)\n",
      "17355 Traning Loss: tensor(0.0300)\n",
      "17356 Traning Loss: tensor(0.0329)\n",
      "17357 Traning Loss: tensor(0.0314)\n",
      "17358 Traning Loss: tensor(0.0312)\n",
      "17359 Traning Loss: tensor(0.0335)\n",
      "17360 Traning Loss: tensor(0.0314)\n",
      "17361 Traning Loss: tensor(0.0311)\n",
      "17362 Traning Loss: tensor(0.0321)\n",
      "17363 Traning Loss: tensor(0.0316)\n",
      "17364 Traning Loss: tensor(0.0304)\n",
      "17365 Traning Loss: tensor(0.0310)\n",
      "17366 Traning Loss: tensor(0.0318)\n",
      "17367 Traning Loss: tensor(0.0313)\n",
      "17368 Traning Loss: tensor(0.0301)\n",
      "17369 Traning Loss: tensor(0.0311)\n",
      "17370 Traning Loss: tensor(0.0311)\n",
      "17371 Traning Loss: tensor(0.0319)\n",
      "17372 Traning Loss: tensor(0.0329)\n",
      "17373 Traning Loss: tensor(0.0299)\n",
      "17374 Traning Loss: tensor(0.0313)\n",
      "17375 Traning Loss: tensor(0.0326)\n",
      "17376 Traning Loss: tensor(0.0313)\n",
      "17377 Traning Loss: tensor(0.0304)\n",
      "17378 Traning Loss: tensor(0.0315)\n",
      "17379 Traning Loss: tensor(0.0329)\n",
      "17380 Traning Loss: tensor(0.0308)\n",
      "17381 Traning Loss: tensor(0.0307)\n",
      "17382 Traning Loss: tensor(0.0324)\n",
      "17383 Traning Loss: tensor(0.0328)\n",
      "17384 Traning Loss: tensor(0.0308)\n",
      "17385 Traning Loss: tensor(0.0321)\n",
      "17386 Traning Loss: tensor(0.0321)\n",
      "17387 Traning Loss: tensor(0.0321)\n",
      "17388 Traning Loss: tensor(0.0314)\n",
      "17389 Traning Loss: tensor(0.0309)\n",
      "17390 Traning Loss: tensor(0.0309)\n",
      "17391 Traning Loss: tensor(0.0324)\n",
      "17392 Traning Loss: tensor(0.0317)\n",
      "17393 Traning Loss: tensor(0.0316)\n",
      "17394 Traning Loss: tensor(0.0314)\n",
      "17395 Traning Loss: tensor(0.0350)\n",
      "17396 Traning Loss: tensor(0.0310)\n",
      "17397 Traning Loss: tensor(0.0314)\n",
      "17398 Traning Loss: tensor(0.0331)\n",
      "17399 Traning Loss: tensor(0.0323)\n",
      "17400 Traning Loss: tensor(0.0323)\n",
      "17401 Traning Loss: tensor(0.0318)\n",
      "17402 Traning Loss: tensor(0.0310)\n",
      "17403 Traning Loss: tensor(0.0321)\n",
      "17404 Traning Loss: tensor(0.0312)\n",
      "17405 Traning Loss: tensor(0.0315)\n",
      "17406 Traning Loss: tensor(0.0310)\n",
      "17407 Traning Loss: tensor(0.0311)\n",
      "17408 Traning Loss: tensor(0.0305)\n",
      "17409 Traning Loss: tensor(0.0323)\n",
      "17410 Traning Loss: tensor(0.0300)\n",
      "17411 Traning Loss: tensor(0.0311)\n",
      "17412 Traning Loss: tensor(0.0311)\n",
      "17413 Traning Loss: tensor(0.0322)\n",
      "17414 Traning Loss: tensor(0.0332)\n",
      "17415 Traning Loss: tensor(0.0327)\n",
      "17416 Traning Loss: tensor(0.0320)\n",
      "17417 Traning Loss: tensor(0.0317)\n",
      "17418 Traning Loss: tensor(0.0320)\n",
      "17419 Traning Loss: tensor(0.0315)\n",
      "17420 Traning Loss: tensor(0.0318)\n",
      "17421 Traning Loss: tensor(0.0313)\n",
      "17422 Traning Loss: tensor(0.0326)\n",
      "17423 Traning Loss: tensor(0.0315)\n",
      "17424 Traning Loss: tensor(0.0305)\n",
      "17425 Traning Loss: tensor(0.0315)\n",
      "17426 Traning Loss: tensor(0.0312)\n",
      "17427 Traning Loss: tensor(0.0327)\n",
      "17428 Traning Loss: tensor(0.0317)\n",
      "17429 Traning Loss: tensor(0.0301)\n",
      "17430 Traning Loss: tensor(0.0326)\n",
      "17431 Traning Loss: tensor(0.0317)\n",
      "17432 Traning Loss: tensor(0.0303)\n",
      "17433 Traning Loss: tensor(0.0315)\n",
      "17434 Traning Loss: tensor(0.0327)\n",
      "17435 Traning Loss: tensor(0.0312)\n",
      "17436 Traning Loss: tensor(0.0347)\n",
      "17437 Traning Loss: tensor(0.0318)\n",
      "17438 Traning Loss: tensor(0.0319)\n",
      "17439 Traning Loss: tensor(0.0318)\n",
      "17440 Traning Loss: tensor(0.0316)\n",
      "17441 Traning Loss: tensor(0.0309)\n",
      "17442 Traning Loss: tensor(0.0325)\n",
      "17443 Traning Loss: tensor(0.0320)\n",
      "17444 Traning Loss: tensor(0.0304)\n",
      "17445 Traning Loss: tensor(0.0316)\n",
      "17446 Traning Loss: tensor(0.0337)\n",
      "17447 Traning Loss: tensor(0.0313)\n",
      "17448 Traning Loss: tensor(0.0309)\n",
      "17449 Traning Loss: tensor(0.0325)\n",
      "17450 Traning Loss: tensor(0.0325)\n",
      "17451 Traning Loss: tensor(0.0313)\n",
      "17452 Traning Loss: tensor(0.0314)\n",
      "17453 Traning Loss: tensor(0.0303)\n",
      "17454 Traning Loss: tensor(0.0309)\n",
      "17455 Traning Loss: tensor(0.0327)\n",
      "17456 Traning Loss: tensor(0.0316)\n",
      "17457 Traning Loss: tensor(0.0321)\n",
      "17458 Traning Loss: tensor(0.0339)\n",
      "17459 Traning Loss: tensor(0.0302)\n",
      "17460 Traning Loss: tensor(0.0317)\n",
      "17461 Traning Loss: tensor(0.0332)\n",
      "17462 Traning Loss: tensor(0.0316)\n",
      "17463 Traning Loss: tensor(0.0321)\n",
      "17464 Traning Loss: tensor(0.0325)\n",
      "17465 Traning Loss: tensor(0.0320)\n",
      "17466 Traning Loss: tensor(0.0323)\n",
      "17467 Traning Loss: tensor(0.0312)\n",
      "17468 Traning Loss: tensor(0.0307)\n",
      "17469 Traning Loss: tensor(0.0321)\n",
      "17470 Traning Loss: tensor(0.0330)\n",
      "17471 Traning Loss: tensor(0.0313)\n",
      "17472 Traning Loss: tensor(0.0320)\n",
      "17473 Traning Loss: tensor(0.0323)\n",
      "17474 Traning Loss: tensor(0.0306)\n",
      "17475 Traning Loss: tensor(0.0315)\n",
      "17476 Traning Loss: tensor(0.0307)\n",
      "17477 Traning Loss: tensor(0.0320)\n",
      "17478 Traning Loss: tensor(0.0302)\n",
      "17479 Traning Loss: tensor(0.0314)\n",
      "17480 Traning Loss: tensor(0.0331)\n",
      "17481 Traning Loss: tensor(0.0308)\n",
      "17482 Traning Loss: tensor(0.0323)\n",
      "17483 Traning Loss: tensor(0.0324)\n",
      "17484 Traning Loss: tensor(0.0306)\n",
      "17485 Traning Loss: tensor(0.0294)\n",
      "17486 Traning Loss: tensor(0.0303)\n",
      "17487 Traning Loss: tensor(0.0310)\n",
      "17488 Traning Loss: tensor(0.0324)\n",
      "17489 Traning Loss: tensor(0.0311)\n",
      "17490 Traning Loss: tensor(0.0324)\n",
      "17491 Traning Loss: tensor(0.0308)\n",
      "17492 Traning Loss: tensor(0.0305)\n",
      "17493 Traning Loss: tensor(0.0310)\n",
      "17494 Traning Loss: tensor(0.0329)\n",
      "17495 Traning Loss: tensor(0.0314)\n",
      "17496 Traning Loss: tensor(0.0305)\n",
      "17497 Traning Loss: tensor(0.0307)\n",
      "17498 Traning Loss: tensor(0.0299)\n",
      "17499 Traning Loss: tensor(0.0321)\n",
      "17500 Traning Loss: tensor(0.0309)\n",
      "17501 Traning Loss: tensor(0.0319)\n",
      "17502 Traning Loss: tensor(0.0305)\n",
      "17503 Traning Loss: tensor(0.0318)\n",
      "17504 Traning Loss: tensor(0.0313)\n",
      "17505 Traning Loss: tensor(0.0311)\n",
      "17506 Traning Loss: tensor(0.0305)\n",
      "17507 Traning Loss: tensor(0.0323)\n",
      "17508 Traning Loss: tensor(0.0313)\n",
      "17509 Traning Loss: tensor(0.0311)\n",
      "17510 Traning Loss: tensor(0.0315)\n",
      "17511 Traning Loss: tensor(0.0332)\n",
      "17512 Traning Loss: tensor(0.0305)\n",
      "17513 Traning Loss: tensor(0.0316)\n",
      "17514 Traning Loss: tensor(0.0310)\n",
      "17515 Traning Loss: tensor(0.0311)\n",
      "17516 Traning Loss: tensor(0.0300)\n",
      "17517 Traning Loss: tensor(0.0314)\n",
      "17518 Traning Loss: tensor(0.0314)\n",
      "17519 Traning Loss: tensor(0.0322)\n",
      "17520 Traning Loss: tensor(0.0325)\n",
      "17521 Traning Loss: tensor(0.0326)\n",
      "17522 Traning Loss: tensor(0.0311)\n",
      "17523 Traning Loss: tensor(0.0321)\n",
      "17524 Traning Loss: tensor(0.0287)\n",
      "17525 Traning Loss: tensor(0.0315)\n",
      "17526 Traning Loss: tensor(0.0305)\n",
      "17527 Traning Loss: tensor(0.0325)\n",
      "17528 Traning Loss: tensor(0.0307)\n",
      "17529 Traning Loss: tensor(0.0298)\n",
      "17530 Traning Loss: tensor(0.0315)\n",
      "17531 Traning Loss: tensor(0.0304)\n",
      "17532 Traning Loss: tensor(0.0313)\n",
      "17533 Traning Loss: tensor(0.0308)\n",
      "17534 Traning Loss: tensor(0.0317)\n",
      "17535 Traning Loss: tensor(0.0297)\n",
      "17536 Traning Loss: tensor(0.0312)\n",
      "17537 Traning Loss: tensor(0.0311)\n",
      "17538 Traning Loss: tensor(0.0307)\n",
      "17539 Traning Loss: tensor(0.0311)\n",
      "17540 Traning Loss: tensor(0.0310)\n",
      "17541 Traning Loss: tensor(0.0322)\n",
      "17542 Traning Loss: tensor(0.0305)\n",
      "17543 Traning Loss: tensor(0.0323)\n",
      "17544 Traning Loss: tensor(0.0327)\n",
      "17545 Traning Loss: tensor(0.0315)\n",
      "17546 Traning Loss: tensor(0.0332)\n",
      "17547 Traning Loss: tensor(0.0318)\n",
      "17548 Traning Loss: tensor(0.0312)\n",
      "17549 Traning Loss: tensor(0.0331)\n",
      "17550 Traning Loss: tensor(0.0327)\n",
      "17551 Traning Loss: tensor(0.0325)\n",
      "17552 Traning Loss: tensor(0.0313)\n",
      "17553 Traning Loss: tensor(0.0310)\n",
      "17554 Traning Loss: tensor(0.0306)\n",
      "17555 Traning Loss: tensor(0.0297)\n",
      "17556 Traning Loss: tensor(0.0311)\n",
      "17557 Traning Loss: tensor(0.0316)\n",
      "17558 Traning Loss: tensor(0.0308)\n",
      "17559 Traning Loss: tensor(0.0326)\n",
      "17560 Traning Loss: tensor(0.0314)\n",
      "17561 Traning Loss: tensor(0.0319)\n",
      "17562 Traning Loss: tensor(0.0301)\n",
      "17563 Traning Loss: tensor(0.0339)\n",
      "17564 Traning Loss: tensor(0.0316)\n",
      "17565 Traning Loss: tensor(0.0301)\n",
      "17566 Traning Loss: tensor(0.0306)\n",
      "17567 Traning Loss: tensor(0.0331)\n",
      "17568 Traning Loss: tensor(0.0304)\n",
      "17569 Traning Loss: tensor(0.0312)\n",
      "17570 Traning Loss: tensor(0.0318)\n",
      "17571 Traning Loss: tensor(0.0316)\n",
      "17572 Traning Loss: tensor(0.0334)\n",
      "17573 Traning Loss: tensor(0.0297)\n",
      "17574 Traning Loss: tensor(0.0316)\n",
      "17575 Traning Loss: tensor(0.0335)\n",
      "17576 Traning Loss: tensor(0.0297)\n",
      "17577 Traning Loss: tensor(0.0306)\n",
      "17578 Traning Loss: tensor(0.0306)\n",
      "17579 Traning Loss: tensor(0.0325)\n",
      "17580 Traning Loss: tensor(0.0308)\n",
      "17581 Traning Loss: tensor(0.0326)\n",
      "17582 Traning Loss: tensor(0.0321)\n",
      "17583 Traning Loss: tensor(0.0315)\n",
      "17584 Traning Loss: tensor(0.0312)\n",
      "17585 Traning Loss: tensor(0.0301)\n",
      "17586 Traning Loss: tensor(0.0316)\n",
      "17587 Traning Loss: tensor(0.0326)\n",
      "17588 Traning Loss: tensor(0.0334)\n",
      "17589 Traning Loss: tensor(0.0316)\n",
      "17590 Traning Loss: tensor(0.0324)\n",
      "17591 Traning Loss: tensor(0.0316)\n",
      "17592 Traning Loss: tensor(0.0295)\n",
      "17593 Traning Loss: tensor(0.0300)\n",
      "17594 Traning Loss: tensor(0.0303)\n",
      "17595 Traning Loss: tensor(0.0315)\n",
      "17596 Traning Loss: tensor(0.0308)\n",
      "17597 Traning Loss: tensor(0.0297)\n",
      "17598 Traning Loss: tensor(0.0302)\n",
      "17599 Traning Loss: tensor(0.0305)\n",
      "17600 Traning Loss: tensor(0.0313)\n",
      "17601 Traning Loss: tensor(0.0316)\n",
      "17602 Traning Loss: tensor(0.0322)\n",
      "17603 Traning Loss: tensor(0.0302)\n",
      "17604 Traning Loss: tensor(0.0302)\n",
      "17605 Traning Loss: tensor(0.0294)\n",
      "17606 Traning Loss: tensor(0.0317)\n",
      "17607 Traning Loss: tensor(0.0319)\n",
      "17608 Traning Loss: tensor(0.0304)\n",
      "17609 Traning Loss: tensor(0.0317)\n",
      "17610 Traning Loss: tensor(0.0309)\n",
      "17611 Traning Loss: tensor(0.0306)\n",
      "17612 Traning Loss: tensor(0.0316)\n",
      "17613 Traning Loss: tensor(0.0320)\n",
      "17614 Traning Loss: tensor(0.0325)\n",
      "17615 Traning Loss: tensor(0.0308)\n",
      "17616 Traning Loss: tensor(0.0320)\n",
      "17617 Traning Loss: tensor(0.0327)\n",
      "17618 Traning Loss: tensor(0.0319)\n",
      "17619 Traning Loss: tensor(0.0324)\n",
      "17620 Traning Loss: tensor(0.0307)\n",
      "17621 Traning Loss: tensor(0.0300)\n",
      "17622 Traning Loss: tensor(0.0319)\n",
      "17623 Traning Loss: tensor(0.0317)\n",
      "17624 Traning Loss: tensor(0.0319)\n",
      "17625 Traning Loss: tensor(0.0299)\n",
      "17626 Traning Loss: tensor(0.0317)\n",
      "17627 Traning Loss: tensor(0.0339)\n",
      "17628 Traning Loss: tensor(0.0299)\n",
      "17629 Traning Loss: tensor(0.0333)\n",
      "17630 Traning Loss: tensor(0.0302)\n",
      "17631 Traning Loss: tensor(0.0313)\n",
      "17632 Traning Loss: tensor(0.0315)\n",
      "17633 Traning Loss: tensor(0.0325)\n",
      "17634 Traning Loss: tensor(0.0326)\n",
      "17635 Traning Loss: tensor(0.0303)\n",
      "17636 Traning Loss: tensor(0.0317)\n",
      "17637 Traning Loss: tensor(0.0306)\n",
      "17638 Traning Loss: tensor(0.0307)\n",
      "17639 Traning Loss: tensor(0.0308)\n",
      "17640 Traning Loss: tensor(0.0304)\n",
      "17641 Traning Loss: tensor(0.0332)\n",
      "17642 Traning Loss: tensor(0.0328)\n",
      "17643 Traning Loss: tensor(0.0316)\n",
      "17644 Traning Loss: tensor(0.0337)\n",
      "17645 Traning Loss: tensor(0.0320)\n",
      "17646 Traning Loss: tensor(0.0314)\n",
      "17647 Traning Loss: tensor(0.0302)\n",
      "17648 Traning Loss: tensor(0.0303)\n",
      "17649 Traning Loss: tensor(0.0324)\n",
      "17650 Traning Loss: tensor(0.0316)\n",
      "17651 Traning Loss: tensor(0.0305)\n",
      "17652 Traning Loss: tensor(0.0313)\n",
      "17653 Traning Loss: tensor(0.0304)\n",
      "17654 Traning Loss: tensor(0.0324)\n",
      "17655 Traning Loss: tensor(0.0325)\n",
      "17656 Traning Loss: tensor(0.0314)\n",
      "17657 Traning Loss: tensor(0.0308)\n",
      "17658 Traning Loss: tensor(0.0330)\n",
      "17659 Traning Loss: tensor(0.0316)\n",
      "17660 Traning Loss: tensor(0.0317)\n",
      "17661 Traning Loss: tensor(0.0330)\n",
      "17662 Traning Loss: tensor(0.0333)\n",
      "17663 Traning Loss: tensor(0.0343)\n",
      "17664 Traning Loss: tensor(0.0306)\n",
      "17665 Traning Loss: tensor(0.0314)\n",
      "17666 Traning Loss: tensor(0.0324)\n",
      "17667 Traning Loss: tensor(0.0333)\n",
      "17668 Traning Loss: tensor(0.0335)\n",
      "17669 Traning Loss: tensor(0.0329)\n",
      "17670 Traning Loss: tensor(0.0331)\n",
      "17671 Traning Loss: tensor(0.0318)\n",
      "17672 Traning Loss: tensor(0.0313)\n",
      "17673 Traning Loss: tensor(0.0308)\n",
      "17674 Traning Loss: tensor(0.0352)\n",
      "17675 Traning Loss: tensor(0.0339)\n",
      "17676 Traning Loss: tensor(0.0311)\n",
      "17677 Traning Loss: tensor(0.0320)\n",
      "17678 Traning Loss: tensor(0.0305)\n",
      "17679 Traning Loss: tensor(0.0327)\n",
      "17680 Traning Loss: tensor(0.0302)\n",
      "17681 Traning Loss: tensor(0.0318)\n",
      "17682 Traning Loss: tensor(0.0318)\n",
      "17683 Traning Loss: tensor(0.0310)\n",
      "17684 Traning Loss: tensor(0.0317)\n",
      "17685 Traning Loss: tensor(0.0310)\n",
      "17686 Traning Loss: tensor(0.0323)\n",
      "17687 Traning Loss: tensor(0.0307)\n",
      "17688 Traning Loss: tensor(0.0315)\n",
      "17689 Traning Loss: tensor(0.0334)\n",
      "17690 Traning Loss: tensor(0.0309)\n",
      "17691 Traning Loss: tensor(0.0323)\n",
      "17692 Traning Loss: tensor(0.0315)\n",
      "17693 Traning Loss: tensor(0.0309)\n",
      "17694 Traning Loss: tensor(0.0314)\n",
      "17695 Traning Loss: tensor(0.0311)\n",
      "17696 Traning Loss: tensor(0.0309)\n",
      "17697 Traning Loss: tensor(0.0316)\n",
      "17698 Traning Loss: tensor(0.0325)\n",
      "17699 Traning Loss: tensor(0.0359)\n",
      "17700 Traning Loss: tensor(0.0305)\n",
      "17701 Traning Loss: tensor(0.0343)\n",
      "17702 Traning Loss: tensor(0.0316)\n",
      "17703 Traning Loss: tensor(0.0303)\n",
      "17704 Traning Loss: tensor(0.0310)\n",
      "17705 Traning Loss: tensor(0.0327)\n",
      "17706 Traning Loss: tensor(0.0314)\n",
      "17707 Traning Loss: tensor(0.0305)\n",
      "17708 Traning Loss: tensor(0.0333)\n",
      "17709 Traning Loss: tensor(0.0317)\n",
      "17710 Traning Loss: tensor(0.0315)\n",
      "17711 Traning Loss: tensor(0.0304)\n",
      "17712 Traning Loss: tensor(0.0316)\n",
      "17713 Traning Loss: tensor(0.0322)\n",
      "17714 Traning Loss: tensor(0.0308)\n",
      "17715 Traning Loss: tensor(0.0344)\n",
      "17716 Traning Loss: tensor(0.0328)\n",
      "17717 Traning Loss: tensor(0.0322)\n",
      "17718 Traning Loss: tensor(0.0326)\n",
      "17719 Traning Loss: tensor(0.0314)\n",
      "17720 Traning Loss: tensor(0.0306)\n",
      "17721 Traning Loss: tensor(0.0312)\n",
      "17722 Traning Loss: tensor(0.0328)\n",
      "17723 Traning Loss: tensor(0.0307)\n",
      "17724 Traning Loss: tensor(0.0316)\n",
      "17725 Traning Loss: tensor(0.0307)\n",
      "17726 Traning Loss: tensor(0.0303)\n",
      "17727 Traning Loss: tensor(0.0317)\n",
      "17728 Traning Loss: tensor(0.0327)\n",
      "17729 Traning Loss: tensor(0.0308)\n",
      "17730 Traning Loss: tensor(0.0314)\n",
      "17731 Traning Loss: tensor(0.0295)\n",
      "17732 Traning Loss: tensor(0.0312)\n",
      "17733 Traning Loss: tensor(0.0310)\n",
      "17734 Traning Loss: tensor(0.0306)\n",
      "17735 Traning Loss: tensor(0.0323)\n",
      "17736 Traning Loss: tensor(0.0312)\n",
      "17737 Traning Loss: tensor(0.0339)\n",
      "17738 Traning Loss: tensor(0.0315)\n",
      "17739 Traning Loss: tensor(0.0301)\n",
      "17740 Traning Loss: tensor(0.0312)\n",
      "17741 Traning Loss: tensor(0.0332)\n",
      "17742 Traning Loss: tensor(0.0316)\n",
      "17743 Traning Loss: tensor(0.0315)\n",
      "17744 Traning Loss: tensor(0.0306)\n",
      "17745 Traning Loss: tensor(0.0291)\n",
      "17746 Traning Loss: tensor(0.0306)\n",
      "17747 Traning Loss: tensor(0.0320)\n",
      "17748 Traning Loss: tensor(0.0294)\n",
      "17749 Traning Loss: tensor(0.0307)\n",
      "17750 Traning Loss: tensor(0.0306)\n",
      "17751 Traning Loss: tensor(0.0332)\n",
      "17752 Traning Loss: tensor(0.0331)\n",
      "17753 Traning Loss: tensor(0.0294)\n",
      "17754 Traning Loss: tensor(0.0321)\n",
      "17755 Traning Loss: tensor(0.0302)\n",
      "17756 Traning Loss: tensor(0.0319)\n",
      "17757 Traning Loss: tensor(0.0298)\n",
      "17758 Traning Loss: tensor(0.0311)\n",
      "17759 Traning Loss: tensor(0.0303)\n",
      "17760 Traning Loss: tensor(0.0315)\n",
      "17761 Traning Loss: tensor(0.0323)\n",
      "17762 Traning Loss: tensor(0.0312)\n",
      "17763 Traning Loss: tensor(0.0314)\n",
      "17764 Traning Loss: tensor(0.0308)\n",
      "17765 Traning Loss: tensor(0.0320)\n",
      "17766 Traning Loss: tensor(0.0312)\n",
      "17767 Traning Loss: tensor(0.0310)\n",
      "17768 Traning Loss: tensor(0.0330)\n",
      "17769 Traning Loss: tensor(0.0325)\n",
      "17770 Traning Loss: tensor(0.0300)\n",
      "17771 Traning Loss: tensor(0.0304)\n",
      "17772 Traning Loss: tensor(0.0311)\n",
      "17773 Traning Loss: tensor(0.0305)\n",
      "17774 Traning Loss: tensor(0.0296)\n",
      "17775 Traning Loss: tensor(0.0316)\n",
      "17776 Traning Loss: tensor(0.0320)\n",
      "17777 Traning Loss: tensor(0.0314)\n",
      "17778 Traning Loss: tensor(0.0321)\n",
      "17779 Traning Loss: tensor(0.0321)\n",
      "17780 Traning Loss: tensor(0.0333)\n",
      "17781 Traning Loss: tensor(0.0308)\n",
      "17782 Traning Loss: tensor(0.0330)\n",
      "17783 Traning Loss: tensor(0.0316)\n",
      "17784 Traning Loss: tensor(0.0326)\n",
      "17785 Traning Loss: tensor(0.0323)\n",
      "17786 Traning Loss: tensor(0.0335)\n",
      "17787 Traning Loss: tensor(0.0304)\n",
      "17788 Traning Loss: tensor(0.0322)\n",
      "17789 Traning Loss: tensor(0.0322)\n",
      "17790 Traning Loss: tensor(0.0319)\n",
      "17791 Traning Loss: tensor(0.0320)\n",
      "17792 Traning Loss: tensor(0.0318)\n",
      "17793 Traning Loss: tensor(0.0309)\n",
      "17794 Traning Loss: tensor(0.0320)\n",
      "17795 Traning Loss: tensor(0.0314)\n",
      "17796 Traning Loss: tensor(0.0319)\n",
      "17797 Traning Loss: tensor(0.0305)\n",
      "17798 Traning Loss: tensor(0.0321)\n",
      "17799 Traning Loss: tensor(0.0329)\n",
      "17800 Traning Loss: tensor(0.0289)\n",
      "17801 Traning Loss: tensor(0.0319)\n",
      "17802 Traning Loss: tensor(0.0310)\n",
      "17803 Traning Loss: tensor(0.0310)\n",
      "17804 Traning Loss: tensor(0.0309)\n",
      "17805 Traning Loss: tensor(0.0298)\n",
      "17806 Traning Loss: tensor(0.0312)\n",
      "17807 Traning Loss: tensor(0.0305)\n",
      "17808 Traning Loss: tensor(0.0343)\n",
      "17809 Traning Loss: tensor(0.0319)\n",
      "17810 Traning Loss: tensor(0.0316)\n",
      "17811 Traning Loss: tensor(0.0307)\n",
      "17812 Traning Loss: tensor(0.0315)\n",
      "17813 Traning Loss: tensor(0.0316)\n",
      "17814 Traning Loss: tensor(0.0313)\n",
      "17815 Traning Loss: tensor(0.0304)\n",
      "17816 Traning Loss: tensor(0.0313)\n",
      "17817 Traning Loss: tensor(0.0331)\n",
      "17818 Traning Loss: tensor(0.0306)\n",
      "17819 Traning Loss: tensor(0.0313)\n",
      "17820 Traning Loss: tensor(0.0336)\n",
      "17821 Traning Loss: tensor(0.0317)\n",
      "17822 Traning Loss: tensor(0.0313)\n",
      "17823 Traning Loss: tensor(0.0311)\n",
      "17824 Traning Loss: tensor(0.0313)\n",
      "17825 Traning Loss: tensor(0.0308)\n",
      "17826 Traning Loss: tensor(0.0308)\n",
      "17827 Traning Loss: tensor(0.0305)\n",
      "17828 Traning Loss: tensor(0.0314)\n",
      "17829 Traning Loss: tensor(0.0300)\n",
      "17830 Traning Loss: tensor(0.0316)\n",
      "17831 Traning Loss: tensor(0.0301)\n",
      "17832 Traning Loss: tensor(0.0319)\n",
      "17833 Traning Loss: tensor(0.0305)\n",
      "17834 Traning Loss: tensor(0.0320)\n",
      "17835 Traning Loss: tensor(0.0317)\n",
      "17836 Traning Loss: tensor(0.0311)\n",
      "17837 Traning Loss: tensor(0.0293)\n",
      "17838 Traning Loss: tensor(0.0304)\n",
      "17839 Traning Loss: tensor(0.0299)\n",
      "17840 Traning Loss: tensor(0.0313)\n",
      "17841 Traning Loss: tensor(0.0303)\n",
      "17842 Traning Loss: tensor(0.0297)\n",
      "17843 Traning Loss: tensor(0.0328)\n",
      "17844 Traning Loss: tensor(0.0316)\n",
      "17845 Traning Loss: tensor(0.0312)\n",
      "17846 Traning Loss: tensor(0.0306)\n",
      "17847 Traning Loss: tensor(0.0317)\n",
      "17848 Traning Loss: tensor(0.0309)\n",
      "17849 Traning Loss: tensor(0.0311)\n",
      "17850 Traning Loss: tensor(0.0320)\n",
      "17851 Traning Loss: tensor(0.0308)\n",
      "17852 Traning Loss: tensor(0.0308)\n",
      "17853 Traning Loss: tensor(0.0324)\n",
      "17854 Traning Loss: tensor(0.0306)\n",
      "17855 Traning Loss: tensor(0.0312)\n",
      "17856 Traning Loss: tensor(0.0332)\n",
      "17857 Traning Loss: tensor(0.0308)\n",
      "17858 Traning Loss: tensor(0.0336)\n",
      "17859 Traning Loss: tensor(0.0311)\n",
      "17860 Traning Loss: tensor(0.0296)\n",
      "17861 Traning Loss: tensor(0.0303)\n",
      "17862 Traning Loss: tensor(0.0313)\n",
      "17863 Traning Loss: tensor(0.0304)\n",
      "17864 Traning Loss: tensor(0.0317)\n",
      "17865 Traning Loss: tensor(0.0316)\n",
      "17866 Traning Loss: tensor(0.0308)\n",
      "17867 Traning Loss: tensor(0.0311)\n",
      "17868 Traning Loss: tensor(0.0327)\n",
      "17869 Traning Loss: tensor(0.0326)\n",
      "17870 Traning Loss: tensor(0.0306)\n",
      "17871 Traning Loss: tensor(0.0322)\n",
      "17872 Traning Loss: tensor(0.0334)\n",
      "17873 Traning Loss: tensor(0.0311)\n",
      "17874 Traning Loss: tensor(0.0335)\n",
      "17875 Traning Loss: tensor(0.0306)\n",
      "17876 Traning Loss: tensor(0.0319)\n",
      "17877 Traning Loss: tensor(0.0329)\n",
      "17878 Traning Loss: tensor(0.0328)\n",
      "17879 Traning Loss: tensor(0.0310)\n",
      "17880 Traning Loss: tensor(0.0305)\n",
      "17881 Traning Loss: tensor(0.0313)\n",
      "17882 Traning Loss: tensor(0.0313)\n",
      "17883 Traning Loss: tensor(0.0321)\n",
      "17884 Traning Loss: tensor(0.0316)\n",
      "17885 Traning Loss: tensor(0.0321)\n",
      "17886 Traning Loss: tensor(0.0303)\n",
      "17887 Traning Loss: tensor(0.0319)\n",
      "17888 Traning Loss: tensor(0.0306)\n",
      "17889 Traning Loss: tensor(0.0304)\n",
      "17890 Traning Loss: tensor(0.0337)\n",
      "17891 Traning Loss: tensor(0.0317)\n",
      "17892 Traning Loss: tensor(0.0322)\n",
      "17893 Traning Loss: tensor(0.0304)\n",
      "17894 Traning Loss: tensor(0.0307)\n",
      "17895 Traning Loss: tensor(0.0312)\n",
      "17896 Traning Loss: tensor(0.0313)\n",
      "17897 Traning Loss: tensor(0.0309)\n",
      "17898 Traning Loss: tensor(0.0308)\n",
      "17899 Traning Loss: tensor(0.0337)\n",
      "17900 Traning Loss: tensor(0.0303)\n",
      "17901 Traning Loss: tensor(0.0304)\n",
      "17902 Traning Loss: tensor(0.0319)\n",
      "17903 Traning Loss: tensor(0.0292)\n",
      "17904 Traning Loss: tensor(0.0304)\n",
      "17905 Traning Loss: tensor(0.0314)\n",
      "17906 Traning Loss: tensor(0.0305)\n",
      "17907 Traning Loss: tensor(0.0291)\n",
      "17908 Traning Loss: tensor(0.0306)\n",
      "17909 Traning Loss: tensor(0.0321)\n",
      "17910 Traning Loss: tensor(0.0290)\n",
      "17911 Traning Loss: tensor(0.0302)\n",
      "17912 Traning Loss: tensor(0.0295)\n",
      "17913 Traning Loss: tensor(0.0337)\n",
      "17914 Traning Loss: tensor(0.0299)\n",
      "17915 Traning Loss: tensor(0.0319)\n",
      "17916 Traning Loss: tensor(0.0302)\n",
      "17917 Traning Loss: tensor(0.0292)\n",
      "17918 Traning Loss: tensor(0.0318)\n",
      "17919 Traning Loss: tensor(0.0310)\n",
      "17920 Traning Loss: tensor(0.0313)\n",
      "17921 Traning Loss: tensor(0.0296)\n",
      "17922 Traning Loss: tensor(0.0317)\n",
      "17923 Traning Loss: tensor(0.0311)\n",
      "17924 Traning Loss: tensor(0.0302)\n",
      "17925 Traning Loss: tensor(0.0298)\n",
      "17926 Traning Loss: tensor(0.0320)\n",
      "17927 Traning Loss: tensor(0.0287)\n",
      "17928 Traning Loss: tensor(0.0319)\n",
      "17929 Traning Loss: tensor(0.0299)\n",
      "17930 Traning Loss: tensor(0.0315)\n",
      "17931 Traning Loss: tensor(0.0312)\n",
      "17932 Traning Loss: tensor(0.0280)\n",
      "17933 Traning Loss: tensor(0.0310)\n",
      "17934 Traning Loss: tensor(0.0295)\n",
      "17935 Traning Loss: tensor(0.0307)\n",
      "17936 Traning Loss: tensor(0.0311)\n",
      "17937 Traning Loss: tensor(0.0314)\n",
      "17938 Traning Loss: tensor(0.0330)\n",
      "17939 Traning Loss: tensor(0.0301)\n",
      "17940 Traning Loss: tensor(0.0308)\n",
      "17941 Traning Loss: tensor(0.0317)\n",
      "17942 Traning Loss: tensor(0.0300)\n",
      "17943 Traning Loss: tensor(0.0325)\n",
      "17944 Traning Loss: tensor(0.0303)\n",
      "17945 Traning Loss: tensor(0.0312)\n",
      "17946 Traning Loss: tensor(0.0306)\n",
      "17947 Traning Loss: tensor(0.0308)\n",
      "17948 Traning Loss: tensor(0.0308)\n",
      "17949 Traning Loss: tensor(0.0298)\n",
      "17950 Traning Loss: tensor(0.0318)\n",
      "17951 Traning Loss: tensor(0.0310)\n",
      "17952 Traning Loss: tensor(0.0307)\n",
      "17953 Traning Loss: tensor(0.0307)\n",
      "17954 Traning Loss: tensor(0.0308)\n",
      "17955 Traning Loss: tensor(0.0301)\n",
      "17956 Traning Loss: tensor(0.0308)\n",
      "17957 Traning Loss: tensor(0.0298)\n",
      "17958 Traning Loss: tensor(0.0316)\n",
      "17959 Traning Loss: tensor(0.0300)\n",
      "17960 Traning Loss: tensor(0.0304)\n",
      "17961 Traning Loss: tensor(0.0306)\n",
      "17962 Traning Loss: tensor(0.0298)\n",
      "17963 Traning Loss: tensor(0.0305)\n",
      "17964 Traning Loss: tensor(0.0302)\n",
      "17965 Traning Loss: tensor(0.0317)\n",
      "17966 Traning Loss: tensor(0.0315)\n",
      "17967 Traning Loss: tensor(0.0322)\n",
      "17968 Traning Loss: tensor(0.0301)\n",
      "17969 Traning Loss: tensor(0.0309)\n",
      "17970 Traning Loss: tensor(0.0305)\n",
      "17971 Traning Loss: tensor(0.0324)\n",
      "17972 Traning Loss: tensor(0.0302)\n",
      "17973 Traning Loss: tensor(0.0309)\n",
      "17974 Traning Loss: tensor(0.0303)\n",
      "17975 Traning Loss: tensor(0.0310)\n",
      "17976 Traning Loss: tensor(0.0303)\n",
      "17977 Traning Loss: tensor(0.0306)\n",
      "17978 Traning Loss: tensor(0.0322)\n",
      "17979 Traning Loss: tensor(0.0301)\n",
      "17980 Traning Loss: tensor(0.0292)\n",
      "17981 Traning Loss: tensor(0.0310)\n",
      "17982 Traning Loss: tensor(0.0309)\n",
      "17983 Traning Loss: tensor(0.0308)\n",
      "17984 Traning Loss: tensor(0.0308)\n",
      "17985 Traning Loss: tensor(0.0302)\n",
      "17986 Traning Loss: tensor(0.0289)\n",
      "17987 Traning Loss: tensor(0.0293)\n",
      "17988 Traning Loss: tensor(0.0311)\n",
      "17989 Traning Loss: tensor(0.0292)\n",
      "17990 Traning Loss: tensor(0.0304)\n",
      "17991 Traning Loss: tensor(0.0300)\n",
      "17992 Traning Loss: tensor(0.0314)\n",
      "17993 Traning Loss: tensor(0.0314)\n",
      "17994 Traning Loss: tensor(0.0307)\n",
      "17995 Traning Loss: tensor(0.0336)\n",
      "17996 Traning Loss: tensor(0.0321)\n",
      "17997 Traning Loss: tensor(0.0312)\n",
      "17998 Traning Loss: tensor(0.0307)\n",
      "17999 Traning Loss: tensor(0.0338)\n",
      "18000 Traning Loss: tensor(0.0304)\n",
      "18001 Traning Loss: tensor(0.0296)\n",
      "18002 Traning Loss: tensor(0.0311)\n",
      "18003 Traning Loss: tensor(0.0298)\n",
      "18004 Traning Loss: tensor(0.0336)\n",
      "18005 Traning Loss: tensor(0.0319)\n",
      "18006 Traning Loss: tensor(0.0311)\n",
      "18007 Traning Loss: tensor(0.0298)\n",
      "18008 Traning Loss: tensor(0.0298)\n",
      "18009 Traning Loss: tensor(0.0287)\n",
      "18010 Traning Loss: tensor(0.0302)\n",
      "18011 Traning Loss: tensor(0.0305)\n",
      "18012 Traning Loss: tensor(0.0307)\n",
      "18013 Traning Loss: tensor(0.0320)\n",
      "18014 Traning Loss: tensor(0.0319)\n",
      "18015 Traning Loss: tensor(0.0312)\n",
      "18016 Traning Loss: tensor(0.0327)\n",
      "18017 Traning Loss: tensor(0.0299)\n",
      "18018 Traning Loss: tensor(0.0310)\n",
      "18019 Traning Loss: tensor(0.0302)\n",
      "18020 Traning Loss: tensor(0.0316)\n",
      "18021 Traning Loss: tensor(0.0306)\n",
      "18022 Traning Loss: tensor(0.0298)\n",
      "18023 Traning Loss: tensor(0.0313)\n",
      "18024 Traning Loss: tensor(0.0298)\n",
      "18025 Traning Loss: tensor(0.0303)\n",
      "18026 Traning Loss: tensor(0.0314)\n",
      "18027 Traning Loss: tensor(0.0299)\n",
      "18028 Traning Loss: tensor(0.0319)\n",
      "18029 Traning Loss: tensor(0.0321)\n",
      "18030 Traning Loss: tensor(0.0296)\n",
      "18031 Traning Loss: tensor(0.0322)\n",
      "18032 Traning Loss: tensor(0.0313)\n",
      "18033 Traning Loss: tensor(0.0308)\n",
      "18034 Traning Loss: tensor(0.0301)\n",
      "18035 Traning Loss: tensor(0.0315)\n",
      "18036 Traning Loss: tensor(0.0299)\n",
      "18037 Traning Loss: tensor(0.0315)\n",
      "18038 Traning Loss: tensor(0.0319)\n",
      "18039 Traning Loss: tensor(0.0317)\n",
      "18040 Traning Loss: tensor(0.0307)\n",
      "18041 Traning Loss: tensor(0.0309)\n",
      "18042 Traning Loss: tensor(0.0295)\n",
      "18043 Traning Loss: tensor(0.0305)\n",
      "18044 Traning Loss: tensor(0.0311)\n",
      "18045 Traning Loss: tensor(0.0324)\n",
      "18046 Traning Loss: tensor(0.0328)\n",
      "18047 Traning Loss: tensor(0.0296)\n",
      "18048 Traning Loss: tensor(0.0313)\n",
      "18049 Traning Loss: tensor(0.0298)\n",
      "18050 Traning Loss: tensor(0.0324)\n",
      "18051 Traning Loss: tensor(0.0297)\n",
      "18052 Traning Loss: tensor(0.0307)\n",
      "18053 Traning Loss: tensor(0.0314)\n",
      "18054 Traning Loss: tensor(0.0316)\n",
      "18055 Traning Loss: tensor(0.0326)\n",
      "18056 Traning Loss: tensor(0.0297)\n",
      "18057 Traning Loss: tensor(0.0301)\n",
      "18058 Traning Loss: tensor(0.0303)\n",
      "18059 Traning Loss: tensor(0.0317)\n",
      "18060 Traning Loss: tensor(0.0301)\n",
      "18061 Traning Loss: tensor(0.0312)\n",
      "18062 Traning Loss: tensor(0.0316)\n",
      "18063 Traning Loss: tensor(0.0316)\n",
      "18064 Traning Loss: tensor(0.0300)\n",
      "18065 Traning Loss: tensor(0.0298)\n",
      "18066 Traning Loss: tensor(0.0311)\n",
      "18067 Traning Loss: tensor(0.0308)\n",
      "18068 Traning Loss: tensor(0.0341)\n",
      "18069 Traning Loss: tensor(0.0301)\n",
      "18070 Traning Loss: tensor(0.0295)\n",
      "18071 Traning Loss: tensor(0.0315)\n",
      "18072 Traning Loss: tensor(0.0309)\n",
      "18073 Traning Loss: tensor(0.0306)\n",
      "18074 Traning Loss: tensor(0.0326)\n",
      "18075 Traning Loss: tensor(0.0288)\n",
      "18076 Traning Loss: tensor(0.0311)\n",
      "18077 Traning Loss: tensor(0.0305)\n",
      "18078 Traning Loss: tensor(0.0291)\n",
      "18079 Traning Loss: tensor(0.0287)\n",
      "18080 Traning Loss: tensor(0.0299)\n",
      "18081 Traning Loss: tensor(0.0300)\n",
      "18082 Traning Loss: tensor(0.0324)\n",
      "18083 Traning Loss: tensor(0.0303)\n",
      "18084 Traning Loss: tensor(0.0313)\n",
      "18085 Traning Loss: tensor(0.0301)\n",
      "18086 Traning Loss: tensor(0.0290)\n",
      "18087 Traning Loss: tensor(0.0297)\n",
      "18088 Traning Loss: tensor(0.0328)\n",
      "18089 Traning Loss: tensor(0.0307)\n",
      "18090 Traning Loss: tensor(0.0304)\n",
      "18091 Traning Loss: tensor(0.0310)\n",
      "18092 Traning Loss: tensor(0.0292)\n",
      "18093 Traning Loss: tensor(0.0309)\n",
      "18094 Traning Loss: tensor(0.0316)\n",
      "18095 Traning Loss: tensor(0.0298)\n",
      "18096 Traning Loss: tensor(0.0308)\n",
      "18097 Traning Loss: tensor(0.0288)\n",
      "18098 Traning Loss: tensor(0.0301)\n",
      "18099 Traning Loss: tensor(0.0316)\n",
      "18100 Traning Loss: tensor(0.0305)\n",
      "18101 Traning Loss: tensor(0.0294)\n",
      "18102 Traning Loss: tensor(0.0295)\n",
      "18103 Traning Loss: tensor(0.0309)\n",
      "18104 Traning Loss: tensor(0.0296)\n",
      "18105 Traning Loss: tensor(0.0320)\n",
      "18106 Traning Loss: tensor(0.0298)\n",
      "18107 Traning Loss: tensor(0.0304)\n",
      "18108 Traning Loss: tensor(0.0291)\n",
      "18109 Traning Loss: tensor(0.0290)\n",
      "18110 Traning Loss: tensor(0.0311)\n",
      "18111 Traning Loss: tensor(0.0314)\n",
      "18112 Traning Loss: tensor(0.0342)\n",
      "18113 Traning Loss: tensor(0.0328)\n",
      "18114 Traning Loss: tensor(0.0311)\n",
      "18115 Traning Loss: tensor(0.0317)\n",
      "18116 Traning Loss: tensor(0.0319)\n",
      "18117 Traning Loss: tensor(0.0301)\n",
      "18118 Traning Loss: tensor(0.0321)\n",
      "18119 Traning Loss: tensor(0.0292)\n",
      "18120 Traning Loss: tensor(0.0307)\n",
      "18121 Traning Loss: tensor(0.0300)\n",
      "18122 Traning Loss: tensor(0.0311)\n",
      "18123 Traning Loss: tensor(0.0290)\n",
      "18124 Traning Loss: tensor(0.0306)\n",
      "18125 Traning Loss: tensor(0.0297)\n",
      "18126 Traning Loss: tensor(0.0310)\n",
      "18127 Traning Loss: tensor(0.0324)\n",
      "18128 Traning Loss: tensor(0.0308)\n",
      "18129 Traning Loss: tensor(0.0296)\n",
      "18130 Traning Loss: tensor(0.0317)\n",
      "18131 Traning Loss: tensor(0.0296)\n",
      "18132 Traning Loss: tensor(0.0295)\n",
      "18133 Traning Loss: tensor(0.0325)\n",
      "18134 Traning Loss: tensor(0.0298)\n",
      "18135 Traning Loss: tensor(0.0308)\n",
      "18136 Traning Loss: tensor(0.0298)\n",
      "18137 Traning Loss: tensor(0.0314)\n",
      "18138 Traning Loss: tensor(0.0316)\n",
      "18139 Traning Loss: tensor(0.0307)\n",
      "18140 Traning Loss: tensor(0.0307)\n",
      "18141 Traning Loss: tensor(0.0308)\n",
      "18142 Traning Loss: tensor(0.0297)\n",
      "18143 Traning Loss: tensor(0.0306)\n",
      "18144 Traning Loss: tensor(0.0322)\n",
      "18145 Traning Loss: tensor(0.0306)\n",
      "18146 Traning Loss: tensor(0.0315)\n",
      "18147 Traning Loss: tensor(0.0294)\n",
      "18148 Traning Loss: tensor(0.0329)\n",
      "18149 Traning Loss: tensor(0.0325)\n",
      "18150 Traning Loss: tensor(0.0302)\n",
      "18151 Traning Loss: tensor(0.0324)\n",
      "18152 Traning Loss: tensor(0.0305)\n",
      "18153 Traning Loss: tensor(0.0315)\n",
      "18154 Traning Loss: tensor(0.0295)\n",
      "18155 Traning Loss: tensor(0.0309)\n",
      "18156 Traning Loss: tensor(0.0317)\n",
      "18157 Traning Loss: tensor(0.0319)\n",
      "18158 Traning Loss: tensor(0.0311)\n",
      "18159 Traning Loss: tensor(0.0310)\n",
      "18160 Traning Loss: tensor(0.0317)\n",
      "18161 Traning Loss: tensor(0.0301)\n",
      "18162 Traning Loss: tensor(0.0307)\n",
      "18163 Traning Loss: tensor(0.0317)\n",
      "18164 Traning Loss: tensor(0.0317)\n",
      "18165 Traning Loss: tensor(0.0313)\n",
      "18166 Traning Loss: tensor(0.0300)\n",
      "18167 Traning Loss: tensor(0.0288)\n",
      "18168 Traning Loss: tensor(0.0314)\n",
      "18169 Traning Loss: tensor(0.0325)\n",
      "18170 Traning Loss: tensor(0.0330)\n",
      "18171 Traning Loss: tensor(0.0311)\n",
      "18172 Traning Loss: tensor(0.0318)\n",
      "18173 Traning Loss: tensor(0.0326)\n",
      "18174 Traning Loss: tensor(0.0299)\n",
      "18175 Traning Loss: tensor(0.0313)\n",
      "18176 Traning Loss: tensor(0.0307)\n",
      "18177 Traning Loss: tensor(0.0283)\n",
      "18178 Traning Loss: tensor(0.0305)\n",
      "18179 Traning Loss: tensor(0.0319)\n",
      "18180 Traning Loss: tensor(0.0333)\n",
      "18181 Traning Loss: tensor(0.0318)\n",
      "18182 Traning Loss: tensor(0.0300)\n",
      "18183 Traning Loss: tensor(0.0300)\n",
      "18184 Traning Loss: tensor(0.0310)\n",
      "18185 Traning Loss: tensor(0.0300)\n",
      "18186 Traning Loss: tensor(0.0299)\n",
      "18187 Traning Loss: tensor(0.0301)\n",
      "18188 Traning Loss: tensor(0.0300)\n",
      "18189 Traning Loss: tensor(0.0304)\n",
      "18190 Traning Loss: tensor(0.0318)\n",
      "18191 Traning Loss: tensor(0.0306)\n",
      "18192 Traning Loss: tensor(0.0310)\n",
      "18193 Traning Loss: tensor(0.0295)\n",
      "18194 Traning Loss: tensor(0.0311)\n",
      "18195 Traning Loss: tensor(0.0307)\n",
      "18196 Traning Loss: tensor(0.0305)\n",
      "18197 Traning Loss: tensor(0.0311)\n",
      "18198 Traning Loss: tensor(0.0304)\n",
      "18199 Traning Loss: tensor(0.0313)\n",
      "18200 Traning Loss: tensor(0.0305)\n",
      "18201 Traning Loss: tensor(0.0322)\n",
      "18202 Traning Loss: tensor(0.0297)\n",
      "18203 Traning Loss: tensor(0.0309)\n",
      "18204 Traning Loss: tensor(0.0303)\n",
      "18205 Traning Loss: tensor(0.0299)\n",
      "18206 Traning Loss: tensor(0.0311)\n",
      "18207 Traning Loss: tensor(0.0302)\n",
      "18208 Traning Loss: tensor(0.0308)\n",
      "18209 Traning Loss: tensor(0.0298)\n",
      "18210 Traning Loss: tensor(0.0302)\n",
      "18211 Traning Loss: tensor(0.0303)\n",
      "18212 Traning Loss: tensor(0.0306)\n",
      "18213 Traning Loss: tensor(0.0321)\n",
      "18214 Traning Loss: tensor(0.0311)\n",
      "18215 Traning Loss: tensor(0.0308)\n",
      "18216 Traning Loss: tensor(0.0303)\n",
      "18217 Traning Loss: tensor(0.0320)\n",
      "18218 Traning Loss: tensor(0.0313)\n",
      "18219 Traning Loss: tensor(0.0306)\n",
      "18220 Traning Loss: tensor(0.0310)\n",
      "18221 Traning Loss: tensor(0.0287)\n",
      "18222 Traning Loss: tensor(0.0319)\n",
      "18223 Traning Loss: tensor(0.0297)\n",
      "18224 Traning Loss: tensor(0.0311)\n",
      "18225 Traning Loss: tensor(0.0297)\n",
      "18226 Traning Loss: tensor(0.0292)\n",
      "18227 Traning Loss: tensor(0.0322)\n",
      "18228 Traning Loss: tensor(0.0308)\n",
      "18229 Traning Loss: tensor(0.0303)\n",
      "18230 Traning Loss: tensor(0.0310)\n",
      "18231 Traning Loss: tensor(0.0326)\n",
      "18232 Traning Loss: tensor(0.0304)\n",
      "18233 Traning Loss: tensor(0.0308)\n",
      "18234 Traning Loss: tensor(0.0303)\n",
      "18235 Traning Loss: tensor(0.0302)\n",
      "18236 Traning Loss: tensor(0.0306)\n",
      "18237 Traning Loss: tensor(0.0308)\n",
      "18238 Traning Loss: tensor(0.0304)\n",
      "18239 Traning Loss: tensor(0.0304)\n",
      "18240 Traning Loss: tensor(0.0316)\n",
      "18241 Traning Loss: tensor(0.0329)\n",
      "18242 Traning Loss: tensor(0.0311)\n",
      "18243 Traning Loss: tensor(0.0291)\n",
      "18244 Traning Loss: tensor(0.0308)\n",
      "18245 Traning Loss: tensor(0.0330)\n",
      "18246 Traning Loss: tensor(0.0302)\n",
      "18247 Traning Loss: tensor(0.0308)\n",
      "18248 Traning Loss: tensor(0.0310)\n",
      "18249 Traning Loss: tensor(0.0315)\n",
      "18250 Traning Loss: tensor(0.0319)\n",
      "18251 Traning Loss: tensor(0.0305)\n",
      "18252 Traning Loss: tensor(0.0318)\n",
      "18253 Traning Loss: tensor(0.0294)\n",
      "18254 Traning Loss: tensor(0.0304)\n",
      "18255 Traning Loss: tensor(0.0303)\n",
      "18256 Traning Loss: tensor(0.0294)\n",
      "18257 Traning Loss: tensor(0.0320)\n",
      "18258 Traning Loss: tensor(0.0320)\n",
      "18259 Traning Loss: tensor(0.0305)\n",
      "18260 Traning Loss: tensor(0.0324)\n",
      "18261 Traning Loss: tensor(0.0307)\n",
      "18262 Traning Loss: tensor(0.0318)\n",
      "18263 Traning Loss: tensor(0.0307)\n",
      "18264 Traning Loss: tensor(0.0305)\n",
      "18265 Traning Loss: tensor(0.0326)\n",
      "18266 Traning Loss: tensor(0.0298)\n",
      "18267 Traning Loss: tensor(0.0324)\n",
      "18268 Traning Loss: tensor(0.0301)\n",
      "18269 Traning Loss: tensor(0.0325)\n",
      "18270 Traning Loss: tensor(0.0319)\n",
      "18271 Traning Loss: tensor(0.0315)\n",
      "18272 Traning Loss: tensor(0.0318)\n",
      "18273 Traning Loss: tensor(0.0301)\n",
      "18274 Traning Loss: tensor(0.0304)\n",
      "18275 Traning Loss: tensor(0.0324)\n",
      "18276 Traning Loss: tensor(0.0327)\n",
      "18277 Traning Loss: tensor(0.0304)\n",
      "18278 Traning Loss: tensor(0.0307)\n",
      "18279 Traning Loss: tensor(0.0297)\n",
      "18280 Traning Loss: tensor(0.0311)\n",
      "18281 Traning Loss: tensor(0.0308)\n",
      "18282 Traning Loss: tensor(0.0328)\n",
      "18283 Traning Loss: tensor(0.0293)\n",
      "18284 Traning Loss: tensor(0.0301)\n",
      "18285 Traning Loss: tensor(0.0315)\n",
      "18286 Traning Loss: tensor(0.0299)\n",
      "18287 Traning Loss: tensor(0.0317)\n",
      "18288 Traning Loss: tensor(0.0299)\n",
      "18289 Traning Loss: tensor(0.0301)\n",
      "18290 Traning Loss: tensor(0.0324)\n",
      "18291 Traning Loss: tensor(0.0308)\n",
      "18292 Traning Loss: tensor(0.0315)\n",
      "18293 Traning Loss: tensor(0.0287)\n",
      "18294 Traning Loss: tensor(0.0312)\n",
      "18295 Traning Loss: tensor(0.0318)\n",
      "18296 Traning Loss: tensor(0.0300)\n",
      "18297 Traning Loss: tensor(0.0328)\n",
      "18298 Traning Loss: tensor(0.0298)\n",
      "18299 Traning Loss: tensor(0.0308)\n",
      "18300 Traning Loss: tensor(0.0299)\n",
      "18301 Traning Loss: tensor(0.0351)\n",
      "18302 Traning Loss: tensor(0.0307)\n",
      "18303 Traning Loss: tensor(0.0300)\n",
      "18304 Traning Loss: tensor(0.0309)\n",
      "18305 Traning Loss: tensor(0.0299)\n",
      "18306 Traning Loss: tensor(0.0346)\n",
      "18307 Traning Loss: tensor(0.0303)\n",
      "18308 Traning Loss: tensor(0.0302)\n",
      "18309 Traning Loss: tensor(0.0308)\n",
      "18310 Traning Loss: tensor(0.0320)\n",
      "18311 Traning Loss: tensor(0.0316)\n",
      "18312 Traning Loss: tensor(0.0300)\n",
      "18313 Traning Loss: tensor(0.0329)\n",
      "18314 Traning Loss: tensor(0.0297)\n",
      "18315 Traning Loss: tensor(0.0311)\n",
      "18316 Traning Loss: tensor(0.0336)\n",
      "18317 Traning Loss: tensor(0.0304)\n",
      "18318 Traning Loss: tensor(0.0315)\n",
      "18319 Traning Loss: tensor(0.0310)\n",
      "18320 Traning Loss: tensor(0.0305)\n",
      "18321 Traning Loss: tensor(0.0281)\n",
      "18322 Traning Loss: tensor(0.0308)\n",
      "18323 Traning Loss: tensor(0.0321)\n",
      "18324 Traning Loss: tensor(0.0316)\n",
      "18325 Traning Loss: tensor(0.0294)\n",
      "18326 Traning Loss: tensor(0.0304)\n",
      "18327 Traning Loss: tensor(0.0304)\n",
      "18328 Traning Loss: tensor(0.0308)\n",
      "18329 Traning Loss: tensor(0.0282)\n",
      "18330 Traning Loss: tensor(0.0328)\n",
      "18331 Traning Loss: tensor(0.0314)\n",
      "18332 Traning Loss: tensor(0.0313)\n",
      "18333 Traning Loss: tensor(0.0299)\n",
      "18334 Traning Loss: tensor(0.0306)\n",
      "18335 Traning Loss: tensor(0.0311)\n",
      "18336 Traning Loss: tensor(0.0304)\n",
      "18337 Traning Loss: tensor(0.0312)\n",
      "18338 Traning Loss: tensor(0.0316)\n",
      "18339 Traning Loss: tensor(0.0309)\n",
      "18340 Traning Loss: tensor(0.0305)\n",
      "18341 Traning Loss: tensor(0.0316)\n",
      "18342 Traning Loss: tensor(0.0299)\n",
      "18343 Traning Loss: tensor(0.0316)\n",
      "18344 Traning Loss: tensor(0.0317)\n",
      "18345 Traning Loss: tensor(0.0305)\n",
      "18346 Traning Loss: tensor(0.0332)\n",
      "18347 Traning Loss: tensor(0.0307)\n",
      "18348 Traning Loss: tensor(0.0301)\n",
      "18349 Traning Loss: tensor(0.0319)\n",
      "18350 Traning Loss: tensor(0.0320)\n",
      "18351 Traning Loss: tensor(0.0326)\n",
      "18352 Traning Loss: tensor(0.0314)\n",
      "18353 Traning Loss: tensor(0.0307)\n",
      "18354 Traning Loss: tensor(0.0310)\n",
      "18355 Traning Loss: tensor(0.0320)\n",
      "18356 Traning Loss: tensor(0.0311)\n",
      "18357 Traning Loss: tensor(0.0310)\n",
      "18358 Traning Loss: tensor(0.0311)\n",
      "18359 Traning Loss: tensor(0.0309)\n",
      "18360 Traning Loss: tensor(0.0306)\n",
      "18361 Traning Loss: tensor(0.0319)\n",
      "18362 Traning Loss: tensor(0.0311)\n",
      "18363 Traning Loss: tensor(0.0313)\n",
      "18364 Traning Loss: tensor(0.0308)\n",
      "18365 Traning Loss: tensor(0.0316)\n",
      "18366 Traning Loss: tensor(0.0288)\n",
      "18367 Traning Loss: tensor(0.0300)\n",
      "18368 Traning Loss: tensor(0.0320)\n",
      "18369 Traning Loss: tensor(0.0306)\n",
      "18370 Traning Loss: tensor(0.0315)\n",
      "18371 Traning Loss: tensor(0.0298)\n",
      "18372 Traning Loss: tensor(0.0313)\n",
      "18373 Traning Loss: tensor(0.0309)\n",
      "18374 Traning Loss: tensor(0.0320)\n",
      "18375 Traning Loss: tensor(0.0297)\n",
      "18376 Traning Loss: tensor(0.0314)\n",
      "18377 Traning Loss: tensor(0.0303)\n",
      "18378 Traning Loss: tensor(0.0319)\n",
      "18379 Traning Loss: tensor(0.0302)\n",
      "18380 Traning Loss: tensor(0.0307)\n",
      "18381 Traning Loss: tensor(0.0310)\n",
      "18382 Traning Loss: tensor(0.0305)\n",
      "18383 Traning Loss: tensor(0.0290)\n",
      "18384 Traning Loss: tensor(0.0299)\n",
      "18385 Traning Loss: tensor(0.0293)\n",
      "18386 Traning Loss: tensor(0.0309)\n",
      "18387 Traning Loss: tensor(0.0304)\n",
      "18388 Traning Loss: tensor(0.0302)\n",
      "18389 Traning Loss: tensor(0.0298)\n",
      "18390 Traning Loss: tensor(0.0322)\n",
      "18391 Traning Loss: tensor(0.0304)\n",
      "18392 Traning Loss: tensor(0.0309)\n",
      "18393 Traning Loss: tensor(0.0299)\n",
      "18394 Traning Loss: tensor(0.0300)\n",
      "18395 Traning Loss: tensor(0.0304)\n",
      "18396 Traning Loss: tensor(0.0314)\n",
      "18397 Traning Loss: tensor(0.0309)\n",
      "18398 Traning Loss: tensor(0.0299)\n",
      "18399 Traning Loss: tensor(0.0311)\n",
      "18400 Traning Loss: tensor(0.0304)\n",
      "18401 Traning Loss: tensor(0.0321)\n",
      "18402 Traning Loss: tensor(0.0304)\n",
      "18403 Traning Loss: tensor(0.0291)\n",
      "18404 Traning Loss: tensor(0.0308)\n",
      "18405 Traning Loss: tensor(0.0307)\n",
      "18406 Traning Loss: tensor(0.0299)\n",
      "18407 Traning Loss: tensor(0.0314)\n",
      "18408 Traning Loss: tensor(0.0325)\n",
      "18409 Traning Loss: tensor(0.0311)\n",
      "18410 Traning Loss: tensor(0.0303)\n",
      "18411 Traning Loss: tensor(0.0307)\n",
      "18412 Traning Loss: tensor(0.0309)\n",
      "18413 Traning Loss: tensor(0.0300)\n",
      "18414 Traning Loss: tensor(0.0302)\n",
      "18415 Traning Loss: tensor(0.0295)\n",
      "18416 Traning Loss: tensor(0.0291)\n",
      "18417 Traning Loss: tensor(0.0307)\n",
      "18418 Traning Loss: tensor(0.0304)\n",
      "18419 Traning Loss: tensor(0.0299)\n",
      "18420 Traning Loss: tensor(0.0324)\n",
      "18421 Traning Loss: tensor(0.0302)\n",
      "18422 Traning Loss: tensor(0.0324)\n",
      "18423 Traning Loss: tensor(0.0316)\n",
      "18424 Traning Loss: tensor(0.0294)\n",
      "18425 Traning Loss: tensor(0.0310)\n",
      "18426 Traning Loss: tensor(0.0302)\n",
      "18427 Traning Loss: tensor(0.0307)\n",
      "18428 Traning Loss: tensor(0.0301)\n",
      "18429 Traning Loss: tensor(0.0304)\n",
      "18430 Traning Loss: tensor(0.0313)\n",
      "18431 Traning Loss: tensor(0.0291)\n",
      "18432 Traning Loss: tensor(0.0312)\n",
      "18433 Traning Loss: tensor(0.0303)\n",
      "18434 Traning Loss: tensor(0.0299)\n",
      "18435 Traning Loss: tensor(0.0297)\n",
      "18436 Traning Loss: tensor(0.0295)\n",
      "18437 Traning Loss: tensor(0.0290)\n",
      "18438 Traning Loss: tensor(0.0302)\n",
      "18439 Traning Loss: tensor(0.0322)\n",
      "18440 Traning Loss: tensor(0.0300)\n",
      "18441 Traning Loss: tensor(0.0291)\n",
      "18442 Traning Loss: tensor(0.0296)\n",
      "18443 Traning Loss: tensor(0.0305)\n",
      "18444 Traning Loss: tensor(0.0306)\n",
      "18445 Traning Loss: tensor(0.0301)\n",
      "18446 Traning Loss: tensor(0.0295)\n",
      "18447 Traning Loss: tensor(0.0300)\n",
      "18448 Traning Loss: tensor(0.0300)\n",
      "18449 Traning Loss: tensor(0.0299)\n",
      "18450 Traning Loss: tensor(0.0308)\n",
      "18451 Traning Loss: tensor(0.0307)\n",
      "18452 Traning Loss: tensor(0.0299)\n",
      "18453 Traning Loss: tensor(0.0302)\n",
      "18454 Traning Loss: tensor(0.0311)\n",
      "18455 Traning Loss: tensor(0.0302)\n",
      "18456 Traning Loss: tensor(0.0299)\n",
      "18457 Traning Loss: tensor(0.0295)\n",
      "18458 Traning Loss: tensor(0.0305)\n",
      "18459 Traning Loss: tensor(0.0304)\n",
      "18460 Traning Loss: tensor(0.0309)\n",
      "18461 Traning Loss: tensor(0.0299)\n",
      "18462 Traning Loss: tensor(0.0285)\n",
      "18463 Traning Loss: tensor(0.0307)\n",
      "18464 Traning Loss: tensor(0.0300)\n",
      "18465 Traning Loss: tensor(0.0290)\n",
      "18466 Traning Loss: tensor(0.0301)\n",
      "18467 Traning Loss: tensor(0.0300)\n",
      "18468 Traning Loss: tensor(0.0297)\n",
      "18469 Traning Loss: tensor(0.0304)\n",
      "18470 Traning Loss: tensor(0.0322)\n",
      "18471 Traning Loss: tensor(0.0319)\n",
      "18472 Traning Loss: tensor(0.0297)\n",
      "18473 Traning Loss: tensor(0.0289)\n",
      "18474 Traning Loss: tensor(0.0291)\n",
      "18475 Traning Loss: tensor(0.0314)\n",
      "18476 Traning Loss: tensor(0.0300)\n",
      "18477 Traning Loss: tensor(0.0291)\n",
      "18478 Traning Loss: tensor(0.0299)\n",
      "18479 Traning Loss: tensor(0.0303)\n",
      "18480 Traning Loss: tensor(0.0295)\n",
      "18481 Traning Loss: tensor(0.0299)\n",
      "18482 Traning Loss: tensor(0.0309)\n",
      "18483 Traning Loss: tensor(0.0305)\n",
      "18484 Traning Loss: tensor(0.0300)\n",
      "18485 Traning Loss: tensor(0.0308)\n",
      "18486 Traning Loss: tensor(0.0313)\n",
      "18487 Traning Loss: tensor(0.0320)\n",
      "18488 Traning Loss: tensor(0.0293)\n",
      "18489 Traning Loss: tensor(0.0321)\n",
      "18490 Traning Loss: tensor(0.0296)\n",
      "18491 Traning Loss: tensor(0.0303)\n",
      "18492 Traning Loss: tensor(0.0312)\n",
      "18493 Traning Loss: tensor(0.0299)\n",
      "18494 Traning Loss: tensor(0.0326)\n",
      "18495 Traning Loss: tensor(0.0315)\n",
      "18496 Traning Loss: tensor(0.0297)\n",
      "18497 Traning Loss: tensor(0.0322)\n",
      "18498 Traning Loss: tensor(0.0324)\n",
      "18499 Traning Loss: tensor(0.0309)\n",
      "18500 Traning Loss: tensor(0.0306)\n",
      "18501 Traning Loss: tensor(0.0300)\n",
      "18502 Traning Loss: tensor(0.0306)\n",
      "18503 Traning Loss: tensor(0.0301)\n",
      "18504 Traning Loss: tensor(0.0290)\n",
      "18505 Traning Loss: tensor(0.0311)\n",
      "18506 Traning Loss: tensor(0.0322)\n",
      "18507 Traning Loss: tensor(0.0308)\n",
      "18508 Traning Loss: tensor(0.0303)\n",
      "18509 Traning Loss: tensor(0.0298)\n",
      "18510 Traning Loss: tensor(0.0320)\n",
      "18511 Traning Loss: tensor(0.0307)\n",
      "18512 Traning Loss: tensor(0.0315)\n",
      "18513 Traning Loss: tensor(0.0305)\n",
      "18514 Traning Loss: tensor(0.0314)\n",
      "18515 Traning Loss: tensor(0.0294)\n",
      "18516 Traning Loss: tensor(0.0298)\n",
      "18517 Traning Loss: tensor(0.0301)\n",
      "18518 Traning Loss: tensor(0.0310)\n",
      "18519 Traning Loss: tensor(0.0322)\n",
      "18520 Traning Loss: tensor(0.0316)\n",
      "18521 Traning Loss: tensor(0.0311)\n",
      "18522 Traning Loss: tensor(0.0300)\n",
      "18523 Traning Loss: tensor(0.0311)\n",
      "18524 Traning Loss: tensor(0.0295)\n",
      "18525 Traning Loss: tensor(0.0312)\n",
      "18526 Traning Loss: tensor(0.0323)\n",
      "18527 Traning Loss: tensor(0.0302)\n",
      "18528 Traning Loss: tensor(0.0312)\n",
      "18529 Traning Loss: tensor(0.0312)\n",
      "18530 Traning Loss: tensor(0.0309)\n",
      "18531 Traning Loss: tensor(0.0299)\n",
      "18532 Traning Loss: tensor(0.0308)\n",
      "18533 Traning Loss: tensor(0.0316)\n",
      "18534 Traning Loss: tensor(0.0305)\n",
      "18535 Traning Loss: tensor(0.0318)\n",
      "18536 Traning Loss: tensor(0.0315)\n",
      "18537 Traning Loss: tensor(0.0314)\n",
      "18538 Traning Loss: tensor(0.0317)\n",
      "18539 Traning Loss: tensor(0.0304)\n",
      "18540 Traning Loss: tensor(0.0324)\n",
      "18541 Traning Loss: tensor(0.0296)\n",
      "18542 Traning Loss: tensor(0.0298)\n",
      "18543 Traning Loss: tensor(0.0324)\n",
      "18544 Traning Loss: tensor(0.0316)\n",
      "18545 Traning Loss: tensor(0.0311)\n",
      "18546 Traning Loss: tensor(0.0316)\n",
      "18547 Traning Loss: tensor(0.0308)\n",
      "18548 Traning Loss: tensor(0.0300)\n",
      "18549 Traning Loss: tensor(0.0291)\n",
      "18550 Traning Loss: tensor(0.0308)\n",
      "18551 Traning Loss: tensor(0.0303)\n",
      "18552 Traning Loss: tensor(0.0310)\n",
      "18553 Traning Loss: tensor(0.0323)\n",
      "18554 Traning Loss: tensor(0.0307)\n",
      "18555 Traning Loss: tensor(0.0318)\n",
      "18556 Traning Loss: tensor(0.0325)\n",
      "18557 Traning Loss: tensor(0.0312)\n",
      "18558 Traning Loss: tensor(0.0303)\n",
      "18559 Traning Loss: tensor(0.0314)\n",
      "18560 Traning Loss: tensor(0.0315)\n",
      "18561 Traning Loss: tensor(0.0306)\n",
      "18562 Traning Loss: tensor(0.0312)\n",
      "18563 Traning Loss: tensor(0.0307)\n",
      "18564 Traning Loss: tensor(0.0302)\n",
      "18565 Traning Loss: tensor(0.0296)\n",
      "18566 Traning Loss: tensor(0.0312)\n",
      "18567 Traning Loss: tensor(0.0322)\n",
      "18568 Traning Loss: tensor(0.0318)\n",
      "18569 Traning Loss: tensor(0.0309)\n",
      "18570 Traning Loss: tensor(0.0303)\n",
      "18571 Traning Loss: tensor(0.0312)\n",
      "18572 Traning Loss: tensor(0.0301)\n",
      "18573 Traning Loss: tensor(0.0313)\n",
      "18574 Traning Loss: tensor(0.0311)\n",
      "18575 Traning Loss: tensor(0.0311)\n",
      "18576 Traning Loss: tensor(0.0319)\n",
      "18577 Traning Loss: tensor(0.0305)\n",
      "18578 Traning Loss: tensor(0.0295)\n",
      "18579 Traning Loss: tensor(0.0307)\n",
      "18580 Traning Loss: tensor(0.0307)\n",
      "18581 Traning Loss: tensor(0.0300)\n",
      "18582 Traning Loss: tensor(0.0293)\n",
      "18583 Traning Loss: tensor(0.0311)\n",
      "18584 Traning Loss: tensor(0.0292)\n",
      "18585 Traning Loss: tensor(0.0300)\n",
      "18586 Traning Loss: tensor(0.0297)\n",
      "18587 Traning Loss: tensor(0.0302)\n",
      "18588 Traning Loss: tensor(0.0301)\n",
      "18589 Traning Loss: tensor(0.0327)\n",
      "18590 Traning Loss: tensor(0.0302)\n",
      "18591 Traning Loss: tensor(0.0302)\n",
      "18592 Traning Loss: tensor(0.0305)\n",
      "18593 Traning Loss: tensor(0.0315)\n",
      "18594 Traning Loss: tensor(0.0300)\n",
      "18595 Traning Loss: tensor(0.0310)\n",
      "18596 Traning Loss: tensor(0.0301)\n",
      "18597 Traning Loss: tensor(0.0305)\n",
      "18598 Traning Loss: tensor(0.0315)\n",
      "18599 Traning Loss: tensor(0.0297)\n",
      "18600 Traning Loss: tensor(0.0335)\n",
      "18601 Traning Loss: tensor(0.0295)\n",
      "18602 Traning Loss: tensor(0.0289)\n",
      "18603 Traning Loss: tensor(0.0317)\n",
      "18604 Traning Loss: tensor(0.0305)\n",
      "18605 Traning Loss: tensor(0.0301)\n",
      "18606 Traning Loss: tensor(0.0290)\n",
      "18607 Traning Loss: tensor(0.0297)\n",
      "18608 Traning Loss: tensor(0.0307)\n",
      "18609 Traning Loss: tensor(0.0296)\n",
      "18610 Traning Loss: tensor(0.0289)\n",
      "18611 Traning Loss: tensor(0.0291)\n",
      "18612 Traning Loss: tensor(0.0287)\n",
      "18613 Traning Loss: tensor(0.0312)\n",
      "18614 Traning Loss: tensor(0.0305)\n",
      "18615 Traning Loss: tensor(0.0299)\n",
      "18616 Traning Loss: tensor(0.0326)\n",
      "18617 Traning Loss: tensor(0.0312)\n",
      "18618 Traning Loss: tensor(0.0304)\n",
      "18619 Traning Loss: tensor(0.0302)\n",
      "18620 Traning Loss: tensor(0.0296)\n",
      "18621 Traning Loss: tensor(0.0291)\n",
      "18622 Traning Loss: tensor(0.0290)\n",
      "18623 Traning Loss: tensor(0.0317)\n",
      "18624 Traning Loss: tensor(0.0307)\n",
      "18625 Traning Loss: tensor(0.0290)\n",
      "18626 Traning Loss: tensor(0.0308)\n",
      "18627 Traning Loss: tensor(0.0298)\n",
      "18628 Traning Loss: tensor(0.0324)\n",
      "18629 Traning Loss: tensor(0.0306)\n",
      "18630 Traning Loss: tensor(0.0293)\n",
      "18631 Traning Loss: tensor(0.0296)\n",
      "18632 Traning Loss: tensor(0.0336)\n",
      "18633 Traning Loss: tensor(0.0297)\n",
      "18634 Traning Loss: tensor(0.0299)\n",
      "18635 Traning Loss: tensor(0.0297)\n",
      "18636 Traning Loss: tensor(0.0313)\n",
      "18637 Traning Loss: tensor(0.0303)\n",
      "18638 Traning Loss: tensor(0.0310)\n",
      "18639 Traning Loss: tensor(0.0300)\n",
      "18640 Traning Loss: tensor(0.0311)\n",
      "18641 Traning Loss: tensor(0.0304)\n",
      "18642 Traning Loss: tensor(0.0297)\n",
      "18643 Traning Loss: tensor(0.0311)\n",
      "18644 Traning Loss: tensor(0.0313)\n",
      "18645 Traning Loss: tensor(0.0308)\n",
      "18646 Traning Loss: tensor(0.0304)\n",
      "18647 Traning Loss: tensor(0.0287)\n",
      "18648 Traning Loss: tensor(0.0302)\n",
      "18649 Traning Loss: tensor(0.0303)\n",
      "18650 Traning Loss: tensor(0.0308)\n",
      "18651 Traning Loss: tensor(0.0298)\n",
      "18652 Traning Loss: tensor(0.0315)\n",
      "18653 Traning Loss: tensor(0.0294)\n",
      "18654 Traning Loss: tensor(0.0298)\n",
      "18655 Traning Loss: tensor(0.0295)\n",
      "18656 Traning Loss: tensor(0.0299)\n",
      "18657 Traning Loss: tensor(0.0317)\n",
      "18658 Traning Loss: tensor(0.0305)\n",
      "18659 Traning Loss: tensor(0.0292)\n",
      "18660 Traning Loss: tensor(0.0313)\n",
      "18661 Traning Loss: tensor(0.0294)\n",
      "18662 Traning Loss: tensor(0.0317)\n",
      "18663 Traning Loss: tensor(0.0307)\n",
      "18664 Traning Loss: tensor(0.0305)\n",
      "18665 Traning Loss: tensor(0.0306)\n",
      "18666 Traning Loss: tensor(0.0303)\n",
      "18667 Traning Loss: tensor(0.0293)\n",
      "18668 Traning Loss: tensor(0.0316)\n",
      "18669 Traning Loss: tensor(0.0290)\n",
      "18670 Traning Loss: tensor(0.0293)\n",
      "18671 Traning Loss: tensor(0.0298)\n",
      "18672 Traning Loss: tensor(0.0303)\n",
      "18673 Traning Loss: tensor(0.0322)\n",
      "18674 Traning Loss: tensor(0.0308)\n",
      "18675 Traning Loss: tensor(0.0299)\n",
      "18676 Traning Loss: tensor(0.0292)\n",
      "18677 Traning Loss: tensor(0.0305)\n",
      "18678 Traning Loss: tensor(0.0290)\n",
      "18679 Traning Loss: tensor(0.0295)\n",
      "18680 Traning Loss: tensor(0.0303)\n",
      "18681 Traning Loss: tensor(0.0305)\n",
      "18682 Traning Loss: tensor(0.0308)\n",
      "18683 Traning Loss: tensor(0.0301)\n",
      "18684 Traning Loss: tensor(0.0303)\n",
      "18685 Traning Loss: tensor(0.0297)\n",
      "18686 Traning Loss: tensor(0.0308)\n",
      "18687 Traning Loss: tensor(0.0295)\n",
      "18688 Traning Loss: tensor(0.0295)\n",
      "18689 Traning Loss: tensor(0.0295)\n",
      "18690 Traning Loss: tensor(0.0303)\n",
      "18691 Traning Loss: tensor(0.0306)\n",
      "18692 Traning Loss: tensor(0.0301)\n",
      "18693 Traning Loss: tensor(0.0299)\n",
      "18694 Traning Loss: tensor(0.0312)\n",
      "18695 Traning Loss: tensor(0.0297)\n",
      "18696 Traning Loss: tensor(0.0312)\n",
      "18697 Traning Loss: tensor(0.0298)\n",
      "18698 Traning Loss: tensor(0.0321)\n",
      "18699 Traning Loss: tensor(0.0295)\n",
      "18700 Traning Loss: tensor(0.0306)\n",
      "18701 Traning Loss: tensor(0.0298)\n",
      "18702 Traning Loss: tensor(0.0298)\n",
      "18703 Traning Loss: tensor(0.0301)\n",
      "18704 Traning Loss: tensor(0.0306)\n",
      "18705 Traning Loss: tensor(0.0286)\n",
      "18706 Traning Loss: tensor(0.0310)\n",
      "18707 Traning Loss: tensor(0.0311)\n",
      "18708 Traning Loss: tensor(0.0293)\n",
      "18709 Traning Loss: tensor(0.0315)\n",
      "18710 Traning Loss: tensor(0.0306)\n",
      "18711 Traning Loss: tensor(0.0308)\n",
      "18712 Traning Loss: tensor(0.0297)\n",
      "18713 Traning Loss: tensor(0.0300)\n",
      "18714 Traning Loss: tensor(0.0314)\n",
      "18715 Traning Loss: tensor(0.0289)\n",
      "18716 Traning Loss: tensor(0.0316)\n",
      "18717 Traning Loss: tensor(0.0330)\n",
      "18718 Traning Loss: tensor(0.0307)\n",
      "18719 Traning Loss: tensor(0.0298)\n",
      "18720 Traning Loss: tensor(0.0334)\n",
      "18721 Traning Loss: tensor(0.0303)\n",
      "18722 Traning Loss: tensor(0.0290)\n",
      "18723 Traning Loss: tensor(0.0305)\n",
      "18724 Traning Loss: tensor(0.0291)\n",
      "18725 Traning Loss: tensor(0.0306)\n",
      "18726 Traning Loss: tensor(0.0298)\n",
      "18727 Traning Loss: tensor(0.0288)\n",
      "18728 Traning Loss: tensor(0.0292)\n",
      "18729 Traning Loss: tensor(0.0315)\n",
      "18730 Traning Loss: tensor(0.0316)\n",
      "18731 Traning Loss: tensor(0.0307)\n",
      "18732 Traning Loss: tensor(0.0286)\n",
      "18733 Traning Loss: tensor(0.0310)\n",
      "18734 Traning Loss: tensor(0.0307)\n",
      "18735 Traning Loss: tensor(0.0337)\n",
      "18736 Traning Loss: tensor(0.0327)\n",
      "18737 Traning Loss: tensor(0.0297)\n",
      "18738 Traning Loss: tensor(0.0318)\n",
      "18739 Traning Loss: tensor(0.0293)\n",
      "18740 Traning Loss: tensor(0.0323)\n",
      "18741 Traning Loss: tensor(0.0326)\n",
      "18742 Traning Loss: tensor(0.0293)\n",
      "18743 Traning Loss: tensor(0.0320)\n",
      "18744 Traning Loss: tensor(0.0295)\n",
      "18745 Traning Loss: tensor(0.0331)\n",
      "18746 Traning Loss: tensor(0.0313)\n",
      "18747 Traning Loss: tensor(0.0315)\n",
      "18748 Traning Loss: tensor(0.0336)\n",
      "18749 Traning Loss: tensor(0.0302)\n",
      "18750 Traning Loss: tensor(0.0315)\n",
      "18751 Traning Loss: tensor(0.0301)\n",
      "18752 Traning Loss: tensor(0.0303)\n",
      "18753 Traning Loss: tensor(0.0316)\n",
      "18754 Traning Loss: tensor(0.0327)\n",
      "18755 Traning Loss: tensor(0.0291)\n",
      "18756 Traning Loss: tensor(0.0305)\n",
      "18757 Traning Loss: tensor(0.0297)\n",
      "18758 Traning Loss: tensor(0.0331)\n",
      "18759 Traning Loss: tensor(0.0314)\n",
      "18760 Traning Loss: tensor(0.0293)\n",
      "18761 Traning Loss: tensor(0.0303)\n",
      "18762 Traning Loss: tensor(0.0329)\n",
      "18763 Traning Loss: tensor(0.0314)\n",
      "18764 Traning Loss: tensor(0.0305)\n",
      "18765 Traning Loss: tensor(0.0306)\n",
      "18766 Traning Loss: tensor(0.0305)\n",
      "18767 Traning Loss: tensor(0.0283)\n",
      "18768 Traning Loss: tensor(0.0287)\n",
      "18769 Traning Loss: tensor(0.0301)\n",
      "18770 Traning Loss: tensor(0.0309)\n",
      "18771 Traning Loss: tensor(0.0319)\n",
      "18772 Traning Loss: tensor(0.0308)\n",
      "18773 Traning Loss: tensor(0.0302)\n",
      "18774 Traning Loss: tensor(0.0305)\n",
      "18775 Traning Loss: tensor(0.0299)\n",
      "18776 Traning Loss: tensor(0.0297)\n",
      "18777 Traning Loss: tensor(0.0294)\n",
      "18778 Traning Loss: tensor(0.0293)\n",
      "18779 Traning Loss: tensor(0.0305)\n",
      "18780 Traning Loss: tensor(0.0301)\n",
      "18781 Traning Loss: tensor(0.0314)\n",
      "18782 Traning Loss: tensor(0.0289)\n",
      "18783 Traning Loss: tensor(0.0290)\n",
      "18784 Traning Loss: tensor(0.0287)\n",
      "18785 Traning Loss: tensor(0.0289)\n",
      "18786 Traning Loss: tensor(0.0295)\n",
      "18787 Traning Loss: tensor(0.0303)\n",
      "18788 Traning Loss: tensor(0.0298)\n",
      "18789 Traning Loss: tensor(0.0297)\n",
      "18790 Traning Loss: tensor(0.0292)\n",
      "18791 Traning Loss: tensor(0.0299)\n",
      "18792 Traning Loss: tensor(0.0307)\n",
      "18793 Traning Loss: tensor(0.0300)\n",
      "18794 Traning Loss: tensor(0.0304)\n",
      "18795 Traning Loss: tensor(0.0321)\n",
      "18796 Traning Loss: tensor(0.0307)\n",
      "18797 Traning Loss: tensor(0.0311)\n",
      "18798 Traning Loss: tensor(0.0302)\n",
      "18799 Traning Loss: tensor(0.0316)\n",
      "18800 Traning Loss: tensor(0.0315)\n",
      "18801 Traning Loss: tensor(0.0304)\n",
      "18802 Traning Loss: tensor(0.0309)\n",
      "18803 Traning Loss: tensor(0.0312)\n",
      "18804 Traning Loss: tensor(0.0299)\n",
      "18805 Traning Loss: tensor(0.0311)\n",
      "18806 Traning Loss: tensor(0.0300)\n",
      "18807 Traning Loss: tensor(0.0288)\n",
      "18808 Traning Loss: tensor(0.0285)\n",
      "18809 Traning Loss: tensor(0.0298)\n",
      "18810 Traning Loss: tensor(0.0327)\n",
      "18811 Traning Loss: tensor(0.0305)\n",
      "18812 Traning Loss: tensor(0.0303)\n",
      "18813 Traning Loss: tensor(0.0311)\n",
      "18814 Traning Loss: tensor(0.0283)\n",
      "18815 Traning Loss: tensor(0.0303)\n",
      "18816 Traning Loss: tensor(0.0305)\n",
      "18817 Traning Loss: tensor(0.0317)\n",
      "18818 Traning Loss: tensor(0.0297)\n",
      "18819 Traning Loss: tensor(0.0299)\n",
      "18820 Traning Loss: tensor(0.0300)\n",
      "18821 Traning Loss: tensor(0.0305)\n",
      "18822 Traning Loss: tensor(0.0281)\n",
      "18823 Traning Loss: tensor(0.0303)\n",
      "18824 Traning Loss: tensor(0.0298)\n",
      "18825 Traning Loss: tensor(0.0289)\n",
      "18826 Traning Loss: tensor(0.0314)\n",
      "18827 Traning Loss: tensor(0.0297)\n",
      "18828 Traning Loss: tensor(0.0294)\n",
      "18829 Traning Loss: tensor(0.0314)\n",
      "18830 Traning Loss: tensor(0.0297)\n",
      "18831 Traning Loss: tensor(0.0313)\n",
      "18832 Traning Loss: tensor(0.0316)\n",
      "18833 Traning Loss: tensor(0.0335)\n",
      "18834 Traning Loss: tensor(0.0318)\n",
      "18835 Traning Loss: tensor(0.0295)\n",
      "18836 Traning Loss: tensor(0.0299)\n",
      "18837 Traning Loss: tensor(0.0312)\n",
      "18838 Traning Loss: tensor(0.0302)\n",
      "18839 Traning Loss: tensor(0.0313)\n",
      "18840 Traning Loss: tensor(0.0301)\n",
      "18841 Traning Loss: tensor(0.0326)\n",
      "18842 Traning Loss: tensor(0.0302)\n",
      "18843 Traning Loss: tensor(0.0307)\n",
      "18844 Traning Loss: tensor(0.0306)\n",
      "18845 Traning Loss: tensor(0.0312)\n",
      "18846 Traning Loss: tensor(0.0295)\n",
      "18847 Traning Loss: tensor(0.0297)\n",
      "18848 Traning Loss: tensor(0.0305)\n",
      "18849 Traning Loss: tensor(0.0303)\n",
      "18850 Traning Loss: tensor(0.0287)\n",
      "18851 Traning Loss: tensor(0.0304)\n",
      "18852 Traning Loss: tensor(0.0311)\n",
      "18853 Traning Loss: tensor(0.0308)\n",
      "18854 Traning Loss: tensor(0.0295)\n",
      "18855 Traning Loss: tensor(0.0300)\n",
      "18856 Traning Loss: tensor(0.0298)\n",
      "18857 Traning Loss: tensor(0.0302)\n",
      "18858 Traning Loss: tensor(0.0295)\n",
      "18859 Traning Loss: tensor(0.0299)\n",
      "18860 Traning Loss: tensor(0.0290)\n",
      "18861 Traning Loss: tensor(0.0289)\n",
      "18862 Traning Loss: tensor(0.0301)\n",
      "18863 Traning Loss: tensor(0.0290)\n",
      "18864 Traning Loss: tensor(0.0313)\n",
      "18865 Traning Loss: tensor(0.0287)\n",
      "18866 Traning Loss: tensor(0.0285)\n",
      "18867 Traning Loss: tensor(0.0296)\n",
      "18868 Traning Loss: tensor(0.0293)\n",
      "18869 Traning Loss: tensor(0.0294)\n",
      "18870 Traning Loss: tensor(0.0301)\n",
      "18871 Traning Loss: tensor(0.0304)\n",
      "18872 Traning Loss: tensor(0.0305)\n",
      "18873 Traning Loss: tensor(0.0296)\n",
      "18874 Traning Loss: tensor(0.0285)\n",
      "18875 Traning Loss: tensor(0.0288)\n",
      "18876 Traning Loss: tensor(0.0297)\n",
      "18877 Traning Loss: tensor(0.0302)\n",
      "18878 Traning Loss: tensor(0.0315)\n",
      "18879 Traning Loss: tensor(0.0283)\n",
      "18880 Traning Loss: tensor(0.0317)\n",
      "18881 Traning Loss: tensor(0.0299)\n",
      "18882 Traning Loss: tensor(0.0290)\n",
      "18883 Traning Loss: tensor(0.0293)\n",
      "18884 Traning Loss: tensor(0.0308)\n",
      "18885 Traning Loss: tensor(0.0301)\n",
      "18886 Traning Loss: tensor(0.0300)\n",
      "18887 Traning Loss: tensor(0.0312)\n",
      "18888 Traning Loss: tensor(0.0298)\n",
      "18889 Traning Loss: tensor(0.0304)\n",
      "18890 Traning Loss: tensor(0.0311)\n",
      "18891 Traning Loss: tensor(0.0306)\n",
      "18892 Traning Loss: tensor(0.0283)\n",
      "18893 Traning Loss: tensor(0.0298)\n",
      "18894 Traning Loss: tensor(0.0321)\n",
      "18895 Traning Loss: tensor(0.0294)\n",
      "18896 Traning Loss: tensor(0.0294)\n",
      "18897 Traning Loss: tensor(0.0307)\n",
      "18898 Traning Loss: tensor(0.0315)\n",
      "18899 Traning Loss: tensor(0.0307)\n",
      "18900 Traning Loss: tensor(0.0308)\n",
      "18901 Traning Loss: tensor(0.0302)\n",
      "18902 Traning Loss: tensor(0.0300)\n",
      "18903 Traning Loss: tensor(0.0300)\n",
      "18904 Traning Loss: tensor(0.0304)\n",
      "18905 Traning Loss: tensor(0.0297)\n",
      "18906 Traning Loss: tensor(0.0307)\n",
      "18907 Traning Loss: tensor(0.0298)\n",
      "18908 Traning Loss: tensor(0.0304)\n",
      "18909 Traning Loss: tensor(0.0301)\n",
      "18910 Traning Loss: tensor(0.0298)\n",
      "18911 Traning Loss: tensor(0.0303)\n",
      "18912 Traning Loss: tensor(0.0292)\n",
      "18913 Traning Loss: tensor(0.0300)\n",
      "18914 Traning Loss: tensor(0.0305)\n",
      "18915 Traning Loss: tensor(0.0297)\n",
      "18916 Traning Loss: tensor(0.0295)\n",
      "18917 Traning Loss: tensor(0.0300)\n",
      "18918 Traning Loss: tensor(0.0303)\n",
      "18919 Traning Loss: tensor(0.0315)\n",
      "18920 Traning Loss: tensor(0.0289)\n",
      "18921 Traning Loss: tensor(0.0295)\n",
      "18922 Traning Loss: tensor(0.0292)\n",
      "18923 Traning Loss: tensor(0.0296)\n",
      "18924 Traning Loss: tensor(0.0314)\n",
      "18925 Traning Loss: tensor(0.0336)\n",
      "18926 Traning Loss: tensor(0.0311)\n",
      "18927 Traning Loss: tensor(0.0288)\n",
      "18928 Traning Loss: tensor(0.0291)\n",
      "18929 Traning Loss: tensor(0.0304)\n",
      "18930 Traning Loss: tensor(0.0291)\n",
      "18931 Traning Loss: tensor(0.0285)\n",
      "18932 Traning Loss: tensor(0.0302)\n",
      "18933 Traning Loss: tensor(0.0296)\n",
      "18934 Traning Loss: tensor(0.0328)\n",
      "18935 Traning Loss: tensor(0.0319)\n",
      "18936 Traning Loss: tensor(0.0307)\n",
      "18937 Traning Loss: tensor(0.0305)\n",
      "18938 Traning Loss: tensor(0.0313)\n",
      "18939 Traning Loss: tensor(0.0291)\n",
      "18940 Traning Loss: tensor(0.0292)\n",
      "18941 Traning Loss: tensor(0.0301)\n",
      "18942 Traning Loss: tensor(0.0316)\n",
      "18943 Traning Loss: tensor(0.0301)\n",
      "18944 Traning Loss: tensor(0.0303)\n",
      "18945 Traning Loss: tensor(0.0297)\n",
      "18946 Traning Loss: tensor(0.0305)\n",
      "18947 Traning Loss: tensor(0.0300)\n",
      "18948 Traning Loss: tensor(0.0295)\n",
      "18949 Traning Loss: tensor(0.0301)\n",
      "18950 Traning Loss: tensor(0.0314)\n",
      "18951 Traning Loss: tensor(0.0307)\n",
      "18952 Traning Loss: tensor(0.0301)\n",
      "18953 Traning Loss: tensor(0.0291)\n",
      "18954 Traning Loss: tensor(0.0294)\n",
      "18955 Traning Loss: tensor(0.0310)\n",
      "18956 Traning Loss: tensor(0.0310)\n",
      "18957 Traning Loss: tensor(0.0313)\n",
      "18958 Traning Loss: tensor(0.0307)\n",
      "18959 Traning Loss: tensor(0.0288)\n",
      "18960 Traning Loss: tensor(0.0307)\n",
      "18961 Traning Loss: tensor(0.0308)\n",
      "18962 Traning Loss: tensor(0.0326)\n",
      "18963 Traning Loss: tensor(0.0309)\n",
      "18964 Traning Loss: tensor(0.0310)\n",
      "18965 Traning Loss: tensor(0.0309)\n",
      "18966 Traning Loss: tensor(0.0316)\n",
      "18967 Traning Loss: tensor(0.0308)\n",
      "18968 Traning Loss: tensor(0.0305)\n",
      "18969 Traning Loss: tensor(0.0307)\n",
      "18970 Traning Loss: tensor(0.0304)\n",
      "18971 Traning Loss: tensor(0.0316)\n",
      "18972 Traning Loss: tensor(0.0297)\n",
      "18973 Traning Loss: tensor(0.0312)\n",
      "18974 Traning Loss: tensor(0.0313)\n",
      "18975 Traning Loss: tensor(0.0284)\n",
      "18976 Traning Loss: tensor(0.0306)\n",
      "18977 Traning Loss: tensor(0.0313)\n",
      "18978 Traning Loss: tensor(0.0302)\n",
      "18979 Traning Loss: tensor(0.0287)\n",
      "18980 Traning Loss: tensor(0.0295)\n",
      "18981 Traning Loss: tensor(0.0321)\n",
      "18982 Traning Loss: tensor(0.0315)\n",
      "18983 Traning Loss: tensor(0.0284)\n",
      "18984 Traning Loss: tensor(0.0295)\n",
      "18985 Traning Loss: tensor(0.0293)\n",
      "18986 Traning Loss: tensor(0.0296)\n",
      "18987 Traning Loss: tensor(0.0305)\n",
      "18988 Traning Loss: tensor(0.0300)\n",
      "18989 Traning Loss: tensor(0.0287)\n",
      "18990 Traning Loss: tensor(0.0299)\n",
      "18991 Traning Loss: tensor(0.0306)\n",
      "18992 Traning Loss: tensor(0.0320)\n",
      "18993 Traning Loss: tensor(0.0301)\n",
      "18994 Traning Loss: tensor(0.0299)\n",
      "18995 Traning Loss: tensor(0.0292)\n",
      "18996 Traning Loss: tensor(0.0307)\n",
      "18997 Traning Loss: tensor(0.0324)\n",
      "18998 Traning Loss: tensor(0.0294)\n",
      "18999 Traning Loss: tensor(0.0304)\n",
      "19000 Traning Loss: tensor(0.0298)\n",
      "19001 Traning Loss: tensor(0.0296)\n",
      "19002 Traning Loss: tensor(0.0298)\n",
      "19003 Traning Loss: tensor(0.0300)\n",
      "19004 Traning Loss: tensor(0.0309)\n",
      "19005 Traning Loss: tensor(0.0326)\n",
      "19006 Traning Loss: tensor(0.0290)\n",
      "19007 Traning Loss: tensor(0.0306)\n",
      "19008 Traning Loss: tensor(0.0307)\n",
      "19009 Traning Loss: tensor(0.0299)\n",
      "19010 Traning Loss: tensor(0.0318)\n",
      "19011 Traning Loss: tensor(0.0297)\n",
      "19012 Traning Loss: tensor(0.0309)\n",
      "19013 Traning Loss: tensor(0.0311)\n",
      "19014 Traning Loss: tensor(0.0293)\n",
      "19015 Traning Loss: tensor(0.0299)\n",
      "19016 Traning Loss: tensor(0.0306)\n",
      "19017 Traning Loss: tensor(0.0294)\n",
      "19018 Traning Loss: tensor(0.0290)\n",
      "19019 Traning Loss: tensor(0.0296)\n",
      "19020 Traning Loss: tensor(0.0305)\n",
      "19021 Traning Loss: tensor(0.0298)\n",
      "19022 Traning Loss: tensor(0.0332)\n",
      "19023 Traning Loss: tensor(0.0313)\n",
      "19024 Traning Loss: tensor(0.0309)\n",
      "19025 Traning Loss: tensor(0.0311)\n",
      "19026 Traning Loss: tensor(0.0311)\n",
      "19027 Traning Loss: tensor(0.0300)\n",
      "19028 Traning Loss: tensor(0.0313)\n",
      "19029 Traning Loss: tensor(0.0292)\n",
      "19030 Traning Loss: tensor(0.0314)\n",
      "19031 Traning Loss: tensor(0.0310)\n",
      "19032 Traning Loss: tensor(0.0309)\n",
      "19033 Traning Loss: tensor(0.0312)\n",
      "19034 Traning Loss: tensor(0.0300)\n",
      "19035 Traning Loss: tensor(0.0304)\n",
      "19036 Traning Loss: tensor(0.0300)\n",
      "19037 Traning Loss: tensor(0.0303)\n",
      "19038 Traning Loss: tensor(0.0295)\n",
      "19039 Traning Loss: tensor(0.0294)\n",
      "19040 Traning Loss: tensor(0.0293)\n",
      "19041 Traning Loss: tensor(0.0310)\n",
      "19042 Traning Loss: tensor(0.0296)\n",
      "19043 Traning Loss: tensor(0.0292)\n",
      "19044 Traning Loss: tensor(0.0304)\n",
      "19045 Traning Loss: tensor(0.0302)\n",
      "19046 Traning Loss: tensor(0.0308)\n",
      "19047 Traning Loss: tensor(0.0303)\n",
      "19048 Traning Loss: tensor(0.0295)\n",
      "19049 Traning Loss: tensor(0.0309)\n",
      "19050 Traning Loss: tensor(0.0296)\n",
      "19051 Traning Loss: tensor(0.0299)\n",
      "19052 Traning Loss: tensor(0.0301)\n",
      "19053 Traning Loss: tensor(0.0296)\n",
      "19054 Traning Loss: tensor(0.0296)\n",
      "19055 Traning Loss: tensor(0.0306)\n",
      "19056 Traning Loss: tensor(0.0295)\n",
      "19057 Traning Loss: tensor(0.0295)\n",
      "19058 Traning Loss: tensor(0.0292)\n",
      "19059 Traning Loss: tensor(0.0304)\n",
      "19060 Traning Loss: tensor(0.0292)\n",
      "19061 Traning Loss: tensor(0.0302)\n",
      "19062 Traning Loss: tensor(0.0302)\n",
      "19063 Traning Loss: tensor(0.0285)\n",
      "19064 Traning Loss: tensor(0.0308)\n",
      "19065 Traning Loss: tensor(0.0287)\n",
      "19066 Traning Loss: tensor(0.0299)\n",
      "19067 Traning Loss: tensor(0.0324)\n",
      "19068 Traning Loss: tensor(0.0298)\n",
      "19069 Traning Loss: tensor(0.0294)\n",
      "19070 Traning Loss: tensor(0.0308)\n",
      "19071 Traning Loss: tensor(0.0299)\n",
      "19072 Traning Loss: tensor(0.0284)\n",
      "19073 Traning Loss: tensor(0.0286)\n",
      "19074 Traning Loss: tensor(0.0320)\n",
      "19075 Traning Loss: tensor(0.0303)\n",
      "19076 Traning Loss: tensor(0.0289)\n",
      "19077 Traning Loss: tensor(0.0286)\n",
      "19078 Traning Loss: tensor(0.0307)\n",
      "19079 Traning Loss: tensor(0.0295)\n",
      "19080 Traning Loss: tensor(0.0304)\n",
      "19081 Traning Loss: tensor(0.0296)\n",
      "19082 Traning Loss: tensor(0.0296)\n",
      "19083 Traning Loss: tensor(0.0294)\n",
      "19084 Traning Loss: tensor(0.0303)\n",
      "19085 Traning Loss: tensor(0.0303)\n",
      "19086 Traning Loss: tensor(0.0291)\n",
      "19087 Traning Loss: tensor(0.0307)\n",
      "19088 Traning Loss: tensor(0.0322)\n",
      "19089 Traning Loss: tensor(0.0303)\n",
      "19090 Traning Loss: tensor(0.0292)\n",
      "19091 Traning Loss: tensor(0.0302)\n",
      "19092 Traning Loss: tensor(0.0304)\n",
      "19093 Traning Loss: tensor(0.0288)\n",
      "19094 Traning Loss: tensor(0.0298)\n",
      "19095 Traning Loss: tensor(0.0295)\n",
      "19096 Traning Loss: tensor(0.0308)\n",
      "19097 Traning Loss: tensor(0.0304)\n",
      "19098 Traning Loss: tensor(0.0323)\n",
      "19099 Traning Loss: tensor(0.0312)\n",
      "19100 Traning Loss: tensor(0.0296)\n",
      "19101 Traning Loss: tensor(0.0313)\n",
      "19102 Traning Loss: tensor(0.0313)\n",
      "19103 Traning Loss: tensor(0.0310)\n",
      "19104 Traning Loss: tensor(0.0305)\n",
      "19105 Traning Loss: tensor(0.0300)\n",
      "19106 Traning Loss: tensor(0.0292)\n",
      "19107 Traning Loss: tensor(0.0312)\n",
      "19108 Traning Loss: tensor(0.0295)\n",
      "19109 Traning Loss: tensor(0.0306)\n",
      "19110 Traning Loss: tensor(0.0299)\n",
      "19111 Traning Loss: tensor(0.0302)\n",
      "19112 Traning Loss: tensor(0.0305)\n",
      "19113 Traning Loss: tensor(0.0285)\n",
      "19114 Traning Loss: tensor(0.0296)\n",
      "19115 Traning Loss: tensor(0.0313)\n",
      "19116 Traning Loss: tensor(0.0302)\n",
      "19117 Traning Loss: tensor(0.0284)\n",
      "19118 Traning Loss: tensor(0.0290)\n",
      "19119 Traning Loss: tensor(0.0286)\n",
      "19120 Traning Loss: tensor(0.0296)\n",
      "19121 Traning Loss: tensor(0.0293)\n",
      "19122 Traning Loss: tensor(0.0296)\n",
      "19123 Traning Loss: tensor(0.0300)\n",
      "19124 Traning Loss: tensor(0.0295)\n",
      "19125 Traning Loss: tensor(0.0305)\n",
      "19126 Traning Loss: tensor(0.0304)\n",
      "19127 Traning Loss: tensor(0.0297)\n",
      "19128 Traning Loss: tensor(0.0287)\n",
      "19129 Traning Loss: tensor(0.0298)\n",
      "19130 Traning Loss: tensor(0.0282)\n",
      "19131 Traning Loss: tensor(0.0297)\n",
      "19132 Traning Loss: tensor(0.0296)\n",
      "19133 Traning Loss: tensor(0.0316)\n",
      "19134 Traning Loss: tensor(0.0299)\n",
      "19135 Traning Loss: tensor(0.0307)\n",
      "19136 Traning Loss: tensor(0.0288)\n",
      "19137 Traning Loss: tensor(0.0305)\n",
      "19138 Traning Loss: tensor(0.0313)\n",
      "19139 Traning Loss: tensor(0.0293)\n",
      "19140 Traning Loss: tensor(0.0301)\n",
      "19141 Traning Loss: tensor(0.0303)\n",
      "19142 Traning Loss: tensor(0.0297)\n",
      "19143 Traning Loss: tensor(0.0292)\n",
      "19144 Traning Loss: tensor(0.0308)\n",
      "19145 Traning Loss: tensor(0.0301)\n",
      "19146 Traning Loss: tensor(0.0281)\n",
      "19147 Traning Loss: tensor(0.0295)\n",
      "19148 Traning Loss: tensor(0.0300)\n",
      "19149 Traning Loss: tensor(0.0297)\n",
      "19150 Traning Loss: tensor(0.0306)\n",
      "19151 Traning Loss: tensor(0.0323)\n",
      "19152 Traning Loss: tensor(0.0288)\n",
      "19153 Traning Loss: tensor(0.0302)\n",
      "19154 Traning Loss: tensor(0.0317)\n",
      "19155 Traning Loss: tensor(0.0288)\n",
      "19156 Traning Loss: tensor(0.0291)\n",
      "19157 Traning Loss: tensor(0.0290)\n",
      "19158 Traning Loss: tensor(0.0299)\n",
      "19159 Traning Loss: tensor(0.0321)\n",
      "19160 Traning Loss: tensor(0.0296)\n",
      "19161 Traning Loss: tensor(0.0295)\n",
      "19162 Traning Loss: tensor(0.0306)\n",
      "19163 Traning Loss: tensor(0.0299)\n",
      "19164 Traning Loss: tensor(0.0277)\n",
      "19165 Traning Loss: tensor(0.0301)\n",
      "19166 Traning Loss: tensor(0.0298)\n",
      "19167 Traning Loss: tensor(0.0303)\n",
      "19168 Traning Loss: tensor(0.0300)\n",
      "19169 Traning Loss: tensor(0.0288)\n",
      "19170 Traning Loss: tensor(0.0297)\n",
      "19171 Traning Loss: tensor(0.0313)\n",
      "19172 Traning Loss: tensor(0.0279)\n",
      "19173 Traning Loss: tensor(0.0308)\n",
      "19174 Traning Loss: tensor(0.0292)\n",
      "19175 Traning Loss: tensor(0.0294)\n",
      "19176 Traning Loss: tensor(0.0300)\n",
      "19177 Traning Loss: tensor(0.0299)\n",
      "19178 Traning Loss: tensor(0.0302)\n",
      "19179 Traning Loss: tensor(0.0314)\n",
      "19180 Traning Loss: tensor(0.0300)\n",
      "19181 Traning Loss: tensor(0.0292)\n",
      "19182 Traning Loss: tensor(0.0300)\n",
      "19183 Traning Loss: tensor(0.0281)\n",
      "19184 Traning Loss: tensor(0.0313)\n",
      "19185 Traning Loss: tensor(0.0315)\n",
      "19186 Traning Loss: tensor(0.0301)\n",
      "19187 Traning Loss: tensor(0.0297)\n",
      "19188 Traning Loss: tensor(0.0292)\n",
      "19189 Traning Loss: tensor(0.0297)\n",
      "19190 Traning Loss: tensor(0.0301)\n",
      "19191 Traning Loss: tensor(0.0292)\n",
      "19192 Traning Loss: tensor(0.0296)\n",
      "19193 Traning Loss: tensor(0.0305)\n",
      "19194 Traning Loss: tensor(0.0308)\n",
      "19195 Traning Loss: tensor(0.0327)\n",
      "19196 Traning Loss: tensor(0.0299)\n",
      "19197 Traning Loss: tensor(0.0304)\n",
      "19198 Traning Loss: tensor(0.0300)\n",
      "19199 Traning Loss: tensor(0.0292)\n",
      "19200 Traning Loss: tensor(0.0316)\n",
      "19201 Traning Loss: tensor(0.0315)\n",
      "19202 Traning Loss: tensor(0.0286)\n",
      "19203 Traning Loss: tensor(0.0282)\n",
      "19204 Traning Loss: tensor(0.0304)\n",
      "19205 Traning Loss: tensor(0.0289)\n",
      "19206 Traning Loss: tensor(0.0294)\n",
      "19207 Traning Loss: tensor(0.0317)\n",
      "19208 Traning Loss: tensor(0.0290)\n",
      "19209 Traning Loss: tensor(0.0295)\n",
      "19210 Traning Loss: tensor(0.0317)\n",
      "19211 Traning Loss: tensor(0.0286)\n",
      "19212 Traning Loss: tensor(0.0293)\n",
      "19213 Traning Loss: tensor(0.0289)\n",
      "19214 Traning Loss: tensor(0.0297)\n",
      "19215 Traning Loss: tensor(0.0328)\n",
      "19216 Traning Loss: tensor(0.0296)\n",
      "19217 Traning Loss: tensor(0.0306)\n",
      "19218 Traning Loss: tensor(0.0276)\n",
      "19219 Traning Loss: tensor(0.0319)\n",
      "19220 Traning Loss: tensor(0.0291)\n",
      "19221 Traning Loss: tensor(0.0288)\n",
      "19222 Traning Loss: tensor(0.0291)\n",
      "19223 Traning Loss: tensor(0.0297)\n",
      "19224 Traning Loss: tensor(0.0306)\n",
      "19225 Traning Loss: tensor(0.0284)\n",
      "19226 Traning Loss: tensor(0.0297)\n",
      "19227 Traning Loss: tensor(0.0302)\n",
      "19228 Traning Loss: tensor(0.0298)\n",
      "19229 Traning Loss: tensor(0.0304)\n",
      "19230 Traning Loss: tensor(0.0286)\n",
      "19231 Traning Loss: tensor(0.0279)\n",
      "19232 Traning Loss: tensor(0.0298)\n",
      "19233 Traning Loss: tensor(0.0279)\n",
      "19234 Traning Loss: tensor(0.0313)\n",
      "19235 Traning Loss: tensor(0.0298)\n",
      "19236 Traning Loss: tensor(0.0344)\n",
      "19237 Traning Loss: tensor(0.0296)\n",
      "19238 Traning Loss: tensor(0.0287)\n",
      "19239 Traning Loss: tensor(0.0321)\n",
      "19240 Traning Loss: tensor(0.0297)\n",
      "19241 Traning Loss: tensor(0.0278)\n",
      "19242 Traning Loss: tensor(0.0297)\n",
      "19243 Traning Loss: tensor(0.0275)\n",
      "19244 Traning Loss: tensor(0.0289)\n",
      "19245 Traning Loss: tensor(0.0316)\n",
      "19246 Traning Loss: tensor(0.0292)\n",
      "19247 Traning Loss: tensor(0.0284)\n",
      "19248 Traning Loss: tensor(0.0297)\n",
      "19249 Traning Loss: tensor(0.0300)\n",
      "19250 Traning Loss: tensor(0.0318)\n",
      "19251 Traning Loss: tensor(0.0303)\n",
      "19252 Traning Loss: tensor(0.0300)\n",
      "19253 Traning Loss: tensor(0.0299)\n",
      "19254 Traning Loss: tensor(0.0300)\n",
      "19255 Traning Loss: tensor(0.0305)\n",
      "19256 Traning Loss: tensor(0.0308)\n",
      "19257 Traning Loss: tensor(0.0298)\n",
      "19258 Traning Loss: tensor(0.0284)\n",
      "19259 Traning Loss: tensor(0.0298)\n",
      "19260 Traning Loss: tensor(0.0315)\n",
      "19261 Traning Loss: tensor(0.0283)\n",
      "19262 Traning Loss: tensor(0.0298)\n",
      "19263 Traning Loss: tensor(0.0305)\n",
      "19264 Traning Loss: tensor(0.0282)\n",
      "19265 Traning Loss: tensor(0.0280)\n",
      "19266 Traning Loss: tensor(0.0290)\n",
      "19267 Traning Loss: tensor(0.0302)\n",
      "19268 Traning Loss: tensor(0.0307)\n",
      "19269 Traning Loss: tensor(0.0298)\n",
      "19270 Traning Loss: tensor(0.0277)\n",
      "19271 Traning Loss: tensor(0.0308)\n",
      "19272 Traning Loss: tensor(0.0294)\n",
      "19273 Traning Loss: tensor(0.0286)\n",
      "19274 Traning Loss: tensor(0.0297)\n",
      "19275 Traning Loss: tensor(0.0294)\n",
      "19276 Traning Loss: tensor(0.0285)\n",
      "19277 Traning Loss: tensor(0.0289)\n",
      "19278 Traning Loss: tensor(0.0294)\n",
      "19279 Traning Loss: tensor(0.0291)\n",
      "19280 Traning Loss: tensor(0.0316)\n",
      "19281 Traning Loss: tensor(0.0289)\n",
      "19282 Traning Loss: tensor(0.0290)\n",
      "19283 Traning Loss: tensor(0.0298)\n",
      "19284 Traning Loss: tensor(0.0298)\n",
      "19285 Traning Loss: tensor(0.0326)\n",
      "19286 Traning Loss: tensor(0.0291)\n",
      "19287 Traning Loss: tensor(0.0304)\n",
      "19288 Traning Loss: tensor(0.0296)\n",
      "19289 Traning Loss: tensor(0.0301)\n",
      "19290 Traning Loss: tensor(0.0308)\n",
      "19291 Traning Loss: tensor(0.0289)\n",
      "19292 Traning Loss: tensor(0.0298)\n",
      "19293 Traning Loss: tensor(0.0282)\n",
      "19294 Traning Loss: tensor(0.0310)\n",
      "19295 Traning Loss: tensor(0.0287)\n",
      "19296 Traning Loss: tensor(0.0288)\n",
      "19297 Traning Loss: tensor(0.0332)\n",
      "19298 Traning Loss: tensor(0.0287)\n",
      "19299 Traning Loss: tensor(0.0310)\n",
      "19300 Traning Loss: tensor(0.0316)\n",
      "19301 Traning Loss: tensor(0.0274)\n",
      "19302 Traning Loss: tensor(0.0281)\n",
      "19303 Traning Loss: tensor(0.0325)\n",
      "19304 Traning Loss: tensor(0.0306)\n",
      "19305 Traning Loss: tensor(0.0305)\n",
      "19306 Traning Loss: tensor(0.0306)\n",
      "19307 Traning Loss: tensor(0.0303)\n",
      "19308 Traning Loss: tensor(0.0330)\n",
      "19309 Traning Loss: tensor(0.0279)\n",
      "19310 Traning Loss: tensor(0.0311)\n",
      "19311 Traning Loss: tensor(0.0303)\n",
      "19312 Traning Loss: tensor(0.0318)\n",
      "19313 Traning Loss: tensor(0.0301)\n",
      "19314 Traning Loss: tensor(0.0294)\n",
      "19315 Traning Loss: tensor(0.0302)\n",
      "19316 Traning Loss: tensor(0.0294)\n",
      "19317 Traning Loss: tensor(0.0310)\n",
      "19318 Traning Loss: tensor(0.0285)\n",
      "19319 Traning Loss: tensor(0.0311)\n",
      "19320 Traning Loss: tensor(0.0293)\n",
      "19321 Traning Loss: tensor(0.0289)\n",
      "19322 Traning Loss: tensor(0.0296)\n",
      "19323 Traning Loss: tensor(0.0303)\n",
      "19324 Traning Loss: tensor(0.0308)\n",
      "19325 Traning Loss: tensor(0.0293)\n",
      "19326 Traning Loss: tensor(0.0304)\n",
      "19327 Traning Loss: tensor(0.0296)\n",
      "19328 Traning Loss: tensor(0.0310)\n",
      "19329 Traning Loss: tensor(0.0282)\n",
      "19330 Traning Loss: tensor(0.0329)\n",
      "19331 Traning Loss: tensor(0.0292)\n",
      "19332 Traning Loss: tensor(0.0296)\n",
      "19333 Traning Loss: tensor(0.0311)\n",
      "19334 Traning Loss: tensor(0.0288)\n",
      "19335 Traning Loss: tensor(0.0297)\n",
      "19336 Traning Loss: tensor(0.0312)\n",
      "19337 Traning Loss: tensor(0.0335)\n",
      "19338 Traning Loss: tensor(0.0305)\n",
      "19339 Traning Loss: tensor(0.0297)\n",
      "19340 Traning Loss: tensor(0.0304)\n",
      "19341 Traning Loss: tensor(0.0299)\n",
      "19342 Traning Loss: tensor(0.0290)\n",
      "19343 Traning Loss: tensor(0.0294)\n",
      "19344 Traning Loss: tensor(0.0303)\n",
      "19345 Traning Loss: tensor(0.0295)\n",
      "19346 Traning Loss: tensor(0.0305)\n",
      "19347 Traning Loss: tensor(0.0312)\n",
      "19348 Traning Loss: tensor(0.0294)\n",
      "19349 Traning Loss: tensor(0.0299)\n",
      "19350 Traning Loss: tensor(0.0301)\n",
      "19351 Traning Loss: tensor(0.0317)\n",
      "19352 Traning Loss: tensor(0.0320)\n",
      "19353 Traning Loss: tensor(0.0298)\n",
      "19354 Traning Loss: tensor(0.0308)\n",
      "19355 Traning Loss: tensor(0.0301)\n",
      "19356 Traning Loss: tensor(0.0279)\n",
      "19357 Traning Loss: tensor(0.0315)\n",
      "19358 Traning Loss: tensor(0.0302)\n",
      "19359 Traning Loss: tensor(0.0298)\n",
      "19360 Traning Loss: tensor(0.0297)\n",
      "19361 Traning Loss: tensor(0.0285)\n",
      "19362 Traning Loss: tensor(0.0291)\n",
      "19363 Traning Loss: tensor(0.0318)\n",
      "19364 Traning Loss: tensor(0.0299)\n",
      "19365 Traning Loss: tensor(0.0313)\n",
      "19366 Traning Loss: tensor(0.0301)\n",
      "19367 Traning Loss: tensor(0.0293)\n",
      "19368 Traning Loss: tensor(0.0308)\n",
      "19369 Traning Loss: tensor(0.0296)\n",
      "19370 Traning Loss: tensor(0.0290)\n",
      "19371 Traning Loss: tensor(0.0292)\n",
      "19372 Traning Loss: tensor(0.0296)\n",
      "19373 Traning Loss: tensor(0.0307)\n",
      "19374 Traning Loss: tensor(0.0303)\n",
      "19375 Traning Loss: tensor(0.0303)\n",
      "19376 Traning Loss: tensor(0.0300)\n",
      "19377 Traning Loss: tensor(0.0292)\n",
      "19378 Traning Loss: tensor(0.0296)\n",
      "19379 Traning Loss: tensor(0.0299)\n",
      "19380 Traning Loss: tensor(0.0304)\n",
      "19381 Traning Loss: tensor(0.0303)\n",
      "19382 Traning Loss: tensor(0.0291)\n",
      "19383 Traning Loss: tensor(0.0293)\n",
      "19384 Traning Loss: tensor(0.0283)\n",
      "19385 Traning Loss: tensor(0.0306)\n",
      "19386 Traning Loss: tensor(0.0285)\n",
      "19387 Traning Loss: tensor(0.0283)\n",
      "19388 Traning Loss: tensor(0.0301)\n",
      "19389 Traning Loss: tensor(0.0302)\n",
      "19390 Traning Loss: tensor(0.0302)\n",
      "19391 Traning Loss: tensor(0.0291)\n",
      "19392 Traning Loss: tensor(0.0302)\n",
      "19393 Traning Loss: tensor(0.0293)\n",
      "19394 Traning Loss: tensor(0.0295)\n",
      "19395 Traning Loss: tensor(0.0291)\n",
      "19396 Traning Loss: tensor(0.0279)\n",
      "19397 Traning Loss: tensor(0.0303)\n",
      "19398 Traning Loss: tensor(0.0299)\n",
      "19399 Traning Loss: tensor(0.0279)\n",
      "19400 Traning Loss: tensor(0.0292)\n",
      "19401 Traning Loss: tensor(0.0288)\n",
      "19402 Traning Loss: tensor(0.0292)\n",
      "19403 Traning Loss: tensor(0.0306)\n",
      "19404 Traning Loss: tensor(0.0294)\n",
      "19405 Traning Loss: tensor(0.0303)\n",
      "19406 Traning Loss: tensor(0.0303)\n",
      "19407 Traning Loss: tensor(0.0315)\n",
      "19408 Traning Loss: tensor(0.0297)\n",
      "19409 Traning Loss: tensor(0.0301)\n",
      "19410 Traning Loss: tensor(0.0308)\n",
      "19411 Traning Loss: tensor(0.0287)\n",
      "19412 Traning Loss: tensor(0.0308)\n",
      "19413 Traning Loss: tensor(0.0316)\n",
      "19414 Traning Loss: tensor(0.0303)\n",
      "19415 Traning Loss: tensor(0.0304)\n",
      "19416 Traning Loss: tensor(0.0298)\n",
      "19417 Traning Loss: tensor(0.0294)\n",
      "19418 Traning Loss: tensor(0.0286)\n",
      "19419 Traning Loss: tensor(0.0296)\n",
      "19420 Traning Loss: tensor(0.0307)\n",
      "19421 Traning Loss: tensor(0.0299)\n",
      "19422 Traning Loss: tensor(0.0308)\n",
      "19423 Traning Loss: tensor(0.0304)\n",
      "19424 Traning Loss: tensor(0.0292)\n",
      "19425 Traning Loss: tensor(0.0316)\n",
      "19426 Traning Loss: tensor(0.0304)\n",
      "19427 Traning Loss: tensor(0.0293)\n",
      "19428 Traning Loss: tensor(0.0290)\n",
      "19429 Traning Loss: tensor(0.0302)\n",
      "19430 Traning Loss: tensor(0.0289)\n",
      "19431 Traning Loss: tensor(0.0303)\n",
      "19432 Traning Loss: tensor(0.0294)\n",
      "19433 Traning Loss: tensor(0.0278)\n",
      "19434 Traning Loss: tensor(0.0295)\n",
      "19435 Traning Loss: tensor(0.0309)\n",
      "19436 Traning Loss: tensor(0.0287)\n",
      "19437 Traning Loss: tensor(0.0309)\n",
      "19438 Traning Loss: tensor(0.0297)\n",
      "19439 Traning Loss: tensor(0.0297)\n",
      "19440 Traning Loss: tensor(0.0296)\n",
      "19441 Traning Loss: tensor(0.0289)\n",
      "19442 Traning Loss: tensor(0.0297)\n",
      "19443 Traning Loss: tensor(0.0339)\n",
      "19444 Traning Loss: tensor(0.0297)\n",
      "19445 Traning Loss: tensor(0.0305)\n",
      "19446 Traning Loss: tensor(0.0295)\n",
      "19447 Traning Loss: tensor(0.0289)\n",
      "19448 Traning Loss: tensor(0.0302)\n",
      "19449 Traning Loss: tensor(0.0285)\n",
      "19450 Traning Loss: tensor(0.0294)\n",
      "19451 Traning Loss: tensor(0.0300)\n",
      "19452 Traning Loss: tensor(0.0293)\n",
      "19453 Traning Loss: tensor(0.0302)\n",
      "19454 Traning Loss: tensor(0.0275)\n",
      "19455 Traning Loss: tensor(0.0292)\n",
      "19456 Traning Loss: tensor(0.0300)\n",
      "19457 Traning Loss: tensor(0.0294)\n",
      "19458 Traning Loss: tensor(0.0297)\n",
      "19459 Traning Loss: tensor(0.0306)\n",
      "19460 Traning Loss: tensor(0.0309)\n",
      "19461 Traning Loss: tensor(0.0302)\n",
      "19462 Traning Loss: tensor(0.0291)\n",
      "19463 Traning Loss: tensor(0.0289)\n",
      "19464 Traning Loss: tensor(0.0309)\n",
      "19465 Traning Loss: tensor(0.0305)\n",
      "19466 Traning Loss: tensor(0.0311)\n",
      "19467 Traning Loss: tensor(0.0296)\n",
      "19468 Traning Loss: tensor(0.0320)\n",
      "19469 Traning Loss: tensor(0.0298)\n",
      "19470 Traning Loss: tensor(0.0274)\n",
      "19471 Traning Loss: tensor(0.0287)\n",
      "19472 Traning Loss: tensor(0.0304)\n",
      "19473 Traning Loss: tensor(0.0316)\n",
      "19474 Traning Loss: tensor(0.0293)\n",
      "19475 Traning Loss: tensor(0.0313)\n",
      "19476 Traning Loss: tensor(0.0312)\n",
      "19477 Traning Loss: tensor(0.0286)\n",
      "19478 Traning Loss: tensor(0.0315)\n",
      "19479 Traning Loss: tensor(0.0300)\n",
      "19480 Traning Loss: tensor(0.0296)\n",
      "19481 Traning Loss: tensor(0.0301)\n",
      "19482 Traning Loss: tensor(0.0304)\n",
      "19483 Traning Loss: tensor(0.0302)\n",
      "19484 Traning Loss: tensor(0.0318)\n",
      "19485 Traning Loss: tensor(0.0277)\n",
      "19486 Traning Loss: tensor(0.0305)\n",
      "19487 Traning Loss: tensor(0.0313)\n",
      "19488 Traning Loss: tensor(0.0314)\n",
      "19489 Traning Loss: tensor(0.0290)\n",
      "19490 Traning Loss: tensor(0.0316)\n",
      "19491 Traning Loss: tensor(0.0312)\n",
      "19492 Traning Loss: tensor(0.0296)\n",
      "19493 Traning Loss: tensor(0.0311)\n",
      "19494 Traning Loss: tensor(0.0324)\n",
      "19495 Traning Loss: tensor(0.0298)\n",
      "19496 Traning Loss: tensor(0.0317)\n",
      "19497 Traning Loss: tensor(0.0307)\n",
      "19498 Traning Loss: tensor(0.0308)\n",
      "19499 Traning Loss: tensor(0.0320)\n",
      "19500 Traning Loss: tensor(0.0296)\n",
      "19501 Traning Loss: tensor(0.0286)\n",
      "19502 Traning Loss: tensor(0.0338)\n",
      "19503 Traning Loss: tensor(0.0314)\n",
      "19504 Traning Loss: tensor(0.0308)\n",
      "19505 Traning Loss: tensor(0.0285)\n",
      "19506 Traning Loss: tensor(0.0311)\n",
      "19507 Traning Loss: tensor(0.0318)\n",
      "19508 Traning Loss: tensor(0.0309)\n",
      "19509 Traning Loss: tensor(0.0296)\n",
      "19510 Traning Loss: tensor(0.0298)\n",
      "19511 Traning Loss: tensor(0.0322)\n",
      "19512 Traning Loss: tensor(0.0314)\n",
      "19513 Traning Loss: tensor(0.0299)\n",
      "19514 Traning Loss: tensor(0.0304)\n",
      "19515 Traning Loss: tensor(0.0313)\n",
      "19516 Traning Loss: tensor(0.0311)\n",
      "19517 Traning Loss: tensor(0.0292)\n",
      "19518 Traning Loss: tensor(0.0327)\n",
      "19519 Traning Loss: tensor(0.0310)\n",
      "19520 Traning Loss: tensor(0.0299)\n",
      "19521 Traning Loss: tensor(0.0296)\n",
      "19522 Traning Loss: tensor(0.0311)\n",
      "19523 Traning Loss: tensor(0.0291)\n",
      "19524 Traning Loss: tensor(0.0301)\n",
      "19525 Traning Loss: tensor(0.0296)\n",
      "19526 Traning Loss: tensor(0.0291)\n",
      "19527 Traning Loss: tensor(0.0300)\n",
      "19528 Traning Loss: tensor(0.0288)\n",
      "19529 Traning Loss: tensor(0.0309)\n",
      "19530 Traning Loss: tensor(0.0297)\n",
      "19531 Traning Loss: tensor(0.0312)\n",
      "19532 Traning Loss: tensor(0.0296)\n",
      "19533 Traning Loss: tensor(0.0300)\n",
      "19534 Traning Loss: tensor(0.0300)\n",
      "19535 Traning Loss: tensor(0.0287)\n",
      "19536 Traning Loss: tensor(0.0314)\n",
      "19537 Traning Loss: tensor(0.0325)\n",
      "19538 Traning Loss: tensor(0.0296)\n",
      "19539 Traning Loss: tensor(0.0290)\n",
      "19540 Traning Loss: tensor(0.0286)\n",
      "19541 Traning Loss: tensor(0.0299)\n",
      "19542 Traning Loss: tensor(0.0292)\n",
      "19543 Traning Loss: tensor(0.0305)\n",
      "19544 Traning Loss: tensor(0.0320)\n",
      "19545 Traning Loss: tensor(0.0332)\n",
      "19546 Traning Loss: tensor(0.0285)\n",
      "19547 Traning Loss: tensor(0.0298)\n",
      "19548 Traning Loss: tensor(0.0293)\n",
      "19549 Traning Loss: tensor(0.0300)\n",
      "19550 Traning Loss: tensor(0.0288)\n",
      "19551 Traning Loss: tensor(0.0307)\n",
      "19552 Traning Loss: tensor(0.0300)\n",
      "19553 Traning Loss: tensor(0.0289)\n",
      "19554 Traning Loss: tensor(0.0315)\n",
      "19555 Traning Loss: tensor(0.0304)\n",
      "19556 Traning Loss: tensor(0.0284)\n",
      "19557 Traning Loss: tensor(0.0297)\n",
      "19558 Traning Loss: tensor(0.0288)\n",
      "19559 Traning Loss: tensor(0.0300)\n",
      "19560 Traning Loss: tensor(0.0284)\n",
      "19561 Traning Loss: tensor(0.0302)\n",
      "19562 Traning Loss: tensor(0.0300)\n",
      "19563 Traning Loss: tensor(0.0288)\n",
      "19564 Traning Loss: tensor(0.0287)\n",
      "19565 Traning Loss: tensor(0.0292)\n",
      "19566 Traning Loss: tensor(0.0308)\n",
      "19567 Traning Loss: tensor(0.0302)\n",
      "19568 Traning Loss: tensor(0.0291)\n",
      "19569 Traning Loss: tensor(0.0300)\n",
      "19570 Traning Loss: tensor(0.0302)\n",
      "19571 Traning Loss: tensor(0.0292)\n",
      "19572 Traning Loss: tensor(0.0280)\n",
      "19573 Traning Loss: tensor(0.0280)\n",
      "19574 Traning Loss: tensor(0.0273)\n",
      "19575 Traning Loss: tensor(0.0303)\n",
      "19576 Traning Loss: tensor(0.0301)\n",
      "19577 Traning Loss: tensor(0.0292)\n",
      "19578 Traning Loss: tensor(0.0289)\n",
      "19579 Traning Loss: tensor(0.0297)\n",
      "19580 Traning Loss: tensor(0.0275)\n",
      "19581 Traning Loss: tensor(0.0306)\n",
      "19582 Traning Loss: tensor(0.0311)\n",
      "19583 Traning Loss: tensor(0.0327)\n",
      "19584 Traning Loss: tensor(0.0308)\n",
      "19585 Traning Loss: tensor(0.0279)\n",
      "19586 Traning Loss: tensor(0.0298)\n",
      "19587 Traning Loss: tensor(0.0302)\n",
      "19588 Traning Loss: tensor(0.0304)\n",
      "19589 Traning Loss: tensor(0.0281)\n",
      "19590 Traning Loss: tensor(0.0286)\n",
      "19591 Traning Loss: tensor(0.0314)\n",
      "19592 Traning Loss: tensor(0.0307)\n",
      "19593 Traning Loss: tensor(0.0291)\n",
      "19594 Traning Loss: tensor(0.0285)\n",
      "19595 Traning Loss: tensor(0.0309)\n",
      "19596 Traning Loss: tensor(0.0319)\n",
      "19597 Traning Loss: tensor(0.0298)\n",
      "19598 Traning Loss: tensor(0.0303)\n",
      "19599 Traning Loss: tensor(0.0289)\n",
      "19600 Traning Loss: tensor(0.0305)\n",
      "19601 Traning Loss: tensor(0.0299)\n",
      "19602 Traning Loss: tensor(0.0289)\n",
      "19603 Traning Loss: tensor(0.0305)\n",
      "19604 Traning Loss: tensor(0.0293)\n",
      "19605 Traning Loss: tensor(0.0313)\n",
      "19606 Traning Loss: tensor(0.0280)\n",
      "19607 Traning Loss: tensor(0.0313)\n",
      "19608 Traning Loss: tensor(0.0297)\n",
      "19609 Traning Loss: tensor(0.0308)\n",
      "19610 Traning Loss: tensor(0.0302)\n",
      "19611 Traning Loss: tensor(0.0284)\n",
      "19612 Traning Loss: tensor(0.0311)\n",
      "19613 Traning Loss: tensor(0.0287)\n",
      "19614 Traning Loss: tensor(0.0296)\n",
      "19615 Traning Loss: tensor(0.0313)\n",
      "19616 Traning Loss: tensor(0.0304)\n",
      "19617 Traning Loss: tensor(0.0276)\n",
      "19618 Traning Loss: tensor(0.0345)\n",
      "19619 Traning Loss: tensor(0.0309)\n",
      "19620 Traning Loss: tensor(0.0313)\n",
      "19621 Traning Loss: tensor(0.0301)\n",
      "19622 Traning Loss: tensor(0.0286)\n",
      "19623 Traning Loss: tensor(0.0308)\n",
      "19624 Traning Loss: tensor(0.0305)\n",
      "19625 Traning Loss: tensor(0.0297)\n",
      "19626 Traning Loss: tensor(0.0288)\n",
      "19627 Traning Loss: tensor(0.0319)\n",
      "19628 Traning Loss: tensor(0.0312)\n",
      "19629 Traning Loss: tensor(0.0277)\n",
      "19630 Traning Loss: tensor(0.0285)\n",
      "19631 Traning Loss: tensor(0.0305)\n",
      "19632 Traning Loss: tensor(0.0298)\n",
      "19633 Traning Loss: tensor(0.0293)\n",
      "19634 Traning Loss: tensor(0.0299)\n",
      "19635 Traning Loss: tensor(0.0319)\n",
      "19636 Traning Loss: tensor(0.0290)\n",
      "19637 Traning Loss: tensor(0.0290)\n",
      "19638 Traning Loss: tensor(0.0304)\n",
      "19639 Traning Loss: tensor(0.0296)\n",
      "19640 Traning Loss: tensor(0.0310)\n",
      "19641 Traning Loss: tensor(0.0295)\n",
      "19642 Traning Loss: tensor(0.0293)\n",
      "19643 Traning Loss: tensor(0.0315)\n",
      "19644 Traning Loss: tensor(0.0299)\n",
      "19645 Traning Loss: tensor(0.0290)\n",
      "19646 Traning Loss: tensor(0.0290)\n",
      "19647 Traning Loss: tensor(0.0311)\n",
      "19648 Traning Loss: tensor(0.0291)\n",
      "19649 Traning Loss: tensor(0.0302)\n",
      "19650 Traning Loss: tensor(0.0299)\n",
      "19651 Traning Loss: tensor(0.0294)\n",
      "19652 Traning Loss: tensor(0.0291)\n",
      "19653 Traning Loss: tensor(0.0301)\n",
      "19654 Traning Loss: tensor(0.0323)\n",
      "19655 Traning Loss: tensor(0.0311)\n",
      "19656 Traning Loss: tensor(0.0298)\n",
      "19657 Traning Loss: tensor(0.0303)\n",
      "19658 Traning Loss: tensor(0.0336)\n",
      "19659 Traning Loss: tensor(0.0315)\n",
      "19660 Traning Loss: tensor(0.0289)\n",
      "19661 Traning Loss: tensor(0.0311)\n",
      "19662 Traning Loss: tensor(0.0318)\n",
      "19663 Traning Loss: tensor(0.0282)\n",
      "19664 Traning Loss: tensor(0.0294)\n",
      "19665 Traning Loss: tensor(0.0285)\n",
      "19666 Traning Loss: tensor(0.0309)\n",
      "19667 Traning Loss: tensor(0.0293)\n",
      "19668 Traning Loss: tensor(0.0304)\n",
      "19669 Traning Loss: tensor(0.0302)\n",
      "19670 Traning Loss: tensor(0.0303)\n",
      "19671 Traning Loss: tensor(0.0283)\n",
      "19672 Traning Loss: tensor(0.0270)\n",
      "19673 Traning Loss: tensor(0.0284)\n",
      "19674 Traning Loss: tensor(0.0306)\n",
      "19675 Traning Loss: tensor(0.0292)\n",
      "19676 Traning Loss: tensor(0.0279)\n",
      "19677 Traning Loss: tensor(0.0273)\n",
      "19678 Traning Loss: tensor(0.0284)\n",
      "19679 Traning Loss: tensor(0.0290)\n",
      "19680 Traning Loss: tensor(0.0290)\n",
      "19681 Traning Loss: tensor(0.0277)\n",
      "19682 Traning Loss: tensor(0.0295)\n",
      "19683 Traning Loss: tensor(0.0286)\n",
      "19684 Traning Loss: tensor(0.0289)\n",
      "19685 Traning Loss: tensor(0.0275)\n",
      "19686 Traning Loss: tensor(0.0313)\n",
      "19687 Traning Loss: tensor(0.0280)\n",
      "19688 Traning Loss: tensor(0.0293)\n",
      "19689 Traning Loss: tensor(0.0313)\n",
      "19690 Traning Loss: tensor(0.0313)\n",
      "19691 Traning Loss: tensor(0.0326)\n",
      "19692 Traning Loss: tensor(0.0301)\n",
      "19693 Traning Loss: tensor(0.0298)\n",
      "19694 Traning Loss: tensor(0.0302)\n",
      "19695 Traning Loss: tensor(0.0292)\n",
      "19696 Traning Loss: tensor(0.0312)\n",
      "19697 Traning Loss: tensor(0.0307)\n",
      "19698 Traning Loss: tensor(0.0292)\n",
      "19699 Traning Loss: tensor(0.0311)\n",
      "19700 Traning Loss: tensor(0.0274)\n",
      "19701 Traning Loss: tensor(0.0320)\n",
      "19702 Traning Loss: tensor(0.0302)\n",
      "19703 Traning Loss: tensor(0.0290)\n",
      "19704 Traning Loss: tensor(0.0290)\n",
      "19705 Traning Loss: tensor(0.0303)\n",
      "19706 Traning Loss: tensor(0.0296)\n",
      "19707 Traning Loss: tensor(0.0303)\n",
      "19708 Traning Loss: tensor(0.0279)\n",
      "19709 Traning Loss: tensor(0.0282)\n",
      "19710 Traning Loss: tensor(0.0305)\n",
      "19711 Traning Loss: tensor(0.0310)\n",
      "19712 Traning Loss: tensor(0.0277)\n",
      "19713 Traning Loss: tensor(0.0280)\n",
      "19714 Traning Loss: tensor(0.0292)\n",
      "19715 Traning Loss: tensor(0.0278)\n",
      "19716 Traning Loss: tensor(0.0284)\n",
      "19717 Traning Loss: tensor(0.0303)\n",
      "19718 Traning Loss: tensor(0.0305)\n",
      "19719 Traning Loss: tensor(0.0288)\n",
      "19720 Traning Loss: tensor(0.0286)\n",
      "19721 Traning Loss: tensor(0.0303)\n",
      "19722 Traning Loss: tensor(0.0293)\n",
      "19723 Traning Loss: tensor(0.0292)\n",
      "19724 Traning Loss: tensor(0.0281)\n",
      "19725 Traning Loss: tensor(0.0292)\n",
      "19726 Traning Loss: tensor(0.0300)\n",
      "19727 Traning Loss: tensor(0.0289)\n",
      "19728 Traning Loss: tensor(0.0289)\n",
      "19729 Traning Loss: tensor(0.0281)\n",
      "19730 Traning Loss: tensor(0.0287)\n",
      "19731 Traning Loss: tensor(0.0280)\n",
      "19732 Traning Loss: tensor(0.0301)\n",
      "19733 Traning Loss: tensor(0.0291)\n",
      "19734 Traning Loss: tensor(0.0279)\n",
      "19735 Traning Loss: tensor(0.0291)\n",
      "19736 Traning Loss: tensor(0.0286)\n",
      "19737 Traning Loss: tensor(0.0291)\n",
      "19738 Traning Loss: tensor(0.0293)\n",
      "19739 Traning Loss: tensor(0.0306)\n",
      "19740 Traning Loss: tensor(0.0302)\n",
      "19741 Traning Loss: tensor(0.0307)\n",
      "19742 Traning Loss: tensor(0.0305)\n",
      "19743 Traning Loss: tensor(0.0284)\n",
      "19744 Traning Loss: tensor(0.0291)\n",
      "19745 Traning Loss: tensor(0.0298)\n",
      "19746 Traning Loss: tensor(0.0286)\n",
      "19747 Traning Loss: tensor(0.0290)\n",
      "19748 Traning Loss: tensor(0.0297)\n",
      "19749 Traning Loss: tensor(0.0292)\n",
      "19750 Traning Loss: tensor(0.0295)\n",
      "19751 Traning Loss: tensor(0.0276)\n",
      "19752 Traning Loss: tensor(0.0287)\n",
      "19753 Traning Loss: tensor(0.0286)\n",
      "19754 Traning Loss: tensor(0.0298)\n",
      "19755 Traning Loss: tensor(0.0277)\n",
      "19756 Traning Loss: tensor(0.0297)\n",
      "19757 Traning Loss: tensor(0.0287)\n",
      "19758 Traning Loss: tensor(0.0297)\n",
      "19759 Traning Loss: tensor(0.0298)\n",
      "19760 Traning Loss: tensor(0.0291)\n",
      "19761 Traning Loss: tensor(0.0305)\n",
      "19762 Traning Loss: tensor(0.0305)\n",
      "19763 Traning Loss: tensor(0.0281)\n",
      "19764 Traning Loss: tensor(0.0282)\n",
      "19765 Traning Loss: tensor(0.0289)\n",
      "19766 Traning Loss: tensor(0.0274)\n",
      "19767 Traning Loss: tensor(0.0312)\n",
      "19768 Traning Loss: tensor(0.0306)\n",
      "19769 Traning Loss: tensor(0.0291)\n",
      "19770 Traning Loss: tensor(0.0302)\n",
      "19771 Traning Loss: tensor(0.0292)\n",
      "19772 Traning Loss: tensor(0.0333)\n",
      "19773 Traning Loss: tensor(0.0275)\n",
      "19774 Traning Loss: tensor(0.0306)\n",
      "19775 Traning Loss: tensor(0.0286)\n",
      "19776 Traning Loss: tensor(0.0289)\n",
      "19777 Traning Loss: tensor(0.0292)\n",
      "19778 Traning Loss: tensor(0.0312)\n",
      "19779 Traning Loss: tensor(0.0293)\n",
      "19780 Traning Loss: tensor(0.0292)\n",
      "19781 Traning Loss: tensor(0.0316)\n",
      "19782 Traning Loss: tensor(0.0303)\n",
      "19783 Traning Loss: tensor(0.0291)\n",
      "19784 Traning Loss: tensor(0.0287)\n",
      "19785 Traning Loss: tensor(0.0296)\n",
      "19786 Traning Loss: tensor(0.0289)\n",
      "19787 Traning Loss: tensor(0.0282)\n",
      "19788 Traning Loss: tensor(0.0302)\n",
      "19789 Traning Loss: tensor(0.0299)\n",
      "19790 Traning Loss: tensor(0.0278)\n",
      "19791 Traning Loss: tensor(0.0290)\n",
      "19792 Traning Loss: tensor(0.0280)\n",
      "19793 Traning Loss: tensor(0.0280)\n",
      "19794 Traning Loss: tensor(0.0304)\n",
      "19795 Traning Loss: tensor(0.0284)\n",
      "19796 Traning Loss: tensor(0.0289)\n",
      "19797 Traning Loss: tensor(0.0286)\n",
      "19798 Traning Loss: tensor(0.0289)\n",
      "19799 Traning Loss: tensor(0.0290)\n",
      "19800 Traning Loss: tensor(0.0285)\n",
      "19801 Traning Loss: tensor(0.0291)\n",
      "19802 Traning Loss: tensor(0.0303)\n",
      "19803 Traning Loss: tensor(0.0288)\n",
      "19804 Traning Loss: tensor(0.0324)\n",
      "19805 Traning Loss: tensor(0.0292)\n",
      "19806 Traning Loss: tensor(0.0296)\n",
      "19807 Traning Loss: tensor(0.0306)\n",
      "19808 Traning Loss: tensor(0.0299)\n",
      "19809 Traning Loss: tensor(0.0302)\n",
      "19810 Traning Loss: tensor(0.0302)\n",
      "19811 Traning Loss: tensor(0.0298)\n",
      "19812 Traning Loss: tensor(0.0288)\n",
      "19813 Traning Loss: tensor(0.0292)\n",
      "19814 Traning Loss: tensor(0.0281)\n",
      "19815 Traning Loss: tensor(0.0289)\n",
      "19816 Traning Loss: tensor(0.0290)\n",
      "19817 Traning Loss: tensor(0.0294)\n",
      "19818 Traning Loss: tensor(0.0283)\n",
      "19819 Traning Loss: tensor(0.0302)\n",
      "19820 Traning Loss: tensor(0.0289)\n",
      "19821 Traning Loss: tensor(0.0293)\n",
      "19822 Traning Loss: tensor(0.0301)\n",
      "19823 Traning Loss: tensor(0.0293)\n",
      "19824 Traning Loss: tensor(0.0296)\n",
      "19825 Traning Loss: tensor(0.0304)\n",
      "19826 Traning Loss: tensor(0.0286)\n",
      "19827 Traning Loss: tensor(0.0292)\n",
      "19828 Traning Loss: tensor(0.0274)\n",
      "19829 Traning Loss: tensor(0.0282)\n",
      "19830 Traning Loss: tensor(0.0291)\n",
      "19831 Traning Loss: tensor(0.0308)\n",
      "19832 Traning Loss: tensor(0.0315)\n",
      "19833 Traning Loss: tensor(0.0293)\n",
      "19834 Traning Loss: tensor(0.0293)\n",
      "19835 Traning Loss: tensor(0.0310)\n",
      "19836 Traning Loss: tensor(0.0318)\n",
      "19837 Traning Loss: tensor(0.0271)\n",
      "19838 Traning Loss: tensor(0.0303)\n",
      "19839 Traning Loss: tensor(0.0292)\n",
      "19840 Traning Loss: tensor(0.0288)\n",
      "19841 Traning Loss: tensor(0.0290)\n",
      "19842 Traning Loss: tensor(0.0270)\n",
      "19843 Traning Loss: tensor(0.0275)\n",
      "19844 Traning Loss: tensor(0.0298)\n",
      "19845 Traning Loss: tensor(0.0270)\n",
      "19846 Traning Loss: tensor(0.0315)\n",
      "19847 Traning Loss: tensor(0.0298)\n",
      "19848 Traning Loss: tensor(0.0283)\n",
      "19849 Traning Loss: tensor(0.0294)\n",
      "19850 Traning Loss: tensor(0.0300)\n",
      "19851 Traning Loss: tensor(0.0282)\n",
      "19852 Traning Loss: tensor(0.0302)\n",
      "19853 Traning Loss: tensor(0.0295)\n",
      "19854 Traning Loss: tensor(0.0298)\n",
      "19855 Traning Loss: tensor(0.0284)\n",
      "19856 Traning Loss: tensor(0.0296)\n",
      "19857 Traning Loss: tensor(0.0294)\n",
      "19858 Traning Loss: tensor(0.0300)\n",
      "19859 Traning Loss: tensor(0.0288)\n",
      "19860 Traning Loss: tensor(0.0281)\n",
      "19861 Traning Loss: tensor(0.0296)\n",
      "19862 Traning Loss: tensor(0.0298)\n",
      "19863 Traning Loss: tensor(0.0288)\n",
      "19864 Traning Loss: tensor(0.0306)\n",
      "19865 Traning Loss: tensor(0.0285)\n",
      "19866 Traning Loss: tensor(0.0284)\n",
      "19867 Traning Loss: tensor(0.0299)\n",
      "19868 Traning Loss: tensor(0.0286)\n",
      "19869 Traning Loss: tensor(0.0303)\n",
      "19870 Traning Loss: tensor(0.0283)\n",
      "19871 Traning Loss: tensor(0.0293)\n",
      "19872 Traning Loss: tensor(0.0281)\n",
      "19873 Traning Loss: tensor(0.0294)\n",
      "19874 Traning Loss: tensor(0.0299)\n",
      "19875 Traning Loss: tensor(0.0278)\n",
      "19876 Traning Loss: tensor(0.0313)\n",
      "19877 Traning Loss: tensor(0.0306)\n",
      "19878 Traning Loss: tensor(0.0295)\n",
      "19879 Traning Loss: tensor(0.0279)\n",
      "19880 Traning Loss: tensor(0.0300)\n",
      "19881 Traning Loss: tensor(0.0294)\n",
      "19882 Traning Loss: tensor(0.0285)\n",
      "19883 Traning Loss: tensor(0.0302)\n",
      "19884 Traning Loss: tensor(0.0291)\n",
      "19885 Traning Loss: tensor(0.0272)\n",
      "19886 Traning Loss: tensor(0.0298)\n",
      "19887 Traning Loss: tensor(0.0296)\n",
      "19888 Traning Loss: tensor(0.0281)\n",
      "19889 Traning Loss: tensor(0.0291)\n",
      "19890 Traning Loss: tensor(0.0312)\n",
      "19891 Traning Loss: tensor(0.0305)\n",
      "19892 Traning Loss: tensor(0.0284)\n",
      "19893 Traning Loss: tensor(0.0286)\n",
      "19894 Traning Loss: tensor(0.0283)\n",
      "19895 Traning Loss: tensor(0.0304)\n",
      "19896 Traning Loss: tensor(0.0290)\n",
      "19897 Traning Loss: tensor(0.0301)\n",
      "19898 Traning Loss: tensor(0.0307)\n",
      "19899 Traning Loss: tensor(0.0291)\n",
      "19900 Traning Loss: tensor(0.0272)\n",
      "19901 Traning Loss: tensor(0.0295)\n",
      "19902 Traning Loss: tensor(0.0305)\n",
      "19903 Traning Loss: tensor(0.0296)\n",
      "19904 Traning Loss: tensor(0.0299)\n",
      "19905 Traning Loss: tensor(0.0316)\n",
      "19906 Traning Loss: tensor(0.0287)\n",
      "19907 Traning Loss: tensor(0.0283)\n",
      "19908 Traning Loss: tensor(0.0278)\n",
      "19909 Traning Loss: tensor(0.0297)\n",
      "19910 Traning Loss: tensor(0.0278)\n",
      "19911 Traning Loss: tensor(0.0289)\n",
      "19912 Traning Loss: tensor(0.0276)\n",
      "19913 Traning Loss: tensor(0.0304)\n",
      "19914 Traning Loss: tensor(0.0288)\n",
      "19915 Traning Loss: tensor(0.0296)\n",
      "19916 Traning Loss: tensor(0.0284)\n",
      "19917 Traning Loss: tensor(0.0280)\n",
      "19918 Traning Loss: tensor(0.0290)\n",
      "19919 Traning Loss: tensor(0.0314)\n",
      "19920 Traning Loss: tensor(0.0300)\n",
      "19921 Traning Loss: tensor(0.0269)\n",
      "19922 Traning Loss: tensor(0.0288)\n",
      "19923 Traning Loss: tensor(0.0277)\n",
      "19924 Traning Loss: tensor(0.0288)\n",
      "19925 Traning Loss: tensor(0.0285)\n",
      "19926 Traning Loss: tensor(0.0289)\n",
      "19927 Traning Loss: tensor(0.0314)\n",
      "19928 Traning Loss: tensor(0.0295)\n",
      "19929 Traning Loss: tensor(0.0285)\n",
      "19930 Traning Loss: tensor(0.0304)\n",
      "19931 Traning Loss: tensor(0.0294)\n",
      "19932 Traning Loss: tensor(0.0309)\n",
      "19933 Traning Loss: tensor(0.0308)\n",
      "19934 Traning Loss: tensor(0.0299)\n",
      "19935 Traning Loss: tensor(0.0277)\n",
      "19936 Traning Loss: tensor(0.0299)\n",
      "19937 Traning Loss: tensor(0.0319)\n",
      "19938 Traning Loss: tensor(0.0294)\n",
      "19939 Traning Loss: tensor(0.0305)\n",
      "19940 Traning Loss: tensor(0.0284)\n",
      "19941 Traning Loss: tensor(0.0297)\n",
      "19942 Traning Loss: tensor(0.0283)\n",
      "19943 Traning Loss: tensor(0.0305)\n",
      "19944 Traning Loss: tensor(0.0268)\n",
      "19945 Traning Loss: tensor(0.0295)\n",
      "19946 Traning Loss: tensor(0.0272)\n",
      "19947 Traning Loss: tensor(0.0291)\n",
      "19948 Traning Loss: tensor(0.0310)\n",
      "19949 Traning Loss: tensor(0.0299)\n",
      "19950 Traning Loss: tensor(0.0302)\n",
      "19951 Traning Loss: tensor(0.0300)\n",
      "19952 Traning Loss: tensor(0.0289)\n",
      "19953 Traning Loss: tensor(0.0289)\n",
      "19954 Traning Loss: tensor(0.0277)\n",
      "19955 Traning Loss: tensor(0.0292)\n",
      "19956 Traning Loss: tensor(0.0289)\n",
      "19957 Traning Loss: tensor(0.0308)\n",
      "19958 Traning Loss: tensor(0.0301)\n",
      "19959 Traning Loss: tensor(0.0293)\n",
      "19960 Traning Loss: tensor(0.0297)\n",
      "19961 Traning Loss: tensor(0.0293)\n",
      "19962 Traning Loss: tensor(0.0295)\n",
      "19963 Traning Loss: tensor(0.0312)\n",
      "19964 Traning Loss: tensor(0.0303)\n",
      "19965 Traning Loss: tensor(0.0307)\n",
      "19966 Traning Loss: tensor(0.0286)\n",
      "19967 Traning Loss: tensor(0.0279)\n",
      "19968 Traning Loss: tensor(0.0303)\n",
      "19969 Traning Loss: tensor(0.0297)\n",
      "19970 Traning Loss: tensor(0.0288)\n",
      "19971 Traning Loss: tensor(0.0289)\n",
      "19972 Traning Loss: tensor(0.0291)\n",
      "19973 Traning Loss: tensor(0.0292)\n",
      "19974 Traning Loss: tensor(0.0289)\n",
      "19975 Traning Loss: tensor(0.0291)\n",
      "19976 Traning Loss: tensor(0.0308)\n",
      "19977 Traning Loss: tensor(0.0306)\n",
      "19978 Traning Loss: tensor(0.0295)\n",
      "19979 Traning Loss: tensor(0.0286)\n",
      "19980 Traning Loss: tensor(0.0280)\n",
      "19981 Traning Loss: tensor(0.0286)\n",
      "19982 Traning Loss: tensor(0.0289)\n",
      "19983 Traning Loss: tensor(0.0309)\n",
      "19984 Traning Loss: tensor(0.0283)\n",
      "19985 Traning Loss: tensor(0.0283)\n",
      "19986 Traning Loss: tensor(0.0292)\n",
      "19987 Traning Loss: tensor(0.0305)\n",
      "19988 Traning Loss: tensor(0.0279)\n",
      "19989 Traning Loss: tensor(0.0282)\n",
      "19990 Traning Loss: tensor(0.0275)\n",
      "19991 Traning Loss: tensor(0.0281)\n",
      "19992 Traning Loss: tensor(0.0299)\n",
      "19993 Traning Loss: tensor(0.0291)\n",
      "19994 Traning Loss: tensor(0.0283)\n",
      "19995 Traning Loss: tensor(0.0296)\n",
      "19996 Traning Loss: tensor(0.0289)\n",
      "19997 Traning Loss: tensor(0.0315)\n",
      "19998 Traning Loss: tensor(0.0314)\n",
      "19999 Traning Loss: tensor(0.0287)\n"
     ]
    }
   ],
   "source": [
    "itera = 20000\n",
    "previous_validation_loss = 99999999.0\n",
    "\n",
    "for epoch in range(itera):\n",
    "    optimizer.zero_grad() #Zerar o Gradiente \n",
    "    \n",
    "    # Cálculo de Perdas feitas na cond de contorno\n",
    "    pt_x_bc1 = Variable(torch.from_numpy(x_bc1).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc1 = Variable(torch.from_numpy(t_bc1).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc1 = Variable(torch.from_numpy(u_bc1).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out = net(pt_x_bc1, pt_t_bc1) # saída de u(x,t)\n",
    "    mse_u1 = mse_cost_function(net_bc_out, pt_u_bc1)\n",
    "    \n",
    "    pt_x_bc2 = Variable(torch.from_numpy(x_bc2).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc2 = Variable(torch.from_numpy(t_bc2).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc2 = Variable(torch.from_numpy(u_bc2).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out2 = net(pt_x_bc2, pt_t_bc2) # Saída de u(x,t)\n",
    "    mse_u2 = mse_cost_function(net_bc_out2, pt_u_bc2)\n",
    "    \n",
    "    # Cálculo de Perdas feitas na pde\n",
    "    x_collocation = np.random.uniform(low=0.0, high=1.0, size=(10000,1))\n",
    "    t_collocation = np.random.uniform(low=0.0, high=1.0, size=(10000,1))\n",
    "    all_zeros = np.zeros((10000,1))\n",
    "    \n",
    "    \n",
    "    pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros = Variable(torch.from_numpy(all_zeros).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    f_out = f(pt_x_collocation, pt_t_collocation, net) # saída da função f(x,t)\n",
    "    mse_f = mse_cost_function(f_out, pt_all_zeros)\n",
    "    \n",
    "    # Combinando as perdas em loss\n",
    "    loss = mse_u1+ mse_u2 + 2*mse_f\n",
    "    \n",
    "    \n",
    "    loss.backward() # Computando o gradiente com o algorítimo de backward\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "    \tprint(epoch,\"Traning Loss:\",loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='e15300ce-74c1-4e49-9ea6-a8ccfe2112c3'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.arange(0,1,0.05).reshape(-1,1)\n",
    "t=np.ones(x.shape)*0.1\n",
    "pt_x = Variable(torch.from_numpy(x).float(), requires_grad=True).to(device)\n",
    "pt_t = Variable(torch.from_numpy(t).float(), requires_grad=True).to(device)\n",
    "pt_u = net(pt_x,pt_t)\n",
    "u=pt_u.data.cpu().numpy()\n",
    "plt.plot(x,u,color='red',linestyle='dashed')\n",
    "\n",
    "plt.show()     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHHCAYAAABtF1i4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuwklEQVR4nO3dd3gU1f7H8Xd6SKEGEjoqVYVQlR4RUMSCAoKAgigqYEHFBoqgV0V+V+F6AbsUERGUawEpgkYQIfQqoKFDIAlJIAnp5fz+2GTJkg7JbhI+r+c5T3Znzsx8Z1L2mzPnnHECDCIiIiIO4uzoAEREROTqpmREREREHErJiIiIiDiUkhERERFxKCUjIiIi4lBKRkRERMShlIyIiIiIQykZEREREYdSMiIiIiIOpWREJMvkyZMxxlCjRo0C682dO5ejR4/aKSoRkYpPyYiUKSNGjMAYY1MiIiL47bff6NOnj6PDc6igoCCMMQwYMMDRoZSK2rVrM3nyZAIDA3OtGzJkCOPGjXNAVKWrUqVKTJ48maCgIIfF8Mgjj7B//36SkpL4559/eOqpp4q0XfbPY17l5ptvLuWopaJxdXQAInmZNGkSR48excnJCX9/fx5++GFWrlzJXXfdxc8//+zo8KQU1KlThylTpnDs2DF2795ts27o0KHceOONfPDBBw6KrnR4eXkxZcoUpkyZwrp16+x+/Mcff5xPPvmE7777junTp9OtWzdmzpyJl5cX//d//1ekfXzwwQds3brVZtmhQ4dKI1ypwJSMSJm0cuVKtm/fbn3/xRdfEBERwZAhQ5SMlBNOTk64u7uTkpLi6FBKhZeXF4mJiY4O47J5enry9ttvs3z5cu6//34APv/8c5ydnZk0aRKffvop58+fL3Q/f/zxB0uXLi3laKWi020aKRfOnz9PUlIS6enp1mXZzcSXNnE3bNgQYwwjRoywWd6sWTMWL15MZGQkiYmJHDx4kLfeeqvA4zZo0IDQ0FD27t1LrVq18q3n5OTEuHHj2LdvH0lJSYSHh/Pxxx9TtWpVa5158+Zx9uxZXF1z/w+wevVqDh48WGAsRVWlShVmzJjBiRMnSE5OJjQ0lJdeegknJycAXF1diY6OZs6cObm29fX1JSkpiX//+9/WZe7u7kyZMoXQ0FCSk5M5ceIE06ZNw93d3WZbYwwzZ85k6NCh7Nu3j5SUFOuttTp16vDFF18QHh5OcnIy+/btY+TIkdZtg4KC2LZtG2C5TtnN/SNGjCA4OJi77rqLRo0aWZcX1mcnZywHDx4kKSmJbdu20a1bN5t6DRo0YPbs2Rw8eJDExESioqJYsmQJDRs2tKmXffuwe/fuzJ49m4iICE6dOlWsfVyqYcOGREVFATBlyhTruU2ePLnA7UpKjx498PPz48MPP7RZPnv2bHx8fLjzzjuLvC8fHx9cXFzyXd+rVy/++OMPzp07R3x8PAcPHuTtt9++7Nil4lHLiJRJVapUoUaNGjg5OVGrVi2efvppfHx8+Oqrry5rfy1btuSPP/4gLS2NTz/9lGPHjnHddddx991389prr+W5zbXXXstvv/1GTEwMvXv3Jjo6Ot/9f/LJJzz88MPMnTuX//73v1xzzTU89dRTtGnThi5dupCens6CBQsYMWIEt99+u03rjr+/P7feeitvvPHGZZ1bTpUqVWLdunXUrVuXTz75hBMnTtC5c2emTp1K7dq1ee6550hPT+f777+nf//+PPHEE6SlpVm3v/fee/H09OSbb74BLEnWTz/9RNeuXfn00085cOAALVu25LnnnqNp06bcd999Nse/9dZbGTRoELNmzSIqKopjx45Rq1YtQkJCMMYwa9Yszp49yx133MGcOXOoXLkyH3zwAQcOHGDSpEn861//4pNPPuGPP/4AYOPGjYSFhVGlShXq1avHc889B8CFCxcKvRZBQUEMHjyY//73v6SkpDB27FhWrVrFTTfdxF9//QVAhw4d6Ny5M9988w2nTp2iUaNGjBkzht9//53rr7+epKQkm31++OGHnD17ljfffBNvb+/L2ke2s2fPMnr0aD7++GP+97//8b///Q+APXv25HtOTk5OVK9evdBzB4iNjbVJ3i/Vpk0bAGsSmG379u1kZGTQpk0bFi5cWOhx5s6di6+vL+np6fzxxx+8+OKLNq2a119/PcuXL2fPnj28/vrrpKSk0LhxY7p06VKk85Crh1FRKStlxIgRJi9JSUlm+PDhNnWDgoKMMcYEBQXZLG/YsKExxpgRI0ZYl/3+++8mNjbW1K9fP99jT5482RhjTI0aNUyzZs3MqVOnzObNm03VqlVt6s2dO9ccPXrU+r5Lly7GGGOGDBliU++2226zWe7k5GROnDhhFi1aZFPv2WefNRkZGaZRo0YFXpvs8x0wYEC+dV599VUTHx9vGjdubLP8nXfeMWlpaaZevXoGML179zbGGHPnnXfa1Fu+fLk5dOiQ9f2wYcNMenq66dKli029xx9/3BhjTKdOnazLjDEmPT3dtGjRwqbuZ599ZsLCwkz16tVtln/99dfm3LlzxtPT0wCmXbt2ub5v2WXZsmU217ywkq1t27bWZfXr1zeJiYlm6dKl1mXZx85Zbr75ZmOMMQ8++GCun8v169cbZ2dnm/pF3UdepUaNGsYYYyZPnlyk88r+2S6KS38vLi0zZ840aWlpea6LiIgwX3/9dYHbd+rUyXz77bdm5MiR5u677zYvv/yyOXv2rElMTDStW7e21hs3bpz196qo3z+Vq6/oNo2USWPHjqVXr1706tWLYcOGERwczOeff57rP/Gi8PPzIygoiDlz5nDy5MlC6994442sW7eOY8eO0atXr0Lvm99///2cP3+eNWvWUKNGDWvZvn078fHx9OjRAwBjDAsXLuSee+7Bx8fHuv2wYcPYuHEjx44dK/a55RVLdnN4zljWrl2Lq6sr3bt3B+C3337j7NmzDB482Lpt1apV6d27N4sXL7bZ34EDBzh48KDN/n777TcA67llW7duHQcOHLBZNmDAAJYtW4aTk5PNPlavXk3VqlVp27btFZ93XjZu3MiOHTus70+ePMmPP/7I7bffjrOz5U9fcnKydb2rqyvVq1fn0KFDnDt3Ls+4PvvsMzIzM22WFXcfVyI8PNz6e1FYubQT8KUqVapEampqnuuSk5OpVKlSgdtv2rSJ+++/n7lz57Js2TKmTZtGx44dMcYwdepUa73s359+/fpZbxWKXEq3aaRM2rJli01T76JFi9i5cyezZs1i+fLlNrcWCnPttdcCsG/fviLVX7ZsGREREdx+++0kJCQUWr9JkyZUrVqVs2fP5rk+Z1+TL7/8kldeeYX77ruPBQsW0LRpU9q3b88TTzxhrePv72+zfWxsrM0HXmGxBAYGWvsi5BdLRkYGS5cuZejQobi7u5Oamkr//v1xd3e3SUaaNGnC9ddfX+j+sl3al6NmzZpUq1aNJ554wuYcC9pHSQkNDc217J9//sHb25uaNWsSERGBp6cnEyZMYOTIkdStW9eapIDlVuGl8uqrUtx9XImUlBR+/fXXEtlXUlJSrn4/2Tw9PfO9vVSQw4cP8+OPP9K/f3+cnZ3JzMxk8eLFjBo1ii+++IJ3332XX3/9lf/973989913GGOu9DSkglAyIuWCMYbg4GCeffZZmjRpwv79+/P9Q1ZQR7qiWLp0KQ8//DDDhg3j008/LbS+s7MzERERDBs2LM/1OZOUAwcOsG3bNh588EEWLFjAgw8+SEpKCkuWLLHWCQ8Pt9n+4YcfZv78+UWK3dnZmV9++SXfYZn//POP9fU333zD6NGjueOOO/jxxx8ZNGgQBw4csOmz4OzszJ49e3j++efz3N+lLU2XfoBlfzAvWLAg33MoqI9EaZs5cyYjR47kP//5D5s2bSI2NhZjDN98841NUpEtrw/o4u7jSjg7O1OzZs0i1Y2JiSkwaT9z5gyurq7UrFnT5mfUzc2NGjVqcPr06cuK8eTJk3h4eODt7U18fDzJycl0796dHj16cOedd9KnTx8eeOABfv31V2677bZcLU1ydVIyIuVG9iiU7Fsc586dA7AZsQLkGsVw5MgRwHL7pShefPFF0tPT+fDDD4mPj2fRokUF1j98+DC9evXizz//LFILxpdffsn06dMJCAhg6NCh/Pzzzza3gnr16mVTP7uzZVEcPnwYHx+fIv33vH79ek6fPs3gwYPZsGEDt956a64RDocPHyYwMPCy/xs/e/YscXFxuLi4FLqPgv5Lvpz/oJs0aZJrWdOmTUlISLB++A4cOJD58+fzwgsvWOt4eHjk+pkqyJXso7jnVb9+/SLfzrvlllsKnLtk165dALRv356VK1dal7dv3x4XFxfr+uK69tprSUpKsulkbIzht99+47fffmP8+PFMmDCBd955hx49epRYS4+Ub+ozIuWCq6srt912GykpKdY+CcePHyc9Pd3aDyLb2LFjbd5HRUWxbt06HnnkEerXr1/osYwxPP7443z33XfMnz+fu+++u8D6S5YswdXVlUmTJuVa5+LikqupftGiRRhj+OCDD7juuutyjRD69ddfbcqlLSWFxdK5c2duu+22XOuqVKli02pkjOG7777j7rvv5qGHHsLNzc3mFk32/urVq8djjz2Wa3+enp54eXkVGE9mZiZLly5lwIAB3HDDDbnW+/n5WV9n3xLL60M8ISGh2Lc8OnfubB0xAlCvXj369evHL7/8Yv1vPCMjI1c/hqeffjrP4df5uZJ9ZM9TUtTkpyT7jPz2229ER0czZswYm+VjxowhISHBZsRXjRo1aNasmU0/kpzfu2ytWrXinnvu4ZdffrEmWtWqVctVLzvR8fDwKNJ5S8WnlhEpk+644w6aN28OWPoUDB06lKZNmzJ16lTi4+MBiIuL49tvv+Xpp5/GGMPhw4e566678uyD8Mwzz7BhwwZ27NjBp59+ytGjR2nUqBF33nmnzQdWNmMMDz74ID/88ANLliyhb9++BAcH5xnr+vXr+fjjj5k4cSKtW7fml19+IS0tjSZNmnD//fczbtw4m0mhoqKiWLVqFYMGDeLcuXPFnsRtwIAB1muT0/z58/n3v//NPffcw/Lly5k3bx7bt2/H29ubli1bMnDgQBo1amQzRHnx4sU888wzvPHGG+zZsyfXXCcLFixg0KBBfPzxx/To0YM///wTFxcXmjdvzqBBg7j99ttt+vbk5ZVXXqFHjx5s3ryZzz77jP3791O9enXatm1Lr169rM8COnz4MOfOnWP06NHEx8eTkJDA5s2bOXbsGNu3b+eBBx7g/fffZ+vWrVy4cIHly5cXeNy9e/eyevVqm6G9gM08HsuXL+ehhx4iNjaW/fv306lTJ3r16pVvH5m8XMk+kpOT+euvvxg8eDD//PMPMTEx7Nu3L9/WsJLsM5KcnMykSZP48MMPWbJkCatXr6Zbt2489NBDTJw40dryCPDUU08xZcoUm9aWxYsXk5SUxMaNG4mMjOT666/n8ccfJzExkVdeecW67euvv0737t35+eefOX78OLVq1WLs2LGcPHmSDRs2lMi5SMXg8CE9KirZJa+hvYmJiWbHjh3miSeeyFW/Ro0a5ttvvzUXLlww0dHR5qOPPjLXX399nkNEr7/+erN06VITExNjEhMTzYEDB8wbb7xhXZ9zaG/2Mk9PTxMcHGzi4uLMTTfdZCD30N7sMmrUKLN161aTkJBgYmNjze7du827775rAgICctUdOHCgMcaYjz/+uMjXJntob36yh996e3ubt99+2/zzzz8mOTnZREZGmg0bNpjnn3/euLq65trv8ePHjTHGTJw4Mc/jurq6mhdffNHs3bvXJCUlmejoaLN161YzadIk4+vra61njDEzZ87Mcx81a9Y0M2fONMePHzcpKSnm9OnTZs2aNWbUqFE29e6++26zb98+k5qaavM99PLyMl999ZWJiYkxxphCh/lmxzJ06FDz999/m6SkJLN9+/Zcw12rVKlivvjiCxMZGWni4uLMypUrTdOmTc3Ro0fN3Llzc/1ctmvXLtexirqP/ErHjh3N1q1bTXJysjGm6MN8S6qMGjXKHDhwwCQnJ5vQ0FAzbty4XHWyfzdyXr+nn37ahISEmKioKJOammrCwsLMl19+aa677jqbbXv06GG+//57c+rUKZOcnGxOnTplFi5cmGv4ucpVXxwegIrKVVfuueceY4wxXbt2dXgsFbEUlBipqKiUvaI+IyIO8Nhjj3H48GE1U4uIoD4jInY1ePBgWrVqxV133cUzzzzj6HBERMoEJSMidvTNN98QHx/P559/nusBZSIiVysnLPdrRERERBxCfUZERETEoZSMiIiIiEOVmz4jderUsU52JSIiIuWDr69voc86KhfJSJ06dQgLC3N0GCIiInIZ6tatW2BCUi6SkewWkbp166p1REREpJzw9fUlLCys0M/ucpGMZIuPj1cyIiIiUsGoA6uIiIg4lJIRERERcSglIyIiIuJQ5arPiIiIl5cXfn5+ODk5OToUkauaMYaoqCgSExOveF9KRkSkXHBycmLkyJHccsstjg5FRHL4/fffmTt3LsZc/tNllIyISLkwcuRIgoKCWLx4MQcPHiQ9Pd3RIYlc1VxdXWnevDmDBg0CYM6cOZe/r5IKSkSktHh7e3PLLbewePFifv75Z0eHIyJZDh8+DMDgwYP55ptvLvuWjTqwikiZV6NGDQAOHjzo4EhE5FLZv5d+fn6XvQ8lIyJS5mV3VtWtGZGyJ/v38ko6lSsZEREREYcqdjLSrVs3fvrpJ8LCwjDG0K9fv0K3CQoKYvv27SQnJxMaGsqIESMuK1gREcktODiYGTNm5Lt+7ty5fP/993aMSKR4ip2MeHt7s3v3bp588ski1W/UqBE///wzwcHBtG7dmv/85z98/vnn3HbbbcUOVkSkPMke7phdoqKiWLlyJS1btnR0aCUuKCgIYwxVqlRxdCjFlley1rBhQ4wxBAYGFrhtdr2c3+PVq1fTunVra51Lk8Xg4GCMMQwePNhmX+PGjePo0aPW9yNGjMAYw8qVK23qValSBWMMQUFBxT3VMqvYyciqVauYNGkSP/zwQ5Hqjx49mqNHj/LCCy9w8OBBZs+ezXfffcdzzz1X3EOXOA8vLxrf1M7RYYhIBbZy5UoCAgIICAigZ8+epKens3z5ckeHdVVwc3Oz27F69uxJQEAAt99+Oz4+PqxcubLAxCwpKYm33noLV9eCB7WmpaXRq1evCj+/Tqn3GenUqRNr1661WbZ69Wo6deqU7zbu7u74+vralJLm4ubGyA+m8fgn/6HdXX1KfP8iIgApKSlEREQQERHB7t27effdd2nQoIF15EFeLQqBgYEYY2jYsKF1WefOnQkODiYhIYGYmBhWrVpF1apV8zxm3759OX/+PEOHDs1zvZOTE6+88gpHjhwhMTGRXbt2MWDAAOv60NBQxo8fb7NNdkzXXXfdZV0Hd3d3/v3vf3Pq1CkuXLhASEiI9T97X19fEhMT6dPH9m/xvffeS1xcHJUqVQKgXr16LF68mHPnzhEdHc0PP/xgc42yWzgmTpxIWFgYf//9d6HbTZ48mYcffph7773X2roRFBTEsWPHANi1axfGGIKDgws8v+joaCIiIti+fTsvvPACAQEB3HzzzfnWX7RoEVWrVuWxxx4rcL8JCQnMmTOHd999t8B65V2pJyMBAQFERETYLIuIiKBKlSp4enrmuc2ECROIi4uzlrCwsBKPy2Rmcj4iEhdXV4ZOnUzXofeX+DFEpPS4V/J0SLkS3t7ePPjgg4SGhhIdHV3k7QIDA/n111/Zv38/nTp1omvXrixbtgwXF5dcdYcMGcKiRYsYNmwYX3/9dZ77mzBhAsOHD2f06NHccMMNzJgxg6+++oru3bsDlsmrRo4cabPNyJEjWbdunXVeieKaNWsWnTp14oEHHqBVq1Z8++23rFq1isaNGxMfH8/y5ctzJU/Dhg3jhx9+ICkpCVdXV1avXk18fDzdunWjS5cuXLhwgVWrVtm0gPTs2ZNmzZrRu3dv7rrrrkK3e++991i8eLFNC9bGjRvp0KGDdX8BAQH079+/yOealJQEWBKw/MTFxfH222/z+uuv4+XlVeD+pkyZQsuWLW0SxoqmTE56NnXqVKZPn2597+vrW+IJSWZGBosnvUVSXDzdHxrMfROex6uyL798fPkzyImIfbhX8mTqloL/Uy0tE27qQWpScpHr33XXXcTHxwPg4+PD6dOnueuuu4o1dfZLL73Etm3bbPrq7d+/P1e9sWPH8vbbb3P33Xezfv36PPfl7u7OxIkT6dWrFyEhIQAcPXqUrl278sQTT7B+/XrmzZvHm2++SYcOHdi6dSuurq4MHTqUF154ocgx51S/fn1GjhxJgwYNOHPmDADvv/8+ffr0YeTIkbz66qssXLiQBQsWUKlSJZKSkvD19eXOO+/kvvvuAyyTajk7OzNq1CjrfkeOHMn58+e55ZZbWLNmDWBpSRg1ahRpaWmAJaEpbLukpCQ8PDxs/nE+e/YscLHFo6iqVKnCpEmTiI+PZ8uWLQXW/fDDDxk3bhzPP/88b731Vr71zpw5wwcffMDbb79d5C4S5U2pt4yEh4fj7+9vs8zf35/Y2FiSk/P+hU5NTSU+Pt6mlAZjDD/+339YOetTAG5/8jH6vfysHsAlIiUmu/N+69at6dChA6tXr2blypU0aNCgyPto3bo1v/76a4F1Bg4cyIwZM+jdu3e+iQhA48aN8fb2Zs2aNTZ/Y4cPH269BXPmzBl+/vlnHnnkEQDuvvtuPDw8+PbbbwHYt2+fdbsVK1YUGn/Lli1xdXXln3/+sTlmUFCQ9ZgrVqwgLS2Ne+65B4ABAwYQFxdnvc0fGBhobUXJLjExMXh6etrcOtq7d681ESnOdldq48aNxMfHc/78eQIDAxk8eDCRkZEFbpOamsrrr7/OCy+8YJ3YLz/Tpk2jZs2a1u9JRVPqLSObNm2ib9++Nst69+7Npk2bSvvQRbb2k7kkxcXTf+J4uj84GK/KlVk8+W0y0zMcHZqI5CE1KZkJN/Vw2LGLIyEhwebWxqhRo4iNjeWxxx5j0qRJZGZmArYTRl3a8TK72b8gO3fupG3btjzyyCNs27Yt33o+Pj4A3HnnnblanFNSUqyvP//8cxYsWMBzzz3HyJEjWbx4sTWOvn37WmMsSmw+Pj6kp6fTrl07MjJs/65euHABsHTU/O677xg6dCiLFy+2fs2u7+Pjw/bt2xk2bFiu/We3YoDlel967KJsd6UGDx7M/v37iY6OJjY2tsjbffXVV7zwwgu89tpr1n4qeYmNjWXq1KlMnjy5QnaALnYy4u3tTePGja3vr7nmGgIDA4mJieHkyZO888471K1b1zqXyMcff8xTTz3FtGnTmDNnDrfeeiuDBg3izjvvLLmzKAF/LvqOpLg4HnhrEu3vuYNKvj58+eIk0nP8copI2VHcpKCsMMaQmZlp7ZSZ/YFYu3Ztzp8/D2AzLBRgz5499OzZkylTpuS738OHDzN+/Hh+//13MjIyePrpp/Ost3//fpKTk2nQoEGBLSgrVqwgISGBMWPG0KdPH2t/EoATJ04U4Uwv2rlzJ66urtSqVYsNGzbkW2/hwoWsWbOG66+/nltvvZXXXnvNum7Hjh3W1obitJYXZbvU1NRc/W9SU1MB8uyXk5eTJ09y5MiRIseVzRjDhAkT+N///sdHH31UYN2ZM2fyzDPPMG7cuGIfp6wr9m2a9u3bs2vXLnbt2gXAjBkz2LVrF2+++SZg+YXK2fx47Ngx7rzzTnr37s3u3bsZP348o0aN4pdffimZMyhBO37+hXnPTiAtOYUbenTjsY+m4+FdcMciEZGCeHh44O/vj7+/P82bN2fmzJn4+PiwbNkyAA4dOsSJEyeYMmUKjRs3pm/fvrlGskydOpUOHTowe/ZsWrZsSbNmzRg9enSupv3Q0FB69OjBgAED8p0E7cKFC7z33nvMmDGD4cOHc+2119KmTRueeuophg8fbq2XmZnJvHnzmDp1KqGhodb+JYVp2bIlgYGB1tKqVStCQ0P56quv+PLLL7nvvvto1KgRHTp04JVXXrFpOV+/fj3h4eEsXLiQo0eP2vS5WLhwIVFRUfz444907dqVRo0aERQUxAcffEDdunXzjaco2x07doxWrVrRtGlTatSogaurK5GRkdYRPrVq1aJy5cpFOv/LsWLFCjZv3swTTzxRYL2UlBQmT57MM888U2qxOJIp68XX19cYY4yvr69djndt+zbm7U1rzft7N5lnv5ljvKtVdfg1UFG5mkvDhg3Nl19+aRo2bOjwWIpT5s6da3KKjY01mzdvNv3797ep17lzZ7N7926TmJho1q1bZwYMGGCMMTbn2717d7NhwwaTlJRkYmJizMqVK02VKlUMYIKDg82MGTOsdZs3b27Cw8PNe++9Z43j+++/tznmM888Yw4cOGBSUlJMRESEWblypenWrZtNnWuuucYYY8wLL7xQ6LkGBQWZvKSlpRnAuLq6milTppgjR46YlJQUExYWZpYuXWpuvPFGm/28++67xhhjpkyZkusY/v7+Zt68eSYyMtIkJSWZQ4cOmU8++cT62ZDXeRZlOz8/P7N69WoTFxdnjDEmKCjIAObRRx81x48fN+np6SY4ODjfn01jjAkMDMz32lz6/bn0PWA6duxojDHm6NGj1mUjRoww586ds6nn7Oxs9u3bZxOno0tBv5/F+Px2/IkUVuydjACmboum5o11K8z7ezeZl3/6xlT1r+Xw66CicrWW8pqMlPfStWtXk5KSYmrV0t8/lfxLSSQjelBePsIO/MPsh8dw7kw4ta5pyFMLPsGvYX1HhyUiUurc3d2pW7cuU6ZM4dtvvy10VIjIlVIyUoDIo8eZNXw0kUePU612AE/N/5i6LZo6OiwRkVI1ZMgQjh8/TtWqVXnppZccHY5cBZSMFOJ8eASzHx7Dyf0H8a1RnTFfzObadq0dHZaISKmZP38+rq6utG/fntOnTzs6HLkKKBkpggsx5/jokSc5vG0nlXx9ePzj/9CiW2dHhyUiIlIhKBkpopSERD4d/Rx//b4BN08PRn4wjTZ9b3N0WCIiIuWekpFiSE9JYd5zr7B9+Spc3CwP2Os8OP+HJ11vx9hERETKKyUjxZSZnsGiiW+y4etvcXZ2ZsBrL9Lr8Ydz1bsR2AusBW6yc4wiIiLliZKRy2CM4fup0/nloy8AuOPpJ7jnxWdsni3RHkgDegKbge9RS4mIiEhelIxcgdUffs4P784AIGj4EAa9ORHnrOcYzAOaAnOADOBeLC0l84FG9g9VREQqICcnJ8aPH5/reUbljZKRK/THwiUsevVfZKSnc9O9dzH8/bdxdXcH4ATwKJZbNt9iudjDgQ3Y4XHJInLVCA4OzvdZNABz587l+++/t2NEYi9vvfUW3bt3Z8+ePfnWKeznoyxQMlICtv20gvnPTyQtJYWWPYMYNft9PLwuPmDvIDAIaAesBt4H0nNsX8Wu0YqIvcydOxdjjLVERUWxcuVKWrZs6ejQSlxQUBDGGKpUKX9/0fJK1ho2bIgxhsDAQAdFVbh+/fpxyy238MADD5CZmZlvvf79+zNp0iQ7RlZ8SkZKyF/Bf/DZmOdJTkigScf2jP58Jl5VbJ/yuAPoA/wnx7J7gaPAK4CeDyxS8axcuZKAgAACAgLo2bMn6enpLF++3NFhXRXc3NwcHUKp+vHHH+nSpQtJSUl5rs8+/3PnznHhwgV7hlZsSkZK0OGtO/j40adJOHeeBi2v58l5H1G5Vs1c9UyO10OAasBU4DAwFqjYvz4iV5eUlBQiIiKIiIhg9+7dvPvuuzRo0AA/Pz8g7xaFwMBAjDE0bNjQuqxz584EBweTkJBATEwMq1atomrVqnkes2/fvpw/f56hQ4fmud7JyYlXXnmFI0eOkJiYyK5duxgwYIB1fWhoKOPHj7fZJjum66677rKug7u7O//+9785deoUFy5cICQkhKCgIAB8fX1JTEykT58+Ntvce++9xMXFUalSJQDq1avH4sWLOXfuHNHR0fzwww821yi7hWPixImEhYXx999/F7rd5MmTefjhh7n33nutLVhBQUEcO3YMgF27dmGMITg4ON9zu+GGG1ixYgXx8fGEh4fz5ZdfUqNGDev64OBg/vvf/zJjxgxiYmIIDw9n1KhReHl5MWfOHOLi4ggNDbU5/+yfi759+7J7926SkpLYtGkTN9xwg7XOiBEjOHfunPX95MmT2blzJ48++ihHjhwhOTnZevyct2nc3d159913OXHiBMnJyYSGhvLII49Y13fv3p3NmzeTnJzM6dOnmTp1Ki5Z/SFLi5KREnbyrwPMGjGa8xGRBDS+lnFff06Tm9vnW38I8CBwBAgAZgN/Aw+hb45IYbwKKB7FqOtZxLpXytvbmwcffJDQ0FCio6OLvF1gYCC//vor+/fvp1OnTnTt2pVly5bl+QExZMgQFi1axLBhw/j666/z3N+ECRMYPnw4o0eP5oYbbmDGjBl89dVXdO/eHYA5c+YwcuRIm21GjhzJunXrOHz4cDHO+KJZs2bRqVMnHnjgAVq1asW3337LqlWraNy4MfHx8SxfvjxX8jRs2DB++OEHkpKScHV1ZfXq1cTHx9OtWze6dOnChQsXWLVqlU0LSM+ePWnWrBm9e/fmrrvuKnS79957j8WLF9u0YG3cuJEOHTpY9xcQEED//nnPKVWlShV+++03du7cSfv27enTpw/+/v4sWbLEpt6IESOIioripptuYubMmXz00Ud8++23bNy4kbZt2/LLL7+wYMECa+KV7d///jfjx4+nQ4cOnD17lmXLluHqmn+vw8aNGzNgwAD69++fb6fWL7/8kiFDhvDMM8/QokULnnjiCWvLSZ06dVixYgVbt24lMDCQMWPG8Oijj/Laa6/le8yS4vDHDxdWivoI4rJUqtUOMC//9I15f+8m8/7eTabfy88aN0+PfOu7gRkN5jQYk1W+LgPnoaJSFkp+jyg3BZTll+zjQgF1gy+pG5lPveLGPXfuXJOWlmbi4+NNfHy8McaYsLAw06ZNG2udoKAgY4wxVapUsS4LDAw0xhjr+S5cuND88ccf+R4nODjYzJgxw4wdO9acO3fOdO/ePVcc33//vQGMu7u7uXDhgunYsaNNnc8++8wsXLjQAKZ27domLS3NdOjQwQDG1dXVREZGmuHDh+cbQ17nkV3q169v0tLSTO3atW2Wr1mzxrz99tsGMP369TNxcXGmUqVKBix/9xMTE83tt99uADNs2DBz4MABm+3d3NxMQkKC6d27t/U8z5w5Y9zc3Kx1irpd9vXJ+TNnjDGBgYEFfo9fffVVs2rVKptldevWNcYY06RJE+v3Z/369db1zs7OJj4+3syfP9+6zN/f3xhjzM0332xzPQcNGmStU61aNZOQkGDuv/9+A5gRI0aYc+fOWddPnjzZpKSkGD8/vzx/PgDTpEkTY4wxPXv2zPN83nrrrVzXa8yYMSYuLs44OTkV6/cz+/tYlM9v/fNdSs6dCWfG4If585ulAHR/cDDPL5lP/Rta5Fk/DfgYuA54GTgHLMix3imvjUSkzAsODqZ169a0bt2aDh06sHr1alauXEmDBg2KvI/WrVvz66+/Flhn4MCBzJgxg969e7N+/fp86zVu3Bhvb2/WrFlDfHy8tQwfPtx6C+bMmTP8/PPP1qb7u+++Gw8PD7799lsA9u3bZ91uxYoVhcbfsmVLXF1d+eeff2yOGRQUZD3mihUrSEtL45577gFgwIABxMXFsXbtWsDSOpTdipJdYmJi8PT0tLl1tHfvXtLS0qzvi7rd5QoMDKRHjx42+z948CCAzf5zjnbJzMwkOjqavXv3WpdFREQAUKtWLZv9b9q0yfr63Llz/P3337RokffnCMDx48eJiorKd33r1q1JT09n3bp1ea5v0aKFzTEB/vzzT3x9falXr16++71SGmFailKTkvnf2+/xV/AfDH7zVWpd05Cnv/qUXz+bz5pP55KZnpFrmyTg/4CPgPgcy18GbgUmAtvsEbxIOeBdwLpLf7tq5VnL4tJxCI0uK5q8JSQk2NzaGDVqFLGxsTz22GNMmjTJOgoi56SJl3a8zK+DYk47d+6kbdu2PPLII2zblv9fCR8fHwDuvPNOwsLCbNalpKRYX3/++ecsWLCA5557jpEjR7J48WJrHH379rXGWJTYfHx8SE9Pp127dmRk2H5nsm8PpKWl8d133zF06FAWL15s/Zpd38fHh+3btzNs2LBc+z979qz1dUJCQq5jF2W7y+Xj48OyZct4+eWXc607c+aM9XXOBAnAGJNrGYCz85W1EVx6/pcqyvfLEZSM2MHfGzfz7/4P0v/V8bTtexu3jXmUFt07s2jim0QcOZbnNjkTETfgWcAf6A0sxdLhdXvphi1S5iWWgbrFZYwhMzPT2jcg+wOxdu3anD9/HiDXvf49e/bQs2dPpkyZku9+Dx8+zPjx4/n999/JyMjg6aefzrPe/v37SU5OpkGDBgW2oKxYsYKEhATGjBlDnz59rP1JAE6cOFGEM71o586duLq6UqtWLTZs2JBvvYULF7JmzRquv/56br31Vpt+Cjt27GDw4MFERkYSHx+f7z4uVZTtUlNTc/W/SU1NBSi04+aOHTsYMGAAx44dy5VolYSOHTty8uRJAKpWrUrTpk05cODAZe9v7969ODs7ExQUlGdr24EDB2w6MwN06dKFuLg4Tp06ddnHLYxu09hJUlwcC1+ezIIXXiPhfCz1b2jBc0vm0f2hB2z+I8pLGtARy6yuGcAALK0j64B70DdRpCzz8PDA398ff39/mjdvzsyZM63/TQMcOnSIEydOMGXKFBo3bkzfvn1zjWSZOnUqHTp0YPbs2bRs2ZJmzZoxevRomxEbYBkF06NHDwYMGJDvJFcXLlzgvffeY8aMGQwfPpxrr72WNm3a8NRTTzF8+HBrvczMTObNm8fUqVMJDQ0lJCSkSOfbsmVLAgMDraVVq1aEhoby1Vdf8eWXX3LffffRqFEjOnTowCuvvELfvn2t265fv57w8HAWLlzI0aNH2bJli3XdwoULiYqK4scff6Rr1640atSIoKAgPvjgA+rWrZtvPEXZ7tixY7Rq1YqmTZtSo0YNXF1diYyMtI7wqVWrFpUrV85z/7Nnz6Z69eosWrSI9u3bc+2113LbbbcxZ86cK27lAHj99de59dZbueGGG5g3bx5RUVH88MMPl72/48ePM3/+fObMmUO/fv2s1+P+++8H4MMPP6R+/frMnDmTZs2acc899/DGG28wffp0jDFXfD4FKXanLHuX8tiBtaBSuaafGfXh+9bOrWO+mGWq1Q4o0rYtwMwDk8LFTnVvl4FzUlEpzVJQB7myXObOnWtyio2NNZs3bzb9+/e3qde5c2eze/duk5iYaNatW2cGDBhg04EVMN27dzcbNmwwSUlJJiYmxqxcudLaWTRnB0XANG/e3ISHh5v33nvPGselHTSfeeYZc+DAAZOSkmIiIiLMypUrTbdu3WzqXHPNNcYYY1544YVCzzW7w+Wl0tLSDFg6wU6ZMsUcOXLEpKSkmLCwMLN06VJz44032uzn3XffNcYYM2XKlFzH8Pf3N/PmzTORkZEmKSnJHDp0yHzyySfWz4a8zrMo2/n5+ZnVq1ebuLg4Y4wxQUFBBjCPPvqoOX78uElPTzfBwcH5nnvjxo3N0qVLTUxMjElISDD79+8306dPt66/9PsDmKNHj5px48bZLDPGmH79+tlczzvvvNPs3bvXJCcnm5CQENOyZUtr/bw6sO7cuTNXfJce38PDw7z//vsmLCzMJCcnm3/++cc8/PDDNj9rmzdvNsnJyeb06dNm6tSpxsXF5bJ+P4vx+e34X9jCSkVLRrJLx4H9zDubfzXv791k3t601nS4984ib1sHzDtgosA0y7G8AZiAMnBuKiolWcprMlLeS9euXU1KSoqpVauWw2O52kpBo5PKWtFomnIu5LsfeX/AcI7u2I2njzcP/Os1Rv53Gj41qhW67WksnVnrYJmXJNs7wHFgLlDxJpwWEXtwd3enbt26TJkyhW+//ZbIyEhHhyQVnJIRB4s+FcbskWNZPmM26Wlp3NijOy8s/Yobbw0q0vapOV47A7UBd+BhYA/wC3B7CccsIhXbkCFDOH78OFWrVuWll15ydDhyFVAyUgaYzEyC53zFfx4Yyem/Q/GtUZ2RH7zLA2+9hqdPQYMXbWUCPYGbgMVYOrv2BlYB+4CBpRC7iFQ88+fPx9XVlfbt23P69GlHh3NVWrduHU5OTsTGxjo6FLtQMlKGnPnnMP8Z8ihrP5tPZkYGHfrdyQv/+4rGN7Ur1n62Ag9gmUBtOhAH3EDJzp0gIiJSUpSMlDEZaWms/O/HzH54LFEnTlGtdgBjvphFv5eexdXj0qdtFOw4MB6oDzwPfJZj3X3AJ0DzkgpcRETkMikZKaOO7drD+wOHs3Hx/wDo/tBgnl8yL9/p5AsSB8wAcjb2vQI8DhwAlgM9rjhikdKTPb9BQQ8IExHHyP69vJJ5SJSMlGGpSUksfevffDbmOWIjz+J/bSOe/upTbhvzKM6uV/Y45/HA91j6mdwJ/AbsAEYAlQrYTsQRsp9w27y52vJEyprs38uCnolTGCcsY3zLNF9fX+Li4qhcuXKxpgGuSCpVrsyAV8fTpu9tAJz86wBfT3iDyKPHr2i/jYFxwEguPufjByy3cUTKkkceeYSgoCCWLFnCwYMHSU9Pd3RIIlc1V1dXmjdvzqBBg1i3bh1z5szJVaeon99KRsqZ1n16MeC1F/GqUpm0lBTWfjqPP75aQkrilT1NoxrwGJZbN68A32UtDwDuBb7GcrtHxFGcnJwYOXIkt9xyi6NDEZEcfv/9d+bOnZvnbRolIxVY5Zp+DHpzIi26dgLgQsw5gud8xZ+Ll5KWnFLI1gVzyirZTzGdCLwNJABLgM+BjVd0BJEr4+XlhZ+fX6HPdBKR0mWMISoqisQC/hlWMnIVaHNHb24fO4qajRoAEHc2il8//5KQ734kPTW1kK2L5iEsLSXX51j2F5akZAEQXSJHERGRikjJyFXC2cWFdnfdTu/Rj1KjXh0AzodHsObTeWz9fjkZJXRfvROW2ziDAa+sZeew3MYpmbRHREQqGiUjVxkXV1c63HcXvR9/mKoB/gBEnzrNmk/msH3ZKjIzMkrkOJWBIVgSk71YOr5mexT4GQgvkSOJiEh5p2TkKuXq7k7Hgf3o+dgIKvvVAODssROs/ugLdq1ai8nMLGQPRecBZPdQCQR2AelY5i35HMs09CWTAomISHmkZOQq5+bpQZfBA+jxyIP4VLc8BTj80BFWzf6Mfb+uu6LJafJyM/Ae0DXHslPAnKxyZQOQRUSkPFIyIgB4eHnRdej93DJyKF6VKwMQduAfVs3+jP3rNpT48VpguV0zAvDLWpYJdAf+LPGjiYhIWaZkRGx4+voQ9NADdH/oAeuTgI/v+YvVsz/j742bS/x47ljmJxmFZSROIyy3cMDSCTYe+CXHMhERqXiUjEievKpUpsfIYXQZcj8eXpaJ349s38WqWZ9yeNvOUjmmD3Ah67UTlls29YEoLHOXLAQ2UQ5+EEVEpFiUjEiBfGpU49ZHHqLz4P64ZT0NODRkG6tmfcqx3XtL7bjeWCZRewDwz7H8GJZZXhcAB0vt6CIiYk9KRqRIKteqSa/HRnDzgHtwdXMD4MAfG1k161NO7f+71I7rAtwKDAP6A75Zy2cBT5faUUVExJ6UjEixVKsdQK/HH6bDvXfikvU46H2/rWPdl99wZPuuUj12JeAuLInJVCC7B0tX4F9YWky+wzLJmoiIlB9KRuSy1Khfj9tGP0LbO2/D2cUFgMijxwn57ke2/bSChPOxdovlI2B01utUYAWW/iXLgWS7RSEiIpdLyYhckVrXNCRo+BDa9O2Nh5dlAvj01FT2rv2dTd/9yOGtO0o9hvpY+pYMwzKpWrY44H/AM1hG5YiISNmkZERKhIeXF2369qbjwH7Uv6GFdfnZ4yfZvPRHtv64ggsxpX8D5QYsSclQoCFwFLg2x/rGwBEuPm1YREQcT8mIlLi6LZrScUA/2t55u3Wukoy0dPYFryfkux8IDdlW4jO7XsoJ6AzUAH7KWuYGRGCZmv57YCnwO5qKXkTE0ZSMSKlxr1SJ1n160XHAPTQMvNG6PPpUGJuXLmPLD8uJj4q2Wzw3AH8A1XIsiwJ+xJKY/IqeLCwi4ghKRsQuaje9jo4D+tHurj5UqmwZoJuRns7+dX8S8t0P/L1xS4k+nC8/bliGCg/AMvNrzRzrJgNvlnoEIiJyKSUjYldunh4E3taTjgPu4Zq2F7ubxpw+w5bvl7Pl+2XERpy1SywuWJ6FMwDLHCZ9gD1Z6+7A8tyc74CVQIJdIhIRuTopGRGH8b/uGjoO6Ef7e+7Aq4rl4XyZGRkcWL+RkKU/cXDDJjIz7NOj49If8AXAg1mvk4BVWG7lLMMySkdEREqOkhFxOFd3d1r1voWOA+/luvZtrMvPR0Sy5X/L2PL9cs6dCbdrTG2wPKhvAJYRONlSgbVZyzWHiYhIyVAyImVKrWsacnP/e+jQry/e1apalx/bvZe9a35nz9pgYsLO2DWmVsBALAnI9Vhu5eScz+T2rGX2jUpEpOJQMiJlkoubGy1v7W5pLbmpLc7OztZ1J/cftCYmZ4+dsGtczbF0ev0j670XcDbr6xYsw4h/AkrvEYIiIhWPkhEp83z9atCyZxCtevXgug5trNPPA5wJPcyeNcHsWRNM+KEjdo+tCZb+JTdfsvw4lqTkS2CbvYMSESlnlIxIueJdrSo39uhGq9630uTm9ri4uVrXRR49bklM1gYTduAfu8blj+UhfncDvbG0lAA8D8zIeu0FeKAH+YmIXKpUk5GxY8fy4osvEhAQwO7du3n66afZunVrvvXHjRvHmDFjaNCgAVFRUXz33XdMmDCBlJSUEj0ZqRgqVfbl+qCuBPbuQdPON+Hm4WFdF30qjD1Zt3JO7t1f6jO+2sQF9MSSmEzDMv08WIYKfw78ycXbOYfsFpWISNlVnM9vU5wyaNAgk5ycbB5++GHTokUL88knn5iYmBhTs2bNPOsPGTLEJCUlmSFDhpiGDRua3r17m7CwMPP+++8X+Zi+vr7GGGN8fX2LFatK+S8eXl6mdZ9eZvj7b5upW4LN+3s3WcukNT+Yfi8/a65t19o4OTs7LMYZYMwl5QCYaWC6gHEuA9dRRUVFxRGlqJ/fxW4ZCQkJYevWrTz99NMAODk5cfLkSWbOnMm0adNy1Z85cyYtWrSgV69e1mXvvfceN998M926dSvSMdUyIgDulTxp1qUjrXr34PqgLnh6e1vXxUVFs+/XdexZE8zhbTvtNo9JtoZYWkzuAW7BMiMsWB7cF4ClM6yIyNWmqJ/frvmuyYObmxvt2rVj6tSp1mXGGNauXUunTp3y3Gbjxo08+OCDdOjQga1bt3LNNdfQt29fFixYkO9x3N3d8cjRNO/r61ucMKWCSk1KZu/a39m79ndc3d1p2ukmWvW+hRt6dKOyXw06D+5P58H9STh3nn3Bf7D313Uc3rqd1KTSnznkODArq1TGMiz4HqAqtonISizZ/7Ks18dKPTIRkbKvWMmIn58frq6uRERE2CyPiIigefPmeW6zaNEi/Pz82LBhA05OTri5ufHRRx/ZJDSXmjBhAlOmTClOaHKVSU9NZf+6DexftwEXV1ca39SOVr17cOOt3fGpXo2b+9/Nzf3vJj01lcPbdnJwQwgHN2wi8ujxUo8tDvg2q+RUBeiF5ZfujqxlB7AkJSuwDCvWA/1E5GpUrNs0tWvX5vTp03Tq1ImQkBDr8mnTphEUFETHjh1zbRMUFMQ333zDa6+9xubNm2ncuDEffPABn332GW+99Vaex8mrZSQsLEy3aaRQzi4uXNM2kFa9e9CiW2dq1Ktjsz761GkObtjEwQ0hHNqyzS6tJjk1x9Ji0hfogu1/A98B99s1GhGR0lUqo2nc3NxITExk4MCB/Pjjj9bl8+bNo2rVqtx77725tlm/fj0hISG89NJL1mXDhg3j008/xcfHp0ijIdRnRC5XrWsa0rxrJ5p37ch17dvg6u5uXZeemsqR7bs4sGETB/+wT6tJTtktJX2xtJS8AXySte4aLLdyVmBpOdkApNk1OhGRK1cqfUbS0tLYvn07PXv2tCYjTk5O9OzZk1mzZuW5jZeXF5mXPEI+I6tzoZOTk12HZsrVJ/LocSKPHmf9gm9wr+TJdR3a0aKbJTmpUa8uTTvdRNNON9HvxXHEhJ3h4J+W2zmhIdtITUoq1dhisTykb2nWe7cc6+4AbsgqLwLxWJ6dk52chJVqZCIi9lXs0TSDBg1i/vz5PPHEE2zZsoVnn32WQYMG0bx5cyIjI5k/fz5hYWFMnDgRgMmTJ/P888/z+OOPW2/TfPTRR2zfvp0HHnigSMdUy4iUhpqNGtC8aydadO3Ite3b2Mxnkp6WxtHtuzm4YRMHNmwi4vBRu8ZWFbgNS6tJHyyTr+V0O/CLXSMSESm+Up307Mknn7ROerZr1y6eeeYZtmzZAkBwcDDHjh1j5MiRALi4uPDqq6/y0EMPUbduXc6ePcuyZct49dVXiY2NLdGTEblc7pU8ua59W5pntZr41a9nsz7m9Bn+/nOztdUkJTHRbrE5YXnacPbtnLZALSytJQDjgY5YWkxWogf7iUjZoengRa6AX8P6tOjaieZdO3FdhzxaTXbs5u+NmwkN2UrYwVDMJbciS5MPcCHH+83ATTne78bSavILlr4m9u2iKyJykZIRkRLi5unBdR3aWpMTvwa2rSYJ52M5tGU7/4RsJXTTVqJP2bdHR3ssrSZ9gQ6Ac451p4D6do1GROQiJSMipcSvQT2ad+1Ik44daNyhHZ4+3jbro0+dJjRkq6Vs3kbC+aLdjiwJNbCM0LkNS7+SDUDOnlkbgYNYWk3WAlF2i0xErkZKRkTswNnFhfo3tqBJxw407diBhoE34urmZlPn1P6/CQ3Zyj8hWzm6czdpyUV7QGRJyHlLpxmWRCRbJrCDi7d0NqLhwyJSspSMiDiAe6VKXNsu0JKcdLqJOk0b26xPT03l6M49hIZs45+QrZzaf9Bu/U3cgW5cbDUJvGT9dCydYUVESoqSEZEywLdGdRrf3J6mHTvQtFMHqgbYDtJNjIvj0JYdlpaTTVuIOnHKbrEFcPGWzm3ASCyjccDysL+5WFpMVgO/AeftFpmIVBRKRkTKIL+G9WnasQNNOnagyU3tqFTZ9iGQMafPEBqyjdDN2wjdvJUL0efsEpdTVsluo3kHmJBjfQawBUs/k7XAJnRLR0QKp2REpIxzdnGh3vXNrP1NGrVplau/yZnQw5ZROiHbOLJtp93mN/ECumO5nXMbcP0l6wOBPVmvfbH0Synzf0hExO6UjIiUM+6VPLmmTXZ/kw7Ubd7UZn1GWjon9u23jtI5vnsfGenpdomtHpZbOr2AVliSkew/HPOxzBL7KxdbTk7YJSoRKeuUjIiUc97VqtL4pnY06dieJje3zzUrbEpiEkd27OJQVmfYM/8ccsiznv4Gml6yLBRLUrIG+N7uEYlIWaFkRKSCqV63Nk1utiQmjW9uj2+N6jbrL8Sc49CW7YRutiQnMadO2yUuN+BmLrac3MzFJ3DuwjKVfba2wF+A/QY3i4gjKRkRqcCcnJwIaHKtpSPsze25rn0bPLy8bOpYJ1/bvI1DW7ZzIcY+nWF9gSAsiclxYEbW8krAOSydZDdw8ZbOLi52nBWRikXJiMhVxMXVlQYtr7e0nHTsQMNWN+Li5mpT5/TfodZWkyPbdpGalGTXGK/HMlS47iXLo4HfgS+4OLRYRCoGJSMiVzH3SpW4tn1r622dSzvDpqelcWznHv7euJmDG0Ls2t+kORdv6fQAKmctfw74T9ZrfyydYn8DTtolKhEpDUpGRMTKp3o1Gndoa7mt07EDNerVsVkfFxXNPxu3cPDPEP7ZtIWEc+ftEpcLlof73Qp8i6XjK8AIYF7W61AsScmvQDB6no5IeaJkRETyVaO+5WF/zTrfTOOb2tr0N8nMzCTswN8c/DOEv//czPE9+8hMz7BrfAOAF7AkKi6XrNsNDOfiPCciUnYpGRGRInFxc+OaNq1o1uVmmnW+OdctnaT4C4Ru3sbfGzfz958hnDsdbrfYKmN5nk5PLK0n2c/T8cPS1wQsiUkzLC0nG4Fku0UnIoVRMiIil8XXrwbNOt9sSU463YR3tao26yOPHre0mmzczOGtO+z6FGI/oD2wKsey37D0PQFLIrIRS2LyG7AVy1T2IuIYSkZE5Io5OTtTr0UzmnW5meZdOtKg1Q24uF4cpZOWksLRHbs5uMGSnIQfOmL3GIdi6ezaE6hzybqTQAO7RyQi2ZSMiEiJ8/T1oclN7WiW1d+kep3aNuvPR0Ty95+b2b9uAwf+2ERGmn0fp9cMy+2cnlhaSzYA/XKs3wycwtJq8htwwK7RiVx9lIyISKmrdU1DmnXpSLMuN9O4fVvcPD2s65Li4tmz9nd2rlzDoS3bMZn2ndrMCagGxGS9b4BlEracwrGM0AnGMnX9MXsFJ3KVUDIiInbl6u7Ote0Cad6tM4G33UpV/1rWdXFR0exe/Ss7V67h+O59DonPBWiHpeWkB9AVy9OJs30IPJn12hWojeY4EblSSkZExGGcnJy4pl1r2tzRm8DbbsW7ahXruuhTYexcuZadK9cQHnrYYTG6AzdhSU5uxTJt/Y9Z6zoDfwKHsNzOyW49ibB/mCLlmpIRESkTnF1daNrpJtr2vY0bb+1uM6fJmdDD7Fyxhp2r1tjtwX5F8SjwMRcf+JftLyxJySwsTysWkYIpGRGRMsfN04Prg7rStm9vmnfthKu7u3Xd8d372LHiF3av/pX46JgC9mIfvljmOOmBpeWkNeCcte5mYItjwhIpV5SMiEiZ5unrQ6uet9Cmb28a39QOZxfLXKuZGRkc2rqDnSvWsPfX30mKKxu/89WwPI24O/Aimr9EpCiUjIhIueFbozqBt/ekTd/eNApsaV2enprKwQ2b2LliDX+t22DXCdZE5MopGRGRcql6vTq06dObNn17U7vJddblKYmJ7PttPTtXrOHgnyF2Hyqc0zNAfeBdLk5LLyK5KRkRkXIvoPG1tLmjN2363mbzpOG/N27my/GvknwhwSFxnQTqYZmafrtDIhApH5SMiEiF0qDVDbS5ozc3978bDy8vzoQe5osnX+DcGfs9uC/bFixPFL4bWG73o4uUH0X9/HbOd42ISBlyYs9f/DjtP8weMYbYiLPUbnIdz3z9OfVvaGH3WLLTnwC7H1mkYlIyIiLlStjBf/hg2KOEHfyHyn41GDv3Q268NciuMSgZESlZSkZEpNyJjTjL7BFj2L/+T9wreTJixjsEDR9it+MrGREpWUpGRKRcSklMZO4zL/PnN0txdnbmnhefYcBrL1rnKylNZ7K+1i6wlogUlZIRESm3MjMy+N/b7/HDtP+QmZlJ58H9eWTWv/Hw9ip84yuglhGRkqVkRETKvT++Wsy8Z18hJTGJFl078dSXn9g8Nbik/Q60BfqX2hFEri5KRkSkQvgr+A8+HDmWuLNR1GnamGe+/px61zcrlWOdA3aip/iKlBQlIyJSYZzaf5APho7iTOhhqtSqydi5H3FDj26ODktECqFkREQqlPPhEcx86HH+/jMED69KPPyfd+n24OASP86TwHtAncIqikihlIyISIWTkpDI50+9wMYl3+Ps7My9Lz/LfRPHl+hIm6eA8UCTEtujyNVLyYiIVEiZ6Rks/df/sey9mWRmZtJ1yEBG/ncaHl4lM9JGI2pESo6SERGp0H6f/zVfPj+R1KRkru/ehSfnf0QV/5pXvF8lIyIlR8mIiFR4e39dx4ePPEl8dAx1mzdl3MIvqNu86RXtU8mISMlRMiIiV4WT+/bzwdBHCT90hCr+NXly/ke06N7lsvenZESk5CgZEZGrxrnT4cwc/gT/bNqCh5cXj/x3Gl2HDrysfWlKeJGSo2RERK4qyfEX+Gzs82xe+hPOLi7cN2E8/V5+Fifn4v05VMuISMlRMiIiV53M9AyWTJnK8hmzAej+4GBG/udd3CtVKvI+QrBMCX976YQoclVRMiIiV63gOV8xf/yrpKWkcEOPbjw57yMq1/Qr0rZxaEp4kZKiZERErmp7fvmNjx59igsx56h3fTPGff05PtWrOToskauKkhERueod372PD4aNIvpUGFUD/GnZ85YibfcE8D7QqBRjE7kaKBkREQFiTp3mr+ANANSoX7dI2zwOPA+0KL2wRK4KSkZERLJEnwoDip6MaESNSMlQMiIikiX6ZFYyUq9oz+JVMiJSMpSMiIhkUcuIiGMoGRERyRITdobMzEw8vb2LNKJGs7CKlAwlIyIiWdJTU4mLPAsUrXVELSMiJUPJiIhIDlHF6DeiZESkZFxWMjJ27FiOHj1KUlISISEhdOjQocD6VapUYdasWZw+fZrk5GT+/vtv7rjjjssKWESkNFk7sdavV2jdnUBroGupRiRS8bkWd4NBgwYxffp0Ro8ezebNm3n22WdZvXo1zZo14+zZs7nqu7m5sWbNGiIjIxk4cCBhYWE0bNiQ8+fPl0T8IiIl6uKImsJv0yQAu0s5HpGrhSlOCQkJMTNnzrS+d3JyMqdOnTIvv/xynvWfeOIJc+jQIePq6lqs4+Qsvr6+xhhjfH19L3sfKioqKkUprW/vad7fu8k8Nf9jh8eiolLeS1E/v4t1m8bNzY127dqxdu1a6zJjDGvXrqVTp055bnPPPfewadMmZs+eTXh4OHv37mXChAk4F/C4bnd3d3x9fW2KiIg9RJ86DUD1Is418igwHWheeiGJVHjFSkb8/PxwdXUlIsL2OZUREREEBOTdhevaa69l4MCBuLi40LdvX/71r38xfvx4XnvttXyPM2HCBOLi4qwlLCysOGGKiFy27A6sVWrVxM3To9D6I4DngBtLNyyRCq3UR9M4OzsTGRnJ448/zo4dO1iyZAlvv/02o0ePznebqVOnUrlyZWupW7doExCJiFyppLg4EuPigKL1G9GIGpErV6wOrFFRUaSnp+Pv72+z3N/fn/Dw8Dy3OXPmDGlpaWRmZlqXHThwgNq1a+Pm5kZaWlqubVJTU0lNTS1OaCIiJSb6ZBheN1SmRv26hB86UmBdJSMiV65YLSNpaWls376dnj17Wpc5OTnRs2dPNm3alOc2f/75J40bN8bJycm6rGnTppw+fTrPRERExNGy+40UZeIzzcIqcuWKfZtm+vTpPPbYYwwfPpzmzZvz0Ucf4e3tzdy5cwGYP38+77zzjrX+Rx99RPXq1fnggw9o0qQJffv2ZeLEicyePbvkzkJEpAQVZ3ivWkZErlyx5xlZsmQJNWvW5M033yQgIIBdu3bRp08fIiMjAWjQoIHNLZlTp05x++23M2PGDPbs2UNYWBgffPAB06ZNK7mzEBEpQdEnTwGaEl7EXpywjPEt03x9fYmLi6Ny5crEx8c7OhwRqeCu69CWsXNmc/bYCd69e3CBddsAO4DTgLrai9gq6ud3sVtGREQqupisPiPV6tbGydkZk6O191IHsEwJfybfGiJSGD0oT0TkEucjIklPS8PVzY2q/rUKrJuMZUr4SLtEJlIxKRkREbmEycy0to4Upd+IiFwZJSMiInmIPpX99N7Ck5GHgRlAq1KNSKTiUjIiIpKH7OG9fkVIRh4AnsXSd0REik/JiIhIHi4+ME/De0VKm5IREZE8FGeuEc3CKnJllIyIiOQh++m9fmoZESl1SkZERPIQE2a5TVOpsi9eVSoXWFfJiMiVUTIiIpKHtOQUYiPPAoU/o0bJiMiVUTIiIpIP6wPzCuk3omRE5MooGRERyUdR5xo5AgQCzUo/JJEKSc+mERHJh7UTa/16BdZLA/bYIR6RikotIyIi+YgpxiysInL5lIyIiOQju2WkRr06hdZ9EPgP0KFUIxKpmJSMiIjkI7sDa+VaNXF1dy+w7n3AOKBd6YclUuEoGRERyUfCufMkX0jA2dmZ6nULnl9Vs7CKXD4lIyIiBbg4vLfgTqwa3ity+ZSMiIgUwDq8t5B+I9nJiFpGRIpPyYiISAE08ZlI6VMyIiJSgKhTRZtrRMmIyOVTMiIiUoCitoxkd2ANAJxKNySRCkfJiIhIAbL7jFSvWxsnp/zTjDNAK6AOYOwSmUjFoWRERKQA589EkJGWjpuHB5Vr+eVbLxPYC0TZLTKRikPJiIhIATIzMjh3xtIjpLDhvSJyeZSMiIgUIvrkKQD86hXcb2Qw8AHQrfRDEqlQlIyIiBQi+tRpoPBOrHcBzwA3lX5IIhWKkhERkUJEF/GBeZoSXuTyKBkRESlElKaEFylVSkZERAoRfcrSZ0SzsIqUDiUjIiKFiD5p6TPiXbUKnr4++dZTMiJyeZSMiIgUIjUpifjoGKDgfiPqMyJyeZSMiIgUQXQR+o1kt4xUB9xLPySRCkPJiIhIEURlzzVSQL+Rc0BLwA9ItUtUIhWDq6MDEBEpDy4O7y24E+s+ewQjUsGoZUREpAisE58VkoyISPEpGRERKYKLfUYKTkYGAP8FepV+SCIVhpIREZEiyH4+TdWAWri45n+HuzfwNNDZPmGJVAhKRkREiiA+OoaUxCScXVyoVjf/wbuaa0Sk+JSMiIgUUUyYpd9IQSNqlIyIFJ+SERGRIsq+VVNQJ9bsic+UjIgUnZIREZEiiipCJ9bslhHNwipSdEpGRESKqCgjatQyIlJ8SkZERIqoKHONRGR99QSqlH5IIhWCkhERkSIqSp+RFOB6oAYQa5eoRMo/JSMiIkV07nQ4mRkZuFfyxNevRr71DgAx9gtLpNxTMiIiUkQZ6emcO2O5EVPQ8F4RKR4lIyIixRB9KrsTa7186/QDZgJ32SckkXJPyYiISDFYk5F6dfKt0x14Cuhmn5BEyj0lIyIixVCU4b2ahVWkeJSMiIgUg5IRkZKnZEREpBisyUgRpoTXLKwiRaNkRESkGLL7jPjWqI6Hl1eeddQyIlI8SkZERIoh+UICCefOA1A9n06s2clITcDVLlGJlG9KRkREiin7gXn5zTUSDaRnva5ln5BEyjUlIyIixVTYXCMGuAGoDpy2W1Qi5ddlJSNjx47l6NGjJCUlERISQocOHYq03eDBgzHG8P3331/OYUVEyoSLyUj+nVj/Ac7ZKR6R8q7YycigQYOYPn06b7zxBm3btmX37t2sXr2amjVrFrhdw4YNee+991i/fv1lBysiUhZcHFGT/8RnIlJ0xU5Gnn/+eT777DPmzZvHgQMHGD16NImJiTzyyCP5H8TZmYULFzJ58mSOHDlyRQGLiDhaUeYauROYBQywT0gi5VqxkhE3NzfatWvH2rVrrcuMMaxdu5ZOnTrlu93rr79OZGQkc+bMKdJx3N3d8fX1tSkiImVFdgfWarUDcHZ1ybNOR+BJ4Ba7RSVSfhUrGfHz88PV1ZWIiAib5REREQQE5D2ivkuXLjz66KM89thjRT7OhAkTiIuLs5awsLDihCkiUqriz0aRlpyCi6sr1fL526e5RkSKrlRH0/j4+LBgwQIee+wxoqOji7zd1KlTqVy5srXUratHdYtI2WGMITrMMk6mRv2C5xpRMiJSuGLNxxMVFUV6ejr+/v42y/39/QkPD89V/7rrruOaa65h2bJl1mXOzpb8Jy0tjWbNmuXZhyQ1NZXU1NTihCYiYlfRJ8MIuO4aatSrB2zNtV5TwosUXbFaRtLS0ti+fTs9e/a0LnNycqJnz55s2rQpV/2DBw9y44030rp1a2v56aefCA4OpnXr1pw8efLKz0BExAEK68SqlhGRoiv2TMXTp09n/vz5bNu2jS1btvDss8/i7e3N3LlzAZg/fz5hYWFMnDiRlJQU/vrrL5vtz58/D5BruYhIeRJ96hSQfzKS3bPOG/ABLtglKpHyqdjJyJIlS6hZsyZvvvkmAQEB7Nq1iz59+hAZGQlAgwYNyMzMLPFARUTKkuiTWX1G8plrJAGIB3yxtI4csldgIuWQE5aZi8s0X19f4uLiqFy5MvHx8Y4OR0SEWtc05OWfviE5IYFXO/bKs851WJ5Tc96egYmUIUX9/NazaURELkP0qdNkZmbi6e2NT/VqedY5jBIRkaJQMiIichky0tKIjbDcni5oJlYRKZySERGRyxR9KnuukbyTkduwTAk/1H4hiZRLSkZERC7TxQfm5Z2MtMUyJXzePUpEJJuSERGRy1RYMqK5RkSKRsmIiMhlij5pmWvEL5/bNJqFVaRolIyIiFymKM3CKlIilIyIiFym7A6slWv64ebpkWt9djJSE/2xFSmIfj9ERC5TUlwciXFxQN79Rs4CGYALloRERPKmZERE5AoU9MC8TCAy67X6jYjkT8mIiMgVKOzpvZ2BqsAuewUkUg4V+0F5IiJykXXis3yG9x6zYywi5ZVaRkRErkD28F5NCS9y+ZSMiIhcgezhvX75tIzcCswGHrFfSCLljpIREZErkN1npFrd2jg55/6TeiMwFstzakQkb0pGRESuQGzkWdLT0nB1c6Oqf61c6zULq0jhlIyIiFwBk5lJTAFP79UsrCKFUzIiInKFok/lP7xXyYhI4ZSMiIhcoex+I3k9MC87GakMeNkvJJFyRcmIiMgVuvjAvHq51sUDCVmv1ToikjclIyIiVygm6zZN9Xp18lyvWzUiBdMMrCIiV6iwuUZ6ALFAnP1CEilX1DIiInKFsqeEr1TZF68qlXOtP4kSEZGCKBkREblC6SkpxEacBfLuNyIiBVMyIiJSAqzDe/PoN9IV+BDLTKwikpuSERGRElDQXCNNgTFAX/uGJFJuKBkRESkB1k6sedym0WgakYIpGRERKQHRJzULq8jlUjIiIlICCuozkp2M+ANO9gtJpNxQMiIiUgKyW0Yq16qJq7u7zbpIIBPLxE417B6ZSNmnZEREpAQknDtP8oUEnJ2dqV63ts26dCAq63XtXFuKiJIREZESEl3AM2rUb0Qkf0pGRERKSNTJU0DeT+/tC1QB1tg3JJFyQc+mEREpITFZ08Ln9cC8MHsHI1KOqGVERKSERJ3Kf64REcmfkhERkRJS0FwjHYGPgOftG5JIuaBkRESkhERn9RmpXrc2Tk62M4o0AkYDd9k9KpGyT8mIiEgJOR8eSUZaOm4eHlSu5WezTqNpRPKnZEREpIRkZmRw7owl7bh0eK+SEZH8KRkRESlB2bdq/OrZ9hvJTkaqAR72DUmkzFMyIiJSgqLy6cR6HkjOeq3WERFbSkZEREpQ9lwjBT0wT8mIiC0lIyIiJShKU8KLFJtmYBURKUHRpyx9RvKaa6Q/cAGIt29IImWeWkZEREpQ9EnLbRrvqlXw9PWxWXcGJSIieVEyIiJSglKTkoiPjgHyfmCeiOSmZEREpIRlTwtf/ZLhve2Aj4GJ9g9JpExTMiIiUsKisucauaRlpA7wBNDP/iGJlGlKRkRESpj1gXn5THym0TQitpSMiIiUsPye3qtkRCRvSkZEREpYtHXiM9tkJCLrqztQ3b4hiZRpSkZEREpY9vNpqgbUwsX14nROqUB01mu1johcpGRERKSExUfHkJKYiLOLC9Xq1rZZp1s1IrkpGRERKQXZt2ouHVGTnYz42zkekbJMyYiISCmIOZX3iJqhgC+wyP4hiZRZejaNiEgpiMpnRE2kI4IRKeMuq2Vk7NixHD16lKSkJEJCQujQoUO+dUeNGsX69euJiYkhJiaGNWvWFFhfRKQiyG94r4jkVuxkZNCgQUyfPp033niDtm3bsnv3blavXk3NmjXzrH/LLbewaNEievToQadOnTh58iS//PILderUueLgRUTKqvwmPmsFfAK8af+QRMo0U5wSEhJiZs6caX3v5ORkTp06ZV5++eUibe/s7GxiY2PNQw89VORj+vr6GmOM8fX1LVasKioqKo4qfg3qmff3bjJTtwTbLO8JxoDZWwZiVFEp7VLUz+9itYy4ubnRrl071q5da11mjGHt2rV06tSpSPvw8vLCzc2NmJiY4hxaRKRcOXc6nMyMDNwreeLrV8O6XEN7RXIrVjLi5+eHq6srERERNssjIiIICCjar9a0adM4ffq0TUJzKXd3d3x9fW2KiEh5kpGezrkzlr+VOYf3nsn66ge42T8skTLJrkN7X375ZR544AHuu+8+UlJS8q03YcIE4uLirCUsLMyOUYqIlIzo7OG99etZl53DMhMraK4RkWzFSkaioqJIT0/H39/2V8jf35/w8PB8trIYP348r7zyCrfddht79+4tsO7UqVOpXLmytdStq97oIlL+5DWixnDxGTW6VSNiUaxkJC0tje3bt9OzZ0/rMicnJ3r27MmmTZvy3e7FF19k0qRJ9OnTh+3btxd6nNTUVOLj422KiEh5Y20ZqWc7elD9RkRsFXvSs+nTpzN//ny2bdvGli1bePbZZ/H29mbu3LkAzJ8/n7CwMCZOnAjASy+9xJtvvsnQoUM5duyYtVXlwoULJCQklOCpiIiULfnNNZKdjNSyczwiZVWxk5ElS5ZQs2ZN3nzzTQICAti1axd9+vQhMtIyr2CDBg3IzMy01h8zZgweHh4sXbrUZj9TpkzhjTfeuMLwRUTKrvzmGnkESAL075iIhROWW5hlmq+vL3FxcVSuXFm3bESk3PD08ebtTZaRgxNv7klKYqKDIxKxr6J+futBeSIipST5QgIJ584DUL2eZp0WyY+SERGRUpT9wLycc400Bz4F/u2YkETKHCUjIiKlKK+5RqoCjwEDHBKRSNmjZEREpBTlNaImexZWDe0VsVAyIiJSivKaayR70rNKQBX7hyRS5igZEREpRXm1jCQD57Neq3VERMmIiEipyu7AWq12AM6uLtblmoVV5CIlIyIipSj+bBRpySm4uLpSLcfTzZWMiFykZEREpBQZY3KMqMndiVVTwosoGRERKXXRp04DttPCPwX4ADMdE5JImVLsZ9OIiEjx5NWJNcZRwYiUQWoZEREpZdGnTgG5n94rIhZKRkRESlleU8JfB3yGbtOIgJIREZFSF5PVZyTnw/K8gVHA/Y4JSaRMUTIiIlLKok+dJjMzE09vb3yqVwMujqapCbjku6XI1UHJiIhIKctISyM2IhK42G8kGkjH8kdYw3vlaqdkRETEDi4dUZMJRGat08RncrVTMiIiYgd5zTWiWVhFLJSMiIjYgbVlpF7uWVhrOyAekbJEyYiIiB1En7TMNZJzeG92y4ifA+IRKUuUjIiI2EFUjj4jLq6Wya9fwDLE9/8cF5ZImaDp4EVE7CD7YXmVa/rxfzv/IDMzk4zUNNJSU0hPTSM9JZX01OySZvM6LSWFjLQ00i6tk5JC+iXLL8ScJzYikvPhESTGxjn4rEWKRsmIiIgdJMXFc3BDCM27dgTA2dkZZ08P3Dw9Su2YqUnJlsQkIpLz4ZGcj4ggNvws58MjrMuS4pSwiOM5AcbRQRTG19eXuLg4KleuTHx8vKPDERG5bG6eHri6u+Pq5kZDFxdeSUzE2dmZlxvUx83DHVd3N1zdPSxfPdxxdXO3eZ1nHXdLcfP0wKd6Nar618K3RvUixZOSmGRNWGKtSYulZSXWmrDo765cnqJ+fisZERFxkGuBw0AC4FPC+3Z1d6dKrZpUDahFlYBaVPX3p2pALar616KKfy2qBtSyzgZbmJTERGIjLC0qcWejiY+KJi4q6+vZKOKjY4g7G0XyhYQSPgsp75SMiIiUcd7AhazXvjle24urh4c1YanqX4uqAf5U8a9J1YCLiYt3tapF3l9qUjLx0dHER8XYJCmWpCWa+GjL1wsx58jMyCi9E5MyQ8mIiEg5EIclEWkCHHJwLHlx88xOWPyp4l+Lyn7V8a3pR+UaWV/9auDrV4NKvkVv28nMzCTh3PlcSUp8dAyJsXEkxsaRFBtHYpylJMXGk5GeXopnKaWlqJ/f6sAqIuJA4ViSkQDKZjKSlpxC1IlTRJ04VWA9N08PfP1qULlGDXxr1rAkKTWz3ud47VOjGi6urvjWqI5vjerUadakSHEkJySQFBdvTVYSY+Ms7+MueZ9jfWJsHKlJSSVxGaSUKRkREXGgM1haRcr7LKxpySnEnDpNTNa09/lxcnbGu2oVS+LiV4PKNbOSlRo18K1RjUqVK+NV5WLx9PXB2dkZT29vPL29qVa7eJPnZ6SlWxOW5PgLpCQlkZqYSHJCIqmJSaQkWt6nJCaRkvX14vus1wmJpCRZ1mem6/ZSaVAyIiLiQFfb82lMZiYXYs5xIeYcZ/4pvC3IyckJT18fvHIkKZUq+9okLNb3lS++965aBVd3d1zcLrbClIT01FRLopKQSEpiVkKTleCkJqeQnpJKWkoK6amppCWnkJaaenFZiuV9Wla9i3Wytstel5pqmTsmJaVEYi4PlIyIiDhQdjJSw6FRlF3GGJLi4kmKi7dOHFdUbp4eWclJZbyrVMbTxxt3Ly88vCrh7lUJTy8vm/ceXl54eHvhUSnHe69KeHh74eruDmAdRu1dtUppnG4uliTGkqhkpKWRkZZORno6GWlppKelkZmeQXpammVderplfY7XljrpWXUubmupk5GjbhoH/tjEhZhzdjmvSykZERFxoEnAK4B6NpS8tOQUYpPPEhtx9or35eLqaklQshMVb29LouJVyZLQeHvh5uGRNQ9M1nwwHh64eXhY54Bxc3e3zAvj4Z5VN/c6Nw8PnF1crMfNrlfpis+gcP998DElIyIiVyPNf1o+ZKSnW1toSpuzqwtu7h7W5CT7q4urKy5urri4ueHq5oqzqyuubm64uLnh4upi+ermZq3n6uaWo45r1vK81luWJ5yPLfVzy4+SERERkTIkMz2DlHRLn5SrhZ7aKyLiQAHAF8BCRwci4kBKRkREHOwRYDD6gyxXL/3si4g40FkgE3AB/Bwci4ijKBkREXGgDCwJCVw9c42IXErJiIiIg2XPNVLeZ2EVuVxKRkREHOxM1le1jMjVSsmIiIiDXW1TwotcSsmIiIiDZScjJfP0FJHyR8mIiIiDvQ1UAl52dCAiDqIZWEVEHOyCowMQcTC1jIiIiIhDKRkREXGw6sAc4H+ODkTEQXSbRkTEwdKAkVmvvYCr5/FoIhZqGRERcbB4LiYg/o4MRMRBlIyIiJQBmmtErmZKRkREyoDsWVg1JbxcjZSMiIiUAWoZkauZkhERkTJAyYhczZSMiIiUAdnJSDWHRiHiGEpGRETKgOmAJ/C0owMRcQDNMyIiUgZobhG5mqllRERERBxKyYiISBngA8wFfgacHByLiL1dVjIyduxYjh49SlJSEiEhIXTo0KHA+gMHDuTAgQMkJSWxZ88e7rjjjssKVkSkokoBHgb6YnlWjcjVxhSnDBo0yCQnJ5uHH37YtGjRwnzyyScmJibG1KxZM8/6nTp1MmlpaeaFF14wzZs3N2+++aZJSUkxN9xwQ5GP6evra4wxxtfXt1ixqqioqJSnchaMAXNDGYhFRaUkSlE/v52yXhRZSEgIW7du5emnLX2+nZycOHnyJDNnzmTatGm56n/zzTd4e3tz9913W5dt2rSJXbt2MWbMmCId09fXl7i4OCpXrkx8fHxxwhURKTf2AC2BocCfwHkgLmudOwXPQRKbVQDcKHgm17isfQO4AHULqHsBiMl67QzUK6BuAhCd9doJqF9A3UQgKsf7BgXUTQYic7yvT/63slKAiBzv65H/LYBULg6pBst1cMmnbhoXZ8kFy/V1y6duBhCW430Alu9fXjKBUzne+wMe+dQ1wMkc72sClfKpC3Aix2s/LA9hzM9JipkMFFFxPr+LnOG4ubmZtLQ0069fP5vl8+bNMz/88EOe2xw/ftyMGzfOZtmUKVPMrl278j2Ou7u78fX1tZY6deqoZURFRaXCl1+wtIxklxdzrGt3ybpLy5QcdVsUUvffOeo2KKTu7Bx1axRSd16OupUKqfvtJedeUN2fL6kbX0Dd3y+pG1FA3a2X1D1SQN2/Lqm7t4C6xy6pu7mAumcvqftbAXUTLqm7rJDrlrPu4kLqel9Sv6RKUVtGijW018/PD1dXVyIiImyWR0RE0Lx58zy3CQgIyLN+QED+Of6ECROYMmVKcUITESn3FgE3cfG/6PQc6wyQVMC2pVU37ZL3JVU39QrqJpN/C0ZedfPbd0oe7+1dN/mS96klVPdSacWo6whlcp6RqVOnMn36dOt7X19fwsLCCthCRKT8m5tV8rKDgpvZczpYjLoni1E3uhh1k4pRl2LWrVmMug2LUbdFMeq2L0bd7sWo26cYdQcUo+6DxajrCMVKRqKiokhPT8ff399mub+/P+Hh4XluEx4eXqz6AKmpqaSmXprfioiISEVUrKG9aWlpbN++nZ49e1qXOTk50bNnTzZt2pTnNps2bbKpD9C7d+9864uIiMjVp1idUQYNGmSSkpLM8OHDTfPmzc3HH39sYmJiTK1atQxg5s+fb9555x1r/U6dOpnU1FTz/PPPm2bNmpnJkydraK+KioqKispVUIrx+V38nT/55JPm2LFjJjk52YSEhJibbrrJui44ONjMnTvXpv7AgQPNwYMHTXJystm7d6+54447SutkVFRUVFRUVMpIKbV5RhxB84yIiIiUP0X9/NazaURERMShlIyIiIiIQykZEREREYdSMiIiIiIOpWREREREHErJiIiIiDiUkhERERFxKCUjIiIi4lBKRkRERMShivXUXkfz9fV1dAgiIiJSREX93C4XyUj2yYSFhTk4EhERESkuX1/fAqeDLxfPpgGoU6dOiT+XxtfXl7CwMOrWratn3pQiXWf70bW2D11n+9B1to/Svs6+vr6cPn26wDrlomUEKPRErkR8fLx+0O1A19l+dK3tQ9fZPnSd7aO0rnNR9qkOrCIiIuJQSkZERETEoa7qZCQlJYUpU6aQkpLi6FAqNF1n+9G1tg9dZ/vQdbaPsnCdy00HVhEREamYruqWEREREXE8JSMiIiLiUEpGRERExKGUjIiIiIhDVfhkZOzYsRw9epSkpCRCQkLo0KFDgfUHDhzIgQMHSEpKYs+ePdxxxx12irR8K851HjVqFOvXrycmJoaYmBjWrFlT6PdFLiruz3S2wYMHY4zh+++/L+UIK4biXucqVaowa9YsTp8+TXJyMn///bf+fhRBca/zuHHjOHjwIImJiZw4cYLp06fj4eFhp2jLp27duvHTTz8RFhaGMYZ+/foVuk1QUBDbt28nOTmZ0NBQRowYUepxmopaBg0aZJKTk83DDz9sWrRoYT755BMTExNjatasmWf9Tp06mbS0NPPCCy+Y5s2bmzfffNOkpKSYG264weHnUpZLca/zV199ZcaMGWMCAwNNs2bNzJw5c8y5c+dMnTp1HH4uZb0U91pnl4YNG5qTJ0+adevWme+//97h51HWS3Gvs5ubm9myZYtZvny56dy5s2nYsKHp3r27adWqlcPPpSyX4l7nIUOGmKSkJDNkyBDTsGFD07t3bxMWFmbef/99h59LWS59+vQx//rXv8y9995rjDGmX79+BdZv1KiRuXDhgnnvvfdM8+bNzZNPPmnS0tLMbbfdVppxOv5ClVYJCQkxM2fOtL53cnIyp06dMi+//HKe9b/55huzbNkym2WbNm0yH330kcPPpSyX4l7nS4uzs7OJjY01Dz30kMPPpayXy7nWzs7OZsOGDeaRRx4xc+fOVTJSCtf5iSeeMIcOHTKurq4Oj708leJe55kzZ5q1a9faLHvvvffMH3/84fBzKS+lKMnIu+++a/bu3WuzbNGiRWblypWlFleFvU3j5uZGu3btWLt2rXWZMYa1a9fSqVOnPLfp1KmTTX2A1atX51tfLu86X8rLyws3NzdiYmJKK8wK4XKv9euvv05kZCRz5syxR5jl3uVc53vuuYdNmzYxe/ZswsPD2bt3LxMmTMDZucL+ib1il3OdN27cSLt27ay3cq655hr69u3LihUr7BLz1cIRn4Xl5kF5xeXn54erqysRERE2yyMiImjevHme2wQEBORZPyAgoNTiLO8u5zpfatq0aZw+fTrXD7/Yupxr3aVLFx599FFat25thwgrhsu5ztdeey233norCxcupG/fvjRu3JgPP/wQNzc33nzzTXuEXe5cznVetGgRfn5+bNiwAScnJ9zc3Pjoo4+YOnWqPUK+auT3WVilShU8PT1JTk4u8WMqbReHevnll3nggQe47777NOVzCfPx8WHBggU89thjREdHOzqcCs3Z2ZnIyEgef/xxduzYwZIlS3j77bcZPXq0o0OrUIKCgpg4cSJjx46lbdu23Hfffdx555289tprjg5NrlCFbRmJiooiPT0df39/m+X+/v6Eh4fnuU14eHix6svlXeds48eP55VXXqFXr17s3bu3NMOsEIp7ra+77jquueYali1bZl2WfdsgLS2NZs2aceTIkdINuhy6nJ/pM2fOkJaWRmZmpnXZgQMHqF27Nm5ubqSlpZVqzOXR5Vznf/3rXyxYsIAvvvgCgH379uHt7c2nn37K22+/jTGm1OO+GuT3WRgbG1sqrSJQgVtG0tLS2L59Oz179rQuc3JyomfPnmzatCnPbTZt2mRTH6B379751pfLu84AL774IpMmTaJPnz5s377dHqGWe8W91gcPHuTGG2+kdevW1vLTTz8RHBxM69atOXnypD3DLzcu52f6zz//pHHjxjg5OVmXNW3alNOnTysRycflXGcvLy+bhA8gIyPDuq2UDEd9Fjq8d29plUGDBpmkpCQzfPhw07x5c/Pxxx+bmJgYU6tWLQOY+fPnm3feecdav1OnTiY1NdU8//zzplmzZmby5Mka2lsK1/mll14yycnJpn///sbf399avL29HX4uZb0U91pfWjSapnSuc7169UxsbKz573//a5o0aWL69u1rwsPDzcSJEx1+LmW5FPc6T5482cTGxprBgwebRo0amV69epnQ0FDzzTffOPxcynLx9vY2gYGBJjAw0BhjzLPPPmsCAwNN/fr1DWDeeecdM3/+fGv97KG906ZNM82aNTNjxozR0N4rLU8++aQ5duyYSU5ONiEhIeamm26yrgsODjZz5861qT9w4EBz8OBBk5ycbPbu3WvuuOMOh59DeSjFuc5Hjx41eZk8ebLDz6M8lOL+TOcsSkZK7zp37NjRbNq0ySQlJZlDhw6ZCRMmGGdnZ4efR1kvxbnOLi4u5vXXXzehoaEmMTHRHD9+3MyaNctUqVLF4edRlktQUFCef3Ozr+3cuXNNcHBwrm127NhhkpOTzaFDh8yIESNKNUanrBciIiIiDlFh+4yIiIhI+aBkRERERBxKyYiIiIg4lJIRERERcSglIyIiIuJQSkZERETEoZSMiIiIiEMpGRERERGHUjIiIiIiDqVkRERERBxKyYiI2J2fnx9nzpxhwoQJ1mWdOnUiJSWFW2+91YGRiYijOPwhPioqKldfueOOO0xKSopp166d8fHxMYcOHTLvv/++w+NSUVGxf9GD8kTEYWbNmkWvXr3Ytm0bLVu2pEOHDqSmpjo6LBGxMyUjIuIwnp6e7Nu3j/r169OuXTv27dvn6JBExAHUZ0REHOa6666jTp06ODs706hRI0eHIyIOopYREXEINzc3tmzZwq5du/j777959tlnadmyJWfPnnV0aCJiZ0pGRMQh/u///o+BAwcSGBjIhQsXWLduHbGxsdx9992ODk1EHMDhvWhVVFSurhIUFGRSU1NNly5drMsaNmxozp8/b0aPHu3w+FRUVOxb1DIiIiIiDqUOrCIiIuJQSkZERETEoZSMiIiIiEMpGRERERGHUjIiIiIiDqVkRERERBxKyYiIiIg4lJIRERERcSglIyIiIuJQSkZERETEoZSMiIiIiEMpGRERERGH+n/QyEP/8gurLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('manim_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3d73496ad864bb9618f6b05683fbac58433339514b241b9a186c4833acb2a7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
